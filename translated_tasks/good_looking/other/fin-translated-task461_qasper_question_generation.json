{
  "Definition": [
    "Tässä tehtävässä sinulle esitetään konteksti akateemisesta artikkelista, ja sinun on kirjoitettava siihen perustuva kysymys, johon voi vastata. Kysymyksesi voivat olla poimintakysymyksiä, abstrakteja kysymyksiä tai kyllä-ei-kysymyksiä."
  ],
  "Instances": [
    {
      "input": "Kuten kuvasta käy ilmi, arvioitu testitarkkuus korreloi suuresti todellisen testitarkkuuden kanssa eri tietokokonaisuuksissa, ja pahimmillaan arvot $\\mu <1\\%$ ja $\\sigma <5\\%$ . Huomaa, että vapaiden parametrien määrä on pieni ($||\\\\le 6$) verrattuna pisteiden määrään (42-49 malli-datakokoonpanoa), mikä osoittaa ehdotetun funktion soveltuvuuden monimutkaisen virhemaiseman mallintamiseen.",
      "id": "task461-2a5a69f945574cf18484b20483df13a4",
      "output": [
        "Mikä on todiste siitä, että ehdotettu funktionaalinen muoto approksimoi hyvin yleistysvirhettä käytännössä?"
      ]
    },
    {
      "input": "Ohjattu käyttöliittymä: Ohjattu-roolissa oleville osallistujille näytettävä käyttöliittymä tarjoaa selainikkunan oikeassa reunassa mahdollisia toimintoja. Toiminnot voivat olla sanallisia, kuten viestin lähettäminen, tai sanattomia, kuten robotin aktivoiminen painikkeella.  Vuoropuhelun rakenne: Otimme käyttöön strukturoidut vuoropuhelut käyttäen rajallista tilakonetta (FSM), joka valvoo vuoropuhelun nykyistä tilaa ja tarjoaa useita sopivia ja asiaankuuluvia tilasiirtymiä (toimintoja) ohjatulle henkilölle vuorovaikutuksen kulloisenkin vaiheen, maailman tilan ja historian mukaan. Dialogitilojen, siirtymien ja lausumien graafi ladataan, kun järjestelmä käynnistetään, ja jokaisella keskusteluhuoneella on oma dialogitilansa, joka muuttuu toimintojen kautta. Järjestelmää muuttavat toiminnot: toiminnot aiheuttavat siirtymiä FSM:n tilojen välillä. Erotamme kahdenlaisia toimia: Sanalliset toimet, kuten sillä hetkellä käytettävissä olevat dialogivaihtoehdot. Ohjattu voi valita jonkin useista valmiiksi määritellyistä viesteistä lähetettäväksi tai tarvittaessa kirjoittaa oman viestinsä. Vapaat tekstiviestit eivät muuta FSM:n dialogitilaa, joten on tärkeää minimoida niiden käyttö tarjoamalla ohjatulle riittävästi dialogivaihtoehtoja. Ennalta määritellyt viestit voivat myös laukaista muita niihin liittyviä tapahtumia, kuten ponnahdusikkunoita tai ei-verbaalisia seurantatoimia. ei-verbaaliset toimet, kuten tapahtumia laukaisevat komennot. Nämä voivat olla minkä tahansa muotoisia, mutta käytimme tiedonkeruussa painikkeita robottien ohjaamiseen.Toiminnon lähettäminen muuttaisi dialogin tilaa FSM:ssä, mikä muuttaisi niiden toimintojen joukkoa, jotka ovat käytettävissä seuraavalla Wizardille näkyvällä vuorolla. Jotkin dialogivaihtoehdot ovat mahdollisia vain tietyissä tiloissa, samalla tavalla kuin ei-verbaaliset toiminnot otetaan käyttöön tai poistetaan käytöstä tilasta riippuen. ",
      "id": "task461-f7d758ea790c49f981ed406142fb6a44",
      "output": [
        "Miten varmistetaan, että vuoropuhelu ei riko menettelyjä?"
      ]
    },
    {
      "input": "Menetelmässämme otamme kuvan syötteenä ja luomme luonnollisen kysymyksen tulosteena. Mallimme arkkitehtuuri on esitetty kuvassa KUVA4 . Mallimme sisältää kolme päämoduulia: a) esitysmoduuli, joka poimii multimodaaliset piirteet, b) sekoitusmoduuli, joka sulauttaa multimodaalisen esityksen ja c) dekooderi, joka tuottaa kysymyksen LSTM-pohjaisen kielimallin avulla.",
      "id": "task461-bc47a293ce0040d98fc436388de6e9c8",
      "output": [
        "Miten/missä luonnollinen kysymys syntyy?"
      ]
    },
    {
      "input": "Havaitsemme $R^2$-korrelaatiokertoimia, jotka ovat välillä 0,11-0,22 syötteen ja tuotoksen pituussuhteille ja välillä 0,81-0,88 yhdistelmädiversiolle. ",
      "id": "task461-4033dbcc85414942885f1110c25bec70",
      "output": [
        "Kuinka vahva on negatiivinen korrelaatio yhdisteiden eroavuuden ja tarkkuuden välillä suoritetussa kokeessa?"
      ]
    },
    {
      "input": "Kokeilimme neljää erilaista luokittelijaa, nimittäin tukivektorikonetta BIBREF18 , satunnaismetsää, ylimääräistä puuta ja naiivia Bayes-luokittelijaa BIBREF19 . Piirrevalinta-algoritmia käytetään ominaisuuksien koon pienentämiseksi. Järjestelmäluokittimen kouluttamiseen käytettiin Scikit-learn BIBREF19 .",
      "id": "task461-d59a802f6eef40808ccd3c9b6de2c8a1",
      "output": [
        "Minkä tyyppistä järjestelmää käytetään perusluokituksessa?"
      ]
    },
    {
      "input": "Paikkojen nimiä edustavien opittujen foneemisekvenssien tarkkuus Arvioimme, opittiinko paikkojen nimet oikein opittujen opetuspaikkojen osalta. Tässä kokeessa oletetaan, että pyydetään parasta foneemisekvenssiä INLINEFORM0, joka edustaa robotin omaa paikkaa INLINEFORM1. Robotti liikkuu jokaisen opetuspaikan lähellä. Sanan INLINEFORM2 todennäköisyys, kun robotin itseasento INLINEFORM3 on annettu, INLINEFORM4 , saadaan yhtälön ( EQREF37 ) avulla. Valittiin sana, jolla oli paras todennäköisyys. Vertailimme PAR:ää oikeaan foneemisekvenssiin ja valittuun paikan nimeen. Koska \"kiqchiN\" ja \"daidokoro\" opetettiin samalle paikalle, valittiin sana, jonka PAR oli korkeampi. kuvassa FIGREF63 esitetään PAR:n tulokset sanalle, jota pidettiin paikan nimenä. SpCoA (latticelm), ehdotettu menetelmä, jossa käytetään sanojen segmentoinnin tuloksia ilman valvontaa puheentunnistustulosten perusteella ristikkomuodossa, osoitti parhaan PAR-tuloksen. 1-best- ja BoS-menetelmissä paikan nimen osasäkeistösekvenssi segmentoitiin tarkemmin, kuten taulukossa TABREF55 esitetään. Siksi robotti ei pystynyt oppimaan opetuspaikan nimeä yhtenäisenä foneemisekvenssinä. Sitä vastoin robotti pystyi oppimaan opetuspaikkojen nimet tarkemmin käyttämällä ehdotettua menetelmää.",
      "id": "task461-2c7147d405d04fc484d473457ffee262",
      "output": [
        "Miten he arvioivat, miten heidän mallinsa on hankkinut sanoja?"
      ]
    },
    {
      "input": "Laajennamme Amazon Conversational Bot Toolkit (CoBot) BIBREF6 -ohjelmistoa, joka on joustava tapahtumapohjainen kehys. CoBot tarjoaa ASR-tuloksia ja luonnollisen kielen käsittelyputkia Alexa Skills Kit (ASK) BIBREF7 -paketin kautta. Gunrock korjaa ASR:n kontekstin mukaan (asr) ja luo luonnollisen kielen ymmärtämisen (NLU) (nlu) moduulin, jossa useat komponentit analysoivat käyttäjän lausumia. Dialoginhallinta (DM) (dm) käyttää NLU:n piirteitä aihekohtaisten dialogimoduulien valitsemiseen ja määrittelee yksilöllisen dialogivirran. Kukin dialogimoduuli hyödyntää useita tietopankkeja (knowledge). Tämän jälkeen luonnollisen kielen generointimoduuli (NLG) (nlg) tuottaa vastaavan vastauksen. Lopuksi syntetisoidut vastaukset merkitään ja palautetaan käyttäjille tekstistä puheeksi (TTS) (tts).",
      "id": "task461-a87630839f57469789949450776503ab",
      "output": [
        "Mitä järjestelmämallit esittivät?"
      ]
    },
    {
      "input": "Valvomaton arviointi Valvomattomat tehtävät sisältävät viisi SemEval Semantic Textual Similarity (STS) -tehtävää vuosilta 2012-2016 BIBREF30 , BIBREF31 , BIBREF32 , BIBREF33 , BIBREF34 ja SemEval2014 Semantic Relatedness -tehtävä (SICK-R) BIBREF35 .Kahden lauseen vektoriedustusten välinen kosinin samankaltaisuus määrittää kahden lauseen tekstuaalisen samankaltaisuuden, ja suorituskyky ilmoitetaan Pearsonin korrelaatiopistemääränä ihmisen antamien merkintöjen ja mallin ennusteiden välillä kussakin tietokokonaisuudessa.Valvottu arviointiSe sisältää semanttisen sukulaisuuden (SICK) BIBREF35 , SemEval (STS-B) BIBREF36 , parafraasien havaitsemisen (MRPC) BIBREF37 , kysymystyyppiluokituksen (TREC) BIBREF38 , elokuva-arvostelujen sentimentti (MR) BIBREF39 , Stanford Sentiment Treebank (SST) BIBREF40 , asiakkaiden tuotearvostelut (CR) BIBREF41 , subjektiivisuuden/objektiivisuuden luokittelu (SUBJ) BIBREF42 , mielipiteen polariteetti (MPQA) BIBREF43 .",
      "id": "task461-acfcbfd7bf8745ce917dbb0d3c16d714",
      "output": [
        "Miten he arvioivat lauseiden esityksiä?"
      ]
    },
    {
      "input": "Otimme näistä teoksista vaikutteita suunnitellessamme kokeilujamme CSKS-tehtävän ratkaisemiseksi.",
      "id": "task461-e0d4f69421b14c3c905b1a56132a614f",
      "output": [
        "Mihin ongelmaan he soveltavat siirto-oppimista?"
      ]
    },
    {
      "input": "Kokeet kahdella julkisesti saatavilla olevalla tietokokonaisuudella (Camrest BIBREF11 ja InCar Assistant BIBREF6) vahvistavat KB-retrieverin tehokkuuden.",
      "id": "task461-029127cab050432e84c47c4062d66c5a",
      "output": [
        "Millaisilla dialogitietoaineistoilla he tekivät kokeiluja?"
      ]
    },
    {
      "input": "Ensimmäiseksi korpukseksi kokosimme INLINEFORM0-korpuksen, joka edustaa 80 tieteellisen teoksen, kuten artikkelien, väitöskirjojen, kirjojen lukujen ja teknisten raporttien, otteita, jotka olemme valinneet tunnetulta Digital Bibliography & Library Project (DBLP) -alustalta. Toisena korpuksena kokosimme INLINEFORM0 -korpuksen, joka edustaa kokoelmaa 1 645 chat-keskustelua 550 seksuaalirikollisesta, jotka on poimittu Perverted-Justice-portaalista. Kolmantena korpuksena kokosimme INLINEFORM0 , joka on kokoelma 200 aggregoitua kirjoitusta, jotka on poimittu Reddit-alustalta.",
      "id": "task461-a777ddcdd96d41bda30c28cac858e8cc",
      "output": [
        "Minkä kokoisia korpukset ovat?"
      ]
    },
    {
      "input": "Perusluokittimessa käytetään lineaarista tukivektorikonetta BIBREF7 , joka soveltuu suurelle määrälle ominaisuuksia. ",
      "id": "task461-43e09b04d0624581a5434c5db23811ad",
      "output": [
        "Mitä perustasoa käytetään?"
      ]
    },
    {
      "input": "Myöhemmässä vaiheessa voidaan sisällyttää lauseisiin perustuva sanojen upottaminen sanastokartoituksen parantamiseksi. Tarkemman kohdekoodin saamiseksi jokaiselle riville abstrakti syntaksipuu (AST) voi olla hyödyllinen.",
      "id": "task461-695a980da32d44f9bd9b134f12c81ca6",
      "output": [
        "Mitä lisätekniikoita voitaisiin ottaa käyttöön tarkkuuden parantamiseksi entisestään?"
      ]
    },
    {
      "input": "Tässä asiakirjassa annotoimme manuaalisesti 600 L2-L1-parin predikaatti-argumenttirakenteet oppijan kiinan kielen semanttisen analyysin pohjaksi.",
      "id": "task461-67066a00b720496ca9c8033c14265c78",
      "output": [
        "Kuka kommentoi manuaalisesti semanttiset roolit oppijatekstien joukkoon?"
      ]
    },
    {
      "input": "Suoritimme ehdotetun järjestelmän luotettavuustutkimuksen käyttäen kahta asiantuntijalausunnonantajaparia, P1 ja P2. ",
      "id": "task461-dce8a705bd28448f8c97ffc281029861",
      "output": [
        "käyttävätkö he joukkoistamisalustaa?"
      ]
    },
    {
      "input": "Koska Garimella et al. BIBREF23 ovat julkaisseet koodinsa, toistimme heidän parhaan menetelmänsä Randomwalk meidän tietokokonaisuuksillamme ja mittasimme AUC ROC-arvon, jolloin saimme tulokseksi 0,935. Mielenkiintoinen havainto oli, että heidän menetelmänsä suorituskyky oli heikko heidän omissa aineistoissaan. Tämä johtui siitä (selitetty jo kohdassa SECREF4), että täydellisiä keskusteluja ei voitu palauttaa, eikä missään tapauksessa pystytty palauttamaan yli 50 prosenttia twiiteistä. Päätimme siis poistaa nämä keskustelut ja mitata uudelleen menetelmän AUC ROC -arvon, jolloin saimme arvon 0,99. Hypoteesimme on, että tietojen epätäydellisyys haittasi vakavasti kyseisen menetelmän suorituskykyä. Testasimme menetelmäämme myös näillä aineistoilla ja saimme AUC ROC -arvon 0,99 Walktrapin kanssa ja 0,989 Louvain-klusteroinnin kanssa.",
      "id": "task461-53cc0f7c4756446094d1c1ebe9a961fc",
      "output": [
        "Mitkä ovat uusimmat toimenpiteet?"
      ]
    },
    {
      "input": "Enemmistöperustason lisäksi vertaamme tuloksiamme myös leksikonipohjaiseen lähestymistapaan. Kokeellisten tulosten osalta ilmoitamme enemmistöperustason kunkin kielen osalta, jossa enemmistöperustason arvo vastaa mallin tarkkuutta, jos se ennustaa aina enemmistöluokan tietokokonaisuudessa.",
      "id": "task461-d2cfedd25a294e7c9bfb7391557835e0",
      "output": [
        "mitkä ovat peruslinjat?"
      ]
    },
    {
      "input": "Arvioimme ehdotettuja menetelmiä kahdeksalla kielellä, mikä osoittaa, että ne pystyvät oppimaan osittaisesta datasta. Lisäksi kokeilemme CBL:n alustamista toimialakohtaisilla instanssipainotusjärjestelmillä, ja tulokset ovat vaihtelevia. Prosessissa käytämme suosittujen NER-mallien painotettuja variantteja, jotka osoittavat vahvaa suorituskykyä sekä ei-neuraalisissa että neuraalisissa ympäristöissä. Lopuksi esitämme kokeita todellisessa ympäristössä, jossa ei-kielentaitoiset henkilöt kommentoivat manuaalisesti romanisoitua bengalilaista tekstiä. Kokeilemme 8 kielellä. Neljä kieltä - englanti, saksa, espanja ja hollanti - ovat peräisin CoNLL 2002/2003 -ohjelman jaetuista tehtävistä BIBREF21 ja BIBREF22. Nämä kielet on otettu uutislehtitekstistä, ja niiden merkintäkokonaisuudet ovat Person, Organization, Location, Miscellaneous. Loput neljä kieltä ovat peräisin LORELEI-hankkeesta BIBREF23. Nämä kielet ovat: LDC2016E87), arabia (ara: LDC2016E89), hindi (hin: LDC2017E62) ja somali (som: LDC2016E91). Nämä ovat peräisin eri lähteistä, kuten keskustelufoorumeilta, uutislehdistä ja sosiaalisesta mediasta. ",
      "id": "task461-34b54168508e408098c1b6e807d70633",
      "output": [
        "Mitkä kielet arvioidaan?"
      ]
    },
    {
      "input": "Tässä analyysissä käytetään FBFans-tietokannan viestejä. Laskemme kunkin erillisen kirjoittajan tykkääjätilastot näistä 32 595 viestistä.",
      "id": "task461-5d953da104d54941a6522d2c4d6f0407",
      "output": [
        "Mikä on Kiinan tietojen koko?"
      ]
    },
    {
      "input": "Kuvassa KUVA 9 esitetään ehdotetun Attentional Encoder Network (AEN) -verkon kokonaisarkkitehtuuri, joka koostuu pääasiassa upotuskerroksesta, attentional encoder -kerroksesta, kohdekohtaisesta huomiokerroksesta ja lähtökerroksesta. Upotuskerroksessa on kaksi tyyppiä: GloVe- ja BERT- upotus. Näin ollen mallit ovat nimeltään AEN-GloVe ja AEN-BERT.",
      "id": "task461-9aabc3749cc44fd9be5c9a7b23e7f43a",
      "output": [
        "Miten heidän mallinsa eroaa yhteistyöelimen mallista?"
      ]
    },
    {
      "input": "Testasimme järjestelmää kahdella tietokokonaisuudella, jotka olivat erikokoisia ja monimutkaisia käsiteltävän kielen suhteen.Kokeellinen arviointi ::: Datasets ::: Ensimmäinen (julkisesti saatavilla oleva) tietokokonaisuus, NLU-Benchmark (NLU-BM), sisältää $25,716$ lauseita, jotka on annotoitu kohdennetuilla skenaarioilla, toiminnoilla ja mukana olevilla entiteeteillä. Kokeellinen arviointi ::: Datasets ::: ROMULUS-tietokantaToinen tietokanta, ROMULUS, koostuu 1 431$ lauseesta, joista jokaiselle on annettu dialogitoimet, semanttiset kehykset ja vastaavat kehyselementit. Tämä tietokokonaisuus on kehitetty mallintamaan käyttäjän lausumia avoimen alueen keskustelujärjestelmiin robottialustoille, joiden odotetaan käsittelevän erilaisia vuorovaikutustilanteita/kaavoja - esim. chit-chat, komentojen tulkinta.",
      "id": "task461-13d43121c2bc4d219e7de502dd4a603f",
      "output": [
        "Mitä julkisesti saatavilla olevaa NLU-tietoaineistoa käytetään?"
      ]
    },
    {
      "input": "Arvioimme kehystämme fastText-sulkeumilla, jotka on koulutettu Wikipediassa (2017), UMBC:n webbase-korpuksessa ja statmt.org-uutistietokannassa (16B tokenia) BIBREF11. Yksinkertaisuuden vuoksi kaikissa upotuksissa käytetään vain 22000 ensimmäistä sanaa, vaikka alustavat tulokset osoittavat, että tulokset ulottuvat koko korpukseen. Uusissa menetelmissämme harhojen lieventämiseksi käytetään matalaa neuroverkkoa upotuksen säätämiseen. Mallin ainoa kerros on upotuskerros, jonka painot on alustettu alkuperäisen upotuksen painoihin. Yhdistelmämenetelmässä nämä painot alustetaan todennäköisyyspainotuksen lieventämisen jälkeisen upotuksen painoihin. Malliin syötetään joukko sanaindeksejä, jotka sitten upotetaan ja joille lasketaan tappioarvo, jolloin back-propagation voi säätää upotuksia. Jokaisessa mallissa käytetään kiinteää iteraatiomäärää, jotta estetään ylisovittaminen, joka voi lopulta heikentää suorituskykyä sulauttamisvertailumalleissa (ks. kuva FIGREF12). Arvioimme sulautuksen 1000 iteraation jälkeen ja lopetimme harjoittelun, jos suorituskyky vertailukohteessa heikkeni merkittävästi. Rakensimme luettelon debias-ehdokkaista sanoista, jotka otimme WEAT:n sukupuoleen perustuvassa harhautumistilastossa käytetyistä sanoista. Luettelossa olevien sanojen pitäisi olla sukupuolineutraaleja ja liittyä aiheisiin ura, taide, tiede, matematiikka, perhe ja ammatit (ks. liite). Huomaamme, että tätä luetteloa voidaan helposti laajentaa, jotta se sisältäisi suuremman osan korpuksen sanoista. Esimerkiksi BIBREF4 ehdotti menetelmää, jonka avulla voidaan tunnistaa sukupuolittuneet sanat valvomattoman oppimisen avulla. Vertailemme tätä ennakkoluulojen vähentämismenetelmää ennakkoluulojen vähentämättömään vähentämiseen (\"Orig\"), geometriseen ennakkoluulojen vähentämiseen (\"Geo\"), menetelmämme kahteen osaan yksinään (\"Prob\" ja \"KNN\") ja yhdistelmämenetelmään (\"KNN+Prob\"). Huomaamme, että yhdistelmämenetelmä toimii kohtuullisen hyvin RIPA-mittarin mukaan ja paljon paremmin kuin perinteinen geometrinen harhojen lieventäminen naapuruusmittarin mukaan ilman merkittävää suorituskyvyn heikkenemistä hyväksyttyjen vertailuarvojen mukaan. Tietojemme mukaan tämä on ensimmäinen harhojen lieventämismenetelmä, joka toimii kohtuullisesti molemmilla mittareilla.",
      "id": "task461-99eb32749f4b4acaa8d9d67ed5ae0e4f",
      "output": [
        "Miten laatua arvioidaan?"
      ]
    },
    {
      "input": "Autokieli on abstraktia kieltä, joka liittyy auton fyysisiin ominaisuuksiin. Tässä tapauksessa fyysiset ominaisuudet, joihin termi \"nopea\" viittaa, voivat olla hevosvoimat, tai se voi olla auton muototekijä (miten auto näyttää). Emme kuitenkaan tiedä tarkalleen, mihin ominaisuuksiin termi \"nopea\" viittaa.",
      "id": "task461-03c0bbe8a6d345e986c507ffacf47442",
      "output": [
        "Miten autopuhe liittyy auton fyysisiin ominaisuuksiin?"
      ]
    },
    {
      "input": "Ehdotetun mallin tehokkuuden osoittamiseksi paremmin vertaamme sitä perusmalleihin ja esitämme tulokset taulukossa TABREF12 .",
      "id": "task461-4b72036a151c44349993036d629135e8",
      "output": [
        "Mikä oli ehdotetun mallin pistemäärä?"
      ]
    },
    {
      "input": "Tavoitteena oli arvioida, voisiko D2V tehokkaasti korvata PubMedin related-document-toiminnon, ja siksi suunniteltiin viisi erilaista asiakirjojen samankaltaisuuden arviointia, kuten kuvassa FIGREF9 on esitetty.  Menetelmät ::: Arviointi ::: Merkkijonon pituusVoidaksemme arvioida, voisiko samankaltainen pituus johtaa kahden asiakirjan lähentymiseen, kyselyasiakirjan $D_{x}$ kokoa on verrattu lähimpään asiakirjaan $C_{x}$ 10 000:n satunnaisesti TeS:stä valitun asiakirjan osalta joidenkin esikäsittelyvaiheiden jälkeen (pysäytyssanat ja välilyönnit poistettiin molemmista asiakirjoista). Menetelmät ::: Evaluation :::: Sanojen yhteisesiintymisetSanojen yhteisesiintymismatriisi rakennettiin PubMedin koko korpuksesta. Lyhyesti sanottuna kukin dokumentti alennettiin ja tokenisoitiin. Matriisiin merkittiin, kuinka monta kertaa kaksi sanaa esiintyy yhdessä asiakirjassa. Tämän jälkeen 5 000:lle TeS:n asiakirjalle $D_{x}$ haettiin kaikista malleista ylhäältä lähin asiakirja $C_{x}$. Kaikki mahdolliset yhdistelmät kaikkien sanojen $WD_{x} \\ D_{x}$ ja kaikkien sanojen $WC_{x}$ välillä. \\ in C_{x}$ (lukuun ottamatta stop-sanoja) poimittiin, 500 paria valittiin satunnaisesti ja matriisista poimittiin, kuinka monta kertaa kukin niistä esiintyi yhdessä. Tästä luettelosta laskettiin keskiarvo, joka kuvastaa D:n ja C:n läheisyyttä niiden sanasisällön suhteen. Tämä pistemäärä laskettiin myös kunkin $D_{x}$:n ja pmra-algoritmin palauttaman lähimmän asiakirjan $C_{x}$ välillä. Menetelmät ::: Evaluation ::: Edellä selostettua arviointitehtävää sovellettiin myös 10 000 kantatekstiin (käyttäen Gensimin PorterStemmer-ohjelmaa, joka säilyttää vain sanan juuret). Voidaan arvioida konjugaatiomuodon tai muiden suffiksien vaikutusta. Menetelmät ::: Arviointi ::: MeSH:n samankaltaisuusVoidaan verrata sekä pmra:n että D2V:n kykyä tuoda lähemmäksi artikkeleita, jotka on indeksoitu yhteisillä merkinnöillä. Tätä varten 5000 satunnaisesti TeS:stä valittua dokumenttia $D_{x}$ lähetettiin sekä pmra- että D2V-arkkitehtuureille, ja niistä poimittiin viisi parasta lähempänä olevaa artikkelia $C_{x}$. Seuraavia sääntöjä sovellettiin sitten kuhunkin $D_{x}$:n yhteydessä löydettyyn MeSH-terminiin kunkin asiakirjan $C_{x_i}$ osalta: lisätään 1 pistemäärään, jos kyseinen MeSH-termi esiintyy sekä $D_{x}$:ssä että $C_{x_i}$:ssä, lisätään 3 pistemäärään, jos kyseinen MeSH-termi määritellään pääaiheeksi, ja lisätään 1 pistemäärään jokaista $D_{x}$:n ja Cxi:n yhteistä määritettä kohden, joka koskee kyseistä MeSH-termiä. Tämän jälkeen laskettiin näiden viiden pisteen keskiarvo sekä pmra:lle että D2V:lle.",
      "id": "task461-6d0e2907488743098ea0cfd7a5a09b3a",
      "output": [
        "Mitkä neljä arviointitehtävää on määritelty sen määrittämiseksi, mikä vaikuttaa läheisyyteen?"
      ]
    },
    {
      "input": "Amazonin arvostelutietokanta BIBREF24 on suuri tietokanta, joka sisältää miljoonia arvosteluja eri tuoteryhmistä. Kokeissamme tarkastelemme 20000 arvostelun osajoukkoa aloilta Matkapuhelimet ja lisävarusteet(C), Vaatteet ja kengät(S), Koti ja keittiö(H) sekä Työkalut ja sisustustarvikkeet(T). 20000 arvostelusta 10000 on positiivisia ja 10000 negatiivisia. Käytämme 12800 arvostelua harjoitteluun, 3200 arvostelua validointiin ja 4000 arvostelua testaukseen jokaiselta alueelta.",
      "id": "task461-7dfe3f6551df4ff4bd7e765907414753",
      "output": [
        "Miten tässä asiakirjassa määritetään, että jokin asia on aluespesifistä tietoa?"
      ]
    },
    {
      "input": "Huomaamme kuitenkin, että IR-menetelmät toimivat paremmin kuin parhaat neuromallit. Emme löydä riittävästi todisteita nollahypoteesin hylkäämiseksi sen suhteen, mitä kontekstia siteeratusta asiakirjasta pitäisi käyttää.",
      "id": "task461-6147b68fbafc45faa08097b9d8817cdd",
      "output": [
        "Mikä perustaso toimii parhaiten?"
      ]
    },
    {
      "input": "Sanasäkki-ominaisuusvektoreita käytettiin multinomiaalisen logistisen regressiomallin kouluttamiseen. Olkoon INLINEFORM0 todellinen etiketti, jossa INLINEFORM1 on etikettien kokonaismäärä ja INLINEFORM2 on INLINEFORM4 th osapuoleen liittyvien painovektoreiden INLINEFORM3 ketjutus, niin DISPLAYFORM0",
      "id": "task461-337ca2a26d3b4d90a114468bb1429540",
      "output": [
        "Millaisessa mallissa tekstin piirteitä käytetään ennusteiden tuottamiseen?"
      ]
    },
    {
      "input": "Tutkiaksemme, miten multimodaalinen konteksti voi parantaa suorituskykyä verrattuna unimodaaliseen kontekstiin, arvioimme erilaisia malleja: Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM) ja Textual Kernels Model (TKM).",
      "id": "task461-9d68f12590e6415fbf2b75bad271995f",
      "output": [
        "Mitä eri malleja multimodaaliseen havaitsemiseen on ehdotettu?"
      ]
    },
    {
      "input": "Euroopan parlamentin jäsenten uudelleentwiittauskäyttäytymistä kuvaa heidän uudelleentwiittausverkostonsa. Jokainen Twitterissä aktiivinen MEP on tämän verkon solmu. Kahden MEP:n välinen verkoston särmä on olemassa, kun toinen MEP twiittailee toiselle. Reunan paino on kahden MEP:n välisten uudelleentwiittausten määrä Mittaamme poliittisen ryhmän INLINEFORM0 yhteenkuuluvuutta uudelleentwiittausten keskiarvona, eli ryhmän INLINEFORM1 MEP:ien välisten uudelleentwiittausten määrän suhteena ryhmän INLINEFORM2 MEP:ien määrään. ",
      "id": "task461-397d652ee55c40ab94c2977d243328d1",
      "output": [
        "Ottavatko kirjoittajat mallissaan huomioon erot Twitterin käytössä kansanedustajien keskuudessa?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa käytetyn De7-tietokannan suunnitteli Marc Schroeder, joka oli yksi ensimmäisistä yrityksistä luoda difonitietokantoja ekspressiivistä puhesynteesiä varten BIBREF2. Tietokanta sisältää kolme äänilaatua (modaalinen, pehmeä ja kovaääninen), jotka saksalainen naispuhuja on lausunut, ja kutakin äänilaatua varten on käytettävissä noin 50 minuuttia puhetta.",
      "id": "task461-3f6caaac6b2e4db2b3c209dda79a6a7b",
      "output": [
        "Mitä suurta korpusta käytetään kokeissa?"
      ]
    },
    {
      "input": "Kaikkien luokittelijoiden osalta ominaisuusyhdistelmämme on parempi kuin perusluokittelijat (jotka käyttävät vain unigram-ominaisuuksia) ja BIBREF3 , ja MILR-luokittelijan F-tulos paranee 3,7 prosenttia ja Kappa-ero 0,08 prosenttia. Myös SVM-luokittimella saavutetaan 2 prosentin parannus perustasoon verrattuna, kun käytetään meidän ominaisuusjoukkoamme. Havaitsemme myös, että pelkät katseominaisuudet havaitsevat myös sarkasmiluokkien ja ei-sarkasmiluokkien väliset erot suurella tarkkuudella, mutta alhaisella palautusprosentilla.",
      "id": "task461-aa452ca3fa3a448894137fdc09f458af",
      "output": [
        "Mitä muita arviointimittareita tarkastellaan?"
      ]
    },
    {
      "input": "Vertaillaksemme tuloksiamme käytämme annettua perustasoa, joka on ilman parametreja optimoitu lineaarisen ytimen SVM, joka käyttää syötteenä TF-IDF-sanapussivektoreita. ",
      "id": "task461-8727de1ee76b4c0cb2265dd8f73d3d59",
      "output": [
        "Mikä oli perusmalli?"
      ]
    },
    {
      "input": "Huomasimme, että 51,25 prosentilla kerätyistä jengiläisistä on twiitti, joka linkittää YouTube-videoon. Näiden linkkien jälkeen YouTube-videon kuvauksessa olevien termien gangsta ja hiphop haku yksinkertaisella avainsanahaulla osoitti, että 76,58 prosenttia jaetuista linkeistä liittyy hiphop-musiikkiin, gangsteriräppiin ja tätä musiikkityyppiä ympäröivään kulttuuriin.",
      "id": "task461-31334d104d74458083af31d58a267b46",
      "output": [
        "Mitä eroja YouTube-linkkien käytössä on jengiläisten ja muun Twitter-väestön välillä?"
      ]
    },
    {
      "input": "Kuvissa FIGREF39, FIGREF43 ja FIGREF51 oleva suora viiva on tulos, joka on saatu valvotulla LDA-algoritmilla, jota käytetään perustasona. ",
      "id": "task461-6459e7c98d2e4847800e2286a62e8777",
      "output": [
        "Verrattiinko heikosti valvotun mallin suorituskykyä valvotun mallin suorituskykyyn?"
      ]
    },
    {
      "input": "Käytimme kokeiluissamme Universal Dependencies Treebank UD v2.1 BIBREF0 -tietopankkia. Valitsimme neljä kieliparia, joissa on vähän resursseja ja paljon resursseja, ja kukin niistä on eri kieliperheestä: Tanskan/ruotsin (da/sv), venäjän/bulgaarin (ru/bg), suomen/unkarin (fi/hu) ja espanjan/portugalin (es/pt). Valitsemalla kielet eri kieliperheistä varmistetaan, että tulokset ovat keskimäärin yhdenmukaisia eri kielten välillä.",
      "id": "task461-b3baf89ddaad442aa20d9eea1ac974ec",
      "output": [
        "Mitä kieliä tutkitaan?"
      ]
    },
    {
      "input": "Kokeelliset tulokset on esitetty taulukossa 1, josta käy ilmi, että automaattiset koodaajat päihittivät MLP:n ja CNN:n, sillä suurin saavutettu tarkkuus oli 82,6 %.",
      "id": "task461-8586c3a7beb644e19a5c6cb7881707a4",
      "output": [
        "Kumpi syväoppimismalli toimi paremmin?",
        "Millainen oli niiden suorituskyky kyseisessä tietokokonaisuudessa?"
      ]
    },
    {
      "input": "Manning ja Schütze väittävät, että vaikka se ei olekaan aivan oikein, kielitekstit voidaan mallintaa stationäärisinä ergodisina satunnaisprosesseina BIBREF29, ja me noudatamme tätä oletusta. Lisäksi, kun otetaan huomioon kielentuotannon monimuotoisuus, oletamme, että tämä stationaarinen ergodinen satunnaisprosessi, jolla on äärellinen aakkosto $\\mathcal {A}$ ja jota merkitään $X = \\lbrace X_i, -\\infty < i < \\infty \\rbrace $, ei ole nollassa siinä mielessä, että aina $P(x_{-m}^{-1}) > 0$, jaTätä kutsutaan joskus tasoittumisvaatimukseksi.",
      "id": "task461-b625331e51724859aeb033f52267dc7f",
      "output": [
        "Onko oletus, että luonnollinen kieli on pysyvää ja ergodista, pätevä?"
      ]
    },
    {
      "input": "Löytääksemme aiheita kerätyistä twiiteistä käytimme aiheiden mallintamista, joka klusteroi semanttisesti toisiinsa liittyvät sanat, kuten \"diabetes\", \"syöpä\" ja \"influenssa\" aiheeksi, jolla on yleinen \"sairaus\"-teema BIBREF44 , BIBREF45 . Teemamalleista Latent Dirichlet Allocation (LDA) BIBREF49 on suosituin tehokas malli BIBREF50 , BIBREF19 , koska tutkimukset ovat osoittaneet, että LDA on tehokas laskennallisen kielitieteen malli aiheiden löytämiseksi korpuksesta BIBREF51 , BIBREF52 . Käytimme LDA:n Mallet-toteutusta BIBREF49 , BIBREF56 sen oletusasetuksilla tutkiaksemme mielipiteitä twiiteissä.",
      "id": "task461-6b63e25985ef4a16af45e87c5c2fc5f4",
      "output": [
        "Miten DDEO:ta koskevat kiinnostavat aiheet tunnistettiin?"
      ]
    },
    {
      "input": "Huumorin tunnistaminen sosiaalisen median teksteistä analysoidaan luokitteluongelmana ja käytetään useita koneoppimisen luokittelumalleja.",
      "id": "task461-6719076213c44d3c9b9fe8cfb1e320d9",
      "output": [
        "Mitä kokeita korpuksella tehtiin?"
      ]
    },
    {
      "input": "Ensiksi esitellään kaksivaiheinen tunnetekstien merkintästrategia. Ensimmäisessä vaiheessa annotoijia pyydetään merkitsemään suuri määrä lyhyitä tekstejä, joissa on suhteellisen puhtaat tunnesuuntaukset. Kunkin näytteen leimaa vain yksi kommentoija. Toisessa vaiheessa annotoidaan suhteellisen pieni määrä tekstinäytteitä, joissa on sekalaisia tunnesuuntauksia, ja useampi annotoija merkitsee jokaisen näytteen. ",
      "id": "task461-d83d3f17432e4207805698e9421e5f8a",
      "output": [
        "Mikä on uusi merkintästrategia?"
      ]
    },
    {
      "input": "Päätimme arvioida malliamme käyttämällä painotettua F1-pistemäärää, eli luokkakohtainen F1-pistemäärä lasketaan ja keskiarvoistetaan painottamalla kutakin etikettiä sen tuen mukaan. ",
      "id": "task461-ab8a7fe4897c411b856164f3a937d4a6",
      "output": [
        "mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Tässä luvussa kuvataan teoreemantodistajien taustalla oleva formalismi, sellaisena kuin se näkyy vuorovaikutteisen todistusjäljen aikana, ja esitellään yleinen strategia, jota teoreemantodistajat noudattavat.  Tämän luvun loppuosa on jäsennelty seuraavasti. Jaksossa \"Tyyppilogiset kieliopit\" esitetään yleinen johdanto tyyppilogisiin kielioppiin ja havainnollistetaan sen peruskäsitteitä Lambek-laskennan avulla, ja jakso päättyy joihinkin ongelmiin Lambek-laskennan syntaksi-semantiikan rajapinnassa. Tyyppilogiset kieliopit ovat kielioppiformalismin perhe, joka perustuu logiikkaan ja tyyppiteoriaan. Tyyppilogiset kieliopit saivat alkunsa, kun BIBREF4 esitteli syntaktisen kalkyylinsä (jota myöhemmät kirjoittajat kutsuvat Lambekin kalkyyliksi, L). Vaikka Lambek perustui BIBREFin5 , BIBREFin6 ja muiden töihin, Lambekin tärkein innovaatio oli laskennan esittäminen logiikkana, jossa hän esitti sekvenssilaskennan ja osoitti ratkaisukelpoisuuden leikkausten eliminoinnin avulla.",
      "id": "task461-df5d2e54b6594dc38a003b5db64014b7",
      "output": [
        "Mitä formalismia Grail käyttää?"
      ]
    },
    {
      "input": "Arvioimme CAHANin eri versioiden ja HAN-perustason avulla opittujen asiakirjojen upotusten laatua kolmella laajamittaisella asiakirjaluokitustietokannalla, jotka esiteltiin BIBREF14:ssä ja joita käytettiin alkuperäisessä HAN-julkaisussa BIBREF5.",
      "id": "task461-419e40315e0049a4b170a7a19b8bc96e",
      "output": [
        "Onko niitä verrattavissa muihin malleihin HANin lisäksi?"
      ]
    },
    {
      "input": "Vertailemme FSDM:ää neljään perusmenetelmään ja kahteen ablaatioon.NDM BIBREF7 ehdottaa modulaarista päästä päähän -koulutettavaa verkkoa. LIDM BIBREF9 parantaa NDM:ää käyttämällä diskreettia latenttia muuttujaa taustalla olevien dialogitekojen oppimiseen. KVRN BIBREF13 ottaa käyttöön kopioidun Seq2Seq-mallin agentin vastausten generoimiseksi ja käyttää KB:n huomiomekanismia. TSCP/RL BIBREF10 on kaksivaiheinen CopyNet, joka koostuu yhdestä koodaajasta ja kahdesta kopiomekanismilla täydennetystä dekooderista uskomustilan ja vastauksen tuottamista varten.",
      "id": "task461-9112946fcc60472bb11aa4921430c9e0",
      "output": [
        "Mitä perustasoja tässä työssä on käytetty?"
      ]
    },
    {
      "input": " Kuten BIBREF0:ssa käsiteltiin, pelkkää tekstiä sisältävä UMT on pohjimmiltaan huonosti ratkaistu ongelma, koska on mahdollisesti monia tapoja yhdistää kohde- ja lähdelauseet. Koska visuaalinen sisältö ja kieli liittyvät läheisesti toisiinsa, kuva voi intuitiivisesti toimia \"kielenä\", joka yhdistää nämä kaksi kieltä ilman rinnakkaista korpusta, jolloin ongelmasta tulee \"tarkemmin määritelty\", koska se voidaan vähentää valvottuun oppimiseen.",
      "id": "task461-c10c48abb4da410296e0677b0b970f92",
      "output": [
        "Miksi tämä työ eroaa pelkän tekstin UNMT:stä?"
      ]
    },
    {
      "input": "Kuvassa FIGREF29 esitetään vertailun vuoksi ehdotetun DP-LSTM:n ja vanilla-LSTM:n $\\text{MPA}$. ",
      "id": "task461-28ce3a1d6e35419a9cf9cd2a5d9dd3ae",
      "output": [
        "Verrataanko mallia lineaarisen regression perustasoon?"
      ]
    },
    {
      "input": "Tässä asiakirjassa käytämme kolmea kirjallisuudesta löytyvää aineistoa oman luokittelijamme kouluttamiseen ja arviointiin. BIBREFin3 keräämät tiedot, joita kutsumme Sexist/Racist (SR) -datajoukoksi, kerättiin alustavalla Twitter-haulla, jonka jälkeen kirjoittajat ja heidän tiiminsä analysoivat ja suodattivat ne. He tunnistivat 17 yleistä lausetta, hashtagia ja käyttäjää, jotka viittasivat loukkaavaan puheeseen. BIBREF4 keräsi HATE-tietoaineiston etsimällä twiittejä Hatebase.orgin tarjoaman sanaston avulla. Lopullisen käyttämämme aineiston, jota kutsumme nimellä HAR, keräsi BIBREF9 ; poistimme kaikki uudelleentwiittaukset ja pienensimme aineiston 20 000 twiittiin. Twiitit merkittiin \"häiritseviksi\" tai \"ei-häiritseviksi\"; vihapuhetta ei nimenomaisesti merkitty, vaan sitä käsiteltiin merkitsemättömänä osajoukkona laajemmasta \"häiritsevä\"-luokasta BIBREF9 . Monet väärät negatiiviset tulokset ovat viittauksia \"My Kitchen Rules\" -televisiosarjan hahmoihin, eivät niinkään naisiin yleensä.  Tämä voi olla rajoitus, joka johtuu siitä, että otetaan huomioon vain twiitin sisältö, mutta se voi olla myös virheellinen nimitys. debra are now my most hated team on #mkr after least night's ep. Snakes in the grass those two.Along these lines, we also see correct predictions of harmittomia puheita, mutta löydämme dataa, joka on leimattu väärin vihapuheeksi:@LoveAndLonging ...how is that example \"sexism\"?@amberhasalamb ...in what way?",
      "id": "task461-c9ba571f348241c296e97eb31a86f567",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Leksikaalisiin ominaisuuksiimme kuuluvat 1-, 2- ja 3-grammat sekä sana- että merkkitasolla. Käytämme myös merkkien ja sanojen lukumäärää ominaisuuksina. Tämän jälkeen käytämme kaikkia POS-tunnisteita ja niitä vastaavia tf-idf-arvoja syntaktisina ominaisuuksina ja ominaisuusarvoina. Ensin käytämme GloVe BIBREF:stä29 saatuja 300-ulotteisia esivalmistettuja sanojen upotuksia twiitin upotuksen laskemiseen twiitin sanojen upotusten keskiarvona. Toiseksi käytämme latenttia semanttista indeksointia BIBREF30 kuvaamaan tietokokonaisuuden taustalla olevaa semantiikkaa. Jokainen twiitti esitetään 100-ulotteisena vektorina. Kolmanneksi uutamme twiitin esityksen myös soveltamalla Brownin klusterointialgoritmia BIBREF31 , BIBREF32 - hierarkkista klusterointialgoritmia, joka ryhmittelee sanat, joilla on samanlainen merkitys ja syntaktinen funktio, yhteen. Kiihdyttämämme verbaalisen ironian avulla polariteettikontrastin avulla, kuten \"I really love this year's summer; weeks and weeks of awful weather\", käytämme twiitissä esiintyvien polariteettisignaalien lukumäärää polariteettipiirteinä. Signaaleja ovat positiiviset sanat (esim. rakkaus), negatiiviset sanat (esim. kauhea), positiivinen emoji-ikoni ja negatiivinen emoji-ikoni. Käytämme BIBREF33:n tarjoamia sentimenttisanakirjoja tunnistamaan positiiviset ja negatiiviset sanat twiitissä. Lisäksi käytämme boolean-ominaisuuksia, joilla tarkistetaan, onko twiitissä negaatiosana (esim. not, n't).",
      "id": "task461-f718f2ad739b432894a198433f408180",
      "output": [
        "Minkälaisia leksikaalisia, syntaktisia, semanttisia ja polariteettipiirteitä käytetään?"
      ]
    },
    {
      "input": "Keräsimme COVID-19:ään liittyviä arabialaisia twiittejä 1. tammikuuta 2020 ja 15. huhtikuuta 2020 välisenä aikana Twitterin streaming API:n ja Tweepy Python-kirjaston avulla. ",
      "id": "task461-c532348bf1b843c986bf2800f14d0e3e",
      "output": [
        "Minkä ajanjakson aikana twiittejä kerättiin?"
      ]
    },
    {
      "input": "Vertailemalla rinnakkaisten aineistojemme luonnollisia ja keinotekoisia lähteitä useiden kielellisten ja jakaumallisten ominaisuuksien suhteen havaitsemme, että (ks. kuvat KUVA 21 - KUVA 22 ): keinotekoiset lähteet ovat keskimäärin lyhyempiä kuin luonnolliset lähteet: BT:tä käytettäessä tapaukset, joissa lähde on lyhyempi kuin kohde, ovat harvinaisempia, kun taas tapaukset, joissa lähde on samanpituinen, ovat yleisempiä.Keinotekoisten lähteiden väliset automaattiset sanakohdistukset ovat yleensä monotonisempia kuin luonnollisia lähteitä käytettäessä, mikä mitataan lähde-kohde-kohdistusten keskimääräisellä Kendall INLINEFORM0 -luvulla BIBREF22 : ranskan ja englannin osalta vastaavat luvut ovat 0,048 (luonnolliset lähteet) ja 0,018 (keinotekoiset lähteet); saksan ja englannin osalta 0,068 ja 0,053.  Intuitio on, että ominaisuuksien (i) ja (ii) pitäisi auttaa kääntämistä verrattuna luonnolliseen lähteeseen, kun taas ominaisuuden (iv) pitäisi olla haitallinen.",
      "id": "task461-f060e7dc65e541d38e1486c800e28653",
      "output": [
        "Mikä on heidän selityksensä takaisinkääntämisen tehokkuudelle?"
      ]
    },
    {
      "input": "Vaikka tämän tietopohjan rakentamiseen käytettävät tekniikat eivät kuulu tämän asiakirjan piiriin, mainitsemme ne lyhyesti. Taulukot rakennettiin käyttämällä manuaalisia ja puoliautomaattisia tekniikoita.",
      "id": "task461-db44e9a2f5c24228b551865a0e56ae1f",
      "output": [
        "Miten puolistrukturoitu tietopohja luodaan?"
      ]
    },
    {
      "input": "Havaitsemme sarkastisen luokan adjektiivi- ja adverbikuvioita runsaasti, vaikka emme käytä adjektiivi- ja adverbikuvioita regex-haun menetelmässämme.  Monissa sarkastisissa kysymyksissämme keskitytään nimenomaan vastaanottajan henkisiin kykyihin kohdistuviin hyökkäyksiin. Tämä yleistäminen tulee selväksi, kun poimimme ja analysoimme verbin, subjektin ja objektin argumentit Stanfordin riippuvuusjäsennyksen jäsentäjän BIBREF32 avulla RQ-tietokannan kysymyksistä.  Kuten edellä todettiin, eräs yleinen hyperbolian malli liittyy adverbeihin ja adjektiiveihin. Emme käyttäneet tätä kuviota hyperbolin hakemiseen, mutta koska jokainen hyperbolinen sarkastinen lausahdus sisältää useita vihjeitä, opimme laajennetun luokan hyperbolin kuvioita.  Opimme useita verbaalisia malleja, joita emme olleet aiemmin yhdistäneet hyperboliin, kuten taulukossa TABREF34 näkyy. ",
      "id": "task461-a9ea690d629e437ab3651ccc4d628a4c",
      "output": [
        "Mitä leksikaalis-syntaktisia vihjeitä käytetään sarkastisten lausumien hakemiseen?"
      ]
    },
    {
      "input": "Esityksemme sijoittuivat toiseksi (EI-Reg), toiseksi (EI-Oc), neljänneksi (V-Reg) ja viidenneksi (V-Oc), mikä osoittaa, että ehdotettu menetelmä on tarkka espanjankielisten twiittien tunteiden voimakkuuden ja sentimentin automaattisessa määrittämisessä.",
      "id": "task461-322d5983e08641918c6877c86818b27a",
      "output": [
        "Mihin osatehtäviin he osallistuivat?"
      ]
    },
    {
      "input": "Suodatin 1: String match -suodatin poistaa kaikki KB-kolmikot, joissa oikea vastaus (esim. Apple) on aiheena olevan entiteetin nimen (esim. Apple Watch) iso-kirjaimet erittelemätön osajono. Suodatin 2: Entiteettien nimet voivat tietysti olla paljastavia hienovaraisemmilla tavoilla. Kuten ranskalaisen näyttelijän esimerkki osoittaa, henkilön nimi voi olla hyödyllinen ennakkotieto, jonka perusteella voidaan arvata hänen äidinkielensä ja siten myös hänen kansallisuutensa, syntymäpaikkansa jne. Henkilön nimisuodattimessamme käytetään cloze-tyyppisiä kysymyksiä BERT:lle ominaisten nimiassosiaatioiden selvittämiseksi ja poistetaan niiden kanssa korreloivat KB-kolmiot.",
      "id": "task461-777256be58aa4a728cf33f2522e59c0e",
      "output": [
        "Miten määritetään, että jokin tosiasia on helposti arvattavissa?"
      ]
    },
    {
      "input": "Kaikkiaan 27 eri genreä raaputettiin.",
      "id": "task461-ca54f91ba0fb4308868e770cf84c1e68",
      "output": [
        "kuinka monta elokuvagenreä he tutkivat?"
      ]
    },
    {
      "input": "Prototyyppinen toteutus, jossa sanojen oletetaan olevan erityisen ortogonaalisen ryhmän INLINEFORM0 perustavanlaatuisessa esityksessä ja jossa sanojen suhteelliselle toiminnalle herkkien tappioiden ehdoilla, on toisen, parhaillaan valmisteilla olevan käsikirjoituksen aiheena.",
      "id": "task461-3da4e3f1a15f40928047cdf56ae82a54",
      "output": [
        "Onko olemassa muodollinen todiste siitä, että RNN:t muodostavat ryhmän edustuksen?"
      ]
    },
    {
      "input": "Valvomaton luokittelumallimme päihittää valvotun IMS-järjestelmän 1,02 %:lla CoNLL:n F1-tuloksessa ja saavuttaa kilpailukykyisen suorituskyvyn latentin puumallin kanssa. Lisäksi lähestymistapamme kaventaa huomattavasti eroa muihin taulukossa 3 lueteltuihin valvottuihin järjestelmiin.",
      "id": "task461-b7de8aaf7dcb465cafecb72fe70f368c",
      "output": [
        "Onko asiakirjassa esitetty malli uusinta tekniikkaa?"
      ]
    },
    {
      "input": "Toinen laajalti käytetty menetelmä harhaanjohtavan sisällön luokitteluun on käyttää etäisiä merkintöjä, esimerkiksi luokitella twiitti twiitin jakaman URL-osoitteen toimialueen tai twiitin sisältämän hashtagin perusteella BIBREF6, BIBREF7, BIBREF8. Jotta metatietoja laajemmat merkinnät voitaisiin skaalata suurempiin tietokokonaisuuksiin, tekstisisällön automaattiseen merkitsemiseen voidaan käyttää luonnollisen kielen prosessoinnin (NLP) malleja.",
      "id": "task461-53b8bc0057ee4042a6fffa3ac9a22fc7",
      "output": [
        "Millaisia tietojen merkitsemisen apuvälineitä on käytetty aiemmissa tietokokonaisuuksissa?"
      ]
    },
    {
      "input": "Maalausten keskimääräinen sisältöpistemäärä on 3,7, mikä osoittaa, että tuotettu proosa liittyy maalaukseen. Keskimääräinen luovuuspistemäärä on 3,9, mikä osoittaa, että malli kuvaa onnistuneesti maalauksen muutakin kuin perusobjekteja käyttämällä kohtauksen runollisia vihjeitä. Keskimääräinen tyyliarvosana on 3,9, mikä osoittaa, että tuotetun proosan koetaan olevan Shakespearen tyylistä.",
      "id": "task461-3afa2a932ca6431fa39f317d08226124",
      "output": [
        "Millainen on lopullinen malli Likertin asteikolla?"
      ]
    },
    {
      "input": "RC-QED$^{\\\\rm E}$ voidaan luonnollisesti ratkaista polkujen järjestykseen perustuvalla KGC:llä (PRKGC), jossa kyselytripletti vastaa kysymystä ja näytteeksi otetut polut vastaavat kysymystä ja johdannaisvaiheita.",
      "id": "task461-d44d9c38b63641d282ae6c8f850c0ab5",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Trinomit esiintyvät todennäköisesti täsmälleen yhdessä järjestyksessä, ja kun niitä esiintyy useammassa kuin yhdessä järjestyksessä, viimeinen sana on lähes aina sama kaikissa tapauksissa. ",
      "id": "task461-c939d3f7559045b39de24694ee457941",
      "output": [
        "Onko trinomien analyysissä mitään uutta havaintoa, jota ei ollut binomien analyysissä?"
      ]
    },
    {
      "input": "Keskitymme BIBREF3:n jakamiin tietoihin ja testaamme empiirisesti, missä määrin arviointisuunnitelmaan tehdyt muutokset vaikuttavat ihmisarvioinnin tuloksiin. Tässä tutkimuksessa käsittelemme kolmea näkökohtaa, jotka ovat mielestämme erityisen tärkeitä monikielisen tekstin inhimillisen arvioinnin kannalta, ja keskitymme erityisesti ihmisen ja koneen välisen tasavertaisuuden testaamiseen: arvioijien valinta, kielellisen kontekstin käyttö ja vertailukäännösten laatiminen. Testataan empiirisesti näiden tekijöiden vaikutusta monikielisen tekstin inhimilliseen arviointiin ja keskustellaan siitä jaksoissa SECREF3-SECREF5. ",
      "id": "task461-2e5b3a4c8f4a4dd0afddaf80599b2130",
      "output": [
        "Mihin virallisiin tutkimuksiin he viittaavat?"
      ]
    },
    {
      "input": "Koe 1: modifioitujen viittaavien ilmaisujen kohtausvaihtelu Rekrytoimme 58 osallistujaparia (yhteensä 116 osallistujaa) Amazonin Mechanical Turk -palvelun kautta, ja jokaiselle osallistujalle maksettiin 1,75 dollaria osallistumisesta.",
      "id": "task461-ab4948b6c5ed4aefad9d9054df03a9e4",
      "output": [
        "Kuvataanko artikkelissa oikeilla ihmisillä tehtyjä kokeita?"
      ]
    },
    {
      "input": "Kolme perusluokitusmenetelmää: SVM, Adaboost ja Random Forests -menetelmiä käytetään arvioimaan poimittuja ominaisuuksia. Käytetyt luokittelijat koulutetaan kussakin tietokokonaisuudessa ensin yksittäisellä ominaisuudella ja sitten kahden ominaisuuden yhdistelmällä.",
      "id": "task461-9d3e770032d64fd3ac59fa0907c40a4f",
      "output": [
        "LDA on valvomaton menetelmä; esitelläänkö tässä asiakirjassa valvomaton lähestymistapa roskapostin havaitsemiseen?"
      ]
    },
    {
      "input": "Teemme erilaisia kokeita havainnollistaaksemme ominaisuuksia, joita kannustetaan eri KL-suuruusluokkien avulla. Erityisesti tarkastelemme uudelleen nopeuden ja vääristymän välistä riippuvuutta ja valotamme KL:n vaikutusta approksimoitujen jälkijäämien terävyyteen. Tämän jälkeen osoitamme tekstin tuottamista koskevien kvalitatiivisten ja kvantitatiivisten kokeiden avulla, miten VAE:ille voidaan asettaa tiettyjä generatiivisia käyttäytymismalleja maksimikanavakapasiteettien avulla. Lopuksi tehdään joitakin kokeita sen selvittämiseksi, onko latenttiin tilaan koodattu minkäänlaista syntaktista tietoa.",
      "id": "task461-4033ee9ca56644de8b02e5d8581a4981",
      "output": [
        "Mitä posteriorisen jakauman eri ominaisuuksia tutkielmassa tarkastellaan?"
      ]
    },
    {
      "input": "Tätä viitekehystä voidaan soveltaa vertailtaessa erilaisia kultaisia standardeja, harkittaessa uuden kultaisen standardin suunnitteluvalintoja ja suoritettaessa ehdotetun lähestymistavan laadullisia virheanalyysejä.",
      "id": "task461-3dcde36913c74a659644804bb7987d01",
      "output": [
        "Ovatko he yrittäneet korjata MRC:n kultaisia standardeja havaintojensa mukaisesti? "
      ]
    },
    {
      "input": "Kansallisessa jengiuhkien arviointiraportissa vahvistetaan, että ainakin kymmenet tuhannet jengiläiset käyttävät jokapäiväisessä elämässään Twitterin kaltaisia sosiaalisia verkostosivustoja ja YouTuben kaltaisia videonjakosivustoja BIBREF0 . He ovat hyvin aktiivisia verkossa; National Assessment Centerin vuonna 2007 tekemän jengiläisiä koskevan tutkimuksen mukaan 25 prosenttia jengiläisistä käyttää Internetiä vähintään neljä tuntia viikossa BIBREF4 .",
      "id": "task461-c476bbcab0ed49ddaaac9822ec5aedbd",
      "output": [
        "Esittävätkö kirjoittajat todisteita siitä, että \"useimmat\" katujengien jäsenet käyttävät Twitteriä toisten pelotteluun?"
      ]
    },
    {
      "input": "Toisin kuin tekstimuotoisen datan kohdalla, tässä asiakirjassa tavoitteenamme on tutkia suurta määrää kategorista dataa, joka usein kerätään matkatutkimuksissa. Tällaisia ovat esimerkiksi matkan tarkoitus, koulutustaso tai perhetyyppi. Tarkastelemme myös muita muuttujia, jotka eivät välttämättä ole luonteeltaan kategorisia, mutta jotka segmentoinnin vuoksi päätyvät tyypillisesti dummy-koodaukseen, kuten ikä, tulot tai jopa lähtö- ja määräpaikkapari.",
      "id": "task461-5c87cb973b144df69bb6939dcf2c0d12",
      "output": [
        "Miten ne mallintavat matkustuskäyttäytymistä?"
      ]
    },
    {
      "input": "Siksi käytämme vain yksinkertaista yksikerroksista RNN:ää, jossa on LSTM-kenno, luokittelemaan esikäsitellyt lauseet ironisiin ja ei-ironisiin lauseisiin, koska LSTM-verkkoja käytetään laajalti ironian havaitsemisessa.",
      "id": "task461-124b9355aebd4c9c8435d07f5cb33a13",
      "output": [
        "Miten kirjoittajat löysivät ironista dataa Twitteristä?"
      ]
    },
    {
      "input": "Kuvassa FIGREF18 esitetään annotoijien välisten merkintöjen sekoitusmatriisit lämpökarttoina.",
      "id": "task461-3aa4de9b15da4e8a8fac7c3f96d8c53f",
      "output": [
        "Miten annotaatiokokeilua arvioidaan?"
      ]
    },
    {
      "input": "Kukin tietokokonaisuus koostui viidestä arabian murteesta: Egyptin (EGY), Levantin (LEV), Persianlahden (GLF), Pohjois-Afrikan (NOR) ja modernin standardiarabian (MSA) murteet.",
      "id": "task461-1bc92c2f312941439eef22c39a92ebcc",
      "output": [
        "Mitkä ovat neljä arabian murretta?"
      ]
    },
    {
      "input": "Toisin kuin skaalattu pistepotentiaalihuomio, Gaussin maskeeraama suuntakohtainen huomio odottaa kiinnittävänsä huomiota kunkin aseman vierekkäisiin merkkeihin ja valaa merkkien välisen paikallisuussuhteen kiinteänä Gaussin painoarvona huomiolle. Oletamme, että Gaussin paino perustuu vain merkkien väliseen etäisyyteen.",
      "id": "task461-08aa1ce006dd426da5b85e1c39e65bb1",
      "output": [
        "Miten Gaussin naamioitu suunnattu monipäinen huomio toimii?"
      ]
    },
    {
      "input": "Kuten kuvassa FIGREF3 on esitetty, mallimme sisältää kaksi keskeistä komponenttia, nimittäin lyhennetyn historian ja huomion (Truncated History-Attention, THA) ja valikoivan transformaatioverkon (Selective Transformation Network, STN), jotka kuvaavat näkökohtien havaitsemishistoriaa ja mielipiteiden yhteenvetoa. THA ja STN rakentuvat kahdesta LSTM:stä, jotka tuottavat alkuperäiset sanarepresentaatiot ensisijaista ATE-tehtävää varten ja ylimääräistä mielipiteiden havaitsemistehtävää varten. THA on suunniteltu integroimaan näkökohtien havaitsemishistorian tiedot nykyiseen näkökohtaominaisuuteen uuden historiatietoisen näkökohtaesityksen luomiseksi. STN laskee ensin uuden mielipide-esityksen, joka perustuu nykyiseen aspekti-ehdokkaaseen. Sen jälkeen käytämme bilineaarista huomioverkkoa laskeaksemme mielipiteen yhteenvedon uusien mielipide-esitysten painotettuna summana sen mukaan, miten ne liittyvät nykyiseen näkökohtaesitykseen. Lopuksi historiatietoinen näkökohtaesitys ja mielipiteiden yhteenveto yhdistetään ominaisuuksiksi, joita käytetään nykyisen ajanjakson näkökohtien ennustamiseen.",
      "id": "task461-8bd6fcc481494b46afc78e21c15d4de6",
      "output": [
        "Miten he määrittävät lausuntoyhteenvedon?"
      ]
    },
    {
      "input": "Taulukossa TABREF19 esitetään neljän perustason suorituskyky ReviewQA:n testijoukossa. Nämä tulokset ovat näiden neljän mallin omalla toteutuksella saavutettu suorituskyky.",
      "id": "task461-9c57f3c25dfc4d8ca96837e642974244",
      "output": [
        "Mitä tehtäviä arvioitiin?"
      ]
    },
    {
      "input": "Kun otetaan huomioon parannukset, jotka RNN-malli saavutti enemmistön perustasoon verrattuna sekä muiden kuin englannin kielen osalta (keskimäärin 22,76 % suhteellinen parannus; 15,82 % suhteellinen parannus espanjan kielen osalta, 72,71 % vs. 84,21 %, 30,53 % suhteellinen parannus turkin kielen osalta, 56,97 % vs. 84,21 %). 74,36 %, 37,13 % suhteellinen parannus hollannin kielessä, 59,63 % vs. 81,77 %, ja 7,55 % suhteellinen parannus venäjän kielessä, 79,60 % vs. 85,62 %) ja englanninkielisissä testisarjoissa (27,34 % suhteellinen parannus), voimme tehdä johtopäätöksen, että mallimme on vankka käsittelemään useita kieliä.",
      "id": "task461-cf20de288c28467dab4534d984748467",
      "output": [
        "Minkä muun kuin englannin kielen tulos oli paras?",
        "Minkä muun kuin englannin kielen tulokset olivat huonoimmat?"
      ]
    },
    {
      "input": "Käytämme kaikissa tehtävissä TensorFlow-toteutusta. AraNet ennustaa sosiaalisen median viesteistä ikää, murretta, sukupuolta, tunteita, ironiaa ja tunteita. Se tarjoaa huippuluokan ja kilpailukykyisen suorituskyvyn näissä tehtävissä, ja sen etuna on, että se käyttää yhtenäistä, yksinkertaista kehystä, joka perustuu äskettäin kehitettyyn BERT-malliin. ",
      "id": "task461-092b01ae2516431986f1707f2c1ecd16",
      "output": [
        "Kokeilivatko he kaikkia tehtäviä?"
      ]
    },
    {
      "input": "E2E NLG -haasteiden tietokanta: E2E-haastetietokannan harjoitusjoukko, joka koostuu 42 000 näytteestä, jaettiin satunnaisprosessin avulla 10 000 paritettuun ja 32 000 parittomaan tietokokonaisuuteen.  Wikipedia Company -tietokanta: Jaksossa SECREF18 esitelty Wikipedian yritystietokanta suodatettiin siten, että se sisälsi vain yrityksiä, joiden tiivistelmä oli vähintään 7 sanaa ja enintään 105 sanaa. Tämän jälkeen tietokokonaisuus jaettiin seuraaviin osiin: harjoitusjoukko (35K), kehitysjoukko (4,3K) ja testijoukko (4,3K). Koulutusjoukko jaettiin myös parittaisten ja parittomien tietokokonaisuuksien saamiseksi. ",
      "id": "task461-d731f47d4d604f15955dcdc65909928c",
      "output": [
        "Mitä ei-annotoituja tietokokonaisuuksia otetaan huomioon?"
      ]
    },
    {
      "input": "Tuloksena saatu vektorisarja koodataan LSTM-koodaimella. ",
      "id": "task461-2482373ac8e8414794eba6a6c3c5506d",
      "output": [
        "Mikä on kooderin arkkitehtuuri?"
      ]
    },
    {
      "input": "Havaitsemme, että BIBREF27 zhao2018valvomaton käyttää joukkoa erillisiä muuttujia, jotka määrittelevät vastauksen korkean tason ominaisuudet. Vaikka ne tulkitsevat opittujen diskreettien latenttien muuttujien merkityksiä klusteroimalla tiedot tiettyjen luokkien (esim. dialogitekojen) mukaan, tällaisilla latenteilla muuttujilla ei silti ole tarkkoja merkityksiä. Meidän mallissamme yhdistämme jokaisen latentin muuttujan sanastossa olevaan sanaan, joten jokaisella latentilla muuttujalla on tarkka semanttinen merkitys. Lisäksi he keskittyvät monikierroksisen dialogin tuottamiseen ja esittelivät kontekstista opitun, valvomattoman diskreetin lause-esityksen oppimismenetelmän, kun taas me keskitymme ensisijaisesti yhden kierroksen dialogin tuottamiseen ilman kontekstitietoa.",
      "id": "task461-cf608e8650a54d1b9af5edaaf4f5c066",
      "output": [
        "Miten erillisellä latentilla muuttujalla on eksplisiittinen semanttinen merkitys CVAE:n parantamiseksi lyhyen tekstin keskusteluissa?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa käytettiin seuraavia tietolähteitä RNN-T:n ja siihen liittyvien RNN-LM:ien harjoitteluun.Lähdealueeseen perustuva RNN-T: noin 120 miljoonaa segmentoitua lausetta (190 000 tuntia ääntä) YouTube-videoista, ja niihin liittyvät transkriptiot, jotka saatiin puolivalvotusta kuvatekstien suodatuksesta BIBREF28.Lähdealueeseen perustuva normalisoiva RNN-LM: transkriptiot samasta 120 miljoonan lausekkeen YouTube-harjoittelusarjasta. Tämä vastaa noin 3B tokenia käytetyistä alasanayksiköistä (ks. jäljempänä, SECREF30).Kohdealue RNN-LM: 21M pelkkää tekstiä sisältävää lausetason transkriptiä anonymisoidusta, manuaalisesti transkriptoidusta äänitiedostosta, joka edustaa erään Voice Search -palvelun tietoja. Tämä vastaa noin 275M sanan alitunnusta.Kohdealueen RNN-T hienosäätöaineisto: 10K, 100K, 1M ja 21M lausetason {audio, transkriptio} paria, jotka on otettu anonymisoidusta, transkriptoidusta Voice Search -datasta. Nämä hienosäätöjoukot vastaavat karkeasti 10 tuntia, 100 tuntia, 1000 tuntia ja 21 000 tuntia ääntä.",
      "id": "task461-4ae2c652813249f595d64971e7ba1f77",
      "output": [
        "Kuinka paljon harjoitusaineistoa käytetään?",
        "Miten koulutustiedot kerätään?"
      ]
    },
    {
      "input": "Arvioimme lausetason semantiikkaa käyttämällä keskiarvotettuja vektoripussin (BoV) esityksiä BIBREF:n21 Semanttinen tekstuaalinen samankaltaisuus (STSB) -tehtävässä ja SentEval BIBREF:n22 Sanasisältö (WC) -tehtävässä (tunnista sanaluettelosta, mikä sisältyy lauseen esitykseen). Syntaksi: Vastaavasti käytämme Google Syntactic analogies (GSyn) BIBREF9 -tehtävää sanatason syntaktisen tiedon arvioimiseksi ja SentEval BIBREF22 -tehtävän Depth (Dep) ja Top Constituent (TopC) (syötteen lauseen rakenneosan jäsennyspuun) koettelutehtäviä lausetason syntaksin arvioimiseksi.",
      "id": "task461-7f6be152ac9b4f128580dd3f0527653c",
      "output": [
        "Mitä semanttisia ja syntaktisia tehtäviä käytetään koekappaleina?"
      ]
    },
    {
      "input": "TED-puheiden automaattiset käännökset sisältävät enemmän sanoja kuin vastaava viitekäännös, mikä tarkoittaa, että tämäntyyppisissä konekäännetyissä teksteissä on myös enemmän potentiaalisia tokeneita, jotka voivat muodostaa coreference-suhteen, mikä saattaa olla osoitus läpilyöntivaikutuksesta. Samaa ei tapahdu uutistestijoukon kohdalla. Näemme, kuinka NMT-käännökset lisäävät $30\\%$-mainintojen määrää suhteessa ihmisviittauksiin, mikä osoittaa jopa selvempää eksplikointivaikutusta kuin ihmiskäännökset.",
      "id": "task461-dd1c286e78f44150b3f9b40de93bcccb",
      "output": [
        "Mitä käännösvaikutuksia analyysissä on havaittu?"
      ]
    },
    {
      "input": ". Tässä työssä haastamme nykyiset esitystekniikat ja ehdotamme tilan esittämistä luonnollisella kielellä, joka vastaa tapaa, jolla me ihmiset tiivistämme ja siirrämme tietoa tehokkaasti toisesta toiseen BIBREF5.",
      "id": "task461-b39f05e2b39c41e99140b48276692d5d",
      "output": [
        "Miten oppimisen ja tehtävien suorittamisen tila esitetään luonnollisen kielen avulla?"
      ]
    },
    {
      "input": "Malli koostuu yhdestä LSTM-kerroksesta, jota seuraa kolme tiheää kerrosta. LSTM-kerroksessa käytetään pudotusarvoa 0,2. ",
      "id": "task461-db0b60837cea43ad9ed42f9c8ac44eb7",
      "output": [
        "Käyttävätkö he dropoutia?"
      ]
    },
    {
      "input": " Kokeellisesti kolmessa konekääntämisen vertailutietokannassa - WMT2014, WMT2016 ja IWSLT-2014 - FlowSeq saavuttaa vertailukelpoisen suorituskyvyn ei-autoregressiivisten mallien kanssa ja lähes vakio dekoodausajan sekvenssin pituuden suhteen verrattuna tyypilliseen vasemmalta oikealle Transformer-malliin, joka on super-lineaarinen.",
      "id": "task461-f42beceab3514b41bbaa8f6109f9b108",
      "output": [
        "Mitä kolmea neuraalisen konekääntämisen (NMT) vertailutietoaineistoa käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Upotimme COSTRA-lauseet LASER BIBREF15 -menetelmällä, joka toimi erittäin hyvin lineaaristen suhteiden paljastamisessa BaBo2019:ssä.",
      "id": "task461-2472a4a7d7524688b7930bc0157b96c3",
      "output": [
        "Onko joitakin perusmalleja koulutettu tällä tietokokonaisuudella?"
      ]
    },
    {
      "input": "Sen lisäksi poimimme jokaisesta arvostelusta kolme käsin laadittua polariteettipistemäärää, jotka ovat minimi-, keski- ja maksimipolariteettipisteet. Nämä sanojen polariteettipisteet lasketaan kuten (DISPLAY_FORM4). Jos esimerkiksi arvostelu koostuu viidestä sanasta, sillä on viisi polariteettipistemäärää, ja käytämme vain kolmea näistä tunnepistemääristä, kuten mainittiin. Lopuksi yhdistämme nämä kolme pistettä arvostelukohtaiseksi keskimääräiseksi sanavektoriksi, eli kutakin arvostelua edustaa sen muodostavien sanojen upotusten keskimääräinen sanavektori ja kolme valvottua pistettä. Tämän jälkeen syötämme nämä syötteet SVM-menetelmään. Kehyksemme vuokaavio on esitetty kuvassa KUVA 11. Kun yhdistämme valvomattomat piirteet, jotka ovat sanavektoreita, jotka on luotu sanakohtaisesti, kolmeen valvottuun pisteytykseen, jotka on poimittu arvostelukohtaisesti, saamme parempia huipputason tuloksia.",
      "id": "task461-5861aa1e69004d0e9119b4448db4332f",
      "output": [
        "Mitkä käsityönä tehdyt ominaisuudet yhdistetään word2veciin?"
      ]
    },
    {
      "input": "Dialoginen teko (DA) kuvaa puhujan aikomuksen tyyppiä lausuman tuottamisen aikana, ja se vastaa suunnilleen BIBREF0:n illokuutioaktia tai BIBREF1:n puheaktia. DA:n tunnistaminen on olennaista diskurssin rakenteen mallintamisessa ja automaattisessa havaitsemisessa, erityisesti kehitettäessä ihmisen ja koneen välistä dialogijärjestelmää. On luonnollista ennustaa kysymys-tyyppisen lausuman jälkeiset vastausaktit ja sitten sovittaa kysymys-lausuma kuhunkin QA-pariin tietämyskannassa. Ennustettu DA voi myös ohjata vastauksen generointiprosessia BIBREF2. Esimerkiksi järjestelmä luo tervehdystyyppisen vastauksen entiseen tervehdystyyppiseen lausahdukseen. DA:n tunnistamisen tarkoituksena on antaa merkintä jokaiselle keskustelun lausumalle. Se voidaan muotoilla valvotuksi luokitusongelmaksi. Ongelman ratkaisemiseksi on kaksi suuntausta: 1) sekvenssilappuongelmana se ennustaa kaikkien koko keskusteluhistorian lausumien leimat BIBREF13, BIBREF14, BIBREF9; 2) lauseenluokitusongelmana se käsittelee lausumia itsenäisesti ilman mitään kontekstihistoriaa BIBREF5, BIBREF15. ",
      "id": "task461-9d702d3c2bcb4a21b1be142f09a65575",
      "output": [
        "Mitä on vuoropuhelun tunnistaminen?"
      ]
    },
    {
      "input": "Yksi SCRF-mallien suurimmista haitoista on niiden korkeat laskentakustannukset. Kokeissamme CTC-malli on noin 3-4 kertaa nopeampi kuin SRNN-malli, joka käyttää samaa RNN-kooderia. Laskentakustannusten alentamiseksi tutkimme, voidaanko CTC:tä käyttää RNN-kooderin esivalmennukseen yhteisen mallin harjoittelun nopeuttamiseksi. Kuvassa 2 esitetään yhteisen mallin konvergenssikäyrät CTC:n esivalmennuksen kanssa ja ilman sitä, ja nähdään, että esivalmennus todellakin parantaa yhteisen mallin konvergenssinopeutta.",
      "id": "task461-627aca31c6834d719e7b64326809be6e",
      "output": [
        "Voidaanko SCRF:ää käyttää mallin esivalmennukseen?"
      ]
    },
    {
      "input": "Tältä osin havaitsimme, että HDGAN tuotti suhteellisesti parempia visuaalisia tuloksia CUB- ja Oxford-tietokannoissa, kun taas AttnGAN tuotti muita huomattavasti vaikuttavampia tuloksia monimutkaisemmassa COCO-tietokannassa. Mitä tulee inception score (IS) -mittariin, jota sovellettiin useimpiin malleihin DC-GANia lukuun ottamatta, taulukossa TABREF48 esitetyt tulokset osoittavat, että StackGAN++ paransi vain hieman edeltäjäänsä StackGANia teksti-kuvasynteesissä. Taulukon TABREF48 tulokset osoittavat myös, että DM-GAN BIBREF53:n suorituskyky on paras, ja seuraavaksi paras on Obj-GAN BIBREF81. Huomaa, että sekä DM-GAN että Obj-GAN ovat alan viimeisimpiä kehitettyjä menetelmiä (molemmat julkaistu vuonna 2019), mikä osoittaa, että tekstistä kuvaan -synteesin tutkimus parantaa jatkuvasti tuloksia paremman visuaalisen hahmottamisen ja kuuntelun saavuttamiseksi.",
      "id": "task461-e71b00b5c41d4de7979d550d1d677ea2",
      "output": [
        "Mikä on ehdotetun ratkaisun vertailun johtopäätös?"
      ]
    },
    {
      "input": "Lopullisessa koulutusprosessissa käytetään 500 validointidataa rekursiivisen neuromallin luomiseen, mikä on 3 % koulutusdatasta. Koulutuksen päätyttyä lähdekorpuksen validointidataa käyttävän mallin tarkkuus oli 74,40 %.",
      "id": "task461-8470b4c39f224b4b9cc998ad94d0e906",
      "output": [
        "Mitä tietokokonaisuutta käytetään tarkkuuden mittaamiseen?"
      ]
    },
    {
      "input": "Testausta varten sovelsimme TongueNetiä myös UBC:n BIBREF14-tietokantaan ilman harjoittelua, jotta näimme mallin yleistämiskyvyn.",
      "id": "task461-202403332b1e4addba3505445b78b4d1",
      "output": [
        "Mitä aiemmin kommentoituja tietokantoja on saatavilla?"
      ]
    },
    {
      "input": "Arvioimme perusmallia ja malliamme käyttäen mittarina tarkkuutta ROCStories-tietokannassa ja esitimme yhteenvedon tuloksista taulukossa 2 .",
      "id": "task461-691a15904a4c40fbb84d0da47e813c3f",
      "output": [
        "Millä mittareilla he arvioivat?"
      ]
    },
    {
      "input": "Toiseksi tutkimme Washington Postin vaikutusta käyttäjien näkemyksiin. Tämä tehdään tarkastelemalla väittelyn ehdokkaiden mielipiteitä (voittajien ennustamiseksi) ennen ja jälkeen sen, kun Washington Postin asiantuntijat ovat ilmoittaneet voittajat. Näin voimme nähdä, onko Washington Postilla ollut vaikutusta käyttäjien mielipiteisiin. Washington Postin ehdottamat voittajat näkyvät taulukossa TABREF35. ",
      "id": "task461-6ce9d88cca3748dd915f474e26253304",
      "output": [
        "Miten saadaan selville, kuka voitti väittelyn?"
      ]
    },
    {
      "input": "Lisäksi meillä on toinen riippumaton inhimillinen arviointitehtävä tyylin voimakkuudesta - esitämme TitleStylistin ja perustasojen tuottamat otsikot inhimillisille tuomareille ja annamme heidän valita sen, joka vastaa parhaiten tavoiteltua tyyliä, kuten huumoria. Tämän jälkeen määrittelemme tyylin vahvuuden pistemäärän valintojen osuutena.",
      "id": "task461-4cd8f8807cc24079b24728bd06a40852",
      "output": [
        "Miten kolmen kohdetyylin olemassaolo havaitaan?"
      ]
    },
    {
      "input": "Vaikka tietokokonaisuuksien ja lähdekoodien jakamiseen on panostettu suosituilla ohjelmistokehitysalustoilla, kuten GitHubissa (github.com) tai Zenodossa (zenodo.org), muiden ryhmien tietojen tai koodin käyttäminen on edelleen haasteellista.",
      "id": "task461-c997a472362740aa8086a1d0421ba4be",
      "output": [
        "Ovatko tietokokonaisuudet julkisesti saatavilla?"
      ]
    },
    {
      "input": "Kaiken kaikkiaan havaitsemme positiivisen korrelaation uudelleentwiittauksen ja yhteisäänestyksen välillä, joka eroaa merkittävästi nollasta. Vahvimmat positiiviset korrelaatiot ovat vapauden, turvallisuuden ja oikeuden alueella, unionin ulkosuhteissa ja sisämarkkinoilla. Heikompia, mutta silti positiivisia korrelaatioita havaitaan aloilla Taloudellinen, sosiaalinen ja alueellinen yhteenkuuluvuus, Euroopan kansalaisuus sekä unionin tila ja kehitys. Ainoa poikkeus, jonka kerroin on merkitsevästi negatiivinen, on talous- ja valuuttajärjestelmä. Tämä tarkoittaa, että talous- ja rahajärjestelmän alalla havaitaan merkittävä poikkeama tavanomaisista yhteisäänestysmalleista.",
      "id": "task461-3a58643627c24a699d90c744a71828e9",
      "output": [
        "Mikä on yhteisäänestys- ja uudelleentwiittaustottumusten välinen suhde?"
      ]
    },
    {
      "input": "Korkeampi pistemäärä tarkoittaa parempaa vaihejärjestystä (maksimipistemäärä on 2). tab:coherencemetrics osoittaa, että personoidut mallit saavuttavat keskimääräiset reseptitason koherenssiarvot 1,78-1,82, mikä ylittää perustason 1,77. Ihmisarvioijat pitivät keskimäärin 63 %:ssa tapauksista personoituja mallituloksia parempina kuin perustasoa, mikä vahvistaa, että personoitu huomio parantaa tuotettujen reseptien semanttista uskottavuutta.",
      "id": "task461-a9df9ec4582041178079e604f00f1485",
      "output": [
        "Millaisia tuloksia he saivat uudella aineistolla?"
      ]
    },
    {
      "input": "Itse asiassa, kun ymmärsimme suuren tekstikorpuksen tarpeellisuuden Sindhille, aloitimme tämän tutkimuksen keräämällä raakakorpuksen useista verkkoresursseista käyttäen web-scrappy-kehystä uutispalstojen uutisoimiseksi päivittäisistä Kawish- ja Awami Awaz Sindhi -sanomalehdistä, Wikipedian dumpeista, novelleista ja urheilu-uutisista Wichaarin yhteiskunnallisesta blogista, uutisista Focus Word press -blogista, historiallisista kirjoituksista, romaaneista, tarinoista, kirjoista Sindh Salamatin kirjallisilta verkkosivustoilta, romaaneista, historiallisista ja uskonnollisista kirjoista Sindhi Adabi Boardista ja uutisia ja urheilua koskevista twiiteistä, jotka on kerätty twitteristä.",
      "id": "task461-1fd42b0176a9483fae035c96ee6040a3",
      "output": [
        "Miten tiedot on kerätty, mitä verkkolähteitä on käytetty?"
      ]
    },
    {
      "input": "CNN:ää voidaan käyttää myös sarkasmiaineistoissa sarkastisten ja ei-sarkastisten twiittien tunnistamiseen. Kutsumme tästä verkosta poimittuja piirteitä peruspiirteiksi, menetelmää perusmenetelmäksi ja tässä perusmenetelmässä käytettyä CNN-arkkitehtuuria perus-CNN:ksi. Koska täysin kytketyssä kerroksessa on 100 neuronia, meillä on kokeessamme 100 peruspiirrettä. ",
      "id": "task461-5a5f739dbac44d629a7ca6b63a83dca9",
      "output": [
        "Mitkä ovat verkon perusominaisuudet?"
      ]
    },
    {
      "input": "Se on harjoitusajan kannalta kertaluokkaa tehokkaampi. Malli on monimutkainen sekä toteutuksen että suoritusajan kannalta. Malli vaatii esivalmennusta ja keskinäistä oppimista ja vaatii päiviä harjoitteluaikaa, kun taas ehdottamamme yksinkertainen arkkitehtuuri vaatii noin tunnin (ja se on helppo toteuttaa). MGNC-CNN on yleensä parempi kuin MG-CNN. Subj-tietokannassa MG-CNN saavuttaa itse asiassa hieman parempia tuloksia kuin BIBREF11 , ja sen monimutkaisuus ja koulutukseen tarvittava aika ovat huomattavasti pienemmät (MGNC-CNN toimii tässä vertailukelpoisesti, vaikkakaan ei paremmin).",
      "id": "task461-7b17696523484b27b9ef0af0c57ab335",
      "output": [
        "Kuinka paljon nopeampi MGNC-CNN:n koulutusaika on peruslinjoihin verrattuna?"
      ]
    },
    {
      "input": "Taivutuksen realisaatio määrittelee lekseemin/lemman taivutetut muodot. Laskennallisena tehtävänä, johon usein viitataan nimellä \"morfologinen taivutus\", taivutuksen toteutus on kartoitus, jossa lemman ja morfologisten tunnisteiden yhdistäminen yhdistetään vastaavaan sanamuotoon. Esimerkiksi SJQ Chatino -verbimuotojen taivutuksen realisointi tarkoittaa, että lemman lyu1 `putoaa' ja tag-joukon 1;SG;PROG yhdistäminen yhdistetään sanamuotoon nlyon32. Morfologisen analyysin tehtävänä on morfosyntaktisen kuvauksen luominen tietylle sanalle. Se voidaan laatia kontekstista riippumatta (kuten meidän tapauksessamme) tai tietyn kontekstin sisällä, kuten esimerkiksi SIGMORPHON 2019:n toisen jaetun tehtävän BIBREF11 yhteydessä.",
      "id": "task461-4f327f40875d49edb13975114cdc81ba",
      "output": [
        "Miten morfologinen analyysi eroaa morfologisesta taivutuksesta?"
      ]
    },
    {
      "input": "Tämän jälkeen määrittelemme INLINEFORM7:n ja INLINEFORM8:n välisen samankaltaisuuden seuraavasti: DISPLAYFORM0 Huomaamme, että edellä lauseille määriteltyä samankaltaisuusmittaria voidaan soveltaa yhtä lailla myös n-grammien hakuun.",
      "id": "task461-a3d3d08a2f854876a3fd6b4d04b1138d",
      "output": [
        "Mitä samankaltaisuusmittaria he käyttävät n-grammin hakumenetelmässään?"
      ]
    },
    {
      "input": "Jaetut itsetarkkailukerrokset Koska mallimme tarjoaa kaksi tulostetta yhdestä syötteestä, on olemassa kaksijakoinen asetus sille, kuinka paljon jaettua osaa tulisi määrittää. Sekä konstituentti- että riippuvuusjäsennyksen jäsentäjät jakavat tokenin esityksen ja enintään 8 itsehuomautuskerrosta. Jos oletetaan, että kumpikin jäsentäjä ottaa aina syötteen tietovirran 8 itsehuomautuskerroksen kautta, kuten kuvassa FIGREF4 on esitetty, jaettujen itsehuomautuskerrosten määrä, joka vaihtelee 0:sta 8:aan, voi kuvastaa jaetun osuuden astetta mallissa. Kun luku on 0, se osoittaa, että vain merkkien esitys on jaettu molemmille jäsentäjille, jotka on koulutettu yhteiseen häviöön kummankin oman 8 itsetarkkailukerroksen kautta. Kun luku on pienempi kuin 8, esimerkiksi 6, se tarkoittaa, että molemmat jäsentäjät jakavat ensin 6 kerrosta merkkien esittämisestä ja sitten omat 2 itsetarkkailukerroksensa. Eri jaettujen kerrosten lukumäärillä saadut tulokset ovat taulukossa TABREF14. Poistamme konstituentti- ja riippuvuusjäsennyksen jäsentäjän käytöstä, jotta saamme mallissamme molemmille jäsentäjille erilliset oppimisasetukset. Taulukossa TABREF14 oleva vertailu osoittaa, että vaikka jaettuja itsehuomautuskerroksia ei olekaan, mallimme yhteinen harjoittelu voi olla huomattavasti parempi kuin erillinen oppimistila. Paras suorituskyky saavutetaan edelleen jakamalla kaikki 8 itsetarkkailukerrosta.",
      "id": "task461-13727fa8285f48f991490e8708a12402",
      "output": [
        "Miten eri verkkokomponentteja arvioidaan?"
      ]
    },
    {
      "input": "Chatbottien arviointi on edelleen avoin ongelma alalla. Viimeaikaiset työt BIBREF25 ovat osoittaneet, että konekääntämisestä lainatut automaattiset arviointimittarit, kuten BLEU-pisteet BIBREF26 , vastaavat yleensä huonosti ihmisen arviointia. Sen vuoksi tässä asiakirjassa käytetään pääasiassa inhimillistä arviointia ja perpleksisyyttä, kuten aiemmissa töissä on tehty.",
      "id": "task461-ef8f6ccd807045a59902c63a9c2915d3",
      "output": [
        "Mitataanko jotain muita mittareita kuin hämmennystä?"
      ]
    },
    {
      "input": "Kokeilemme ja arvioimme mallejamme Manner-Kiinan siviilioikeudellisessa järjestelmässä. Keräämme ja rakennamme laajamittaisen reaalimaailman aineiston INLINEFORM0-tapausasiakirjoista, jotka Kiinan kansantasavallan korkein kansantuomioistuin on asettanut julkisesti saataville.",
      "id": "task461-f2cae67a5622401eb1215a218b4e49a4",
      "output": [
        "Mikä on todellisen siviilitapaustietokannan koko?"
      ]
    },
    {
      "input": "Teho-osaston muistiinpanoissa (esim. tekstiesimerkki vasemmassa ylälaatikossa kuvassa 2) tunnistetaan ensin kaikki lyhenteet säännöllisten lausekkeiden avulla ja yritetään sitten löytää näiden lyhenteiden kaikki mahdolliset laajennukset aluespesifisestä tietopohjasta ehdokkaiksi.",
      "id": "task461-3e373381cd624f90b5acdc5d0dc18dd8",
      "output": [
        "Käyttävätkö he mitään tietopohjaa lyhenteiden laajentamiseen?",
        "Miten he tunnistavat lyhenteet?"
      ]
    },
    {
      "input": "d Kokeet kahdella vertailuaineistolla, Stanford Sentiment Treebank BIBREF7 ja AG English news corpus BIBREF3 , osoittavat, että 1) menetelmämme saavuttaa erittäin kilpailukykyisen tarkkuuden, 2) jotkin näkemykset erottuvat muista luokittelemalla tietyt luokat paremmin ja 3) kun perus-sanapussi-ominaisuusjoukkoamme täydennetään konvoluutio-ominaisuuksilla, menetelmä saavuttaa molemmissa aineistoissa uuden huipputason.  Stanford Sentiment Treebank AG Englanninkielinen uutiskorpus. ",
      "id": "task461-f52923d93a864498a21d3b437c0c5291",
      "output": [
        "Millaisia vertailutehtäviä he kokeilivat?"
      ]
    },
    {
      "input": "Rakensimme yhdistetyt ennusteet valitsemalla verkon vastauksen, jonka todennäköisyys oli suurin, ja valitsemalla ei vastausta, jos jokin verkko ei ennustanut mitään vastausta.",
      "id": "task461-a2ad93ebef324716b23de85d4e8ec3e2",
      "output": [
        "Mitä ensemble-menetelmiä käytetään parhaan mallin löytämiseksi?"
      ]
    },
    {
      "input": "Nämä ovat neljä konjunktiokirjoitettua ngunin kieltä (zul, xho, nbl, ssw), afrikaans (afr) ja englanti (eng), kolme disjunktiokirjoitettua sothon kieltä (nso, sot, tsn) sekä tshiVenda (ven) ja Xitsonga (tso). Nguni-kielet ovat keskenään samankaltaisia ja niitä on vaikeampi erottaa toisistaan. Sama pätee myös sothokieliin. Samankaltaisia kieliä ovat:- Nguni-kielet: zul, xho, nbl, ssw- Sotho-kielet: nso, sot, tsn.",
      "id": "task461-c10579b6c08a4c98bc02a00374f98d90",
      "output": [
        "Mitkä kielet muistuttavat toisiaan?"
      ]
    },
    {
      "input": "Tulokset paljastavat, että vastoin yleistä käsitystä Rougen ja Pyramidin pisteiden väliset korrelaatiot ovat heikkoja, mikä kyseenalaistaa sen tehokkuuden tieteellisessä tiivistämisessä. Lisäksi eri Rouge-muunnosten ja manuaalisten arviointien välisten korrelaatioiden välinen vaihtelu on suurta, mikä tekee Rougen luotettavuudesta tieteellisten tiivistelmien arvioinnissa entistä epäselvempää.",
      "id": "task461-8f90a7080d9647e69619b142fc2e1e7c",
      "output": [
        "Mikä on se yleinen uskomus, jonka tämä asiakirja kumoaa? (esim. \"vastoin yleistä uskomusta ROUGE ei ole kovinkaan luotettava\")."
      ]
    },
    {
      "input": "Ehdotamme, että ihmisen ja ihmisen välisistä vuoropuheluista johdetaan palkintoja antamalla positiivisia arvoja aineistossa havaituille kontekstisidonnaisille vastauksille ja negatiivisia arvoja satunnaisesti valituille vastauksille, jotka johtuvat johdonmukaisuuden puutteesta (joita kutsutaan myös \"ei-ihmisen kaltaisiksi vastauksiksi\") - ks. esimerkki taulukoissa TABREF29 ja TABREF30 .",
      "id": "task461-61b33c2c25154082b15699ff31d5fc03",
      "output": [
        "Miten ne saavat ihmisten tuottamia politiikkoja?"
      ]
    },
    {
      "input": "Ensimmäisessä tehtävässä osallistujia ohjeistettiin lukemaan lauseita luonnollisesti ilman mitään muuta erityistehtävää kuin ymmärtäminen. Osallistujia kehotettiin lukemaan lauseet normaalisti ilman erityisiä ohjeita.",
      "id": "task461-ecbeb42301ef44b3a8303d4fc24034fc",
      "output": [
        "Mikä on normaali lukuparadigma?"
      ]
    },
    {
      "input": "Keräsimme tietokokonaisuuden joukkorahoituksella Amazon Mechanical Turkista (MTurk).",
      "id": "task461-892338991d4e4f76af343d3280a3b7e5",
      "output": [
        "Miten aineisto kerättiin?",
        "Käyttivätkö kirjoittajat joukkoistamisalustoja?"
      ]
    },
    {
      "input": "Rakennamme iSQuAD- ja iNewsQA-aineistot SQuAD v1.1 BIBREF0- ja NewsQA BIBREF1-tietokantojen pohjalta. iMRC: Making MRC Interactive ::: Koska iMRC sisältää sekä MRC:n että RL:n, otamme käyttöön molempien asetusten arviointimittareita. Ensiksi, kysymysten vastaustehtävänä, käytämme $\\text{F}_1$-pistemäärää vertaillaksemme ennustettuja vastauksia perustotuuteen, kuten aiemmissa töissä. Kun on olemassa useita perustotuuden vastauksia, ilmoitamme suurimman $\\text{F}_1$-pistemäärän. Toiseksi, useiden pelien hallitseminen on edelleen melko haastavaa RL-agenttien kannalta. Siksi arvioimme agentin suorituskykyä sekä koulutus- että testausvaiheessa. Koulutuksen aikana raportoimme koulutuskäyrät, jotka on laskettu keskiarvona kolmesta satunnaisesta siemenestä. Testauksen aikana noudatamme valvotun oppimisen tehtävissä yleistä käytäntöä, jossa raportoimme agentin testisuorituksen, joka vastaa sen parasta validointisuoritusta.",
      "id": "task461-1f797c7519834fb3a2e9d0baf4455ab4",
      "output": [
        "Millä perusteella mallit arvioidaan?"
      ]
    },
    {
      "input": "Tehtäväkokoelmaa koskevat toiveemme olivat: riittävä monimuotoisuus, melko suurten tietokokonaisuuksien olemassaolo harjoittelua varten ja onnistuminen itsenäisinä harjoittelutavoitteina lauseiden representaatioille.Monitehtäväinen harjoitteluasetelma",
      "id": "task461-ce4512738b514986a6f9f61c6fe7f376",
      "output": [
        "Minkä malliarkkitehtuurin ne tekevät lauseiden koodaukseen?"
      ]
    },
    {
      "input": "Laajentaaksemme kokeilupohjaamme lisäsimme uusia keskusteluja, joista kustakin on tarkempia tietoja UNKREF6:n taulukossa TABREF24. Uusien keskustelujen valitsemiseksi ja sen määrittämiseksi, ovatko ne kiistanalaisia vai eivät, etsittiin aiheita, joita valtamedia on käsitellyt laajasti ja jotka ovat herättäneet runsaasti keskustelua sekä verkossa että sen ulkopuolella. Keskityimme \"pehmeisiin uutisiin\" ja viihteeseen, mutta myös tapahtumiin, jotka olivat vaikuttavia ja/tai dramaattisia, mutta eivät aiheuttaneet suuria kiistoja. Vahvistaaksemme tämän intuition tarkistimme manuaalisesti otoksen twiittejä, emmekä kyenneet tunnistamaan yhtään selkeää kiistatapausta. Toisaalta kiistanalaisissa keskusteluissa keskityimme poliittisiin tapahtumiin, kuten vaaleihin, korruptiotapauksiin tai oikeuden päätöksiin.",
      "id": "task461-45c02e2c411d424ca7f77695d5ce06a3",
      "output": [
        "Mitä kiistanalaisia aiheita kokeillaan?"
      ]
    },
    {
      "input": "Teemme kokeita WikiSQL BIBREF8 -tietokannalla, joka tarjoaa 87 726 kommentoitua kysymys-SQL-paria 26 375 verkkotaulukosta. Teemme tutkimuksemme SimpleQuestions BIBREF10 -tietokannalla, joka sisältää 108 442 yksinkertaista kysymystä, joihin kuhunkin liittyy subjekti-suhde-objekti-kolmio. Teemme kokeita SequentialQA BIBREF9 -tietokannalla, joka on johdettu WikiTableQuestions BIBREF19 -tietokannasta.",
      "id": "task461-cf4c291bf54c4dceb8f32e1384b071b4",
      "output": [
        "Mitä tietokokonaisuuksia tässä asiakirjassa käytetään?"
      ]
    },
    {
      "input": "Kokeissa tarkastellut vastaustyylit vastasivat kahta tehtävää. NLG-tehtävässä edellytetään hyvin muotoiltua vastausta, joka on abstrakti tiivistelmä kysymyksestä ja kymmenestä kappaleesta, keskimäärin 16,6 sanaa. Kysymys- ja vastaustehtävässä edellytetään myös abstraktia vastausta, mutta siinä suositaan tiiviimpää vastausta kuin NLG-tehtävässä, keskimäärin 13,1 sanaa, jossa monet vastaukset eivät sisällä kysymyksen asiayhteyttä.",
      "id": "task461-5f8ea527d291489e9b9f685bad7d8a58",
      "output": [
        "Mikä on \"vastaustyyli\"?",
        "Mitä he tarkoittavat vastaustyyleillä?",
        "Onko jokaista tietokokonaisuutta kohti olemassa täsmälleen yksi \"vastaustyyli\"?"
      ]
    },
    {
      "input": "Päätimme käyttää kokeilussamme Europarl-tietokokonaisuutta, jossa käytetään WMT:n tietoja11 .",
      "id": "task461-217d96c952c448ecb00dbed4964be978",
      "output": [
        "Onko tätä lähestymistapaa kokeiltu sanojen upotuksissa?"
      ]
    },
    {
      "input": "Jotta voitaisiin luoda minimaalisia pareja, jotka edustavat laajaa valikoimaa kielellisiä kontrasteja, on tarpeen luoda kaikki tietokokonaisuudet keinotekoisesti. Näin varmistetaan sekä se, että meillä on riittävästi esimerkkejä, joita ei voida hyväksyä, että se, että aineisto on täysin kontrolloitua, mikä mahdollistaa yksittäisen kielellisen ilmiön toistuvan eristämisen kussakin paradigmassa BIBREF30. Tietojen luomisessa käytetään perusmallia kunkin paradigman luomiseksi, ja siinä käytetään yli 3000 sanan sanastoa, johon on merkitty morfologiset, syntaktiset ja semanttiset piirteet, joita tarvitaan kieliopillisesti ja semanttisesti onnistuneiden lauseiden luomiseksi. Esimerkit SECREF6 ja SECREF6 osoittavat yhden tällaisen mallin parin \"hyväksyttäville\" ja \"ei-hyväksyttäville\" lauseille: ainoa ero niiden välillä on alleviivattu sana, joka eroaa vain siinä, onko anafora samansuuruinen lukumäärältään kuin edeltäjänsä. Sukupolven koodipohja ja skriptit ovat vapaasti saatavilla. Tämä generointimenettely ei ole rajoittamaton, ja käyttämästämme hyvin yksityiskohtaisesta sanastosta huolimatta syntyy toisinaan epätodennäköisiä lauseita (esim. `Sam juoksi jäätiköiden ympäri'). Näissä tapauksissa sekä hyväksyttävät että hyväksymättömät lauseet ovat kuitenkin yhtä epätodennäköisiä, kun otetaan huomioon maailman tietämys, joten kaikki erot niille annetuissa todennäköisyyksissä johtuvat edelleen tarkoitetusta kieliopillisesta kontrastista.",
      "id": "task461-8c29e490048d457e92365da4f2359a22",
      "output": [
        "Miten tiedot luodaan automaattisesti?"
      ]
    },
    {
      "input": " BIBREF3 käyttää myös kaksikielisiä joukkojen työntekijöitä, mutta tutkimukset, jotka tukevat joukkoistamisen käyttöä monikielisen kääntämisen arvioinnissa, on tehty vanhemmilla monikielisillä järjestelmillä, eivätkä niiden tulokset välttämättä sovellu nykyisten laadukkaampien neuraalisten konekäännösjärjestelmien (NMT) arviointiin. Lisäksi MT-kehittäjät, joihin joukkoistustyöntekijöitä verrattiin, eivät yleensä ole ammattikääntäjiä.  Oletamme, että BIBREF3:ssa sovellettu lauseiden arviointi yksinään estää arvioijia havaitsemasta käännösvirheitä, jotka tulevat esiin vasta, kun lauseiden välinen konteksti on käytettävissä, ja että he arvioivat MT:n laatua huonommin, kun he arvioivat kokonaisia asiakirjoja. BIBREF3 käytti kokeissaan kaikkia WMT 2017 Chinese-English -testisarjan lähdetekstejä, joista vain puolet oli alun perin kirjoitettu kiinaksi; ",
      "id": "task461-9a859081473848c385b7cb1e049b2076",
      "output": [
        "Mikä oli Hassanin ym. arviointisuunnitelman heikkous?"
      ]
    },
    {
      "input": "Mittaamme ensin Logicianin eri komponenttien hyödyllisyyttä optimaalisen mallin valitsemiseksi ja vertaamme sitten tätä mallia uusimpiin menetelmiin neljänlaisissa tiedonlouhintatehtävissä: verbi/prepositio-pohjainen suhde, nominaalinen attribuutti, kuvaileva lause ja hyponymisuhde.",
      "id": "task461-c54fba4fa6c1437e9c373462e5bc726a",
      "output": [
        "Mitä avoimien suhteiden louhintatehtäviä he kokeilivat?"
      ]
    },
    {
      "input": " Perustason määrittämiseksi tarkastelemme satunnaista menetelmää, joka ennustaa positiivisen merkinnän 0,15 todennäköisyydellä (positiivisten tapausten perusprosentti). Tutkiaksemme ominaisuuksiemme hyödyllisyyttä neuraalisessa kehyksessä muokkaamme sanatason tehtäväämme edelleen merkintätehtäväksi ja käytämme LSTM:ää perustasona. Konkreettisesti ketjutamme OP:n ja PC:n siten, että erotinmerkki on erityinen, jotta LSTM-malli voi mahdollisesti erottaa OP:n PC:stä, ja sitten merkitsemme jokaisen sanan sen kantasanan merkinnän perusteella. Käytämme GloVe-sanojen upotuksia sanojen upotusten BIBREF40 alustamiseen. Yhdistämme ehdotetut piirteemme vastaavasta kantasanasta sanan upotukseen; tuloksena oleva ero suorituskyvyssä vanilja-LSTM:n välillä osoittaa ehdotettujen piirteidemme hyödyllisyyden.",
      "id": "task461-8b71ac1b481045bcb5739a78944a6e4a",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Tunnistamme monia erityisiä syntaktisia piirteitä, jotka vaikeuttavat lauseiden luokittelua, ja monia, joiden vaikutus on vähäinen. Esimerkiksi lauseet, joissa on epätavallisia tai merkittyjä argumenttirakenteita, eivät ole keskimääräistä lausetta vaikeampia, kun taas lauseet, joissa on pitkien etäisyyksien riippuvuuksia, ovat vaikeita oppia. Löydämme lauseista myös piirteitä, jotka korostavat tai minimoivat mallien välisiä eroja. Muunnosmallit näyttävät oppivan pitkien etäisyyksien riippuvuudet paljon paremmin kuin rekursiivinen malli, mutta niillä ei ole etua lauseissa, joissa on morfologisia rikkomuksia. Tunnistamme monia erityisiä syntaktisia piirteitä, jotka vaikeuttavat lauseiden luokittelua, ja monia, joiden vaikutus on vähäinen. Esimerkiksi lauseet, joissa on epätavallisia tai merkittyjä argumenttirakenteita, eivät ole keskimääräistä lausetta vaikeampia, kun taas lauseet, joissa on pitkän matkan riippuvuuksia, ovat vaikeita oppia. Löydämme lauseista myös piirteitä, jotka korostavat tai minimoivat mallien välisiä eroja. Muunnosmallit näyttävät oppivan pitkien etäisyyksien riippuvuudet paljon paremmin kuin rekursiivinen malli, mutta niillä ei ole etua lauseissa, joissa on morfologisia rikkomuksia.",
      "id": "task461-62a07cfbb72640b7b29c251fb6bfc805",
      "output": [
        "Mitkä mallit ovat parhaita pitkän matkan liikkumisen oppimiseen?"
      ]
    },
    {
      "input": "CN-Celeb keskittyy erityisesti kiinalaisiin julkkiksiin, ja se sisältää yli 130 000$ lausumia 1000$ henkilöltä.CN-Celeb kattaa useampia puhegenrejä. Keräsimme tarkoituksella tietoja 11 genrestä, mukaan lukien viihde, haastattelu, laulaminen, näytelmä, elokuva, vlogi, suora lähetys, puhe, draama, lausunta ja mainos. Tietyn puhujan puhe voi kuulua useampaan kuin viiteen genreen. Vertailun vuoksi voidaan todeta, että suurin osa VoxCelebissä käytetyistä lausahduksista poimittiin haastatteluvideoista. Genrejen moninaisuus tekee tietokannastamme edustavamman todellisten skenaarioiden kannalta rajoittamattomissa olosuhteissa, mutta myös haastavamman.",
      "id": "task461-9f2cf483ea2844669b2c3a8e0d8c3a6c",
      "output": [
        "Millaisista ympäristöistä lausahdukset ovat peräisin?"
      ]
    },
    {
      "input": "Nämä työntekijät suorittivat 1001 tehtävää: 496 tehtävää valvonnassa ja 505 tehtävää AUI:ssa. ",
      "id": "task461-2bcb546439744165b8114deb04674a38",
      "output": [
        "Kuinka monta vastausta he saivat?"
      ]
    },
    {
      "input": "Vaikka tehtävämme ja vuoden 2013 ShARE/CLEF-tehtävä 1 ovat hyvin samankaltaisia, käytämme vuoden 2010 i2b2/VA:n CE-tehtävän kliinisiä muistiinpanoja, koska 1) vuoden 2010 i2b2/VA:n tiedot ovat helpommin saatavilla ja analysoitavissa ja 2) vuoden 2013 ShARE/CLEF sisältää epäyhtenäisiä kokonaisuuksia, mikä edellyttää monimutkaisempia merkintäjärjestelmiä.",
      "id": "task461-5ac74a81d31e4e3995d09240927d2d64",
      "output": [
        "Mistä he saivat kommentoidut kliiniset muistiinpanot?"
      ]
    },
    {
      "input": "Vastaamattomien kysymysten generointia varten luomme harjoitusaineistoa käyttämällä (uskottavia) vastausvälejä kappaleissa pivotteina, joiden avulla kohdistamme vastattavien kysymysten ja vastaamattomien kysymysten parit. Näin saamme dataa, jonka avulla mallit voivat oppia esittämään vastaamattomia kysymyksiä muokkaamalla vastaavia kysymyksiä sananvaihdoilla, negaatioilla jne.",
      "id": "task461-57822a9f28c2457683447c44392f979e",
      "output": [
        "Miten he varmistavat, että luotuihin kysymyksiin ei voi vastata?"
      ]
    },
    {
      "input": "Tarkastelemme YK:n BIBREF3 -julkaisun kansainvälistä kehitysagendaa YK:n yleiskeskustelujen aineistona (UNGDC), joka sisältää GD:n lausumia vuosilta 1970-2016. ",
      "id": "task461-c7b33b9209fb430bbfc723d063f4ec5e",
      "output": [
        "Onko tietokokonaisuus monikielinen?"
      ]
    },
    {
      "input": "Aloitimme alkuperäisestä korpuksesta, jossa ei ollut tarkistuksia, ja lisäsimme jatkuvasti uusia asiakirjoja ja tarkistimme olemassa olevia asiakirjoja. Käyttämiämme tarkistustoimintoja olivat sanojen, lauseiden, kappaleiden, jaksojen nimien ja asiakirjojen otsikoiden poistaminen, lisääminen ja korvaaminen. Sanojen, ..., jaksojen nimien ja uusien asiakirjojen lisääminen otettiin Wikipedian tiivistelmistä. Loimme kuusi datajoukkoa käyttäen erilaisia satunnaiskylvöjä, ja kukin datajoukko sisälsi kuusi korpusta (Corpus 0 - 5).",
      "id": "task461-75f8d61bc9d5434ba9ad9724555835ba",
      "output": [
        "Mitä simuloituja tietokokonaisuuksia kerätään?"
      ]
    },
    {
      "input": "Neuraalisena luokittelumallina käytämme konvoluutiohermoverkkoa (convolutional neural network, CNN) BIBREF29, joka on aiemmin osoittanut hyviä tuloksia twiittien luokittelussa BIBREF30, BIBREF27.",
      "id": "task461-fad6c260ae154556be3eb81f92eeaea4",
      "output": [
        "Mitä neuraalisia luokittelijoita käytetään?"
      ]
    },
    {
      "input": "Käytämme GPT-muuntajaa (Generative Pre-trained Transformer) BIBREF2 esikoulutettuna kielimallina. ",
      "id": "task461-f49897b4c2b348cb881732a5497b143c",
      "output": [
        "Mitä esivalmennettua LM:ää käytetään?"
      ]
    },
    {
      "input": "Huomaa myös, että tässä tehtävässä ei odoteta täydellistä tarkkuutta, koska voi olla tilanteita, joissa useampi kuin yksi toiminta on järkevää, ja koska kirjailijat kertovat tarinaa leikitellen yllätyksellisyydellä tai epävarmuudella.",
      "id": "task461-bee6ca261b834d8db99cd73f18486bb2",
      "output": [
        "Miksi he pitävät tätä tehtävää vaikeana?  Mikä on lähtötason suorituskyky?"
      ]
    },
    {
      "input": "Welchin t-testin avulla molemmat muutokset weGAN-koulutuksen jälkeen ovat tilastollisesti merkitseviä INLINEFORM0-merkitsevyystasolla. ",
      "id": "task461-56328a4917274237aaad6d731a8d6494",
      "output": [
        "Arvioivatko ne tuotetun tekstin kieliopillisuutta?"
      ]
    },
    {
      "input": "Useissa menetelmissä käytetään ylimääräistä tietoa olioiden havaittuina ominaisuuksina joko yhdistämällä, ketjuttamalla tai keskiarvottamalla olio ja sen ominaisuudet sen upotusten laskemiseksi, kuten numeeriset arvot BIBREF26 (käytämme KBLN:ää tästä työstä verrataksemme sitä lähestymistapaamme, jossa käytetään ylimääräisinä ominaisuuksina vain numeerisia arvoja), kuvat BIBREF27 , BIBREF28 (käytämme ensimmäisessä työssä käytettyä IKRL:ää verrataksemme sitä lähestymistapaamme, jossa käytetään vain kuvia lisäattribuutteina), teksti BIBREF29 , BIBREF30 , BIBREF31 , BIBREF31 , BIBREF32 , BIBREF32 , BIBREF33 , BIBREF34 sekä tekstin ja kuvan yhdistelmä BIBREF35 . Lisäksi BIBREF7 käsittelee monikielistä relaatioiden louhintatehtävää universaalin skeeman aikaansaamiseksi ottamalla huomioon raakatekstin, jossa ei ole merkintöjä, ylimääräisenä ominaisuutena ja käyttämällä matriisitekijöintiä KB- ja tekstisuhteiden yhdistämiseen BIBREF36 . Sen lisäksi, että ylimääräistä tietoa käsitellään ominaisuuksina, graafien upottamista koskevissa lähestymistavoissa BIBREF37 , BIBREF38 otetaan huomioon havaitut attribuutit koodauksen aikana tarkempien upotusten aikaansaamiseksi.",
      "id": "task461-c9c36ce6f6134bc5bbe8fb75526b8284",
      "output": [
        "Mitä muita multimodaalisia tietopohjan upotusmenetelmiä on olemassa?"
      ]
    },
    {
      "input": "Aineisto koostuu monikielisistä sanoista: Se sisältää 20 substantiivia, 20 verbiä ja 10 adjektiivia, ja siinä on 20-100 kontekstia sanaa kohti, yhteensä 4664 kontekstia, jotka on poimittu Open American National Corpus -aineistosta. Kilpailun osallistujien oli jaettava monikielisen sanan kontekstit klustereihin sanan merkityksen mukaan. Tehtävässä voidaan käyttää kahta asetusta: luokiteltu WSI, jossa osallistujat voivat antaa useita aistimuksia sanaa kohti ja ilmoittaa kunkin aistin todennäköisyyden tietyssä kontekstissa, ja ei-luokiteltu WSI, jossa malli määrittää yhden aistin sanalle kontekstissa. Kokeissamme suoritimme luokittelemattoman WSI:n. Katsoimme sopivimmaksi merkitykseksi sen, jolla oli suurin kosinin samankaltaisuus kontekstin upotusten kanssa, kuten kohdassa SECREF9 on kuvattu.",
      "id": "task461-034984dce30d4a08a7a1ed89d5793d49",
      "output": [
        "Miten eri aistit on merkitty/merkitty? "
      ]
    },
    {
      "input": "Tässä työssä kokeissa käytetään IARPA:n babel-ohjelmasta kerättyä BABEL-puhekorpusta. ",
      "id": "task461-e2df6aedd6a740f4990da0373b11ff86",
      "output": [
        "Millä aineistolla kielimallit koulutetaan?"
      ]
    },
    {
      "input": "BIBREF3:n mukaisesti ilmoitetaan BLEU-pisteet ja rakovirheprosentti (ERR). BLEU-pistemäärällä arvioidaan, kuinka luonnollinen tuotettu lausuma on verrattuna ihmislukijoihin. ERR mittaa, kuinka tarkasti slot-tokenit sopivat yhteen ehdokaslausekkeissa. $\\text{ERR}=(p+q)/M$, jossa $M$ on dialogin kokonaislukumäärä ja $p$, $q$ on puuttuvien ja tarpeettomien slottien lukumäärä kyseisessä toteutuksessa. Kustakin vuoropuhelusta luodaan viisi lausumaa ja valitaan lopputulokseksi se, jonka ERR on alhaisin.",
      "id": "task461-803e994c1e56435fb3adc093e55d792d",
      "output": [
        "Mitä automaattisia mittareita käytetään järjestelmän suorituskyvyn mittaamiseen?"
      ]
    },
    {
      "input": "Toinen lähestymistapamme sisällyttää matalaa syntaktista tietoa myöhemmissä tehtävissä token-tason kappaletunnisteiden upotusten avulla. Tehtävien harjoitus- (ja testi-) data pilkotaan automaattisesti, ja pilkkurajoja koskeva tieto siirretään tehtävämalliin merkintöjen BIOUL-koodauksen avulla. Lisäämme satunnaisesti alustettuja kappaletunnisteiden upotuksia tehtäväkohtaisiin syötekoodereihin, jotka sitten hienosäädetään tehtäväkohtaisia tavoitteita varten.",
      "id": "task461-41f0f2191f5c492094adab0371c34688",
      "output": [
        "Mitä syntaktisia piirteitä saadaan automaattisesti tehtäväkohtaisista tiedoista?"
      ]
    },
    {
      "input": "Vertailemme logististen regressiomallien ennusteita, jotka perustuvat unigram-sanapussi-ominaisuuksiin (BOW), sentimenttisignaaleihin (SENT), aiemmissa analyyseissämme käytettyihin kielellisiin ominaisuuksiin (LING) ja näiden ominaisuuksien yhdistelmiin.",
      "id": "task461-0a2c38a04be84f82afaf8300d30adb98",
      "output": [
        "Millainen ennustemalli he rakentavat?"
      ]
    },
    {
      "input": "Pitkän ja lyhyen aikavälin hybridimuisti ja monitarkkailulohko. Long-short Term Hybrid Memory (LSTHM) on Long-short Term Memory (LSTM) -muistin laajennus muotoilemalla muistin komponentti uudelleen siten, että se sisältää hybriditietoa.  LSTHM-mallissa pyrimme rakentamaan kullekin modaliteetille muistimekanismin, joka näkymäkohtaisen dynamiikan tallentamisen lisäksi kykenee tallentamaan myös kyseisen modaliteetin kannalta tärkeät näkymien väliset dynamiikat. Näin muisti voi toimia hybridisesti.",
      "id": "task461-20ac112e8a694ef9a8ddfcc507c154d5",
      "output": [
        "Mitä eroa on pitkä- ja lyhytkestoisella hybridimuistilla ja LSTM-muistilla?"
      ]
    },
    {
      "input": "Suoritimme kokeilumme CSJ BIBREF25 -aineistolla, joka on yksi yleisimmin käytetyistä japanilaisen puheen tunnistuksen arviointijoukoista. CSJ koostuu yli 600 tunnista japaninkielisiä äänitteitä. Vaikka suurin osa sisällöstä on yhden puhujan luentotallenteita, CSJ sisältää myös 11,5 tuntia 54 dialogitallennetta (keskimäärin 12,8 minuuttia per äänite), joissa on kaksi puhujaa, jotka olivat ASR:n ja puhujan päiväkirjamäärityksen pääkohde tässä tutkimuksessa.",
      "id": "task461-fcd2ee37450b47db88d3245d292b4aa5",
      "output": [
        "Kuinka kauan keskustelutallenteita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Axelrodin kausaalikartoitusmenetelmään kuuluu joukko konventioita, joiden avulla voidaan esittää graafisesti syiden ja vaikutusten verkostot (verkon solmut) sekä tämän suhteen laadulliset näkökohdat (verkon suunnatut reunat, erityisesti väitteet siitä, onko kausaalisuhde positiivinen vai negatiivinen).",
      "id": "task461-71c3f89dcd7345c09f5202244601b24f",
      "output": [
        "Mitä kausaalikartoitusmenetelmiä käytetään?"
      ]
    },
    {
      "input": "Koska esivalmennetut mallit toimivat alasanatasolla, meidän on arvioitava alasanojen käännöstodennäköisyydet. Mallimme oppimien kontekstuaalisten representaatioiden arvioimiseksi emme käytä puheosamerkintöjä. Kontekstuaaliset representaatiot syötetään suoraan Deep-Biaffine-kerroksiin kaari- ja etikettipisteiden ennustamiseksi. Taulukossa TABREF34 esitetään Labeled Attachment Scores (LAS) nollakohtaisen riippuvuusjäsennyksen jäsennyksen osalta.",
      "id": "task461-dbd9820af1204757ac3f6c2bc927b3c4",
      "output": [
        "Mitä mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "jos kuvaajassa on virhe, kolmio on todennäköisesti epäjohdonmukainen lähiympäristönsä kanssa, joten mallin tulisi luottaa vähiten tähän kolmioon. Toisin sanoen virhekolmion pitäisi vaikuttaa vähiten mallin ennusteeseen harjoitusdatasta. Seuraavassa esitellään toinenkin mahdollinen vastakohtaisten muutosten käyttömahdollisuus: virheellisten kolmioiden löytäminen tietämysgraafista. Intuitiivisesti, jos graafissa on virhe, kolmio on todennäköisesti epäjohdonmukainen lähiympäristönsä kanssa, ja näin ollen mallin pitäisi luottaa vähiten tähän kolmioon. Toisin sanoen virheellisellä kolmikolla pitäisi olla vähiten vaikutusta mallin ennusteeseen harjoitusdatasta. Virheellisen kolmion $\\langle s^{\\prime }, r^{\\prime }, o\\rangle $ löytämiseksi koulutuskolmion $\\langle s, r, o\\rangle $ naapurustosta, meidän on löydettävä kolmio $\\langle s^{\\prime },r^{\\prime },o\\rangle $, jonka poistaminen kuvaajasta aiheuttaa pienimmän muutoksen $\\Delta _{(s^{\\prime },r^{\\prime })}(s,r,o)$.",
      "id": "task461-a12487b9de6c4526b998f9697d424742",
      "output": [
        "Miten tätä lähestymistapaa käytetään virheellisten tosiseikkojen havaitsemiseen?"
      ]
    },
    {
      "input": "Ensinnäkin GRU sallii vain lauseet, joilla on kontekstia niitä edeltävistä lauseista, mutta ei niiden jälkeisistä lauseista. Tämä estää tiedon leviämisen tulevista lauseista. Toiseksi tukevat lauseet voivat olla sanatasolla liian kaukana toisistaan, jotta nämä kaukana olevat lauseet voisivat olla vuorovaikutuksessa sanatason GRU:n kautta.",
      "id": "task461-650d54f848eb4f4aa2a9db92655ff0f4",
      "output": [
        "Miksi tukeva tosiasioiden valvonta on välttämätöntä DMN:n osalta?"
      ]
    },
    {
      "input": "Toteutamme annotaatiotutkimuksemme Amazon Mechanical Turkissa, jossa turkkilaisille esitetään Human Intelligence Tasks (jäljempänä HIT) -tehtäviä, jotka koostuvat yhdestä asiakkaan ja agentin välisestä keskustelusta. Jokaisessa HIT-tehtävässä esitämme turkkilaisille kunkin keskustelutoimen määritelmän sekä esimerkin annotoidusta keskustelusta. Jokaisen keskustelun käännöksen osalta annamme turkkilaisille mahdollisuuden valita taksonomiastamme niin monta merkintää kuin on tarpeen käännöksen tarkoituksen täydelliseksi kuvaamiseksi. Lisäksi annotoijille esitetään jokaisen keskustelun HIT:n lopussa kolme kysymystä, joihin he voivat vastata, että he ovat samaa mieltä, eri mieltä tai eivät osaa sanoa:",
      "id": "task461-a68e1b2e959547d4a6512b0fe2c29bed",
      "output": [
        "Miten kerätään tietoja asiakastyytyväisyydestä, asiakkaiden turhautumisesta ja ongelmanratkaisun kokonaisuudesta?"
      ]
    },
    {
      "input": "Tutkimme myös 12742 STRENGTH-lauseen klusterointia suoraan CLUTO BIBREF19- ja Carrot2 Lingo BIBREF20 -klusterointialgoritmeilla. ",
      "id": "task461-1855e434e9144d029ca402557c92ebfc",
      "output": [
        "Mitä klusterointialgoritmeja käytettiin?"
      ]
    },
    {
      "input": "Aiemmin mainitut tietokokonaisuudet ovat kaikki englanninkielisiä.",
      "id": "task461-4aecd3f8c30c4639a2fdcb2f5a386f58",
      "output": [
        "Mille kielille on luotu suurin osa MRC:n nykyisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Arvioimme malliamme ensin MultiWOZ 2.0 -tietokannalla, joka on esitetty taulukossa TABREF16. Vertaamme sitä viiteen julkaistuun perusmalliin. TRADE BIBREF3 on tämänhetkinen julkaistu huippumalli. Taulukossa TABREF24 esitetään tulokset WOZ $2.0$ -tietokannalla. Vertaamme neljään julkaistuun perusmalliin. SUMBT BIBREF17 on tämänhetkinen huippumalli WOZ 2.0 -tietokannassa.",
      "id": "task461-ee6c5010a05f462c9f1efddff3c5ad3f",
      "output": [
        "Mikä on nykyinen uusin malli?"
      ]
    },
    {
      "input": "Lopullisessa järjestelmässämme, kun olemme esivalmentaneet eteen- ja taaksepäin suuntautuvat LM:t erikseen, poistamme ylimmän kerroksen softmaxin ja yhdistämme eteen- ja taaksepäin suuntautuvat LM-kuvioinnit kaksisuuntaisiksi LM-kuvioinneiksi, eli INLINEFORM0 . ",
      "id": "task461-974dd4ffd98445baba8d2d0c7ff4c03e",
      "output": [
        "miten saadaan kaksisuuntaiset lms-arvot?"
      ]
    },
    {
      "input": "MCD-jakojen avulla saavutetaan muihin kokeisiin verrattuna huomattavasti korkeampi yhdisteiden hajonta samalla atomien hajonnalla. ",
      "id": "task461-cfab094c7d3544b3ad5088f27bf133b3",
      "output": [
        "Millaisia tuloksia saadaan, kun uutta menetelmää verrataan muihin lähestymistapoihin kompositionaalisen yleistämisen vertailuarvojen luomiseksi?"
      ]
    },
    {
      "input": "Tässä työssä esittelemme IndoSumin, uuden indonesian kielen tekstin tiivistämisen vertailutietokannan, ja arvioimme useita tunnettuja yksittäisten asiakirjojen tiivistämismenetelmiä kyseisellä tietokannalla. Tietokokonaisuus koostuu verkkouutisartikkeleista, ja siinä on lähes 200 kertaa enemmän asiakirjoja kuin seuraavaksi suurimmassa saman toimialueen tietokokonaisuudessa BIBREF2 Käytimme indonesialaisen uutisaggregaattori- ja tiivistämisyrityksen Shortirin tarjoamaa tietokokonaisuutta. Tietokanta sisältää noin 20 000 uutisartikkelia. ",
      "id": "task461-926ad86d955d4b3bb5b8b976548d1581",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Nykyinen ominaisuusjoukkomme koneoppimisen luokittelijan kouluttamista varten on suhteellisen pieni ja koostuu kappaleen toimialueen pistemääristä, sanapussista, oleskelun pituudesta ja aiempien sisäänottojen määrästä, mutta aiomme sisällyttää siihen monia lisäominaisuuksia, jotka eivät kuulu tämän tutkimuksen piiriin. Näihin kuuluu EHR-tietokannoissa olevien kliinisten kertomusten syvällisempi analyysi: seuraava tehtävämme on laajentaa EHR-tietoputkea erottelemalla kliinisesti positiiviset ja negatiiviset ilmiöt kullakin riskitekijäalueella. Tähän liittyy joukko annotaatiotehtäviä, joiden avulla voimme luoda leksikonipohjaisia ja korpuspohjaisia tunneanalyysityökaluja. Tämän jälkeen voimme käyttää näitä kliinisiä tunnepisteitä tuottaaksemme potilaan paranemisen tai heikkenemisen asteittaisen kuvauksen ajan myötä.",
      "id": "task461-ba72ee4287a34edcb16c5d917b98abb8",
      "output": [
        "Mitä lisäominaisuuksia ehdotetaan tulevaa työtä varten?"
      ]
    },
    {
      "input": "Jotta kommentoidut tiedot olisivat julkisesti saatavilla, valitsimme 70 uutisartikkelia arabialaisesta WikiNews-sivustosta. Nämä artikkelit kattavat viimeaikaisia uutisia vuodesta 2013 vuoteen 2015 useista eri genreistä (politiikka, talous, terveys, tiede ja teknologia, urheilu, taide ja kulttuuri). Artikkeleissa on 18 300 sanaa, ja ne on jaettu tasaisesti näiden seitsemän genren kesken siten, että kutakin genreä kohti on 10 artikkelia. Sanat on erotettu välilyönneistä ja välimerkeistä, ja joitakin oikeinkirjoitusvirheitä on korjattu (1,33 % kaikista sanoista), jotta saamme erittäin puhtaita testitapauksia. Lemmatisoinnista huolehtii arabian kielen asiantuntija, joka merkitsee oikeinkirjoituskorjaukset, ja lemmat varustetaan täydellisellä diakritisaatiolla, kuten kuvassa KUVA 2 esitetään.",
      "id": "task461-effc11c5d89149218619920a6b6818c5",
      "output": [
        "Miten tietokokonaisuutta kommentoitiin?"
      ]
    },
    {
      "input": "Intuitiivisesti ajateltuna alikäännettyjen sanojen pitäisi vaikuttaa vain vähän NMT-tuloksiin, jolloin sanojen merkitys olisi paljon pienempi.  Hyödyntämällä attribuutiomenetelmällä laskettua sanojen tärkeyttä voimme tunnistaa alikäännösvirheet automaattisesti ilman ihmistulkkien osallistumista. ",
      "id": "task461-662b8cc1e3734997be32fbb1d075543e",
      "output": [
        "Miten ne mittaavat, mitkä sanat NMT-mallit kääntävät liian vähän?"
      ]
    },
    {
      "input": "Vektoriportti on saanut vaikutteita BIBREF11- ja BIBREF12-ohjelmista, mutta se eroaa edellisistä siinä, että porttimekanismi vaikuttaa sana- ja merkkitason vektoreiden kuhunkin ulottuvuuteen, ja eroaa jälkimmäisistä siinä, että porttimekanismin laskennassa ei käytetä ulkoisia tietolähteitä.",
      "id": "task461-f451a7854ad347e0a1911a1451e66ba4",
      "output": [
        "Missä ne käyttävät ominaisuuksiin perustuvaa sigmoidista porttausta?"
      ]
    },
    {
      "input": "Kahden menetelmän valintaa empiiriseen tutkimukseemme perusteltiin logistisen regression parhaalla suorituksella, jonka se saavutti SemEval 2017 -tapahtumassa kysymysten samankaltaisuudessa (paras järjestelmä BIBREF37 ja toiseksi paras järjestelmä BIBREF38 ), sekä neuroverkkojen korkealla suorituskyvyllä, jonka ne saavuttivat suuremmissa tietokokonaisuuksissa, kuten SNLI:ssä BIBREF13 , BIBREF39 , BIBREF40 , BIBREF41 ",
      "id": "task461-09a3d60552324f1a90920982c7e634d3",
      "output": [
        "Mitä koneoppimisen ja syväoppimisen menetelmiä käytetään RQE:ssä?"
      ]
    },
    {
      "input": "Keräsimme japanin ja vietnamin välistä rinnakkaista dataa TED-puheista, jotka oli poimittu WIT3:n korpuksesta BIBREF15 . ",
      "id": "task461-90fdedd0b15c41509b80f706ba829c05",
      "output": [
        "mitä japanilais-vietnamilaista tietokokonaisuutta he käyttävät?",
        "keräsivätkö he omat tietonsa?"
      ]
    },
    {
      "input": "Teimme joukkoistettuja monivalintakysymyksiä kahdessa osassa ja kannustimme työntekijöitä käyttämään kieltä mielikuvituksellisesti ja monipuolisesti. Ensin työntekijöille annettiin alaan liittyvä kvalitatiivinen suhdeluku q+/-( INLINEFORM0 ), joka ilmaistiin englanniksi (esim. \"Jos pinnalla on enemmän kitkaa, esine kulkee hitaammin\"), ja heitä pyydettiin syöttämään kaksi vertailtavaa esinettä, ihmistä tai tilannetta.",
      "id": "task461-e617a6c57db44e9892931c8f9554a131",
      "output": [
        "Annetaanko kaikissa tietokannan kysymyksissä vastauksissa mahdollisuus valita kahdesta vaihtoehdosta?"
      ]
    },
    {
      "input": "Vertaillaksemme USVC:n ja PitchNetin välisiä muunnoksia käytimme automaattista ja inhimillistä arviointipistemäärää. Automaattinen pisteytys noudatti suunnilleen BIBREF13:n suunnitelmaa. Syöttö- ja lähtöäänen sävelkorkeustiedon poimimiseen käytettiin librosa-paketin BIBREF18 sävelkorkeudenseurantaohjelmaa. Tämän jälkeen tulosteiden äänenkorkeutta verrattiin tulosteiden äänenkorkeuteen käyttämällä normalisoitua ristikkäiskorrelaatiota (NCC), joka antaa pistemäärän välillä 0-1. Mitä korkeampi pistemäärä on, sitä paremmin tulosteiden äänenkorkeus vastaa tulosteiden äänenkorkeutta. Arviointi suoritettiin USVC:llä (meidän) ja PitchNetillä. Muunto- ja rekonstruktiotehtävien arvioidut automaattiset pisteet näkyvät taulukossa. TABREF14. Menetelmämme suoriutui paremmin sekä muuntamisessa että rekonstruoinnissa. Rekonstruktiosta saadut pisteet ovat korkeammat kuin muuntamisesta saadut pisteet, koska molemmat mallit koulutettiin rekonstruktiohäviön avulla. Menetelmämme pisteet muuntamisessa ovat kuitenkin jopa korkeammat kuin USVC:n (meidän) pisteet rekonstruoinnissa. Keskimääräistä mielipidepistemäärää (Mean Opinion Score, MOS) käytettiin subjektiivisena mittarina muunnetun äänen laadun arvioimiseksi. Kaksi kysymystä esitettiin: (1) Mikä on äänen laatu? (luonnollisuus) (2) Kuinka hyvin muunnettu versio vastaa alkuperäistä? (samankaltaisuus) Kysymyksiin vastattaessa annettaisiin pistemäärä 1-5. Arviointi suoritettiin USVC:llä (Our) ja PitchNetillä. Lisäksi mukaan otettiin myös BIBREF0:n toimittamat muunnetut näytteet vakuuttavamman arvioinnin aikaansaamiseksi. Kuten taulukosta Tab. TABREF15, menetelmämme luonnollisuus ja samankaltaisuus ovat molemmat korkeammat kuin kahden muun menetelmän. USVC-toteutuksemme suoriutui hieman heikommin kuin alkuperäisen tekijän toteutus, koska emme voi täysin toistaa niiden tuloksia. Seuraavaksi analysoimme kvalitatiivisesti syöttökorkeuden vaikutusta menetelmäämme. Käytimme syötteenä eri sävelkorkeuksia havainnoidaksemme, miten ulostulon sävelkorkeus muuttuu syötteen sävelkorkeuden mukana. Syöttökorkeus kerrottiin vastaavasti 0,7:llä, 1,0:lla ja 1,3:lla. Lähtökorkeus poimittiin myös librosa-paketin pitch tracker -ohjelmalla. Kuvassa FIGREF16 esitetään tuloäänen ja lähtöäänen korkeus, kun tuloäänen korkeus on eri, mutta tavoiteääni pysyy samana. Kuten kuvasta FIGREF16 käy ilmi, ulostulon äänenkorkeus muuttuu merkittävästi tulon äänenkorkeuden mukana. Esimerkit on esitetty myös verkkosivuillamme.",
      "id": "task461-3d6b9ef399384ea5b522e7acfc222001",
      "output": [
        "Miten lauluäänen laatua mitataan?"
      ]
    },
    {
      "input": "Käytämme samaa järjestelmää kuin BIBREF47 merkitäksemme MT-tulosteet ydinviittausketjuilla. Tämän järjestelmän avulla annotoija voi määritellä jokaisen merkinnän tietyksi mainintatyypiksi (pronomini, NP, VP tai lauseke). Maininnat voidaan määritellä edelleen niiden koheesiotoimintojen perusteella (antecedentti, anaforinen, kataforinen, komparatiivi, substituutio, ellipsi, appositio). Antecedentit voidaan merkitä joko yksinkertaisiksi tai jaetuiksi tai entiteeteiksi tai tapahtumiksi. Merkintäjärjestelmä sisältää myös pronominityypin (persoonapronominit, possessiivipronominit, demonstratiivipronominit, refleksiivipronominit, relatiivipronominit) ja NP:iden modifiointityypit (possessiivipronominit, demonstratiivipronominit, määräiset artikkelit tai ei mitään, jos kyseessä ovat oikeat nimet), ks. tarkemmin BIBREF46. Samaan diskurssiesineeseen viittaavat maininnat on linkitetty toisiinsa. Käytämme annotaatiotyökalua MMAX2 BIBREF48 , jota käytettiin myös ParCorFullin annotoinnissa. Seuraavassa vaiheessa ketjun jäsenet annotoidaan niiden oikeellisuuden kannalta. Mainintojen virheellisiä käännöksiä varten otamme mukaan seuraavat virhekategoriat: sukupuoli, luku, tapaus, moniselitteinen ja muu. Jälkimmäinen luokka on avoin, mikä tarkoittaa, että annotoijat voivat lisätä omia virhetyyppejään annotoinnin aikana. Tämän myötä lopulliseen virhetypologiaan kuuluivat myös väärä nimetty entiteetti, väärä sana, puuttuva sana, väärä syntaktinen rakenne, oikeinkirjoitusvirhe ja osoiterivirhe.",
      "id": "task461-b49866353b284b8280e1b345734813f8",
      "output": [
        "Miten MT-tulosteiden (mahdollisesti virheelliset) ydinviittausketjut annotoidaan?"
      ]
    },
    {
      "input": "Tulokset osoittavat, että NCEL päihittää johdonmukaisesti erilaiset perusratkaisut, ja sen yleistyskyky on hyvä.",
      "id": "task461-7572cfc075a14f2c909ce3df4773e90e",
      "output": [
        "Kuinka tehokas heidän NCEL-lähestymistapansa on kaiken kaikkiaan?"
      ]
    },
    {
      "input": "Puhtaasti sisältöön perustuvan mallin suorituskyky pysyy luonnollisesti vakaana, mutta muiden järjestelmien suorituskyky heikkenee huomattavasti - ne toimivat huonommin kuin sisältöön perustuva malli.",
      "id": "task461-be6e99f3386e4129b095b85d67721610",
      "output": [
        "Miten ne osoittavat tulostensa kestävyyden?"
      ]
    },
    {
      "input": "Käytimme kahta rinnakkaista korpusta: Asian Scientific Paper Excerpt Corpus (ASPEC) BIBREF0 ja NTCIR PatentMT Parallel Corpus BIBREF1 .",
      "id": "task461-814cdad4dc0d44829fba161c98152f7d",
      "output": [
        "Mitä rinnakkaista korpusta he käyttivät?"
      ]
    },
    {
      "input": "$LS \\cup KLD \\cup CONN$ ja $KLD \\cup LS \\cup LS_{inter}$ ovat parhaat järjestelmät, joilla on korkein recall- ja F1-tulos.",
      "id": "task461-c4781a6e12174587bbcb9101106a295d",
      "output": [
        "Mikä oli aiempi uusin lähestymistapa?"
      ]
    },
    {
      "input": "Rakensimme 16 mallia sanojen upotuksista käyttäen CBOW- ja Skip-gram-menetelmien toteutusta FastText-työkalussa BIBREF9 .",
      "id": "task461-4746370be03a4303bd29c48a8f22a287",
      "output": [
        "Mitä sulautusalgoritmia käytetään sulautusten muodostamiseen?"
      ]
    },
    {
      "input": "Yhteistyössä Saksan kansainvälisen koulutustutkimuslaitoksen tutkijoiden kanssa kartoitimme seuraavat ajankohtaiset kiistanalaiset aiheet englanninkielisten maiden koulutuksessa: (1) kotiopetus, (2) julkiset ja yksityiset koulut, (3) redshirting - ikäisen lapsen siirtäminen päiväkotiin tarkoituksellisesti, jotta lapsella olisi enemmän aikaa kypsyä emotionaalisesti ja fyysisesti BIBREF51 , (4) rukous kouluissa - pitäisikö rukous sallia ja ottaa osaksi opetusta vai kieltää kokonaan, (5) yksisukupuolinen opetus - yksisukupuoliset luokat (miehet ja naiset erillään) verrattuna sekasukupuolisiin luokkiin (\"co-ed\"), ja (6) valtavirtaistaminen - erityistarpeita omaavien lasten ottaminen mukaan tavallisiin luokkiin.",
      "id": "task461-fdba5de8928144ae93db244791562696",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Gensimin julkaiseman D2V-algoritmin virittämiseen käytettävissä olevista parametreista valittiin kuusi parametria BIBREF14-optimointia varten. Parametri window_size vaikuttaa tekstien analysoinnissa käytettävän liukuikkunan kokoon. Parametri alpha edustaa verkon oppimisnopeutta. Sample-asetuksella malli voi vähentää suurtaajuisille sanoille annettua painoarvoa. dm-parametri määrittää koulutuksessa käytettävän arkkitehtuurin (PV-DM tai PV-DBOW). ",
      "id": "task461-ea1e49b25d3843dba272af51ab2e03ca",
      "output": [
        "Mitä muita Doc2Vec-arkkitehtuureja kuin PV-DBOW:ta on kokeiltu?"
      ]
    },
    {
      "input": "Segmentoimme hashtagin merkityksellisiksi englanninkielisiksi lauseiksi. Tätä varten käytämme englanninkielisten sanojen sanakirjaa. Sentimentti url: Koska lähes kaikki artikkelit on kirjoitettu hyvin muotoillulla englannilla, analysoimme artikkelin ensimmäisen kappaleen sentimenttiä Standfordin sentimenttianalyysityökalulla BIBREF4 . ",
      "id": "task461-15fba80e7a5b4ce59fb25fb8ba8a3a89",
      "output": [
        "Raportoivatko kirjoittajat vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Puoliparametriset mallit koulutettiin 32 GPU:lla siten, että kukin kopio jaettiin kahdelle GPU:lle, joista toinen koulutettiin käännösmallia ja toinen CSTM:n laskentaa varten.",
      "id": "task461-c1e101e679214e1482c4af66f1c7032d",
      "output": [
        "Koulutetaanko heidän ei-parametrisen haun ja neuroverkon yhdistelmänsä alusta loppuun?"
      ]
    },
    {
      "input": "Käytämme tässä työssä kahta tietokokonaisuutta: harjoittelu tehdään Fisherin englanninkielisellä korpuksella BIBREF15 (LDC2004S13) ja testaus itsemurhien riskinarviointikorpuksella BIBREF16 yhdessä Fisherin kanssa.",
      "id": "task461-8a19676f37c4429d94aa64a54d2af551",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät upotusten oppimiseen?"
      ]
    },
    {
      "input": "Aktiiviset oppimismenetelmät voidaan yleensä jakaa kahteen osaan: oppimismoottoriin ja valintamoottoriin BIBREF28 . Oppimismoottori on pohjimmiltaan luokittelija, jota käytetään pääasiassa luokitusongelmien harjoitteluun. Valintamoottori perustuu näytteenottostrategiaan, joka valitsee merkitsijöiden uudelleenmerkitsemistä näytteistä merkitsemättömästä datasta näytteet, jotka on merkittävä uudelleen. Tämän jälkeen uudelleenmerkityt näytteet lisätään harjoitusjoukkoon, jotta luokittelija voi kouluttautua uudelleen, jolloin luokittelijan tarkkuus paranee jatkuvasti. Tässä asiakirjassa oppimismoottorina käytetään CRF-pohjaista segmentoijaa ja valintamallina pisteytysmallia.",
      "id": "task461-8a1b0aebbcbc448badf1421d547e2486",
      "output": [
        "Miten aktiivisen oppimisen malli toimii?"
      ]
    },
    {
      "input": "Kaikkien käsitteiden keskiarvon laskemisen jälkeen menetämme tiedon kunkin käsitteen leksikaalisesta vaihtelusta, mutta toisaalta voimme nyt tutkia, millä alueilla on samanlaista geolektistä vaihtelua, mikä johtaa hyvin määriteltyihin kielellisiin lajityyppeihin. Ne solut, joilla on samanlaiset värit joko kuviossa FIGREF16 tai kuviossa FIGREF17, voidaan olettaa kuuluvan samaan murrealueeseen. Näin ollen kartoissa voidaan erottaa kaksi pääaluetta tai klusteria. Violetti tausta peittää suurimman osan kartasta ja edustaa maaseutualueita, joilla on pieni, hajallaan oleva väestö. Analyysimme osoittaa, että tällä soluryhmällä on leksikossaan enemmän erityisiä sanoja. Vihreät ja keltaiset solut sen sijaan muodostavat toisen klusterin, joka on suurelta osin keskittynyt keskustaan ja rannikolle, jotka vastaavat suurkaupunkeja ja teollisuusalueita. Näissä soluissa espanjan kielen vakiokielen käyttö on yleistä, mikä johtuu todennäköisesti kouluopetuksesta, tiedotusvälineistä, matkailijoista jne. Sen sanaston luonne on yhtenäisempi verrattuna violettiin ryhmään. Siinä missä violetti rypäs suosii tiettyjä lausumia, kaupunkiryhmän sanasto sisältää suurimman osan avainsanoista. ",
      "id": "task461-cf1a81da7e4044b08a94c9b18c092150",
      "output": [
        "Mitkä ovat maaseudun murteen ominaispiirteet?"
      ]
    },
    {
      "input": "Vertailemme ja analysoimme huolellisesti eri kontekstin mallintamismenetelmien suorituskykyä kahdella suurella, monimutkaisella ja monialaisella tietokokonaisuudella, SParC BIBREF2:lla ja CoSQL BIBREF6:lla, tehtyjen kokeiden avulla.",
      "id": "task461-b62ff356dd54448890452b3589fe74f9",
      "output": [
        "Millä kahdella tietokokonaisuudella malleja testataan?"
      ]
    },
    {
      "input": "Pyydämme kommentoijia luomaan jokaiselle aineiston sukupuolittuneelle hahmolle uuden hahmon, jolla on vastakkaista sukupuolta oleva persoona ja joka on muuten identtinen lukuun ottamatta viittaavia substantiiveja tai pronomineja.",
      "id": "task461-ebe536636c92483da3b45775f7baf3fc",
      "output": [
        "Minkä tyyppisiä tietoja kohdennetussa tiedonkeruussa kohdennetaan?"
      ]
    },
    {
      "input": " Sen sijaan, että aloittaisimme Twitterin API-hausta, tarkastelemme kahden suuren uutissivuston (CNN, NBC) arkistoituja tilannekuvia ja poimimme sitten uutisartikkeleihin upotetut twiittilohkot.",
      "id": "task461-2437770853bb4225a05a089bce176bf0",
      "output": [
        "Miten he määrittävät, ovatko toimittajat käyttäneet twiittejä?"
      ]
    },
    {
      "input": "Voisi olettaa, että harjoittelu useammalla datalla parantaisi upotusten laatua, mutta C3-tietokannasta saatujen tulosten perusteella havaitsimme, että vain korkealaatuinen data auttaa.",
      "id": "task461-66f4a80e70684c559018d994c2be7f40",
      "output": [
        "Kumpi osoittautuu tärkeämmäksi, suuri määrä vai korkea laatu?"
      ]
    },
    {
      "input": "Rekrytoimme Amazon Mechanical Turk (AMT) -palveluun 100 joukkorakentajaa ja mittasimme Yelp-korpuksesta satunnaisesti poimittujen lauseiden kirjoittamiseen käytetyt ajat ja tarkkuudet. ",
      "id": "task461-3d85cbd445bc40c7bf2eb70b347dd265",
      "output": [
        "Mitä käyttäjävariaatioita on testattu?",
        "Kuinka monta osallistujaa kokeili tätä viestintäpeliä?"
      ]
    },
    {
      "input": "Viime aikoina syvien neuroverkkojen menestys monissa luonnollisen kielen käsittelytehtävissä ( BIBREF20 ) on innoittanut uutta työtä abstraktiivisen tiivistämisen alalla. BIBREF2 ehdottaa tämän tehtävän ratkaisemiseksi neuraalista huomiomallia, jossa on konvoluutiokooderi.  Hiljattain BIBREF4 laajensi BIBREF2:n työtä RNN-dekooderilla, ja BIBREF8 ehdotti RNN-kooderi-dekooderiarkkitehtuuria tiivistämistä varten. Molemmat tekniikat ovat tällä hetkellä DUC-kilpailun huippuluokkaa.",
      "id": "task461-4ed9a918bd9f4d6a8d9acf65c8f7aea0",
      "output": [
        "Mikä on tekniikan nykytila?"
      ]
    },
    {
      "input": "Annotoija suoritti kaiken annotoinnin.",
      "id": "task461-c60eb603df0e415289e2a7ce12ffabb0",
      "output": [
        "Kuinka monta kommentoijaa merkitsi jokaisen twiitin?"
      ]
    },
    {
      "input": ". Tätä työtä voidaan laajentaa ennustamaan tulevia tapahtumia yhden päivän päähän, jolloin käytämme samaa menetelmää ominaisuuksien valintaan sekä sanaparien historiallisten mallien aikasarja-analyysiä.",
      "id": "task461-575908c3f5ca47049cb57965eb461c20",
      "output": [
        "Ehdottavatko kirjoittajat, että tätä työtä laajennettaisiin tulevaisuudessa?"
      ]
    },
    {
      "input": "Näin voimme leimata 77 uutta Venäjä-mielistä reunaa tarkastelemalla 415 twiittiä, mikä tarkoittaa, että 19 prosenttia ehdokkaista on osumia. Ukrainalaismyönteisen luokan osalta voimme merkitä 110 uutta reunaa tarkastelemalla 611 twiittiä (18 % osumia). Vaikka luokittimen ennusteiden laatu on liian heikko, jotta ne voitaisiin integroida verkostoanalyysiin heti, luokittimen avulla voidaan kuitenkin helpottaa huomattavasti inhimillisten merkitsijöiden merkintäprosessia verrattuna suodattamattomien twiittien merkitsemiseen (alkuperäisten merkintöjen perusteella voidaan päätellä, että suodattamattomista twiiteistä vain 6 prosenttia on osumia Venäjä-mielisen luokan osalta ja 11 prosenttia Ukraina-mielisen luokan osalta).",
      "id": "task461-40c1c7a418b5428a8d8556c54cef149f",
      "output": [
        "Miten luokittelija voi helpottaa annotointitehtävää ihmisannotoijien kannalta?"
      ]
    },
    {
      "input": "Huomaamme myös, että paras yhdistelmä näyttää koostuvan siitä, että mallimme koulutetaan alkuperäisellä kontekstin ulkopuolisella tietokokonaisuudella ja testataan sitä kontekstin sisäisillä pareilla. Tällä kokoonpanolla saavutamme F-tuloksen (0,72), joka on vain hieman alhaisempi kuin BIBREF3:ssa ilmoitettu tulos (0,74), ja saavutamme korkeimman Pearsonin korrelaation, 0,3 (joka ei kuitenkaan ole vahva verrattuna BIBREF3:n parhaaseen tulokseen, 0,75). ",
      "id": "task461-78dc4d9ccc11482ba4d83d1ebe2a43be",
      "output": [
        "Mitkä olivat ensimmäisen kokeen tulokset?"
      ]
    },
    {
      "input": "Malliin käytettiin seuraavia käsityönä tehtyjä piirteitä:Bias-piirreToken-piirreUppercase-piirre (y/n)Titlecase-piirre (y/n)Character trigram-piirreQuotation-piirre (y/n)Sanan suffix-piirre (kolme viimeistä merkkiä)POS-tunniste (spaCy-apuohjelmien tarjoama)Sanan muoto (spaCy-apuohjelmien tarjoama)Sanan sulauttaminen (ks. taulukko TABREF26).",
      "id": "task461-002f95a920744ed2885a06f0f6b6fd10",
      "output": [
        "Mitä käsityönä tehtyjä ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Yksisuuntainen: Constellation AI BIBREF5:ssä kehitetyn MiM-keskustelurobotin lausumien ja vastausten yhden käännöksen tapaukset. Multi-Turn: Tämä tietokokonaisuus on peräisin ConvAI2-haasteesta, ja se koostuu erityyppisistä vuoropuheluista, jotka on luotu ihmisen ja tietokoneen välisistä keskusteluista.",
      "id": "task461-4546f0b4bcf14b70819e946156a1dd6c",
      "output": [
        "mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Ensimmäiseksi mukautamme Freebase-tietokannasta poimitun FB24K-tietokannan, jota BIBREF26 käyttää. Sitten keräämme DBpedian ylimääräisiä entiteettejä ja suhteita, joilla on vähintään 100 mainintaa BIBREF7:ssä ja jotka voivat linkittyä FB24K:ssa oleviin entiteetteihin sameAs-kolmioilla. Lopuksi muodostetaan tietokokonaisuus nimeltä DBP24K. Lisäksi muodostamme pelien tietämysgraafista pelidatan, joka on nimeltään Game30K.",
      "id": "task461-97706f48e606443aa1a0d857f76eeae3",
      "output": [
        "Mitä kolmea tietokokonaisuutta käytetään suorituskyvyn mittaamiseen?"
      ]
    },
    {
      "input": "Annotaatioprosessin lopussa olemme annotoineet 700 twiittiä, joista 175 twiittiä kannattaa ja 175 twiittiä vastustaa tavoitetta 1, ja vastaavasti 175 twiittiä kannattaa ja 175 vastustaa tavoitetta 2. ",
      "id": "task461-020cae3c71f348de842c51641ffdb534",
      "output": [
        "Kuinka monta twiittiä he keräsivät?"
      ]
    },
    {
      "input": "Suuren muinaismodernin kiinan tietokokonaisuuden rakentamiseksi keräsimme internetistä 1,7 000 kaksikielistä muinaismodernin kiinan artikkelia. Tarkemmin sanottuna suuri osa käyttämistämme muinaiskiinalaisista tiedoista on peräisin muinaiskiinalaisten historiankirjoituksista useiden dynastioiden ajalta (noin 1000 eaa. - 200 eaa.) ja tuon aikakauden julkkisten kirjoittamista artikkeleista.",
      "id": "task461-b9448faff3a244198783591755e7118a",
      "output": [
        "Mistä muinaiskiinalainen aineisto on peräisin?"
      ]
    },
    {
      "input": "Syötämme edellä kuvatut käsin luodut ominaisuudet yhdessä syvän neuroverkon oppimien tehtäväkohtaisten sulautusten kanssa (yhteensä 1892 ominaisuutta) tukivektorikoneiden (SVM) luokittimeen BIBREF37 .",
      "id": "task461-8e4f0bffdbc949df89e14c08be438085",
      "output": [
        "mitä luokittelijoita tässä asiakirjassa käytettiin?"
      ]
    },
    {
      "input": "Päädymme poistamaan 5,86 % kaikista merkeistä, ja saamme 45 821 merkkiä ja 12 815 ainutlaatuista HLA:ta, jolloin saamme yhteensä 945 519 merkki-HLA-paria.  Päädymme poistamaan 5,86 % kaikista merkkeistä, ja lopulta meillä on 45 821 merkkiä ja 12 815 ainutlaatuista HLA:ta, jolloin hahmo-HLA-parien kokonaismäärä on 945 519.",
      "id": "task461-e01ef7d162354c7fb9da8b03c2134329",
      "output": [
        "Kuinka monta erilaista merkkiä aineistossa oli?"
      ]
    },
    {
      "input": "Mukana on myös uusimpia malleja: RegSum BIBREF0 ja GCN+PADG BIBREF3. ROUGE-1:n suhteen olemme molempia parempia. ROUGE-2-pisteiden osalta saavutamme parempia tuloksia kuin GCN+PADG, mutta ilman aluespesifisiä käsintehtyjä piirteitä ja paljon pienemmällä ja yksinkertaisemmalla mallilla. RegSum saavuttaa samanlaiset ROUGE-2-tulokset, mutta se laskee lauseiden saliences-pisteet sanapisteiden perusteella ja käyttää runsaasti sanatason ja toimialakohtaisia piirteitä.",
      "id": "task461-75a4e62c14194d5aa0fc9ce9401cb7d9",
      "output": [
        "Kuinka paljon paremmat tulokset ovat kuin tämän mallin tulokset? "
      ]
    },
    {
      "input": "Harjoittelimme mallimme etukäteen OSCAR-korpuksen hollanninkielisellä osalla, joka on suuri monikielinen korpus, joka saatiin Common Crawl -korpuksen BIBREF16 kieliluokittelun avulla.",
      "id": "task461-f24cb3de2e0c4295bd6f9e7a9f710526",
      "output": [
        "Mitä tietoja he käyttivät?"
      ]
    },
    {
      "input": "Siksi otamme käyttöön vahvistusoppimisen ja suunnittelemme kaksi palkkiota kuvaamaan ironian tarkkuutta ja tunteiden säilymistä.",
      "id": "task461-11f7086d588f42e8821495f913bc9f17",
      "output": [
        "Mikä on palkintojen yhdistelmä vahvistusoppimisessa?"
      ]
    },
    {
      "input": "Esittelemme korvaavan koulutustavoitteen, jolla vältetään nämä ongelmat ja joka on täysin jatkuva.  Muodostamme jatkuvan funktion softLB, joka pyrkii lähentämään tulosta, joka saadaan, kun dekooderi ajetaan INLINEFORM0-syötteellä ja sitten arvioidaan tulos INLINEFORM1:n suhteen INLINEFORM2:n avulla.",
      "id": "task461-efabaffbffb145bf9d0be6397441533f",
      "output": [
        "Tarjoavatko ne puitteet, joiden avulla voidaan rakentaa aladifferentiaali mille tahansa lopulliselle tappiomittarille?"
      ]
    },
    {
      "input": "Kun siirrytään semantiikkaan ja käytetään eri tekstikappaleiden aiheuttamien aktivaatioiden visualisointia, osoitamme viitteellisiä todisteita siitä, että BERT erottaa sanojen aistit hyvin hienolla tasolla.  Sovellamme tarkkaavaisuuskoettimia tehtävään tunnistaa kahden sanan välisen riippuvuussuhteen olemassaolo ja tyyppi.",
      "id": "task461-14a4dca8d392414ebd5ed953f5c6249b",
      "output": [
        "Miten ominaisuuksien esityksiä arvioitiin?"
      ]
    },
    {
      "input": "Tästä korpuksesta on useita versioita, ja valitsemme seuraavat kaksi versiota, koska niiden testitietokannassa on huomattavasti suurempi määrä useiden relaatiotuplien tapauksia, joissa on päällekkäisiä entiteettejä. (i) Ensimmäistä versiota käyttää BIBREF6 (BIBREF6) (joka mainitaan heidän artikkelissaan nimellä NYT), ja siinä on 24 relaatiota. Nimeämme tämän version nimellä NYT24. (ii) Toista versiota käyttää BIBREF11 (BIBREF11) (joka mainitaan artikkelissaan nimellä NYT10), ja siinä on 29 relaatiota.",
      "id": "task461-e9329eb4cea449c4bdfda1e526e44850",
      "output": [
        "Onko olemassa tietokokonaisuuksia, joihin on merkitty relaatiotuplet, ja kuinka suuria tietokokonaisuuksia on saatavilla?"
      ]
    },
    {
      "input": "GPT2:n hienosäätämiseksi tekstin tuottamista varten on tyypillistä yhdistää ehdollistava konteksti $X = x_1 \\ldots x_n$ ja lainauslause $Y = y_1 \\ldots y_m$ erityisellä erotinmerkillä $\\mho $. Kunkin asiakirjan tiivistelmä upotetaan yhdeksi tiheäksi vektoriksi laskemalla keskiarvo BIBREF11:n SciBERT-mallin tarjoamista kontekstiupotuksista ja normalisoimalla.",
      "id": "task461-85eaaddc6c7a43c5b0d0bf9d3bb5c462",
      "output": [
        "Mitä lähtötasoja tutkitaan?"
      ]
    },
    {
      "input": " Käytämme erityisesti Semeval 2014 BIBREF34 Twitter Sentiment Analysis Dataset -tietokokonaisuutta koulutukseen Kokeessa käytetyt sarkasmiaineistotTämän tietokokonaisuuden on luonut BIBREF8 . Twiitit ladattiin Twitteristä käyttäen #sarcasm-merkkiä sarkastisten twiittien merkkinä. Kyseessä on yksikielinen englanninkielinen tietokokonaisuus, joka koostuu tasapainoisesta jakaumasta, joka koostuu 50 000 sarkastisesta twiitistä ja 50 000 ei-sarkastisesta twiitistä.Koska sarkastisia twiittejä käytetään harvemmin BIBREF8 , meidän on myös tutkittava valittujen piirteiden ja näillä piirteillä koulutetun mallin kestävyyttä epätasapainoisessa tietokokonaisuudessa. Tätä varten käytimme toista englanninkielistä tietokokonaisuutta BIBREF8 . Se koostuu 25 000 sarkastisesta twiitistä ja 75 000 ei-sarkastisesta twiitistä.Saimme tämän tietokokonaisuuden The Sarcasm Detector -ohjelmasta. Se sisältää 120 000 twiittiä, joista 20 000 on sarkastisia ja 100 000 ei-sarkastisia. Otimme satunnaisotannalla 10 000 sarkastista ja 20 000 ei-sarkastista twiittiä tietokokonaisuudesta. Sekä alkuperäisen että osajoukon datan visualisointi osoittaa samanlaisia ominaisuuksia.",
      "id": "task461-4c238b8ffe284ac486066f1aaa290e31",
      "output": [
        "Mitä vertailutietoaineistoja käytetään?"
      ]
    },
    {
      "input": "Määrittelemme pisteet x:n tehokkaan sanapistemäärän seuraavasti:EFWS(x) = N(+x) - N(-x),jossa N(x) on niiden sanojen lukumäärä twiitissä, joiden polariteettipisteet x ovat.",
      "id": "task461-730c07fc1af545b8b5aba3c59caa153b",
      "output": [
        "Miten tehokkaan sanan pistemäärä lasketaan?"
      ]
    },
    {
      "input": "Oktaavikonvoluutiokerros BIBREF0 faktoroi konvoluutiokerroksen lähtöominaisuuskartat kahteen ryhmään. Matalataajuisten piirrekarttojen resoluutiota pienennetään oktaavilla - korkeus- ja leveysulottuvuudet jaetaan kahdella. Tässä työssä tutkitaan tilallista pienentämistä jopa kolmella oktaavilla - jakamalla $2^t$:llä, jossa $t=1,2,3$ - ja jopa neljällä ryhmällä. Kutsumme tällaista kerrosta monioktaavikonvoluutiokerrokseksi (MultiOctConv), ja kuvassa FIGREF1 on esitetty esimerkki, jossa on kolme ryhmää ja yhden ja kahden oktaavin vähennykset.",
      "id": "task461-3fbc5820db9542e183f1c3b6ed4a7b12",
      "output": [
        "Miten oktaavikonvoluution käsitettä laajennetaan useisiin resoluutioihin ja oktaaveihin?"
      ]
    },
    {
      "input": "Nykyinen uusin lähestymistapa BIBREF14 , BIBREF15 käyttää maksimientropia- ja CRF-malleja, joissa yhdistetään kielimalli ja käsin laaditut piirteet ennustamaan, onko hashtagin jokainen merkki uuden sanan alku.",
      "id": "task461-7a795b24787948848119685982805921",
      "output": [
        "Mitä nykyistä uusinta menetelmää käytettiin vertailussa?"
      ]
    },
    {
      "input": "Arvioimme malliamme sekä englannin- että kiinankielisellä segmentoinnilla.",
      "id": "task461-a94e93abdcae442784266ad2c7b88572",
      "output": [
        "Mitä kieltä he tarkastelevat?"
      ]
    },
    {
      "input": "Ensimmäinen tässä työssä arvioimamme luokittelijatyyppi on feedforward-neuraaliverkot (DNN), jotka koostuvat kolmesta piilokerroksesta, joissa kussakin on 512 rektifioitua lineaarista yksikköä (ReLU), joissa on softmax-aktivointifunktio. Toisena arvioitavana luokittelijana käytämme konvoluutiohermoverkkoja (convolutional neural networks, CNN), joissa on 2 konvoluutio- ja max pooling-kerrosta, joita seuraa 2 täysin yhdistettyä ReLU-kerrosta, joissa on 512 solmua.",
      "id": "task461-d933b5a69d654708b63086c1f97e5283",
      "output": [
        "Millaisia malleja käytetään luokittelussa?"
      ]
    },
    {
      "input": "Tämä työ tarjoaa myös uuden INLINEFORM0-tietokannan, joka koostuu vapaamuotoisista luonnollisen kielen ohjeista ja korkean tason navigointisuunnitelmista. Tämä tietokokonaisuus kerättiin Mechanical Turkin kautta käyttäen 100 simuloitua ympäristöä ja vastaavaa topologista karttaa, ja tietojemme mukaan se on ensimmäinen laatuaan käyttäytymisnavigointia varten. Tietokokonaisuus avaa mahdollisuuksia tutkia dataan perustuvia menetelmiä navigointikomentojen perustamiseksi korkean tason liikesuunnitelmiin. Vaikka tietokokonaisuus kerättiin simuloitujen ympäristöjen avulla, navigointikäskyille ei asetettu mitään rakennetta, kun tietoja kerättiin joukolla. Näin ollen monet aineistossamme olevat ohjeet ovat moniselitteisiä. Lisäksi ohjeiden käyttäytymisjärjestys ei ole aina sama. Esimerkiksi eräs henkilö sanoi \"käänny oikealle ja etene\" kuvaamaan osaa reitistä, kun taas toinen henkilö sanoi \"mene suoraan käännyttyään oikealle\" vastaavassa tilanteessa. Koska aineistomme luonnollisen kielen kuvauksissa on suurta vaihtelua, ohjeiden purkaminen käyttäytymiseksi ei ole aivan yksinkertaista. Katso lisäaineiston liite A, jossa on lisätietoja tiedonkeruupyrkimyksistämme.",
      "id": "task461-61867e2e678840c9b7f21693d61611df",
      "output": [
        "Käytettiinkö keruuprosessissa WoZ-menetelmää?"
      ]
    },
    {
      "input": "Tarkastelemme siis vastausten tuottamista TweetQA:ssa ja käytämme useita luonnollisen kielen tuottamiseen tarkoitettuja standardimittareita arvioidaksemme QAjärjestelmiä aineistossamme, nimittäin BLEU-1 BIBREF16 , Meteor BIBREF17 ja Rouge-L BIBREF18 tässä asiakirjassa.",
      "id": "task461-78059227587a4e0facf63dfd0278fc9a",
      "output": [
        "Mitä arviointimittareita ne käyttävät?"
      ]
    },
    {
      "input": "Valitettavasti $\\mathit {PMI}(w,c)$ on negatiivinen ääretön, kun sana-kontekstipari $(w,c)$ ei esiinny harjoituskorpuksessa. Epäluotettavien tilastojen vuoksi tämä tapahtuu hyvin usein äärellisissä korpuksissa. ",
      "id": "task461-06be03f2aef2448cb59387f6072facac",
      "output": [
        "Miksi rajallisista korpuksista saadut tilastot ovat epäluotettavia?"
      ]
    },
    {
      "input": "Tärkeintä on, että kaikilla kolmella kielellä on testitarkoituksiin käytettävät virheenkorjatut korpukset, vaikka niiden automaattista kielioppivirheiden korjausta koskeva työ on erittäin vähäistä (ks. kohta SECREF3 ).",
      "id": "task461-07e2d14895ff456090ed8947aacbf19a",
      "output": [
        "Tuovatko ne virheitä tietoihin vai sisältävätkö tiedot jo virheitä?"
      ]
    },
    {
      "input": "Ehdotamme yhteisölle seuraavaa haastetta: Meidän on kehitettävä uskollisuudelle muodollinen määritelmä ja arviointi, joka antaa meille vapauden sanoa, milloin menetelmä on riittävän uskollinen ollakseen käyttökelpoinen käytännössä.Toteamme kaksi mahdollista lähestymistapaa tähän tavoitteeseen: Mallien ja tehtävien yhdistäminen: Uskollisuuden aste (harmaasävyisenä) tiettyjen mallien ja tehtävien tasolla. Ehkä jotkin mallit tai tehtävät mahdollistavat riittävän uskollisen tulkinnan, vaikka sama ei päde toisiin. esimerkiksi menetelmä ei ehkä ole uskollinen jollekin kysymys-vastaus-tehtävälle, mutta uskollinen elokuva-arvostelujen sentimentille, kenties näiden tehtävien erilaisten syntaktisten ja semanttisten ominaisuuksien perusteella. across input space: Uskottavuuden aste syöttöavaruuden aliavaruuksien, kuten samankaltaisten syötteiden naapurustojen tai yksittäisten syötteiden tasolla. Jos pystymme sanomaan tietyllä varmuudella, onko tietyn päätöksen selitys uskollinen mallille, vaikka tulkintamenetelmää ei pidettäisikään yleisesti uskollisena, sitä voidaan käyttää vain näiden erityisalueiden tai -tapausten osalta.",
      "id": "task461-2cdf4259ed904624aa8e79ec360b7f5b",
      "output": [
        "Mitä uskollisuuden kriteerejä he ehdottavat?",
        "Mitä lähestymistapoja he ehdottavat?"
      ]
    },
    {
      "input": "Tässä asiakirjassa keskitymme BIBREFissä0 ehdotettuun skipgrammimenetelmään, jossa käytetään satunnaisia negatiivisia esimerkkejä. ",
      "id": "task461-54677226dd7c4f018cbbb82bf28d2f95",
      "output": [
        "Käyttävätkö he word2vecin skipgram-versiota?"
      ]
    },
    {
      "input": "MTurk-kyselymme vastaajilla oli eniten vaikeuksia tunnistaa luokan $(b=0.3, \\lambda=-5)$ arvosteluja, joissa todellisten positiivisten arvostelujen osuus oli $40.4\\%$, kun taas todellisten negatiivisten arvostelujen osuus oli $62.7\\%$. Tarkkuus oli vastaavasti 16 \\%$ ja 86 \\%$. Luokan keskimääräinen F-pistemäärä on 47,6 \\%$, mikä on lähellä satunnaisarvoa. Yksityiskohtaiset luokitusraportit on esitetty liitteen taulukossa~\\ref{table:MTurk_sub}. MTurk-tutkimuksemme osoittaa, että \\emph{Meidän NMT-väärennetyt arvostelut muodostavat merkittävän uhan arvostelujärjestelmille}, koska \\emph{tavallisilla englantia äidinkielenään puhuvilla on hyvin suuria vaikeuksia erottaa todelliset arvostelut väärennetyistä arvosteluista}. Käytämme arvosteluluokkaa $(b=0.3, \\lambda=-5)$ tulevissa käyttäjätesteissä, koska MTurkin osallistujilla oli eniten vaikeuksia havaita näitä arvosteluja. Käytämme tästä kategoriasta tässä asiakirjassa nimitystä NMT-Fake*. Luokittelija on erittäin tehokas havaitsemaan arvosteluja, joita ihmisillä on vaikeuksia havaita. Esimerkiksi väärennetyt arvostelut, joita MTurkin käyttäjillä oli eniten vaikeuksia havaita ($b=0.3, \\lambda=-5$), havaitaan erinomaisella 97\\% F-tuloksella.",
      "id": "task461-605c5800c5dc424990fb45a7a12e0c85",
      "output": [
        "Toimiiko heidän havaitsemisvälineensä paremmin kuin ihmisen havaitseminen?"
      ]
    },
    {
      "input": "Tietomme on kerätty akateemisesta yelp-tietokannasta, jonka tarjoaa Yelp.com, suosittu ravintola-arvostelusivusto. Tietoaineisto sisältää kolmenlaisia objekteja: liiketoiminta-, käyttäjä- ja arvosteluobjekteja, joissa liiketoimintaobjektit sisältävät perustietoja paikallisista yrityksistä (esim. ravintoloista), arvosteluobjektit sisältävät arvostelutekstejä ja tähtiluokituksia, ja käyttäjäobjektit sisältävät yksittäisen käyttäjän yhteenlaskettuja tietoja koko Yelpistä. Taulukossa TABREF31 esitetään tietokokonaisuuden yleiset tilastotiedot.",
      "id": "task461-a723caf5f54f4ac194f49e1855a83f35",
      "output": [
        "Keskittyvätkö ne johonkin tiettyyn tuote-/palvelualaan?"
      ]
    },
    {
      "input": "Osoitamme, että määrittämällä ja integroimalla heterogeeninen joukko eri modaliteeteista peräisin olevia piirteitä - esteettiset piirteet lähetetyistä kuvista (värikkyys, värisävyjen vaihtelu, terävyys, kirkkaus, epätarkkuus, luonnollisuus), profiilikuvan valinta (sukupuolen, iän ja kasvojen ilmeen osalta), näyttönimi, kielelliset piirteet sekä tekstisisällöstä että profiilin kuvauksesta (n-grammi, tunne, sentimentti) ja lopuksi sosiaalisuus ego-verkostosta ja käyttäjän sitoutumisesta - voimme luotettavasti havaita todennäköiset masentuneet henkilöt 8 770 ihmisen kommentoimasta Twitter-käyttäjästä koostuvasta aineistosta.",
      "id": "task461-1626183d78ec46f397ef4424f7c1dce1",
      "output": [
        "Mikä on käyttäjän vuorovaikutustietojen lähde? ",
        "Mikä on tekstiaineiston lähde? ",
        "Mikä on visuaalisen tiedon lähde? "
      ]
    },
    {
      "input": "Taulukosta TABREF24 käy ilmi, että vaikka dekooderikerrosten vaihtaminen koodauskerroksiin on koulutuksessa pieni nopeutus, dekoodauksessa se on merkittävä. Transformer, jossa on 10 koodauskerrosta ja 2 dekoodauskerrosta, on 2,32 $ kertaa nopeampi kuin 6-kerroksinen Transformer ja saavuttaa samalla hieman korkeamman BLEU-arvon.",
      "id": "task461-469a964fc9eb415e9deb0b2f4657a5a1",
      "output": [
        "Kuinka paljon dekoodausnopeus kasvaa, kun kooderin syvyyttä lisätään ja dekooderin syvyyttä pienennetään?"
      ]
    },
    {
      "input": "Esittelemme ehdottamamme monimuotoisuus-, tiheys- ja homogeenisuusmittarit sekä niiden yksityiskohtaiset muotoilut ja keskeiset intuitiot.",
      "id": "task461-2a13a3d182a8438ab3b61e507dd566c3",
      "output": [
        "Ehdottivatko he muita mittareita?"
      ]
    },
    {
      "input": "Käytämme kokeissa kahta tietokokonaisuutta (taulukko TABREF29 ): (Se koostuu 1 108 ainutlaatuisesta englanninkielisestä hashtagista 1 268 satunnaisesti valitusta twiitistä Stanfordin sentimenttianalyysitietokannasta BIBREF36 sekä niiden joukkoryhmittäisistä segmentoinneista ja meidän lisäkorjauksistamme; ja (b) STAN INLINEFORM1 , uusi asiantuntijoiden kuratoima tietokokonaisuutemme, joka sisältää kaikki 12 594 ainutlaatuista englanninkielistä hashtagia ja niihin liittyvät twiitit samasta Stanfordin tietokokonaisuudesta.",
      "id": "task461-f0a40598963b4b5caf689e8b43cf9125",
      "output": [
        "Sisältävätkö hashtag- ja SemEval-tietokannat vain englanninkielisiä tietoja?",
        "Mistä hashtagien tietokanta on peräisin?"
      ]
    },
    {
      "input": "Keskitymme Twitter-sivuston sosiaalisen median viesteihin, jotka ovat erinomainen testialusta merkkipohjaisille malleille tekstin meluisan luonteen vuoksi. Slangin runsas käyttö ja runsaat kirjoitusvirheet tarkoittavat, että ortografisesti ja semanttisesti samankaltaisia merkkejä on paljon, ja erikoismerkit, kuten hymiöt, ovat myös erittäin suosittuja ja sisältävät hyödyllistä semanttista tietoa. Kohtalaisen suuressa, 2 miljoonan twiitin mittaisessa harjoitusaineistossa oli noin 0,92 miljoonaa yksilöllistä sanatyyppiä.",
      "id": "task461-aef881d0159a47939edc286523893290",
      "output": [
        "Osoitetaanko asiakirjassa selvästi, että tässä luetellut haasteet ovat olemassa kyseisessä tietokokonaisuudessa ja tehtävässä?"
      ]
    },
    {
      "input": "Kone-kone-vuorovaikutus Aiheeseen liittyvässä työssä tutkitaan simulointipohjaista vuoropuhelun tuottamista, jossa käyttäjän ja järjestelmän roolit simuloidaan täydellisen keskustelun kulun luomiseksi, joka voidaan sitten muuntaa luonnolliseksi kieleksi joukkojen työntekijöiden avulla BIBREF1. Tällainen kehys voi olla kustannustehokas ja virheenkestävä, koska sen taustalla oleva joukko-osallistujien tehtävä on yksinkertaisempi ja semanttiset merkinnät saadaan automaattisesti. Usein väitetään, että simulaatiopohjainen tiedonkeruu ei tuota luonnollisia dialogeja tai riittävää kattavuutta verrattuna muihin lähestymistapoihin, kuten Wizard-of-Oz:iin. Väitämme, että simulaatiopohjainen tiedonkeruu on parempi vaihtoehto tämänkaltaisten tietokokonaisuuksien keräämiseen jäljempänä esitettyjen tekijöiden vuoksi.",
      "id": "task461-756ca72783f046e6b6e70d40db8c1626",
      "output": [
        "Miten he keräsivät tiedot?"
      ]
    },
    {
      "input": "Vaikka BERT-QC saavuttaa ARC-tietokannassa suuria voittoja nykyisiin menetelmiin verrattuna, tässä osoitamme, että BERT-QC vastaa myös TREC BIBREF6 -tietokannassa uusimman tekniikan tasoa ja ylittää uusimman tekniikan tason myös kuluttajien terveyskysymyksiä sisältävässä GARD-tietokannassa BIBREF3 ja biolääketieteellisiä kysymyksiä sisältävässä MLBioMedLAT-tietokannassa BIBREF4 .",
      "id": "task461-b722230b316143c88abf55874fb1b24a",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Käytämme DNN-pohjaista akustista mallia BIBREF0, jossa on 11 piilokerrosta, ja mallin kouluttamiseen käytetty kohdistus on peräisin SAT-kriteerillä koulutetusta HMM-GMM-mallista.",
      "id": "task461-b1c3eebcbad648fe8e99056438f42dab",
      "output": [
        "Mitä syväoppimisarkkitehtuureja tehtävässä käytetään?"
      ]
    },
    {
      "input": "Uutiskategoria-aineisto BIBREF11 on kokoelma HuffPostin BIBREF12 vuosina 2012-2018 julkaisemia otsikoita, ja se saatiin verkossa Kaggle BIBREF13 -palvelusta. Koko tietokokonaisuus sisältää 200k uutisotsikkoa, joissa on kategoriatunnisteet, julkaisupäivät ja lyhyet tekstikuvaukset.",
      "id": "task461-ae13940ff5f44e4bb3129e4afec95491",
      "output": [
        "Mitä uutistietoaineistoa käytettiin?"
      ]
    },
    {
      "input": "Tässä jaksossa arvioimme ehdotettua menetelmää sisäisesti sen suhteen, pystyykö matalan sijan approksimaation jälkeinen yhteisesiintymismatriisi kuvaamaan samankaltaisia käsitteitä opiskelijoiden vastausdatajoukoissa, ja myös ulkoisesti tiivistämisen lopputehtävän suhteen kaikissa korporaatioissa. Seuraavissa kokeissa yhteenvedon pituudeksi asetetaan ihmisten tekemien yhteenvetojen keskimääräinen sanamäärä tai vähemmän. Vaihtoehtoinen tapa arvioida hypoteesia on antaa ihmisten arvioida, ovatko kaksi bigramia samankaltaisia vai eivät, minkä jätämme tulevaa työtä varten.",
      "id": "task461-1bf67429336744c49ee4be2d573f5b45",
      "output": [
        "Arvioivatko he kvantitatiivisesti vai kvalitatiivisesti matalan sijan approksimaation tulosta tarkistaakseen leksikaalisten nimikkeiden ryhmittelyn?"
      ]
    },
    {
      "input": "Tunneanalyysikokeissa havaitsimme, että twiitti voi sisältää useita tunteita. Groundtruth-tunnisteet sisältävät 210 positiivista, 521 neutraalia ja 305 negatiivista tunnetta ehdokkaille.",
      "id": "task461-be283148ad714b1ab13ffa306db1456e",
      "output": [
        "Ovatko tunneanalyysin tietokokonaisuudet tasapainossa?"
      ]
    },
    {
      "input": "Ominaisuutemme koostuivat suorasta samankaltaisuudesta ConceptNetin Numberbatch-sulkeumien kanssa, SME:n ConceptNetistä päättelemistä suhteista, ominaisuuksista, jotka yhdistävät ConceptNetin muihin resursseihin (WordNet ja Wikipedia), sekä puhtaasti korpuspohjaisesta ominaisuudesta, joka etsii kahden sanan lauseita Google Books -tietokannasta.",
      "id": "task461-f06d77fc013145deb71e2e3a658cc39c",
      "output": [
        "Mitä ominaisuuksia he harjoittelivat?"
      ]
    },
    {
      "input": "sanojen upottaminen, syötteen koodaus, kohdistaminen, yhdistäminen ja ennustaminen.",
      "id": "task461-b756df30cb8846fcb159810f3067ad31",
      "output": [
        "mikä on perusmallin arkkitehtuuri?"
      ]
    },
    {
      "input": " Korkealla tasolla arvioimme epäsuorasti sisällön relevanssia ehdokasyhteenvedon ja ihmisen tekemän yhteenvedon välillä tiedonhaun avulla. Tätä varten käytämme tiivistelmiä hakukyselyinä ja vertailemme haettujen tulosten päällekkäisyyksiä. ",
      "id": "task461-f1f573b6746641b397071998ffc5b3b9",
      "output": [
        "Miten ehdotetussa mittarissa mitataan sisällön merkityksellisyyttä?"
      ]
    },
    {
      "input": "Mukana on kymmenen subredditiä viidellä alueella, jotka ovat väärinkäyttö, sosiaalinen, ahdistus, PTSD ja talous, kuten tab:data-spreadissa on esitetty, ja analyysimme keskittyy verkkotunnustasolle. ",
      "id": "task461-6abf478844374c8ba6a4fd9d527b7ac4",
      "output": [
        "Mistä luokista tietokokonaisuus on peräisin?"
      ]
    },
    {
      "input": "Osoittaaksemme arkkitehtuurissamme olevien tehtäväkohtaisten BiRNN-kerrosten tehokkuuden, teimme ablaatiotutkimuksen CoNLL04-tietokannan avulla. Koulutimme ja arvioimme samalla edellä kuvatulla tavalla käyttäen samoja hyperparametreja seuraavin poikkeuksin: Käytimme joko (i) yhtään NER-kohtaista BiRNN-kerrosta, (ii) yhtään RE-kohtaista BiRNN-kerrosta tai (iii) yhtään minkäänlaista tehtäväkohtaista BiRNN-kerrosta.Lisäsimme jaettujen BiRNN-kerrosten määrää, jotta mallin parametrien kokonaismäärä pysyisi samansuuruisena kuin perusmallissa.Keskitimme kunkin hyperparametrin tulokset kolmesta kokeesta satunnaisten painojen alustusten avulla.",
      "id": "task461-d07180915b484929946944ec68d7c35b",
      "output": [
        "Mitkä olivat ablaatiotutkimuksen muuttujat?"
      ]
    },
    {
      "input": " SemEval-2015- ja SemEval-2016-tapahtumissa parhaiten suoriutuneet järjestelmät käyttivät syviä konvoluutioverkkoja BIBREF53 , BIBREF54 ",
      "id": "task461-7c1286f0540f4c7c936ec958f57e970a",
      "output": [
        "Mikä on tämänhetkinen SOTA tunneanalyysille Twitterissä tätä kirjoitettaessa?"
      ]
    },
    {
      "input": "Joukkoruotsittajat antoivat sanapareille samankaltaisuuden sanojen samankaltaisuustehtävän aikana. ",
      "id": "task461-cfe9b8468d2f426b9b2c70cba8e7472c",
      "output": [
        "käyttivätkö he joukkoistamisalustaa huomautusten tekemiseen?"
      ]
    },
    {
      "input": "Frege kannatti sitä, mitä voisimme kutsua lauseen holismiksi: \"Vain lauseen yhteydessä sanalla on merkitys.\" BIBREF10",
      "id": "task461-17a86cfbf1c04dadafa821b6e7cdc648",
      "output": [
        "Mitä Fregen holistinen ja funktionaalinen lähestymistapa merkitykseen toteaa?"
      ]
    },
    {
      "input": "Konkreettisesti valitsimme kultakantastandardit, jotka sopivat ongelman määritelmäämme ja jotka on julkaistu vuosina 2016-2019, joilla on vähintään $(2019 - julkaisuvuosi\\ vuosi) \\ kertaa 20$ viittauksia, ja poimimme ne vastausten valintatyylien mukaisesti, kuten luvussa SECREF4 on kuvattu.",
      "id": "task461-9bd72766f5c74f9cb8df6602314f6b4f",
      "output": [
        "Mitä nykyaikaisia MRC:n kultaisia standardeja analysoidaan?"
      ]
    },
    {
      "input": "Analyysimme osoittaa, että tarkkaavaisuus mallintaa perinteistä linjausta joissakin tapauksissa tarkemmin, kun taas toisissa tapauksissa se tallentaa linjauksen ulkopuolista tietoa. Esimerkiksi substantiivien kohdalla huomio vastaa pitkälti perinteistä kohdistusta. Verbeissä se kuitenkin tallentaa muutakin tietoa kuin vain käännösvastineen. Voidaan nähdä, että huomion menetys vaihtelee huomattavasti eri POS-tunnisteiden välillä. Keskitymme erityisesti tapauksiin NOUN ja VERB, jotka ovat aineistossa yleisimmät POS-tunnisteet. Kuten nähdään, NOUNin huomio on keskimäärin lähimpänä kohdistuksia. VERBin keskimääräinen huomionmenetys on kuitenkin lähes kaksi kertaa suurempi kuin NOUNin.",
      "id": "task461-a6774f15b819408689cb42460150f6aa",
      "output": [
        "Mitä hyödyllistä tietoa tarkkaavaisuus tallentaa?"
      ]
    },
    {
      "input": "Tämän artikkelin koeasetukset ja Mboshi-korpuksen arviointiprotokolla (Boundary F-pisteet käyttäen ZRC-puheviitettä) ovat samat kuin BIBREF8:ssa. Taulukossa esitetään tulokset kaksikielisen UWS:n ja monikielisen vivutuksen osalta. ",
      "id": "task461-fd2b7362df8d42f89c1409e28e040138",
      "output": [
        "Ilmoitetaanko asiakirjassa mallin tarkkuus?"
      ]
    },
    {
      "input": "VQA-tutkimus alkoi toden teolla vuoden 2014 lopulla, kun DAQUAR-tietokanta julkaistiin BIBREF0",
      "id": "task461-5847e7a548f147f8a7428d5fd8ec8b4e",
      "output": [
        "Mistä lähtien monet VQA:n tietokokonaisuudet on kerätty?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvataan, miten arvioidaan ja vertaillaan sellaisten algoritmien tuloksia, jotka antavat sanoille relevanssipisteitä (kuten LRP tai SA) sisäisen validoinnin avulla. Lisäksi ehdotamme mallin selitysvoiman mittausta, joka perustuu ulkoiseen validointimenettelyyn.",
      "id": "task461-bf10b81b572c47b4b1d362ddd07151cb",
      "output": [
        "Arvioidaanko kirjoittajien esittelemiä asiakirjavektoreita jollakin muulla tavalla kuin kirjoittajien ehdottamalla uudella tavalla?"
      ]
    },
    {
      "input": "Toisessa testisarjassa käytettiin kaikkia \"asiantuntija\"-osakorpuksen $E$ asiakirjoja, koska Annodis-osakorpuksen asiakirjat eivät ole identtisiä.  Järjestelmän arvioinnissa käytämme vertailukohtana 78 $E$-asiakirjaa.  Laskemme tarkkuuden $P$, palautuksen $R$ ja $F$-pistemäärän testeissä käytetystä tekstikorpuksesta seuraavasti:",
      "id": "task461-3b3e957166324691ad52e512cae3d663",
      "output": [
        "Miten segmentoinnin laatua arvioidaan?"
      ]
    },
    {
      "input": "Mallimme tuottaa parhaat tulokset sekä ammattikorkeakoulu- että LAS-mittareilla kaikissa kielissä japania lukuun ottamatta. Japanin osalta mallimme antaa epätyydyttäviä tuloksia, koska alkuperäinen puupankki oli kirjoitettu roomalaisilla foneettisilla kirjaimilla hiraganan sijasta, jota käytetään sekä tavallisessa japanin kirjoitusasussa että esivalmennetuissa upotuksissa. Tästä huolimatta mallimme antaa kokonaisuutena 1,0 % paremmat keskimääräiset ammattikorkeakoulu- ja ammattikorkeakoulu- ja ammattikorkeakoululaskennan tulokset kuin edellinen paras jäsentäjä, BIAF. Vaikka sekä BIAF- että STACKPTR-jäsennysmallit ovat saavuttaneet suhteellisen korkean jäsennystarkkuuden 12 kielellä ja niiden kaikkien UAS on yli 90 %, mallimme saavuttaa huipputulokset kaikilla kielillä sekä UAS:n että LAS:n osalta. Kaiken kaikkiaan mallimme raportoi yli 1,0 % korkeamman keskimääräisen ammattikorkeusasteen kuin STACKPTR ja 0,3 % korkeamman kuin BIAF.",
      "id": "task461-c5aad0478c7a46e2a055f975e59a7c6c",
      "output": [
        "Mikä on suorituskyky verrattuna aiempiin malleihin?"
      ]
    },
    {
      "input": "Tätä vaihetta seurasi esikäsittelyvaihe, jossa tekstit normalisoitiin korvaamalla ZWNJ (zero-width-non-joiner) BIBREF2 -merkki ja tarkistamalla ortografia manuaalisesti Irakin Kurdistanin alueen viiteortografian perusteella.",
      "id": "task461-060211e6421942ccad5e61d7eeacb7ca",
      "output": [
        "Miten korpus normalisoidaan?"
      ]
    },
    {
      "input": "S2-GORC on laaja viittausgrafiikkatietokanta, joka sisältää 8,1 miljoonan tieteellisen asiakirjan kokotekstit. Korpuksemme on 154 000 tietotekniikka-artikkelin osajoukko. Näistä poimimme 622K viittauslausetta, jotka viittaavat muihin korpuksen asiakirjoihin. Pidämme 2500 esimerkkiä kumpaankin validointi- ja testijoukkoon.",
      "id": "task461-7968ed18d66740c698ad310eba7282ac",
      "output": [
        "Mikä on korpuksen koko?"
      ]
    },
    {
      "input": "BIBREFin3 keräämät tiedot, joita kutsumme seksistiseksi/rasistiseksi (SR) tietokokonaisuudeksi, kerättiin käyttämällä alustavaa Twitter-hakua, jonka jälkeen kirjoittajat ja heidän tiiminsä tekivät analyysin ja suodatuksen ja tunnistivat 17 yleistä lausetta, hashtagia ja käyttäjää, jotka viittasivat loukkaavaan puheeseen. BIBREF4 keräsi HATE-tietoaineiston etsimällä twiittejä Hatebase.orgin tarjoaman sanaston avulla. Lopullisen käyttämämme aineiston, jota kutsumme nimellä HAR, keräsi BIBREF9 ; poistimme kaikki uudelleentwiittaukset ja pienensimme aineiston 20 000 twiittiin.",
      "id": "task461-b026dc8314a0432a881ae45125af1676",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Tämän teknologian tulevan kehityksen kannalta korostamme, että on tärkeää vastata neljään kysymykseen: 1) Miten otetaan käyttöön valvomaton esiharjoittelu NLG-tehtävissä, joissa on ristikkäismodaalinen konteksti? 2) Miten suunnitella geneerinen esivalmennusalgoritmi, joka sopii monenlaisiin NLG-tehtäviin? 3) Miten vähentää laajamittaiseen esivalmennukseen tarvittavia laskentaresursseja? 4) Minkälaista tietoa esikoulutetut mallit tarjoavat paremman kielen tuottamisen kannalta?",
      "id": "task461-2f96765ac55541ff81934725d502886e",
      "output": [
        "Mistä NLG:n tulevasta suunnasta keskustellaan?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua malliamme BIBREF12:n kirjoittajilta saadulla Twitter-tietoaineistolla. Lopullinen tietokokonaisuutemme koostuu 11 576 käyttäjästä (eli faktantarkistajasta), 4 732 faktantarkistusosoitteesta ja 63 429 vuorovaikutuksesta. Tietokokonaisuus sisältää myös kunkin käyttäjän sosiaalisen verkoston tiedot. Huomaa, että kunkin käyttäjän sosiaaliset suhteet on rajoitettu tietokannassa käytettävissä oleviin käyttäjiin.",
      "id": "task461-ecf6d668b00049529a4289f602495877",
      "output": [
        "Mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Aiempien tutkimusten BIBREF1 mukaisesti keräämme tapahtumiin liittyviä mikroposteja Twitteristä käyttämällä 11 ja 8 siementapahtumaa (ks. jakso SECREF2) vastaavasti CyberAttack- ja PoliticianDeath-tapahtumille.",
      "id": "task461-c3b61bc02da947b18d9587d0d2d8c45c",
      "output": [
        "Mitä reaalimaailman tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Otimme 200 lauseparia BIBREF3 -tietokannasta ja annoimme jokaiselle parille asiakirjakontekstin, joka koostuu edeltävästä ja seuraavasta lauseesta, kuten seuraavassa esimerkissä.",
      "id": "task461-ecddee7330de4832a5e85b361e402d6f",
      "output": [
        "Mikä asiakirjan konteksti lisättiin?"
      ]
    },
    {
      "input": "Koulutamme yksikerroksisen LSTM:n, jossa on 150-ulotteinen piilotila viha/ei-viha luokittelua varten. Syötteen ulottuvuudeksi asetetaan 100, ja sanojen syöttöesityksinä käytetään GloVe BIBREF26 -sisällön upotuksia.",
      "id": "task461-2c0a7e8dd58a4c96844b592c5a9a3dbb",
      "output": [
        "Mitä unimodaalisia havaintomalleja käytettiin?"
      ]
    },
    {
      "input": "Vaikka MCDN ei saavuta suurinta tarkkuutta, se parantaa F1-tulosta 10,2 % ja 3 % verrattuna nykyisiin parhaisiin järjestelmiin $LS \\cup KLD \\cup CONN$ ja $KLD \\cup LS \\cup LS_inter}$.",
      "id": "task461-e8d710962d704093a0081c43b08830e4",
      "output": [
        "Millainen suorituskyky ehdotetulla menetelmällä saavutettiin ja kuinka paljon parempi se on kuin aiempi huipputekniikka?"
      ]
    },
    {
      "input": "Vähintään kaksi kommentoijaa tarkistaa kaikkien kysymys-vastausparien tyypin ja oikeellisuuden.",
      "id": "task461-8049aee2c02044b2a797e29c559c7bec",
      "output": [
        "Mikä oli kommentoijien välinen sopimus?"
      ]
    },
    {
      "input": "Koulutamme Word2Vecin, jonka vektorin koko on $d_\\mathrm {W2V} = d_\\mathrm {LM} = 768$, PubMed+PMC-tietokannalla (lisätietoja on liitteessä). Sen jälkeen noudatamme SECREF3-jaksossa kuvattua menettelyä päivittääksemme sanakappaleiden upotuskerroksen ja tokenisaattorin yleistason BERT-järjestelmän sanakappaleiden upotuskerroksen ja tokenisaattorin.",
      "id": "task461-d099dd34df3649c59c93b30e8024fba5",
      "output": [
        "Mitä domainin sisäistä tekstiä he käyttivät?"
      ]
    },
    {
      "input": "Viralliset tuloksemme (sarake Ens Test taulukossa TABREF19 ) ovat sijoittaneet meidät SemEval AIT-2018 -kilpailun tulostaulukossa toiseksi (EI-Reg, EI-Oc), neljänneksi (V-Reg) ja viidenneksi (V-Oc).",
      "id": "task461-672c5b45b4f3409dbc826514b0ca6b1f",
      "output": [
        "Mitkä olivat heidän järjestelmänsä pisteet?"
      ]
    },
    {
      "input": "Esitämme jokaisen kuvan, kysymyksen ja käyttäjän valinnan kolmikkona, joka koostuu kuvan ominaisuudesta, kysymyksen ominaisuudesta ja käyttäjän vastauksen merkintävektorista. Lisäksi useiden samanlaisten käyttäjien tekemien valintojen kerääminen mahdollistaa sen, että voimme esittää kaksi saman käyttäjän tekemää tapausta kolmikkoparina, kun oletetaan lähde-kohde-suhde. Näiden kolmikkoparien avulla voimme kouluttaa järjestelmän ennustamaan käyttäjän valinnan uudessa kuvassa ja uudessa kysymyksessä, kun otetaan huomioon saman käyttäjän valinta edellisessä kuvassa ja siihen liittyvä kysymys. Kuten aiemmin todettiin, pyrimme heijastamaan käyttäjän kiinnostusta esittämällä kysymyksiä, jotka tarjoavat visuaalisen kontekstin. Toisin sanoen kysymys, jonka vastaus on niin ilmeinen, että siihen voidaan vastata samalla tavalla, ei kelpaisi interaktiiviseksi kysymykseksi.   Jos todennäköisimmän ehdokkaan $c_i=\\max p_{ans}$ , jossa $c_i \\ in C$ , vastaustodennäköisyys on yli tietyn kynnysarvon $\\alpha$ , kysymyksellä katsotaan olevan vain yksi ilmeinen vastaus, eikä sitä siten pidetä hyväksyttävänä.  Kokeissamme asetimme $\\alpha$:ksi 0,33. Lisäksi jätimme pois kyllä/ei-tyyppiset kysymykset. ",
      "id": "task461-164f031f1a3846f2957e06425a416ea3",
      "output": [
        "Mitä ominaisuuksia käytetään kohdekäyttäjien vuorovaikutuksen mukauttamiseen? "
      ]
    },
    {
      "input": " Tässä tehtävässä aineistona käytetään keskusteluketjujen englanninkielisiä twiittejä, joista jokainen liittyy uutisarvoiseen tapahtumaan ja sitä ympäröiviin huhuihin. Tavoitteena on määrittää, tukeeko, kiistääkö, kyseenalaistaa vai kommentoiko keskusteluketjuun kuuluva twiitti alkuperäistä huhua, josta keskustelu alkoi. ",
      "id": "task461-cf7eff21d80b45ac8e091c1eb88bf429",
      "output": [
        "Onko tämä englanninkielinen tietokokonaisuus?"
      ]
    },
    {
      "input": "Tämä johtaa kolmeen lisävektoriin, jotka vastaavat INLINEFORM3-, INLINEFORM4- ja INLINEFORM5-erovektoreita.Tulokset",
      "id": "task461-5cde86c3b598442a8cc28bc9a6756aa3",
      "output": [
        "Miten EAU:n tekstivälejä kommentoidaan?"
      ]
    },
    {
      "input": "Valitsimme mallimme arvioimiseksi suuren kiinalaisen BIBREF0-tietokannan, jossa on miljoonia oikeita kommentteja, ja ihmisen kommentoiman testikannan. Tietokokonaisuus on kerätty Tencent Newsilta, joka on yksi suosituimmista kiinalaisista uutis- ja mielipideartikkelisivustoista. Tietoaineisto koostuu 198 112 uutisartikkelista. Jokainen uutinen sisältää otsikon, artikkelin sisällön ja luettelon käyttäjien kommenteista.",
      "id": "task461-187417395f004e14a4bd3955a0114f76",
      "output": [
        "Mitä uutiskommenttiaineistoa käytettiin?"
      ]
    },
    {
      "input": "Tässä lähestymistavassa kahden sanan välinen samankaltaisuus ei perustu varsinaisesti niiden esiintymistiheyteen, vaan pikemminkin niiden muiden sanojen esiintymistiheyteen, jotka esiintyvät molempien sanojen kanssa (eli toisen asteen esiintymistiheys). Tämä lähestymistapa on osoittautunut onnistuneeksi semanttisen sukulaisuuden kvantifioinnissa BIBREF12 , BIBREF13 .",
      "id": "task461-953a0c151aa34eb2853b2c399e4cf068",
      "output": [
        "Mikä on toisen kertaluvun kookurenssimatriisi?"
      ]
    },
    {
      "input": "Arvioimme malliamme kahdella vertailupankilla, englanninkielisellä Penn Treebankilla (PTB) ja kiinankielisellä Penn Treebankilla (CTB5.1), jotka noudattavat vakiomuotoista tiedonjakoa BIBREF30, BIBREF31. POS-tunnisteet ennustetaan Stanford Tagger BIBREF32 -ohjelmalla. Konstituenttien jäsentelyssä käytämme vakiomuotoista evalb-työkalua F1-tuloksen arvioimiseksi. Riippuvuuksien jäsentämiseen käytetään Stanfordin perusriippuvuuksien (SD) esitystä BIBREF4 , jonka Stanfordin jäsentäjä on muuntanut. Aiempien töiden BIBREF27 ja BIBREF33 mukaisesti raportoimme tulokset ilman välimerkkejä molempien puupankkien osalta. Taulukoissa TABREF17, TABREF18 ja TABREF19 verrataan malliamme olemassa olevaan huipputekniikkaan, jossa indikaattori Separate with our model osoittaa mallimme tulokset, jotka on saatu oppimalla konstituenttien tai riippuvuuksien jäsennys erikseen, ja (Sum) ja (Concat) vastaavasti tulokset, joissa on ilmoitettu merkkien esitys. PTB:ssä mallimme saavuttaa 93,90 F1-tuloksen konstituenttien jäsennyksessä ja 95,91 ammattikorkeakoulu- ja 93,86 LAS-tuloksen riippuvuuksien jäsennyksessä. CTB:ssä mallimme saavuttaa uuden huipputuloksen sekä ainesosien että riippuvuuksien jäsentelyssä. Lopuksi malliamme arvioidaan kahdella vertailupankilla sekä konstituentti- että riippuvuusjäsennyksen jäsennyksen osalta. Empiiriset tulokset osoittavat, että jäsentäjämme saavuttaa uuden huipputason kaikissa jäsentämistehtävissä.",
      "id": "task461-63f0ae34704e4a97872cd4c67980c8a2",
      "output": [
        "Miten riippuvuuksien jäsentäminen todennetaan empiirisesti?"
      ]
    },
    {
      "input": "Useissa viimeaikaisissa töissä on tutkittu akustisen mallin ja peittävän puheenparannusmallin yhteistä harjoittelua BIBREF11, BIBREF12, BIBREF13 , mutta näissä töissä järjestelmää ei ole arvioitu puheenparannusmittareilla. Sisäiset kokeilumme osoittavat, että ilman puhdasta dataa yhteinen harjoittelu heikentää huomattavasti suorituskykyä näillä mittareilla.",
      "id": "task461-e931c17362654f3489f9ab6b4b8c4a92",
      "output": [
        "Mitä jäädytettyä akustista mallia he käyttävät?"
      ]
    },
    {
      "input": "Kokeelliset tulokset julkisista tietokannoista osoittavat, että CRU-mallimme voi päihittää huomattavasti eri järjestelmät ja luoda uusia huippuluokan suorituskykyjä asiaan liittyvissä tietokannoissa.",
      "id": "task461-a9b4fede0137410bb1aaef6f997b4b5c",
      "output": [
        "Onko näissä tehtävissä saavutettu joitakin nykyistä parempia tuloksia?"
      ]
    },
    {
      "input": "Arviointimittareina käytetään tarkkuutta, palautusta, F1:tä ja tarkkuutta.",
      "id": "task461-ec93f63007174268ac7f24ef79354d04",
      "output": [
        "mitä arviointimittareita raportoidaan?"
      ]
    },
    {
      "input": "Kuten INLINEFORM0 -menetelmässä, Vihreät, EFA, S&D ja EPP osoittavat suurinta yhteenkuuluvuutta, vaikka niiden järjestys on muuttunut INLINEFORM1 -menetelmällä saatuun järjestykseen verrattuna. Asteikon toisessa päässä havaitaan sama tilanne kuin INLINEFORM2 :n yhteydessä: liittoutumattomien NI-jäsenten koheesio on alhaisin, ja seuraavina ovat EFDD ja ENL. Ainoa kohta, jossa nämä kaksi menetelmää eroavat toisistaan, on GUE-NGL:n koheesiotaso. Alphan mukaan GUE-NGL:n koheesiotaso on melko korkea, yhtä korkea kuin ALDE:n, kun taas ERGM:n mukaan se on paljon alhaisempi.",
      "id": "task461-48a8d49b23934b0897b0e57d26924d73",
      "output": [
        "Mitä tietoja analyysi antaa Euroopan parlamentin poliittisten ryhmien yhteenkuuluvuudesta?"
      ]
    },
    {
      "input": "Vertaamme menetelmäämme Adoben sisäisellä NLU-työkalulla koulutettuihin malleihin sekä Pytext BIBREF18- ja Rasa BIBREF19 NLU-työkaluihin.",
      "id": "task461-b7d6b821be9d4bf9a7aa2d878ac26dbe",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "WinogradSchemas-kokoelman 144 skeemasta 33 voidaan kääntää tällä tavalla.",
      "id": "task461-94faa82758794c7694a83958378c9f71",
      "output": [
        "Keräsivätkö he omia tietokokonaisuuksiaan?"
      ]
    },
    {
      "input": "BIBREF11 mukaisesti kokeilemme anonymisoimatonta versiota BIBREF:stä. Yhteenvetoja luodessamme noudatamme vakiokäytäntöä, jossa säädämme tulosteen enimmäispituuden ja kiellämme saman trigrammin toistamisen BIBREF27 , BIBREF14 . Tätä tehtävää varten koulutamme kielimallin representaatioita newscrawlin ja harjoitusdatan yhdistelmällä. Taulukko TABREF16 osoittaa, että valmiiksi koulutetut upotukset voivat parantaa merkittävästi vahvan perusmuuntimen lisäksi. Vertaamme myös BIBREF26:een, joka käyttää tehtäväkohtaista arkkitehtuuria verrattuna yleiseen sekvenssistä sekvenssiksi -perusarkkitehtuuriin. Esikoulutetut esitykset täydentävät heidän menetelmäänsä.",
      "id": "task461-ffc46e6f8fbe4ca394010304c1d71121",
      "output": [
        "Mihin muihin malleihin niitä verrataan?"
      ]
    },
    {
      "input": "AblaatiotutkimusVoidaksemme tutkia tarkemmin kehyksemme keskeisten komponenttien eli THA:n ja STN:n tehokkuutta suoritamme ablaatiotutkimuksen taulukon TABREF39 toisessa lohkossa esitetyllä tavalla. Tulokset osoittavat, että THA ja STN auttavat kumpikin parantamaan suorituskykyä, ja STN:n osuus on hieman suurempi kuin THA:n. \"OURS ilman THA:ta ja STN:ää\" säilyttää vain perusbi-lineaarisen huomion. Vaikka se ei suoriudu huonosti, se on silti heikommin kilpailukykyinen kuin vahvin perusversio (CMLA), mikä viittaa siihen, että pelkkä huomiomekanismin käyttäminen mielipiteiden yhteenvedon tislaamiseen ei riitä. Kun STN-komponentti on lisätty ennen bilineaarista huomiota, eli \"OURS w/o THA\", saadaan noin 1 prosentin absoluuttinen parannus kussakin tietokokonaisuudessa, ja sen jälkeen suorituskyky on verrattavissa CMLA:n suorituskykyyn. Lisäämällä THA:n, eli \"OURS\", suorituskyky paranee entisestään, ja kaikki uusimmat menetelmät ohitetaan.",
      "id": "task461-376f4e5339f34e278b1663160ae0f368",
      "output": [
        "Tutkivatko he, kuinka hyödyllinen on havaintohistoria ja lausuntotiivistelmä?"
      ]
    },
    {
      "input": "a) Rinnakkainen skannauksen päättely b) Vektoroitu jäsennys c) Semiring-matriisioperaatiot Torch-Struct pyrkii laskennalliseen ja muistitehokkuuteen. Naiivisti toteutettuna Pythonissa dynaamisen ohjelmoinnin algoritmit ovat kohtuuttoman hitaita. Siksi Torch-Struct tarjoaa keskeisiä primitiivejä, jotka auttavat näiden algoritmien panostamisessa ja vektoroinnissa, jotta GPU-laskentaa voidaan hyödyntää ja minimoida takaperin etenemisestä aiheutuvat yleiskustannukset kaavioihin perustuvan dynaamisen ohjelmoinnin avulla.",
      "id": "task461-6d2fac0a6400484a956a9079e4ca1413",
      "output": [
        "Mitä yleiskäyttöisiä optimointeja sisältyy?"
      ]
    },
    {
      "input": "FarsNet [20] [21] on ensimmäinen persian kielen WordNet, jonka Shahid Beheshti -yliopiston NLP-laboratorio on kehittänyt ja joka noudattaa samaa rakennetta kuin alkuperäinen WordNet.",
      "id": "task461-4a910173e5f041efa53405b394ea3c03",
      "output": [
        "Mikä on persian kielen WordNet-vastine?"
      ]
    },
    {
      "input": " Määritimme sekvenssin merkitsemistehtävän, jonka avulla käyttäjän syötteestä voidaan poimia mukautettuja entiteettejä. Oletimme, että malli tunnistaa seitsemän (7) mahdollista entiteettiä (ks. taulukko TABREF43): aihe, alateema, tenttimismuoto ja -taso, kysymyksen numero, aikomus sekä muut entiteetit lausuman jäljellä oleville sanoille.   Määrittelimme luokitusongelman, jonka tarkoituksena on ennustaa järjestelmän seuraava toiminto käyttäjän antaman syötteen perusteella. Oletimme 13 mukautettua toimintoa (ks. taulukko TABREF42), joita pidimme merkintöinä. Keskusteluaineistossa sääntöpohjainen järjestelmä merkitsi automaattisesti jokaisen syötteen vastaavalla seuraavalla toiminnolla ja dialogitunnuksella. Näin ollen ylimääräistä jälkikäteistä merkitsemistä ei tarvittu. ",
      "id": "task461-81264cab6d684730952bc1467425fb4d",
      "output": [
        "Miten IPA merkitsee tiedot vuorovaikutuksessa käyttäjien kanssa?"
      ]
    },
    {
      "input": "Kuvasta FIGREF5 käy ilmi, että E-BERT toimii suodattamattomassa LAMA:ssa vertailukelpoisesti BERT:n ja ERNIE:n kanssa.",
      "id": "task461-dbcb304d1cff4a97b857cfad77379ab1",
      "output": [
        "Kumpi näistä kahdesta kokonaisuudesta tuottaa parhaan tuloksen?"
      ]
    },
    {
      "input": "Arvioimme STM-analyysia varten määriteltävien aiheiden optimaalisen määrän. Noudatamme alkuperäisen STM-asiakirjan suosituksia ja keskitymme yksinoikeuden ja semanttisen koherenssin toimenpiteisiin. Tietyssä aihepiirissä erittäin usein esiintyvien sanojen, jotka eivät esiinny kovin usein muissa aihepiireissä, katsotaan tekevän kyseisestä aihepiiristä eksklusiivisen.  BIBREF8:n mukaisesti luomme joukon ehdokasmalleja, jotka vaihtelevat 3 ja 50 aiheen välillä. Tämän jälkeen piirretään yksinoikeus ja semanttinen koherenssi (numerot lähempänä 0:ta tarkoittavat suurempaa koherenssia), ja niiden päälle asetetaan lineaarinen regressio (kuva FIGREF3 ). Regressiosuoran yläpuolella olevilla malleilla on \"parempi\" yksinoikeuden ja semanttisen koherenssin tasapaino. Valitsemme 16 aihepiirin mallin, jolla on suurin positiivinen jäännös regressiosovituksessa ja joka tarjoaa suuremman yksinoikeuden samalla semanttisen koherenssin tasolla. Aiheen laatua arvioidaan yleensä suurimman todennäköisyyden sanojen perusteella, mikä on esitetty kuvassa KUVIO4 .",
      "id": "task461-5132c49bd65c4be490845f4a4c3e613a",
      "output": [
        "Miten valtioiden esiin nostamat tärkeimmät kansainväliset kehitysyhteistyöaiheet tunnistetaan?"
      ]
    },
    {
      "input": "Annotaatioprosessi oli kokeilu ja erehdys, jossa annotaatiojaksot koostuivat annotaatiosta, hämmentävistä yksiköistä keskustelemisesta, annotaatio-oppaan kaavion päivittämisestä ja korpusosion uudelleen läpikäymisestä yksikköjen korjaamiseksi oppaan muutosten jälkeen.",
      "id": "task461-9db884dac5344f8ea63392a549151e6a",
      "output": [
        "Kokeilivatko he korpusta?"
      ]
    },
    {
      "input": "Tässä luvussa kuvaamme yksityiskohtaisesti keskusteluja, joita käytämme mittarimme testaamiseen, ja miten määrittelemme perustotuuden (eli onko keskustelu kiistanalainen vai ei). Käytämme kolmekymmentä erilaista keskustelua, jotka käytiin maaliskuun 2015 ja kesäkuun 2019 välisenä aikana, joista puolet oli kiistanalaisia ja puolet kiistattomia. Tarkastelimme keskusteluja neljällä eri kielellä: Ne käytiin viidellä eri alueella eri puolilla maailmaa: Etelä- ja Pohjois-Amerikassa, Länsi-Euroopassa, Keski- ja Etelä-Aasiassa. Tutkimme näitä keskusteluja myös ottamalla ensin 140 merkkiä ja sitten 280 merkkiä kustakin twiitistä analysoidaksemme eroa suorituskyvyssä ja laskenta-ajassa viestien pituuden mukaan.",
      "id": "task461-8aab08750af84bcda800bfb7f7c98ab5",
      "output": [
        "Kuinka monta kieltä he kokeilevat?"
      ]
    },
    {
      "input": "Menetelmämme on puhtaasti tekstipohjainen, eikä siinä oteta huomioon julkaisupäivää eikä artikkelin lähdettä. Siinä yhdistetään tehtäväkohtaiset sulautukset, jotka on tuotettu kaksitasoisella huomiopohjaisella syvän neuroverkon mallilla, manuaalisesti laadittuihin ominaisuuksiin (stilometriset, leksikaaliset, kieliopilliset ja semanttiset) ja kernel-pohjaiseen SVM-luokittimeen.",
      "id": "task461-c746184a3dc74b1599676aa7483bc955",
      "output": [
        "millaisia ominaisuuksia käytettiin?"
      ]
    },
    {
      "input": ". Erittäin dynaaminen yhteisö vaihtaa jatkuvasti kiinnostuksen kohteita aikaikkunasta toiseen, ja nämä ajalliset vaihtelut heijastuvat sen häilyvässä kielenkäytössä. Muodollisesti määrittelemme yhteisön INLINEFORM0 dynaamisuuden kaikkien INLINEFORM1 -yhteisön lausumien keskimääräiseksi volatiliteetiksi. ",
      "id": "task461-b03b85cc37734d0599b1329894c9650a",
      "output": [
        "Miten kirjoittajat mittaavat, kuinka ajallisesti dynaaminen yhteisö on?"
      ]
    },
    {
      "input": "Kaikki asiakirjat on jaettu kappaleisiin ja käsitelty kappaleiden tasolla (sekä harjoittelussa että päättelyssä); tämä on hyväksyttävää, koska olemme havainneet, että useimmat kappaleet ovat alle 200 merkkiä. BERT-tokenizer segmentoi syötesekvenssit siten, että alussa on erityinen [CLS]-merkki ja lopussa erityinen [SEP]-merkki.",
      "id": "task461-76ad051d980f414092523dc9d4b84e04",
      "output": [
        "Millä tekstiyksiköllä/tasolla asiakirjoja käsiteltiin?",
        "Hyödynnettiinkö mallia koulutettaessa sääntelyasiakirjojen rakennetta? "
      ]
    },
    {
      "input": "Wikipedia-artikkelin laatuluokan määrittelevät Wikipedian arvioijat tai kuka tahansa rekisteröitynyt käyttäjä, jotka voivat keskustella artikkelin keskustelusivulla päästäkseen yhteisymmärrykseen. ArXivin tietokokonaisuus BIBREF2 koostuu kolmesta osajoukosta tietotekniikan (cs) arXiv-tietokantaan kuuluvia akateemisia artikkeleita kolmelta aihealueelta: Artificial Intelligence (cs.ai), Computation and Language (cs.cl) ja Machine Learning (cs.lg). Alkuperäisen BIBREF2 -tietokannan muotoilun mukaisesti artikkeli katsotaan hyväksytyksi (eli positiivisesti merkityksi), jos se vastaa DBLP-tietokannassa olevaa artikkelia tai on muuten hyväksytty jossakin seuraavista konferensseista: ACL, EMNLP, NAACL, EACL, TACL, NIPS, ICML, ICLR tai AAAI. Jos näin ei tapahdu, se katsotaan hylätyksi (huomioiden, että joitakin artikkeleita ei välttämättä ole toimitettu mihinkään näistä konferensseista).",
      "id": "task461-2a61cf7139744e44a41f44bb2c694556",
      "output": [
        "Mistä he saavat perustotuuden mukaiset laatuarvionsa?"
      ]
    },
    {
      "input": "Tässä artikkelissa osoitamme, että sekä ihmisen että koneen kääntäminen voi muuttaa aineiston pinnallisia kuvioita, mikä edellyttää aiempien havaintojen tarkistamista kieltenvälisen siirto-oppimisen alalla.",
      "id": "task461-895dc7c4f791403c8d9b81a621739e32",
      "output": [
        "Ottaako ammattimainen käännös vai konekäännös käyttöön artefaktit?"
      ]
    },
    {
      "input": "BIBREF1:n kokeellisia asetuksia noudattaen yhdistämme mallimme tuottamat lauseiden esitykset ja modernimmalla valvomattomalla oppimismallilla (Layer Normalized Skip-Thoughts, ST-LN) BIBREF31 saadut esitykset. BIBREF1:n koesuunnitelmaa noudattaen teemme kokeita kolmella eri oppimistavoitteella: Cap2All, Cap2Cap ja Cap2Img.",
      "id": "task461-d5cff210933d4cb3b031211172588e40",
      "output": [
        "Mihin perustasoihin ehdotettua menetelmää verrataan?"
      ]
    },
    {
      "input": "Tutkimuksessamme käytetään WikiHop BIBREF0 -tietokokonaisuutta, koska se on entiteettipohjainen monisatamapohjainen laadunvarmistustietokanta, jota on käytetty aktiivisesti.",
      "id": "task461-8c32b3995c4b4c5bbf072ac59acc5666",
      "output": [
        "Mitä tietokokonaisuutta käytettiin kokeessa?"
      ]
    },
    {
      "input": "Tämän ongelman ratkaisemiseksi tutkimme, miten BERT-pohjaisten MCQA-mallien yleistettävyyttä voidaan parantaa rajoitetun harjoitusdatan rajoitteella käyttämällä neljää edustavaa MCQA-aineistoa: DREAM, MCTest, TOEFL ja SemEval-2018 Task 11.",
      "id": "task461-bb778e8a198c4aa7aaf42d971134701f",
      "output": [
        "Mitä neljää edustavaa tietokokonaisuutta käytetään bechmarkissa?"
      ]
    },
    {
      "input": "Yksi tärkeimmistä sanalle suoritettavista operaatioista on saada joukko sanoja, joiden merkitys on samankaltainen kuin sanan merkitys tai joiden käyttö tekstissä on samankaltaista kuin sanan käyttö. Kutsumme tätä joukkoa sanan naapurijoukoksi. Olemme havainneet, että monisanaisen sanan naapuri koostuu sanoista, jotka muistuttavat monisanaisen sanan ensisijaista merkitystä.  Vaikka sana voi olla polysemi, se vastaa yleensä yhtä vektoria hajautetussa esityksessä. Tämä vektori määräytyy ensisijaisesti päämerkityksen mukaan, jota käytetään useimmin. Sanan sivumerkitystä koskeva informaatio on hienovaraista, ja sivumerkityksen vaikutusta on vaikea erottaa tilastollisesta vaihtelusta. Vähäisen merkityksen vaikutuksen mittaamiseksi tässä asiakirjassa ehdotetaan ympäröivän yhdenmukaisuuden käsitteen käyttöä. Ympäröivä yhtenäisyys vastaa karkeasti ottaen tilastollista vaihtelua vektoreissa, jotka vastaavat naapurissa olevia sanoja Ympäröivä yhtenäisyys (SU) voidaan ilmaista seuraavasti: $SU(\\vec{w}) = \\frac{|\\vec{s}(\\vec{w})|}{|\\vec{w}| + \\sum _{i}^{N}|\\vec{a_i}(\\vec{w})|}$ jossa $\\vec{s}(\\vec{w}) = \\vec{w} + \\sum _{i}^{N} \\vec{a_i}(\\vec{w}).$\\vec{a_i}(\\vec{w}).",
      "id": "task461-674f2fe3a9484b5a9314c95e90375cb4",
      "output": [
        "Miten sanan ja sen naapureiden merkityksessä tapahtuva vaihtelu mitataan?"
      ]
    },
    {
      "input": "Spoken-SQuAD on valittu harjoitus- ja testausaineistoksi. Spoken-SQuAD BIBREF5 on automaattisesti luotu korpus, jossa asiakirja on puhutussa muodossa ja kysymys tekstimuodossa. Viitteelliset transkriptiot ovat peräisin SQuAD BIBREF1 -tietokannasta. Koulutus- ja testausjoukoissa on 37 111 ja 5 351 kysymysvastausparia, ja molempien joukkojen sanavirheprosentti (WER) on noin 22,7. Alkuperäinen SQuAD, Text-SQuAD, on valittu lähdeaineistoksi, jossa käytetään vain Spoken-SQuADissa esiintyviä kysymysvastauspareja. Tehtäväasetuksessamme koulutamme ehdotettua QA-mallia harjoittelun aikana sekä Text-SQuAD- että Spoken-SQuAD-koulutusjoukoilla. Testausvaiheessa arvioimme suorituskykyä Spoken-SQuAD-testausjoukolla.",
      "id": "task461-efcbcb4db5a64c73ab003d2a7fc0c3a1",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät arvioinnissa?"
      ]
    },
    {
      "input": "Tiedot kerättiin 10 prosentin yhtenäisestä otoksesta vuoden 2013 aikana tehdyistä Twitter-viesteistä, erityisesti Gardenhose API:sta. Lisäksi valittiin kontrolliasiakirjoja. Nämä asiakirjat eivät sisältäneet yhtään sanaa `caused', `causing' tai `causes', eivätkä mitään kaksisuuntaisia sanoja, ja ne sovitettiin edelleen ajallisesti yhteen, jotta saatiin sama määrä kontrolliasiakirjoja kuin kausaalisia asiakirjoja kullakin viidentoista minuutin jaksolla vuoden 2013 aikana. Kontrollidokumentit valittiin muuten satunnaisesti; kausaalisynonyymit voivat olla läsnä.",
      "id": "task461-df54517a0eeb426799954160ebcb21e0",
      "output": [
        "Mikä on \"valvonta\"-korpuksen lähde?",
        "miten he keräävät vertailukelpoisen korpuksen?"
      ]
    },
    {
      "input": "Käytimme HEOT-tietokokonaisuutta, joka on peräisin Mathur et al. tekemästä aiemmasta tutkimuksesta, jossa he kommentoivat joukon puhdistettuja twiittejä, jotka on saatu Twitteristä Intian niemimaalla käytyjen keskustelujen osalta. Vastaavien englanninkielisten twiittien merkitty tietokokonaisuus saatiin myös Davidson et al. tekemästä tutkimuksesta.",
      "id": "task461-76fd103ae6aa4cbfa8f0403aa815c463",
      "output": [
        "Mitä tietokokonaisuutta käytetään?",
        "Miten tietokokonaisuus on kerätty?",
        "Mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Meta-tutkimuksessa havaittiin, että vain yksi yhdeksästä ihmisen ja tietokoneen vuorovaikutuksen laadullisesta artikkelista raportoi arvioijien välisen luotettavuuden mittarit BIBREF31. Toinen aiheeseen liittyvä alue on metatutkimus ja menetelmiä käsittelevät artikkelit, joissa keskitytään tunnistamaan tai estämään joukko-osallistujien vähäisen panostuksen vastauksia - joita kutsutaan joskus \"roskapostiksi\" tai \"satunnaisiksi\" vastauksiksi tai vaihtoehtoisesti \"huijareiksi\" tai \"huijareiksi\". Usein käytetään \"itseään hyväksyviä\" määriä, joilla määritetään, merkitseekö sama henkilö saman kohteen eri tavalla myöhemmässä vaiheessa.",
      "id": "task461-32323413e9b846939ca59f0215a1c4b0",
      "output": [
        "Mitkä ovat keskeiset kysymykset, jotka liittyvät siihen, ovatko tällaisessa annotaatiossa tuotetut kultaiset standarditiedot luotettavia? "
      ]
    },
    {
      "input": "Tästä huolimatta JESSI sijoittuu osatehtävässä A toiseksi, ja sen F1-tulos on 77,78 % 33 muun ryhmän tarjouksen joukossa. Se menestyy hyvin myös osatehtävässä B, jonka F1-pisteet ovat 79,59 %.",
      "id": "task461-36823ff3cff547acbdd22f64eb695f2d",
      "output": [
        "Miten he pärjäsivät muihin joukkueisiin verrattuna?"
      ]
    },
    {
      "input": "Sovellamme tarkkaavaisuusluotainta tehtävään tunnistaa kahden sanan välisen riippuvuussuhteen olemassaolo ja tyyppi. Ensimmäinen kokeilumme on kartoittava visualisointi siitä, miten sanan merkitys vaikuttaa kontekstin upotuksiin. ",
      "id": "task461-251dc9f5750e4688b6db1d2ed84762ff",
      "output": [
        "Mitä kielellisiä piirteitä tutkittiin?"
      ]
    },
    {
      "input": "Voimme tunnistaa kolme pääasiallista tapausta, joissa malli tuottaa virheen:oikea luokka voidaan päätellä suoraan tekstin sisällöstä helposti, jopa ilman taustatietoaoikea luokka voidaan päätellä tekstin sisällöstä, jos tapahtumakohtainen tieto on annettuoikea luokka voidaan päätellä tekstin sisällöstä, jos tekstiä tulkitaan oikein.",
      "id": "task461-410c56d4297c4defa865ec65e5b0f76f",
      "output": [
        "Millaisia virheitä luokittelijat käyttävät?"
      ]
    },
    {
      "input": "LangID- ja NoLangID-järjestelmiä koskevia tuloksia verrataan deri2016graphemen esittelemään järjestelmään, joka on tuloksissamme tunnistettu wFST:ksi.",
      "id": "task461-e307eb95240148a2866fd281764bf689",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Oletamme, että äänisignaaleista voidaan poimia puheäänikirjoituksia suurella tarkkuudella, kun otetaan huomioon ASR-tekniikoiden kehittyminen BIBREF7 .",
      "id": "task461-b6545f194dfa442fb87d931611dc4128",
      "output": [
        "Käyttävätkö he tietokokonaisuuksia, joissa on puhtaaksikirjoitettua tekstiä, vai määrittävätkö he tekstin äänen perusteella?"
      ]
    },
    {
      "input": "Käytämme harjoitteluun ja testaukseen WikiTableQuestions BIBREF0 -tietokannan, joka sisältää 22 033 kysymys- ja vastausparia, jotka perustuvat 2 108 Wikipedia-taulukkoon, harjoittelu-, validointi- ja testiosaa. Tätä tietokokonaisuutta käyttävät myös perusasetuksemme BIBREF0 , BIBREF3 .",
      "id": "task461-0951860941a04646a23a9d7b026dffa2",
      "output": [
        "Eroaako heidän käyttämänsä tietokokonaisuus Pasupatin ja Liangin (2015) käyttämästä tietokokonaisuudesta?"
      ]
    },
    {
      "input": "Oletamme, että jokaiselle korpukselle INLINEFORM0 annetaan sanojen upotukset jokaiselle sanalle INLINEFORM1 , jossa INLINEFORM2 on kunkin sanojen upotuksen ulottuvuus. Meille annetaan myös asiakirjojen luokittelutehtävä, jota edustaa parametrinen malli INLINEFORM3 , jossa asiakirjojen upotukset ovat ominaisvektoreita. Rakennamme GAN-mallin, joka yhdistää erilaiset sanojen upotukset INLINEFORM4 , INLINEFORM5 yhdeksi sanojen upotusten joukoksi INLINEFORM6 . Huomaa, että INLINEFORM7 on annettu, mutta INLINEFORM8 on koulutettu. Tässä tarkastelemme INLINEFORM9:ää generaattorina, ja diskriminatorin tavoitteena on erottaa alkuperäisten INLINEFORM10- upotusten ja uusien INLINEFORM11- upotusten edustamat asiakirjat toisistaan.",
      "id": "task461-71da93f117014f0883e66dbd33ea1711",
      "output": [
        "Mitä GAN:ia he käyttävät?"
      ]
    },
    {
      "input": "Yhteisöllä, jolla on hyvin omaleimainen identiteetti, on yleensä omaleimaisia intressejä, jotka ilmaistaan erikoiskielellä. Muodollisesti määrittelemme yhteisön INLINEFORM0-erityisyyden kaikkien INLINEFORM1:n lausumien keskimääräiseksi erityisyydeksi. ",
      "id": "task461-84cbd54095254b4aa39bbccb9290f92a",
      "output": [
        "Miten kirjoittajat mittaavat sitä, kuinka omaleimainen yhteisö on?"
      ]
    },
    {
      "input": "Jotta korpusten kerääminen olisi helpompaa ja nopeampaa, otimme käyttöön puoliautomaattisen menettelyn, joka perustuu peräkkäisiin neuromalleihin BIBREF19, BIBREF20. Koska merkit transkriboidaan morfeemitasolla, jaoimme arabian merkit merkkeihin ja arabian merkit morfeemeihin ja käsittelimme kutakin merkkiä sekvenssinä. Mallimme oppii näin kartoittamaan arabialaiset merkit arabialaisiksi morfeemeiksi. Tämän mallin avulla transkriboimme automaattisesti arabian morfeemeiksi noin 5 000 ylimääräistä merkkiä, jotka vastaavat toista annotaatiolohkoa.  Manuaalinen transkriptio sekä",
      "id": "task461-05e9fe21eda34b46a6f6e239b66d4dd6",
      "output": [
        "Miten puoliautomaattinen rakennusprosessi toimii?"
      ]
    },
    {
      "input": "äskeisen rajoituksen välittömänä vaikutuksena on se, että vältetään romahdusongelma ($D_{KL}=0$) asettamalla KL-termiä koskeva nollasta poikkeava positiivinen rajoitus ($C\\ge 0$) ($|D_{KL}\\big (q_\\phi ({z}|{x}) || p({z})\\big )-C|$).",
      "id": "task461-855772c4106d4f0f8d2b3c8bf4152e9a",
      "output": [
        "Miksi ehdotettu termi auttaa välttämään posteriorista romahdusta?"
      ]
    },
    {
      "input": "Samoihin 36 kysymykseen vastattiin neljällä QALD-välineellä: WDAqua BIBREF0 , QAKiS BIBREF7 , gAnswer BIBREF6 ja Platypus BIBREF8 .",
      "id": "task461-f7b6e9f6f2c04fb2ad6d3ae2b7e6175d",
      "output": [
        "Mitä neljää laadunvarmistusjärjestelmää he käyttävät?"
      ]
    },
    {
      "input": "Arvioimme hiljattain ehdottamiamme malleja ja niihin liittyviä perusmalleja useissa eri kielten vähäresurssiympäristöissä todellisilla, etäisesti valvotuilla aineistoilla, joissa ei ole synteettistä kohinaa. ",
      "id": "task461-bb6fb4b72e5c483a9aca22f3ae4f2716",
      "output": [
        "Miten he arvioivat lähestymistapaansa?"
      ]
    },
    {
      "input": "Mitataksemme Bertramin lisäämisen vaikutusta yhteistyöelimeen myöhempiin tehtäviin sovellamme SECREF4-jaksossa kuvattua menettelyä yleisesti käytettyyn tekstin sisältävään päättelyaineistoon sekä kahteen tekstiluokittelua koskevaan aineistoon: MNLI BIBREF21, AG's News BIBREF22 ja DBPedia BIBREF23. ",
      "id": "task461-19741007df354576a22ad7bf4ac16754",
      "output": [
        "Mitkä ovat kolme jatkojalostustehtävän tietokokonaisuutta?"
      ]
    },
    {
      "input": " Arvioidaksemme valitsemamme luokittelijan todellista suorituskykyä (eli suorituskykyä ilman mallin ja parametrien vääristymiä), suoritamme luokittelun odotusjoukosta. Tässä joukossa luokittelijamme tarkkuus oli 89,6 % ja F1-tulos 89,2 %. ",
      "id": "task461-0df4ae4d803b455396671b0fb9741cbe",
      "output": [
        "Mikä oli heidän järjestelmänsä suorituskyky?"
      ]
    },
    {
      "input": "Vertaamme lähestymistapaamme kahteen perusnäkemykseen perustuvaan menetelmään, joita on ehdotettu BIBREF:ssä6 ja BIBREF:ssä7 ja jotka mittaavat kahden globaalien visuaalisten piirteiden joukon samankaltaisuutta kaksikielisen leksikon induktiota varten: CNN-mean: kahden kuvajoukon piirteiden keskiarvon samankaltaisuuspistemäärä.CNN-avgmax: kahden kuvajoukon suurimpien samankaltaisuuspisteiden keskiarvo.",
      "id": "task461-701664fef04d4a1eb45fec53bff325ad",
      "output": [
        "Mitä näköön perustuvia lähestymistapoja tämä lähestymistapa päihittää?",
        "Mitä perusviivaa käytetään koejärjestelyssä?"
      ]
    },
    {
      "input": "Miten populaarimusiikin yleisön musiikkimaku on muuttunut viime vuosisadalla? MUSIC-mallin ominaisuuksien trendiviivat, jotka esitetään kuviossa FIGREF12, paljastavat, että yleisö halusi yhä enemmän nykyaikaisia, intensiivisiä ja hieman uudenlaisia tai hienostuneita tuotteita, mutta yhä vähemmän pehmeää ja (yllättäen) vaatimatonta musiikkia. Toisin sanoen populaarimusiikin yleisö on yhä vaativampi, kun musiikkituotteiden laatu ja monipuolisuus lisääntyvät.",
      "id": "task461-9ed71abe8de04cad8929ea93ccafb8b4",
      "output": [
        "Millaisia suuntauksia musiikillisissa mieltymyksissä on havaittavissa?"
      ]
    },
    {
      "input": "ehdotetun adaptiivisesti harvan muuntajan huomiopäät voivat erikoistua enemmän ja luotettavammin Analysoimme erityisesti, miten ehdotetun adaptiivisesti harvan muuntajan huomiopäät voivat erikoistua enemmän ja luotettavammin.",
      "id": "task461-234d57a5b08b4d189a87a4575e8aec4e",
      "output": [
        "Miten heidän mallinsa parantaa tulkittavuutta softmax-muuntajiin verrattuna?"
      ]
    },
    {
      "input": "Lopullinen annotoitu tietokokonaisuus koostuu 1000 keskustelusta, jotka koostuvat 6833 lauseesta ja 88047 merkistä. ",
      "id": "task461-38b66f0e4d9d46acb4153267cb46caaf",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Haettuja pareja verrataan kultaiseen standardiin ja arvioidaan käyttämällä tarkkuutta $k$:n kohdalla (P@$k$, jolla arvioidaan, kuinka usein oikea käännös on $k$:n haettujen lähimpien naapureiden joukossa). Tässä työssä ilmoitetaan koko ajan P@1, joka vastaa tarkkuutta, mutta liitteessä esitetään myös P@5- ja P@10-tuloksia.",
      "id": "task461-0404d7ffebbb4b2f829e81fa7d4d23a2",
      "output": [
        "Mitä arviointimittareita he käyttivät?"
      ]
    },
    {
      "input": "Lähestymistapamme FEVERiin on korjata hakua ja seurausta koskevien peruslähestymistapojen ilmeisimmät puutteet ja kouluttaa terävä seurausluokittelija, jota voidaan käyttää suodattamaan laajaa joukkoa haettuja potentiaalisia todisteita. Vertailemme seuraamusluokittimen osalta Decomposable Attention BIBREF2 -luokitinta, BIBREF3 -luokitinta sellaisena kuin se on toteutettu virallisessa perusversiossa, ESIM BIBREF4 -luokitinta ja muunnosverkkoa, jossa on valmiiksi koulutetut painot BIBREF5 . Muunnosverkko tukee luonnollisesti sanaston ulkopuolisia sanoja, ja sen suorituskyky on huomattavasti parempi kuin muiden menetelmien.",
      "id": "task461-a2968bea18a34d72b04a36c906199be8",
      "output": [
        "Mihin lähtötasoon niitä verrataan?"
      ]
    },
    {
      "input": "Kun kyseessä on uutistili Twitterissä, luemme sen twiitit tilin aikajanalta. Sitten lajittelemme twiitit julkaisupäivän mukaan nousevasti ja jaamme ne $N$-kappaleisiin. Kukin palanen koostuu lajitellusta twiittien sarjasta, joka on merkitty vastaavan tilin tunnisteella.",
      "id": "task461-0db3fdd0226145f194ea87ffc287be1b",
      "output": [
        "Oliko tässä työssä käytetty lähestymistapa valeuutisten havaitsemiseen täysin valvottu?"
      ]
    },
    {
      "input": "Onneksi 180221 tekijän 231162 nimestä saatiin onnistuneesti yhdistettyä. Jäljelle jääneisiin kattamattomiin tapauksiin on monia syitä. 9073 latinankielistä nimeä ei löytynyt ENAMDICT-nimisanakirjasta, ja 14827 nimen latinankielisen ja kanji-kuvauksen vertailu ei onnistunut. Nämä nimet saattavat puuttua sanakirjasta kokonaan, ne on toimitettu hyvin epätavallisessa muodossa, jota työkalu ei kata, tai ne eivät ehkä ole lainkaan japanilaisia tai ihmisten nimiä. Japanilaiset tietojenkäsittelytieteilijät tekevät tietysti joskus yhteistyötä myös ulkomaisten kollegojen kanssa, mutta työkalumme odottaa japanilaisia nimiä ja on optimoitu niitä varten.",
      "id": "task461-a948086179b14349ae72429cef043dc4",
      "output": [
        "Kuinka hyvin he onnistuvat kirjailijoiden japanin- ja englanninkielisten nimien yhteensovittamisessa?"
      ]
    },
    {
      "input": "Sähköpostiluokitin koneoppimisen avulla ::: Koneoppimisen lähestymistapa ::: Ominaisuuksien valintaNgrammit ovat jatkuva n kohteen sarja tietystä tekstinäytteestä. Otsikosta, rungosta ja OCR-tekstistä valitaan sanat. Kolmen lähekkäisen sanan Ngramit poimitaan Term Frequency-Inverse Document Frequency (TF-IDF) -vektoroinnin avulla, minkä jälkeen piirteet suodatetaan käyttämällä ominaisuuksien pisteytysmenetelmää chi squared. Sähköpostiluokitin koneoppimisen avulla ::: Koneoppimisen lähestymistapa ::: Random forestRandom Forest on bagging-algoritmi, ensemble-oppimismenetelmä luokitteluun, joka toimii rakentamalla useita päätöspuita koulutusaikana ja antamalla tulokseksi luokan, jolla on suurin keskimääräinen enemmistöääni luokistaBIBREF14. Sähköpostiluokitin koneoppimisen avulla ::: Koneoppimisen lähestymistapa ::: XGBoostXGBoost on päätöspuihin perustuva koneoppimisalgoritmi, joka käyttää gradienttipainotteista tehostamismenetelmää. Sitä käytetään yleisesti luokitusongelmissa, joihin liittyy jäsentymätöntä dataaBIBREF5. Sähköpostiluokitin koneoppimisen avulla ::: Koneoppimisen lähestymistapa ::: Hierarkkinen malliKoska kohdetunnisteiden määrä on suuri, korkeamman tarkkuuden saavuttaminen on vaikeaa, kun kaikki luokat pidetään saman ominaisuuksien valintamenetelmän alaisina. Jotkin luokat toimivat hyvin pienemmällä TF-IDF-vektorointialueella ja suuremmilla n-grammaominaisuuksilla, vaikka niiden tarkkuus oli alhaisempi yksittäisessä kokonaismallissa. Siksi hierarkkiset koneoppimismallit rakennetaan 31 luokan luokittelemiseksi ensimmäisessä luokittelumallissa, ja loput luokat nimetään mataliksi accuiksi ja ennustetaan yhdeksi luokaksi. Seuraavassa mallissa ennustetut low-accu-luokat luokitellaan jälleen 47 luokkaan. Vertailun perusteella tämä hierarkkinen malli toimii hyvin, koska eri luokille käytetään erilaisia ominaisuuksien valintamenetelmiäBIBREF5.",
      "id": "task461-c14d6b95b1f947ffaae914cd4a505441",
      "output": [
        "Mitä kaikkia koneoppimisen lähestymistapoja tässä työssä verrataan?"
      ]
    },
    {
      "input": "Näytämme käyttämämme tietokokonaisuuden tilastot tab:statistics-kohdassa, ja rakentamismenettelyt esitellään tässä jaksossa. Wikidata BIBREF8 -tietokannassa faktat voidaan kuvata muodossa (Head item/property, Property, Tail item/property).  Aluksi valitsemme Wikidatasta 202 yleisintä suhdetta ja 120000 oliota lähtötiedoiksi. ReVerb BIBREF9 on ohjelma, joka tunnistaa ja poimii automaattisesti binäärisiä suhteita englanninkielisistä lauseista. Käytämme uuttoja, jotka on saatu ajamalla ReVerb-ohjelma Wikipediassa. FB15K BIBREF3 on freebasen osajoukko. TACRED BIBREF10 on suuri valvottu relaatioiden poimintatietokanta, joka on saatu joukkoistamisen avulla. Käytämme suoraan näitä kahta tietokokonaisuutta, eikä niihin ole sovellettu mitään ylimääräisiä käsittelyvaiheita.",
      "id": "task461-9e8a403da52b4b018fc80e42b2bcc0dc",
      "output": [
        "Mitä tietopohjia ne käyttävät?"
      ]
    },
    {
      "input": "Lopullinen upotusulottuvuus on yhtä suuri kuin harjoitusjoukon ainutlaatuisten sanatunnisteiden määrä, joka on 1061.",
      "id": "task461-55e2ac21292e4ea08e387d4f44cc3e23",
      "output": [
        "Minkälaista ulottuvuutta ne käyttävät upotuksissaan?"
      ]
    },
    {
      "input": "Merkittävä pullonkaula, joka on jäänyt aiemmissa ponnisteluissa huomiotta, on kuitenkin syöttösanaston koko ja sitä vastaava sanojen upotusmatriisi, jotka muodostavat usein merkittävän osan kaikista malliparametreista. Esimerkiksi BERTBASE-mallin upotustaulukko, joka koostuu yli 30 000 WordPiece-merkistä BIBREF14, muodostaa yli 21 \\%$ mallin koosta. Vaikka NLP-mallien sanastokokojen pienentämiseksi on tehty työtä BIBREF15 , tislaustekniikat eivät voi hyödyntää näitä, koska ne edellyttävät, että oppilas- ja opettajamallit jakavat saman sanaston ja tulostusavaruuden. Tämä rajoittaa huomattavasti niiden mahdollisuuksia pienentää mallien kokoa entisestään.",
      "id": "task461-e05a3485ff2b434f8754dc7e9355b3ce",
      "output": [
        "Miksi ennakkotiedon tislaustekniikoiden mallit ovat tehottomia tuottamaan oppilasmalleja, joiden sanastot eroavat opettajan alkuperäisistä malleista?  "
      ]
    },
    {
      "input": "Tämän perusteella ehdotamme, että on oltava varovainen, kun graafien sulautuksia käytetään NLP-putkistoissa, ja että on kehitettävä vankkoja menetelmiä tällaisten sulautusten poistamiseksi.",
      "id": "task461-143378d4b5224c43b6c0f91285cfa1f8",
      "output": [
        "Ehdottavatko he mitään ratkaisua upotusten purkamiseksi?"
      ]
    },
    {
      "input": "Otamme tiedot WMT'14:n englannin ja ranskan (En-Fr) sekä englannin ja saksan (En-De) tietokokonaisuuksista. Jotta tehtävien välille saataisiin luotua suurempi ero, jotta aineiston koko olisi selvästi epätasapainossa, En-De-aineisto rajoitetaan keinotekoisesti vain miljoonaan rinnakkaiseen lauseeseen, kun taas koko En-Fr-tietokokonaisuutta, joka sisältää lähes 40 miljoonaa rinnakkaista lausetta, käytetään kokonaan. ",
      "id": "task461-91037456c12045ed8a50fdc8381147bf",
      "output": [
        "Mitä tietokokonaisuuksia käytetään kokeissa?"
      ]
    },
    {
      "input": "Validoidut puhtaaksikirjoitukset lähetettiin ammattimaisille kääntäjille. Ammattikääntäjien käännösten laadun valvomiseksi teimme käännöksiin erilaisia terveystarkastuksia BIBREF11. Tarkistimme myös harjoitus-, kehitys- ja testijoukkojen päällekkäisyydet transkriptien ja äänileikkeiden osalta (MD5-tiedostojen hashausmenetelmällä) ja varmistimme, että ne ovat täysin erillisiä.",
      "id": "task461-e82fbaac9c514ceea14665dd741c05e3",
      "output": [
        "Miten tietojen laatua arvioidaan empiirisesti? "
      ]
    },
    {
      "input": "Käytämme OpenNMT BIBREF24 NMT-järjestelmän toteutuksena kaikissa kokeissa BIBREF5 . PBMT-R on fraasipohjainen menetelmä, jossa on jälkikäsittelyvaihe BIBREF18 . Hybrid suorittaa lauseiden jako- ja poisto-operaatiot diskurssin esitysrakenteiden perusteella ja yksinkertaistaa sitten lauseita PBMT-R:llä BIBREF25 . SBMT-SARI BIBREF19 on syntaksiin perustuva käännösmalli, joka käyttää PPDB-parafraasitietokantaa BIBREF26 ja muokkaa viritystoimintoa (SARI:n avulla). Dress on koodaaja-dekooderimalli, johon on yhdistetty syvä vahvistusoppimiskehys, ja parametrit valitaan alkuperäisen artikkelin BIBREF20 mukaisesti.",
      "id": "task461-1bab56f334784db5af8343b9561b88b2",
      "output": [
        "mihin uusimpiin menetelmiin niitä verrattiin?"
      ]
    },
    {
      "input": "KBQA (Knowledge Base Question Answering) -järjestelmät vastaavat kysymyksiin hankkimalla tietoa KB-tupeleista BIBREF0 , BIBREF1 , BIBREF2 , BIBREF3 , BIBREF4 , BIBREF5.",
      "id": "task461-d7a7a6cf5fb5436784bd2ac4bed59d1c",
      "output": [
        "Mitä KBQA tarkoittaa lyhenteenä?"
      ]
    },
    {
      "input": "Aiemmista lausunnoista huolimatta esittelemme tässä asiakirjassa järjestelmän, jossa käytetään sääntöpohjaisia ja sanakirjapohjaisia menetelmiä yhdistettynä (tavalla, jota kutsumme mieluummin resurssipohjaiseksi). ",
      "id": "task461-02540b29b17f4ce6a1f308c3aa501f62",
      "output": [
        "Mistä heidän järjestelmänsä koostuu?"
      ]
    },
    {
      "input": "Havaitsimme, että syntyvän leksikon yhdistelmällisyyteen liittyvät ominaisuudet, nimittäin sanojen pituusjakauma, eri muotojen käyttötiheys ja itse yhdistelmällisyyden mittari, heijastavat sekä laadullisesti että määrällisesti vastaavia ominaisuuksia, jotka on mitattu ihmiskielissä, edellyttäen, että muistiparametri $\\tau $ on riittävän suuri, eli että uusien muotojen ymmärtämiseen ja oppimiseen tarvitaan riittävän paljon vaivaa.",
      "id": "task461-51c67e1c76f048bf903d7a3d845f1413",
      "output": [
        "Mihin empiirisiin tietoihin Blending Game -ennusteita verrataan?"
      ]
    },
    {
      "input": "Ensimmäinen, OpenIE 4 BIBREF5 , on peräisin kahdesta suositusta OIE-järjestelmästä OLLIE BIBREF10 ja Reverb BIBREF10 . Toinen oli MinIE BIBREF7 , jonka on raportoitu suoriutuvan paremmin kuin OLLIE, ClauseIE BIBREF9 ja Stanford OIE BIBREF9 .",
      "id": "task461-b0f42509f01d486fb13d4db103b2ac55",
      "output": [
        "Mitä OpenIE-järjestelmiä käytettiin?"
      ]
    },
    {
      "input": "Menetelmäämme testataan Twitter-tietokannoilla. Tätä mikroblogialustaa on käytetty laajasti keskustelujen ja polarisaation analysointiin BIBREF12, BIBREF13, BIBREF14, BIBREF15, BIBREF2. Se on luonteva valinta tämäntyyppisiin ongelmiin, koska se on yksi tärkeimmistä julkisen keskustelun foorumeista sosiaalisessa verkkomediassa BIBREF15, se on affiliatiivisten ilmaisujen yleinen kohde BIBREF16 ja sitä käytetään usein ajankohtaisia tapahtumia koskevien uutisten raportointiin ja lukemiseen BIBREF17. Twitterin lisäetuna tämäntyyppisissä tutkimuksissa on miljoonien käyttäjien tuottaman reaaliaikaisen tiedon saatavuus. Muut sosiaalisen median alustat tarjoavat vastaavia tiedonjakopalveluja, mutta vain harvat niistä pystyvät vastaamaan Twitterin tarjoamaan tietomäärään ja siihen liittyvään dokumentaatioon. Twitterin viimeisenä etuna työssämme ovat uudelleentwiittaukset, jotka tyypillisesti osoittavat hyväksyntää BIBREF18 ja joista näin ollen tulee hyödyllinen käsite keskustelujen mallintamisessa, koska voimme määrittää, kuka on kenen kanssa. Menetelmämme lähestymistapa on kuitenkin yleinen, ja sitä voitaisiin käyttää a priori missä tahansa sosiaalisessa verkostossa. Tässä työssä raportoimme Twitterissä testatuista erinomaisista tuloksista, mutta tulevassa työssä aiomme testata sitä muissa sosiaalisissa verkostoissa.",
      "id": "task461-fd21826a9fc6495e8afdce42662cecf5",
      "output": [
        "Mitä sosiaalisen median alustaa tarkkaillaan?"
      ]
    },
    {
      "input": " Kaiken kaikkiaan tämä johti yhteensä 34 432 käyttäjäkeskusteluun. Yhdessä nämä käyttäjät antoivat Gunrockille keskimäärin 3,65 arvosanan (mediaani: 4,0), joka saatiin keskustelun lopussa (\"Asteikolla 1-5 tähteä, mitä mieltä olet siitä, että voisit keskustella tämän sosiaalibotin kanssa uudelleen?\").",
      "id": "task461-31b2f3115d994bb48b9df39d62d16c6a",
      "output": [
        "Mikä on käyttäjätyytyväisyyden mittaamiseen käytettävän otoksen koko?"
      ]
    },
    {
      "input": "Näistä puutteista huolimatta WER:n käyttö onnistumisen mittarina voi kuvastaa mallimme tehokkuutta SQuAD:n kysymysten kaltaisten kysymysten tuottamisessa annetun lukukappaleen ja vastauksen perusteella. WER:ää voidaan käyttää alustaviin analyyseihin, jotka voivat johtaa syvällisempiin oivalluksiin, kuten jäljempänä käsitellään.",
      "id": "task461-17dfa6b8d6524c20afab27ac587c9648",
      "output": [
        "Miksi he valitsivat arviointimittariksi WER:n?"
      ]
    },
    {
      "input": "Käyttämällä sekvenssistä sekvenssiin -verkkoja tässä lähestymistavassa koulutetaan yhdessä annotoituja lausetason aikomuksia ja aukkoja/aikomuksen avainsanoja lisäämällä /-merkkejä kunkin lausekkeen alkuun/päähän, ja lausetason aikomustyyppi on kyseisten merkkien merkintä. Lähestymistapamme on BIBREF2:n laajennus, jossa lisätään vain termi, jonka intent-tyyppiset tunnisteet liittyvät tähän lauseen loppumerkkiin, sekä LSTM- että Bi-LSTM-tapauksissa. Kokeilimme kuitenkin sekä termien että termien lisäämistä, koska Bi-LSTM:iä käytetään seq2seq-oppimiseen, ja havaitsimme, että näin voidaan saavuttaa hieman parempia tuloksia. Taustalla on ajatus siitä, että koska kyseessä on seq2seq-oppimisongelma, viimeisellä aika-askeleella (eli ennuste klo ) Bi-LSTM:n käänteinen läpikäynti olisi epätäydellinen (katso kuvaa FIGREF24 (a) viimeisen Bi-LSTM-solun havaitsemiseksi). Sen vuoksi merkin lisääminen ja takaperin LSTM:n tuotoksen hyödyntäminen ensimmäisellä aika-askeleella (eli ennuste klo ) voisi mahdollisesti auttaa yhteisessä seq2seq-oppimisessa. Kuvassa FIGREF30 on yhteinen verkkoarkkitehtuuri yhteisiä mallejamme varten. Raportoimme kokeelliset tulokset kahdella muunnelmalla (aikomusavainsanojen kanssa ja ilman aikomusavainsanoja) seuraavasti: Joint-1: Seq2seq Bi-LSTM lausetason aikomuksen havaitsemiseen (yhdessä koulutettu lähtö- ja saapumisaikojen kanssa)Joint-2: Seq2seq Bi-LSTM lausetason aikomuksen havaitsemiseen (yhdessä koulutettu lähtö- ja saapumisaikojen ja aikomusavainsanojen kanssa).",
      "id": "task461-f41c43a1de3447229e48d0bcef9184be",
      "output": [
        "Mitä yhteisessä mallissa jaetaan?"
      ]
    },
    {
      "input": "Aiempien tutkimusten BIBREF1 mukaisesti keräämme tapahtumiin liittyviä mikroposteja Twitteristä käyttämällä 11 ja 8 siementapahtumaa (ks. jakso SECREF2) vastaavasti CyberAttack- ja PoliticianDeath-tapahtumille. CyberAttack-tapahtuman kohdalla käytetään avainsanaa \"hakkerointi\", kun taas PoliticianDeath-tapahtuman kohdalla käytetään joukkoa avainsanoja, jotka liittyvät sanoihin \"poliitikko\" ja \"kuolema\" (kuten \"byrokraatti\", \"kuollut\" jne.).",
      "id": "task461-a9dab5b6f293414aa5b8a2cd92ea25cb",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Käytämme samaa datan jakoa kuin BIBREF31, BIBREF30 ja BIBREF6:ssa, jossa harjoitusjoukkona käytetään uutisia (bn:n ja nw:n yhdistelmää), kehitysjoukkona puolet bc:stä ja testijoukkona loput datasta.Opetamme mallin parametrit käyttämällä Adam BIBREF32:ta. Sovellamme piilokerroksiin dropout BIBREF33 -menetelmää ylisovittamisen vähentämiseksi. Kehitysjoukkoa käytetään mallin hyperparametrien virittämiseen ja aikaiseen pysäytykseen. Koulutamme 5 Bi-LSTM English RE -mallia, jotka on aloitettu erilaisilla satunnaiskylvöillä, sovellamme näitä 5 mallia kohdekieliin ja yhdistämme tuotokset valitsemalla 5 mallin joukosta ne relaatiotyypin merkinnät, joilla on suurin todennäköisyys.",
      "id": "task461-0a8066563bab41fda70c033060540639",
      "output": [
        "Kouluttavatko he omaa RE-malliaan?"
      ]
    },
    {
      "input": "Käsittelemme tätä kysymystä tutkimalla ja tarkistamalla julkisesti saatavilla olevia tietokokonaisuuksia väärinkäytösten havaitsemiseksi, ja tarjoamme niihin pääsyn uudella verkkosivustolla hatespeechdata.com. Käsittelemme tätä kysymystä tarkastelemalla ja arvioimalla julkisesti saatavilla olevia tietokokonaisuuksia väärinkäytösten havaitsemiseksi, ja tarjoamme niihin pääsyn uudella verkkosivustolla hatespeechdata.com.",
      "id": "task461-778ad39210d24b59bd7ebcc3248a17de",
      "output": [
        "Mikä on avoin verkkosivusto väärinkäytösten kielitietojen luetteloimiseksi?"
      ]
    },
    {
      "input": "Testaamme lähestymistapaamme empiirisesti useilla kokeilla WikiTableQuestions-tietokannalla, joka on tietojemme mukaan ainoa tähän tehtävään suunniteltu tietokokonaisuus. Algoritmissa 1 kuvaamme, miten loogiset muodot muunnetaan tulkittaviksi tekstimuotoisiksi esityksiksi, joita kutsutaan \"parafraaseiksi\".",
      "id": "task461-9203205397f541938bc69b3350705931",
      "output": [
        "Mistä kysymysten parafraasit ovat peräisin?"
      ]
    },
    {
      "input": "Kokeilemme ja vertailemme seuraavia malleja.Pointer-Gen on perusmalli, joka on koulutettu optimoimalla $L_\\text{MLE}$ yhtälössä DISPLAY_FORM13.Pointer-Gen+Pos on perusmalli, jossa Pointer-Gen koulutetaan vain positiivisille näytteille, joiden sensationalismipistemäärä on yli 0.5Pointer-Gen+Same-FT on malli, joka hienosäätää Pointer-Gen:ää harjoitusnäytteille, joiden sensationalismipistemäärä on yli 0.1Pointer-Gen+Pos-FT on malli, joka hienosäätää Pointer-Gen:ää harjoitusnäytteillä, joiden sensationalismipisteet ovat suuremmat kuin 0,5Pointer-Gen+RL-ROUGE on perusmalli, joka on koulutettu optimoimalla $L_\\text{RL-ROUGE}$ yhtälössä DISPLAY_FORM17, ja ROUGE-L BIBREF9 on palkkio.Pointer-Gen+RL-SEN on perusmalli, joka on koulutettu optimoimalla $L_\\text{RL-SEN}$ yhtälössä DISPLAY_FORM17, ja $\\alpha _\\text{sen}$ on palkkio.",
      "id": "task461-e10eff1e39264025885d541d49664b86",
      "output": [
        "Mitä perustasoja käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Sitä voidaan käyttää esimerkiksi ominaisuuksien poimimiseen muiden koneoppimistyökalujen käyttöä varten tai tiettyjen ominaisuuksien arviointiin olemassa olevien luokittelijoiden tai regressorien kanssa. Kuvassa FIGREF19 esitetään yksinkertainen ominaisuuksien poimintaohjelma, joka hakee lauseen pituuden.",
      "id": "task461-9d16ed8a15ef4eca8c5594d05555b3ce",
      "output": [
        "Näyttävätkö he esimerkin INFODENSin käytöstä?"
      ]
    },
    {
      "input": "Kokeemme suoritetaan käyttämällä TED-puheista poimitun MuST-C-korpuksen BIBREF25 englanninkielisiä, italian- ja saksankielisiä osia käyttäen samaa train/validointi/testi-jakoa kuin korpuksen mukana (ks. taulukko TABREF18). Lisäaineistona käytämme julkisten ja omien aineistojen yhdistelmää noin 16 miljoonan lauseparin osalta englanti-italia (En-It) ja 4,4 miljoonan WMT14-lauseparin osalta englanti-saksa (En-De) osalta.",
      "id": "task461-5ac5a884f93d4625840d54c9831fe923",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?",
        "Mitä tietokokonaisuutta he käyttävät kokeissa?"
      ]
    },
    {
      "input": "Tärkeimmät tuotoksemme ovat (1) turkkilaisen korpuksen julkaiseminen karkea- ja hienojakoista NER- ja TC-tutkimusta varten, (2) kuusi eri versiota korpuksesta kohinanvähennysmenetelmien ja oliotyyppien mukaan, (3) korpuksen analyysi ja (4) vertailut NER- ja TC-tehtäviä varten ihmisannotaattoreiden kanssa. ",
      "id": "task461-27cbb99423354d49943d482cd1d00484",
      "output": [
        "Kokeilivatko he tietokokonaisuutta joissakin tehtävissä?"
      ]
    },
    {
      "input": "Ottaen huomioon englannin ja kiinan väliset erot teimme PDTB-3-järjestelmään mukautuksia, kuten poistimme AltLexC:n ja lisäsimme Progressionin merkityshierarkiamme.",
      "id": "task461-fdaff2f0dbe6412dab20f200e1a48f80",
      "output": [
        "Miten resurssit mukautetaan kiinalaisen tekstin ominaisuuksiin?"
      ]
    },
    {
      "input": "Koejärjestelyt",
      "id": "task461-635d69761e804b5f8b3d41e7cbe431be",
      "output": [
        "mitä kiinalaisia tietokantoja käytettiin?",
        "mitä englanninkielisiä tietokokonaisuuksia käytettiin?",
        "Mitä alueita tässä asiakirjassa havaitaan?"
      ]
    },
    {
      "input": "Kokeet ::: Tärkeimmät tulokset ja analyysi ::: GCAE:hen verrattuna AGDT:n suorituskyky paranee 2,4 % ja 1,6 % molempien tietokokonaisuuksien \"DS\"-osassa. Nämä tulokset osoittavat, että AGDT-ohjelmamme voi hyödyntää riittävästi annettua aspektia luodakseen aspektiohjatun lause-esityksen ja siten tehdä tarkan tunteen ennustamisen. HDS-tietokanta, jonka tarkoituksena on mitata, pystyykö malli havaitsemaan lauseen erilaiset tunteen polariteetit, koostuu toistetuista lauseista, joissa on erilaisia tunteita useita eri näkökohtia kohtaan. Meidän AGDT:mme ylittää GCAE:n erittäin selvästi (+11,4 % ja +4,9 %) molemmissa tietokokonaisuuksissa. Kokeet ::: Tärkeimmät tulokset ja analyysi ::: HDS-osiossa AGDT-malli saavuttaa +3,6 % suuremman tarkkuuden kuin GCAE ravintola-alalla ja +4,2 % suuremman tarkkuuden kuin GCAE kannettavan tietokoneen alalla, mikä osoittaa, että AGDT:llä on vahvempi kyky ratkaista usean mielialan ongelma kuin GCAE:llä. Nämä tulokset osoittavat lisäksi, että mallimme toimii hyvin eri tehtävissä ja tietokokonaisuuksissa.",
      "id": "task461-b33b7de0447444a996e9e10c77ba179f",
      "output": [
        "Kuinka suuri on parannus verrattuna uusimpiin tuloksiin?"
      ]
    },
    {
      "input": " Käytämme BIBREF3:n $\\textsc {BERT}_{\\textsc {BASE}}}$-kokoonpanoa yhden siirtymän QA-mallina. ",
      "id": "task461-f5432664208149ba8f2fefcd01f8a3a1",
      "output": [
        "Mitä valmista laadunvarmistusmallia käytettiin alakysymyksiin vastaamiseen?"
      ]
    },
    {
      "input": "PeruskokeilutTässä jaksossa kuvaamme lyhyesti peruskokeilun ja arviointiskriptit, jotka julkaisemme yksityiskohtaisen dokumentaation ja korpuksen kanssa.",
      "id": "task461-fd9d61f86d3047969c8f8def97b63030",
      "output": [
        "Minkälaista arviointia tätä tehtävää varten ehdotetaan?",
        "Mitä perusjärjestelmää ehdotetaan?"
      ]
    },
    {
      "input": "Tärkeä ominaisuus, kun ehdotetaan artikkelia INLINEFORM0 kokonaisuuteen INLINEFORM1, on INLINEFORM2:n uutuus suhteessa jo olemassa olevaan kokonaisuusprofiiliin INLINEFORM3 Kun otetaan huomioon kokonaisuus INLINEFORM0 ja jo lisätyt uutisviittaukset INLINEFORM1 vuoteen INLINEFORM2 asti, INLINEFORM3:n uutuutta vuonna INLINEFORM4 mitataan INLINEFORM5:n kielimallin ja INLINEFORM6:n artikkelien välisen KL-eroavuuden avulla. Yhdistämme tämän mittarin INLINEFORM7:n ja INLINEFORM8:n entiteettien päällekkäisyyteen. INLINEFORM9:n uutuusarvo saadaan pienimmän eroavuuden arvosta. Alhaiset pisteet osoittavat, että olioprofiilin INLINEFORM10 uutuusarvo on alhainen.",
      "id": "task461-13e9822539b94b73951007cf31deb9cc",
      "output": [
        "Mitä ominaisuuksia käytetään uutisartikkelien uutuuden esittämiseen kokonaisuussivuille?"
      ]
    },
    {
      "input": "Tällä hetkellä saatavilla on seuraavat tekstikorpuksesta johdetut WSD-mallit: Klusterin sanaominaisuuksiin perustuvat sanan aistit. Tässä mallissa käytetään indusoidun sanamerkityskannan klusterisanoja harvoina merkkeinä, jotka edustavat merkityssisältöä.Word senses based on context word features. Tämä esitys perustuu indusoidun merkitysinventaarin kaikkien klusterisanojen sanavektoreiden summaan, jota painotetaan jakauman samankaltaisuuspisteillä. supersensseihin, jotka perustuvat klusterisanojen ominaisuuksiin. Tämän mallin rakentamiseksi indusoidut sana-aistimukset klusteroidaan ensin globaalisti käyttämällä Chinese Whispers -grafiikkaklusterointialgoritmia BIBREF9 . Tämän aistigraafin reunat muodostetaan disambiguoimalla toisiinsa liittyvät sanat BIBREF11 , BIBREF12 . Tuloksena syntyneet klusterit edustavat semanttisia luokkia, jotka ryhmittelevät sanoja, joilla on yhteinen hyperym, esim. \"eläin\". Tätä semanttisten luokkien joukkoa käytetään automaattisesti opittuna superaistien luettelona: Kaikilla sanoilla on vain yksi yleinen merkitysluettelo, toisin kuin kahdessa aiemmassa perinteisessä sanakohtaisessa mallissa. Kukin semanttinen luokka merkitään hypernymeillä. Tässä mallissa käytetään semanttiseen luokkaan kuuluvia sanoja ominaisuuksina.Superaistit perustuvat kontekstisanojen ominaisuuksiin. Tämä malli perustuu samoihin semanttisiin luokkiin kuin edellinenkin, mutta sen sijaan aistimusedustukset saadaan keskiarvottamalla samaan luokkaan kuuluvien sanojen vektorit.",
      "id": "task461-f511b9f4a6734ac19ad4c02eaf67ee2a",
      "output": [
        "Käyttävätkö he tehtäväänsä neuraalista mallia?"
      ]
    },
    {
      "input": "Kaikki aiemmat IE-vertailukohteet BIBREF18 ovat kuitenkin liian pieniä QA:ssa tyypillisesti käytettävien neuroverkkomallien kouluttamiseen, joten meidän on rakennettava suuri vertailukohde. Siksi rakennamme QA4IE-vertailumittarin, joka koostuu 293 000 Wikipedia-artikkelista ja 2 miljoonasta kultaisesta relaatiokolmiosta, joissa on 636 erilaista relaatiotyyppiä. Löydämme manuaalisesti 148 relaatiota, jotka voidaan projisoida WikiData-relaatioon 2064 DBpedia-relaatiosta.",
      "id": "task461-eb0326ff14e74905ae52bb30df72729d",
      "output": [
        "Onko tämä vertailuarvo luotu automaattisesti olemassa olevasta tietokokonaisuudesta?"
      ]
    },
    {
      "input": "Vertaamme malliamme muihin vahvasti kilpaileviin menetelmiin SQuAD- ja TriviaQA-listalla.",
      "id": "task461-ec31d8bd38d54bdf805d910e5e7950f7",
      "output": [
        "Mihin muihin ratkaisuihin niitä verrataan?"
      ]
    },
    {
      "input": "Ensimmäisessä, kuvassa KUVA 12 esitetyssä mallissa malliin on lisätty erityinen diskriminaattori, jolla valvotaan, että latentti esitys ei sisällä tyylitietoa. Perusarkkitehtuurin toisessa laajennuksessa ei käytetä vastakohtaista komponenttia $D_z$, joka pyrkii poistamaan komponentista $z$ tietoa $c$:stä. Sen sijaan kuvassa FIGREF16 esitetty järjestelmä syöttää \"pehmeän\" generoidun lauseen $\\tilde{G}$ koodaimeen $E$ ja tarkistaa, kuinka lähellä esitys $E(\\tilde{G} )$ on alkuperäistä esitystä $z = E(x)$ kosinusetäisyyden suhteen. Käytämme siitä nimitystä siirretty autokooderi tai SAE. Tutkimme myös molempien edellä kuvattujen lähestymistapojen yhdistelmää, joka on esitetty kuvassa FIGREF17.",
      "id": "task461-bd032a44992a4ce1a09b97facf2e9789",
      "output": [
        "Mitkä ovat kolme uutta ehdotettua arkkitehtuuria?"
      ]
    },
    {
      "input": "Ehdotetun mallin osalta merkitsemme INLINEFORM0-parametrilla INLINEFORM1 neuraalipohjaiseksi ominaisuuksien koodaajaksi, joka kartoittaa molempien alojen asiakirjat jaettuun ominaisuusavaruuteen, ja INLINEFORM2-parametrilla INLINEFORM3 täysin kytketyksi kerrokseksi, jossa on softmax-aktivointi ja joka toimii sentimenttiluokittelijana. Olemme jättäneet määrittelemättä ominaisuuden koodaajan INLINEFORM0, jota varten voidaan harkita muutamia vaihtoehtoja. Toteutuksessamme käytämme yksikerroksista CNN-rakennetta, joka on peräisin aiemmista töistä BIBREF22 , BIBREF4 , koska sen on osoitettu toimivan hyvin tunnetilaluokittelutehtävissä.",
      "id": "task461-2b9f1dd09e2b4c5d9276447d44dec250",
      "output": [
        "Mikä on mallin arkkitehtuuri?"
      ]
    },
    {
      "input": "Tehtävä 1: Tehtävä 2: Kysymysten sijoittaminen Bingin People Also Ask -palvelussa.",
      "id": "task461-99c0fc4325884430b5244f5aeb00c9a0",
      "output": [
        "Millä tehtävillä he testaavat konfliktimenetelmäänsä?"
      ]
    },
    {
      "input": "Analysoidaksemme paremmin mallin yleistämistä uuteen, tuntemattomaan alueeseen sekä mallin hyödyntämistä alueen ulkopuolisista lähteistä, ehdotamme uutta arkkitehtuuria, joka on ARED-mallin laajennus. Jotta semanttista tietoa voitaisiin paremmin valita, aggregoida ja hallita, dekooderin puolelle tuodaan Refinement Adjustment LSTM-pohjainen komponentti (RALSTM). Ehdotettu malli voi oppia epäsymmetrisestä datasta harjoittelemalla yhdessä lauseen suunnittelua ja pinnan toteutusta luonnollisen kielen lauseiden tuottamiseksi. ",
      "id": "task461-091d93aa1228435393db73a4a6f1a15b",
      "output": [
        "Miten ehdotettu malli eroaa tavallisesta RNN-kooderi-dekooderista?"
      ]
    },
    {
      "input": "Vertaillaksemme malliamme valitsemme useita vahvoja yhteenvetomalleja perusjärjestelmiksi. $\\textsc {Lead-X}}$ käyttää yhteenvetona $X$:n suurimpia lauseita BIBREF19. $\\textsc {DRM}$ BIBREF10 käyttää syvää vahvistusoppimista tiivistämiseen. $\\textsc {TConvS2S}$ BIBREF2 perustuu konvoluutiohermoverkkoihin. $\\textsc {BottomUp}$ BIBREF11 käyttää bottom-up-lähestymistapaa yhteenvedon tuottamiseen. ABS BIBREF26 käyttää yhteenvedon tuottamiseen neuraalista huomiota. DRGD BIBREF27 perustuu syvään rekursiiviseen generatiiviseen dekooderiin. Vertaillaksemme vain esivalmisteluun perustuvaan malliimme, otamme mukaan useita valvomattomia abstraktioperustoja: SEQ$^3$ BIBREF28 käyttää yhteenvetoon rekonstruktiohäviötä ja aihekohtaista häviötä. BottleSum BIBREF23 hyödyntää valvomattomia uuttamis- ja itseohjautuvia abstrahointimenetelmiä. GPT-2 BIBREF7 on laajamittainen esivalmennettu kielimalli, jota voidaan käyttää suoraan tiivistelmien tuottamiseen.",
      "id": "task461-f8ce5b882d9744039c540c6b473ab434",
      "output": [
        "Mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Tunneanalyysin osalta tarkastelemme ongelmaamme monimerkkijärjestelmässä, jossa kaksi merkkiä ovat tunteen polariteetti ja tarkasteltava ehdokas/luokka.",
      "id": "task461-2b4ecfb7358c4e7ab9da61d8639e6c64",
      "output": [
        "Kuinka monta tarravaihtoehtoa monitarratehtävässä on?"
      ]
    },
    {
      "input": " Menetelmää arvioidaan BERTbase-mallilla, jossa on 12 kerrosta, 12 itsetarkkailupäätä ja 768 piilotetun tason koko.",
      "id": "task461-d13413af9591442cb6b2376910c2cdbc",
      "output": [
        "Mitä BERT-mallia he testaavat?"
      ]
    },
    {
      "input": "Kokeemme osoittivat, että käyttämällä objektin väriä tai muotoa objektin yksilölliseen tunnistamiseen robotti pystyy suorittamaan binning-tehtävän onnistuneesti 97,6 %:ssa ja 96,0 %:ssa tapauksista. Jos kuitenkin käytettiin pelkkää muotoa yksilöllisenä tunnisteena, tehtävä voitiin suorittaa vain 79,0 prosentissa tapauksista.",
      "id": "task461-caffa332358d4d52ba7bc2a0a9aa1a4f",
      "output": [
        "Mikä on tehtävien onnistumisaste? "
      ]
    },
    {
      "input": "Yksi useista muodoista, joihin FHIR voidaan sarjallistaa, on RDF. Koska RDF on kuitenkin suunniteltu abstraktiksi tietomalliksi ja FHIR on suunniteltu terveydenhuollon operatiiviseen käyttöön, mallien välillä voi olla pieni epäsuhta.",
      "id": "task461-f3c3ec2039164e7a903308d73d51b128",
      "output": [
        "Mitä eroja FHIR:n ja RDF:n välillä on?"
      ]
    },
    {
      "input": "Puhtaasti merkittyjä tietokokonaisuuksia. Käytämme kolmea puhtaasti merkittyä tietokokonaisuutta. Ensimmäinen on BIBREF19:n elokuvan lauseen polariteettitietokanta. Kaksi muuta tietokokonaisuutta ovat SemEval-2016-ohjelmasta kerätyt kannettavan tietokoneen ja ravintolan tietokokonaisuudet. Meluisat leimatut harjoitusaineistot. Edellä mainittuja kolmea aluetta (elokuva, kannettava tietokone ja ravintola) varten keräsimme 2000 arvostelua kutakin aluetta varten samasta arvostelulähteestä.",
      "id": "task461-d0639152278d48a882c73d19fc70b201",
      "output": [
        "Mitä tietokokonaisuutta käytetään mallin kouluttamiseen?"
      ]
    },
    {
      "input": "Kuumat kohdat merkittiin alunperin 8:lla tasolla ja asteella, jotka vaihtelivat tasoista \"ei kuuma\", \"lämmin\" ja \"kuuma +\". Yksi annotoija merkitsi jokaisen lausuman yhdellä näistä erillisistä merkinnöistä. Korostunut osallistuminen on harvinaista, sillä se on merkitty vain 1 prosenttiin lausumista.",
      "id": "task461-21d78a9266e64bc3b093d4d6b7cea535",
      "output": [
        "Mitä merkintöjä ICSI:n kokouskorpus sisältää?"
      ]
    },
    {
      "input": "Taulukossa 1 esitetään SQuAD-testisarjan virallinen pistetaulukko, kun toimitimme järjestelmämme. Mallimme EM-tulos on 68,73 % ja F1-tulos 77,39 %, mikä on huippuluokkaa yksittäisten mallien (ilman mallien yhdistämistä) joukossa.",
      "id": "task461-0057addf927e4022867c9cbe95950147",
      "output": [
        "Mikä on SQUADin tarkka suorituskyky?"
      ]
    },
    {
      "input": "Huomaamme, että A-gen-suorituskyky paranee merkittävästi yhteisen mallin avulla: sekä F1 että EM paranevat noin 10 prosenttiyksikköä.",
      "id": "task461-da37fe07cc27489a80ee9dd461d4a281",
      "output": [
        "Kuinka paljon parannusta QA:n ja QG:n yhteinen oppiminen antaa verrattuna pelkkään QA:n harjoitteluun?"
      ]
    },
    {
      "input": "Kilpailua varten annoimme 1 000 merkittyä dialogia kustakin tietokokonaisuudesta harjoittelua varten ja 240 merkitsemätöntä dialogia kustakin tietokokonaisuudesta arviointia varten. ",
      "id": "task461-ee20caf9b6234b2b868a8a9244c74edc",
      "output": [
        "Kuinka suuri on ensimmäinen tietokokonaisuus?",
        "Mikä on toisen tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Vertaamme edellä mainittua mallia vastaavaan malliin, jossa sen sijaan, että esitämme $K$ ominaisuutta eksplisiittisesti syötteenä, meillä on $K$ ominaisuutta genre-esiintymän muodossa, eli opimme genrekohtaisen sisäkkäisen sisäkkäisosaamisen kullekin gootti-, scifi- ja filosofian genrestä, kuten BIBREF8:ssa ja BIBREF7:ssä tutkittiin.",
      "id": "task461-f4727233fe2b4b0c93884f78c5b79ad9",
      "output": [
        "Onko tämä tyyligeneraattori verrattu johonkin perustasoon?"
      ]
    },
    {
      "input": "Tietoaineiston laadun analysointi ::: Arvioidaksemme tietokokonaisuuden johdonmukaisuutta eri annotaatioiden välillä, mittaamme F1:n käyttämällä UA-mittaria, jossa on 5 generaattoria per predikaatti. Dataset Quality Analysis ::: Arvioimme sekä kultaista standardijoukkoamme että äskettäistä Dense-joukkoa verrattuna integroituun 100 predikaatin asiantuntija-annotoituun näytteeseen.  Dataset Quality Analysis :::: Yhteensopivuus PropBankin aineiston kanssaOn valaisevaa havaita QA-SRL:n ja PropBankin (CoNLL-2009) annotaatioiden välinen yhteensopivuus BIBREF7. ",
      "id": "task461-8f609ee087064689995eaa54f1c6e6df",
      "output": [
        "Miten laatua mitattiin?"
      ]
    },
    {
      "input": "Aiempien töiden mukaisesti suoritamme 10-kertaisen ristiinvalidoinnin ja raportoimme keskimääräiset tulokset. ",
      "id": "task461-987761c9d63c4ebfac0c14a4dc14c308",
      "output": [
        "Miten mallin kestävyyttä arvioidaan?"
      ]
    },
    {
      "input": "Annotaatio-ohjelmistomme avulla poimimme automaattisesti maamerkit 2000:sta UOttawan BIBREF14-tietokannan kuvasta, jotka oli annotoitu kuvan segmentointitehtäviä varten. ",
      "id": "task461-260ad09daca2465f84bb99347b7e018c",
      "output": [
        "Kuinka suuria tietokokonaisuuksia kokeissa käytetään?"
      ]
    },
    {
      "input": "Sosiaalisen median epävirallinen ympäristö kannustaa monikielisiä puhujia usein vaihtamaan kielten välillä puhuessaan tai kirjoittaessaan. Nämä kaikki johtivat koodien sekoittumiseen ja koodinvaihtoon. Koodisekoittamisella tarkoitetaan eri kielten kielellisten yksiköiden käyttöä samassa lausumassa tai lauseessa, kun taas koodinvaihto tarkoittaa kahteen eri kieliopilliseen järjestelmään kuuluvien puheotteiden samanaikaista esiintymistäBIBREF3. Tämä kielten vaihtaminen tekee kieliopista monimutkaisemman, ja siksi sitä on vaikea käsitellä perinteisillä algoritmeilla. Sosiaalisen median teksteissä esiintyvä suuri osuus koodinvaihtelua sisältävästä sisällöstä on siis lisännyt aggression havaitsemistehtävän monimutkaisuutta. Esimerkiksi TRAC-2018-tapahtuman järjestäjien tarjoama tietokokonaisuus BIBREF0, BIBREF2 on itse asiassa koodisekoitettu tietokokonaisuus.",
      "id": "task461-61bbba345b3f4969bcc8a6fdc0e453b1",
      "output": [
        "Mitä tietoja/tutkimuksia kirjoittajat esittävät tukeakseen väitettä, jonka mukaan suurin osa aggressiivisista keskusteluista sisältää koodeja sekoittavia kieliä?"
      ]
    },
    {
      "input": "PolyResponsen ravintolahaku on tällä hetkellä saatavilla 8 kielellä ja 8 kaupungissa ympäri maailmaa: Englanti (Edinburgh), saksa (Berliini), espanja (Madrid), mandariini (Taipei), puola (Varsova), venäjä (Moskova), korea (Soul) ja serbia (Belgrad).",
      "id": "task461-5636054f6b1b49aaba7698fa2fe0b758",
      "output": [
        "Millä 8 kielellä PolyResponse-moottoria käytetään ravintoloiden haku- ja varausjärjestelmässä?"
      ]
    },
    {
      "input": "Ehdotamme yksinkertaista ja käytännöllistä inhimillistä arviointia tekstin tiivistämisen arvioimiseksi, jossa tiivistelmä arvioidaan lähdesisältöä vasten viitteen sijasta. Se käsittelee sekä parafrasoinnin että laadukkaan viitteen puuttumisen ongelmia.  Puutteiden välttämiseksi ehdotamme yksinkertaista inhimillistä arviointimenetelmää semanttisen johdonmukaisuuden arvioimiseksi. Kukin tiivistelmäehdokas arvioidaan tekstin eikä viitteen perusteella. Jos ehdokas on tekstin kannalta epäolennainen tai virheellinen tai jos ehdokas ei ole ymmärrettävä, ehdokas leimataan huonoksi. Muussa tapauksessa ehdokas merkitään hyväksi. Tällöin saadaan hyvien tiivistelmien tarkkuus. Ehdotettu arviointi on hyvin yksinkertainen ja suoraviivainen. Siinä keskitytään tiivistelmän ja tekstin väliseen vastaavuuteen. Semanttisen yhdenmukaisuuden pitäisi olla tärkein näkökohta, kun tekstin tiivistämismenetelmiä otetaan käyttöön, mutta nykyiset automaattiset menetelmät eivät pysty arvioimaan sitä kunnolla. Yksityiskohtaiset ohjeet inhimillisestä arvioinnista löytyvät liitteestä SECREF6 . ",
      "id": "task461-d4107d08075c49b18d189f77a230d0bc",
      "output": [
        "Mitä inhimillistä arviointimenetelmää ehdotetaan?"
      ]
    },
    {
      "input": "Sitten luotiin testisarjat, joissa häiriötoimintojen taso vaihteli - $\\lbrace 20\\%,40\\%,60\\%\\rbrace $.",
      "id": "task461-76153aed92d646a9b4c923181b6a3f89",
      "output": [
        "Koulutetaanko toistuvia neuroverkkoja häiriintyneellä datalla?"
      ]
    },
    {
      "input": "Analysoimme, millaisia diskurssi-ilmiöitä on vaikea kuvata käyttämällä vain yksikielisiä aineistoja. Käyttämiemme testisarjojen neljästä ilmiöstä (deiksi, leksikaalinen koheesio, VP-ellipsis ja NP-alkuiseen taivutukseen vaikuttava ellipsis) havaitsimme, että VP-ellipsis on vaikein ilmiö, joka on vaikeimmin kuvattavissa käyttämällä round-trip-käännöksiä.",
      "id": "task461-9fdccca3769e4f26a89f1ca4df2b0a44",
      "output": [
        "mitä ilmiöitä he mainitsevat vaikeasti vangittaviksi?"
      ]
    },
    {
      "input": "Mallimme eroaa tästä siten, että osa-sanavektorit ja tuloksena oleva representaatio opitaan yhdessä, kun sana-konteksti-koesiintymismatriisin painotettu faktorointi suoritetaan.",
      "id": "task461-c05843d1739f41d6abb6f78aab55d4d6",
      "output": [
        "Mitä matriisifaktorointimenetelmiä ne käyttävät?"
      ]
    },
    {
      "input": "Neljätoista tällaista ominaisuuksien poimintaohjelmaa on toteutettu, ja ne voidaan jakaa kolmeen pääluokkaan:[noitemsep]Lexicon FeaturesWord VectorsSyntax FeaturesSyntax Features",
      "id": "task461-54d8cab908a74ad789688bb4b4877dfa",
      "output": [
        "kuinka monta yhdistettyä ominaisuutta oli yhteensä?"
      ]
    },
    {
      "input": "Meillä on harjoitus- ja testausjoukkoja kolmella eri kielellä: Englanniksi, kiinaksi ja koreaksi. Hienosäätöä tehdessämme otimme käyttöön yhteistyöelimen virallisen koulutuskäsikirjoituksen, jossa oli oletushyperparametrit, ja hienosäädimme kutakin mallia, kunnes koulutustappio oli konvergoitunut.",
      "id": "task461-e3932c6852b24ff6aacb31c4eeef06bd",
      "output": [
        "mitä malli oppii nollapistoolin asetelmassa?"
      ]
    },
    {
      "input": "Huomaamme, että vanhempien laatu on yksinkertainen mutta tehokas ominaisuus, ja SVM-malli, joka käyttää tätä ominaisuutta, saavuttaa huomattavasti korkeamman ($p<0.001$) F1-pistemäärän ($46.61\\%$) kuin etäisyys opinnäytetyöstä ja kielelliset ominaisuudet. Vaikka BiLSTM-malli, jossa on huomio- ja FastText-perusominaisuudet, suoriutuu paremmin kuin SVM-malli, jossa on etäisyys opinnäytetyöstä ja kielelliset ominaisuudet, sen suorituskyky on samankaltainen kuin vanhemman laadun perusominaisuudella. Huomaamme, että kontekstin litteä esitys saavuttaa korkeimman F1-pistemäärän. Suuremmalla parametrimäärällä varustettujen mallien voi olla vaikeampaa suoriutua litteää esitystä paremmin, koska tietokokonaisuus on pieni. Havaitaan myös, että mallintamalla kolme väittämää argumenttipolulla ennen kohdeväittämää saavutetaan paras F1-pistemäärä (55,98 \\%$).",
      "id": "task461-c186f050f80b401099e0be7a6e09748f",
      "output": [
        "Kuinka parempia tulokset ovat verrattuna perusmalleihin?"
      ]
    },
    {
      "input": "CRWIZ-alustan avulla kerättiin 145 ainutlaatuista vuoropuhelua (kukin vuoropuhelu koostuu kahden osallistujan välisestä keskustelusta).  Keskimääräinen aika tehtävää kohden oli 10 minuuttia 47 sekuntia, mikä on hyvin lähellä alkuperäistä 10 minuutin arviotamme, ja tehtävä oli käytettävissä AMT:ssä viisi päivää. 145 dialogista 14 (9,66 %) sai 0,2 dollarin bonuksen hätätilanteen ratkaisemisesta. Ennustimme, että vain pieni osa osallistujista pystyisi ratkaisemaan hätätilanteen alle 6 minuutissa, joten se muotoiltiin pikemminkin bonushaasteeksi kuin vaatimukseksi saada palkkaa. Nopein aika hätätilanteen ratkaisemiseen oli 4 minuuttia 13 sekuntia ja keskiarvo 5 minuuttia 8 sekuntia. Taulukossa TABREF28 esitetään useita vuorovaikutustilastoja kerätystä aineistosta verrattuna yksittäiseen laboratoriossa suoritettuun WoZ-tutkimukseen BIBREF4.Data Analysis :::: Subjektiiviset tiedotTaulukossa TABREF33 esitetään tehtävän jälkeisen kyselyn tulokset. Havaitaan, että subjektiivinen ja objektiivinen tehtävän onnistuminen ovat samankaltaisia siinä mielessä, että hätätilanteen ratkaisseet dialogit arvioitiin johdonmukaisesti korkeammiksi kuin muut.Mann-Whitney-U:n yksisuuntaiset testit osoittavat, että hätätapauksen ratkaisseiden dialogien pisteet olivat Q1:n ja Q2:n osalta 95 prosentin luotettavuustasolla merkitsevästi korkeammat kuin hätätapauksen ratkaisemattomien dialogien pisteet (Q1: $U = 1654.5$, $p < 0.0001$; Q2: $U = 2195$, $p = 0.009$, molemmat $p < 0.05$). Tämä osoittaa, että tehokas yhteistyö ja tiedon helppous ovat avainasemassa tehtävän suorittamisessa tässä ympäristössä. Mitä tulee laadulliseen aineistoon, yksi Wizard-of-Oz-tekniikan tavoitteista oli saada osallistuja uskomaan, että hän on vuorovaikutuksessa automaattisen agentin kanssa, ja laadullinen palaute näytti heijastavan tätä: \"Pelin tekoäly ei ollut lainkaan avulias [...]\" tai \"Keskustelin Fredin, robottiavustajan, kanssa, minulla ei ollut muuta pelikumppania pelissä.\" Aineiston analyysi :::: Taulukossa TABREF28 vertaamme joukkoistamisella kerätyistä dialogeista saatuja eri mittareita aiemmin laboratorioympäristössä samankaltaisesta tehtävästä kerättyihin dialogeihin. Useimmat luvut ovat vertailukelpoisia lukuun ottamatta hätäavustajien vuorojen määrää (ja siten vuorojen kokonaismäärää). Jotta ymmärtäisimme näitä eroja paremmin, olemme ensin ryhmitelleet dialogin tekoja neljään eri laajempaan tyyppiin: Päivitykset, toimet, vuorovaikutukset ja pyynnöt, ja laskimme kunkin tyypin suhteellisen esiintymistiheyden molemmissa aineistokokoelmissa. Lisäksi kuvissa FIGREF29 ja FIGREF30 esitetään yleisimpien dialogitekojen jakautuminen eri ympäristöissä. On nähtävissä, että laboratorioympäristössä, jossa vuorovaikutus tapahtui kasvokkain robotin kanssa, ohjattu käytti enemmän vuorovaikutusta koskevia dialogitekstejä (taulukko TABREF32). Niitä käytettiin usein tilanteissa, joissa ohjatun oli pidettävä vuoro kesken, kun hän etsi sopivaa kehotusta tai odotti, että robotti saapuisi määriteltyyn tavoitteeseen ympäristössä. Toisaalta joukkorekisteröityjen aineistojen keräyspuheissa tilannepäivitykset olivat yleisempi valinta, kun avustaja odotti, että robotti kulkisi määritettyyn tavoitteeseen ympäristössä.Ehkä ei ole yllättävää, että aineistosta käy ilmi keskivahva positiivinen korrelaatio tehtävän onnistumisen ja niiden Toimintatyyppisten dialogitekojen lukumäärän välillä, joita avustaja suorittaa ja jotka laukaisevat tapahtumia maailmassa, jotka johtavat onnistumiseen ($R=0.475$). Tehtävän onnistumisen ja niiden Request-dialogitoimien määrän välillä, joissa pyydetään vahvistusta ennen toimia ($R=0.421$), esim. \"Minkä robotin haluat lähettää?\", on myös positiivinen korrelaatio. Kuten taulukosta 3 käy ilmi, nämä ovat suhteellisen harvinaisia, mutta ehkä ne kuvastavat yhteistyötä, jota tarvitaan tehtävän loppuun saattamiseksi. Taulukossa TABREF40 esitetään yksi kerätyistä dialogeista, joissa hätäapulainen oli jatkuvasti yhteydessä operaattoriin tämäntyyppisten vuoropuhelujen avulla.Tehtävän onnistumisprosentti oli myös hyvin erilainen näiden kahden asetelman välillä. BIBREF4:ssä raportoiduissa kokeissa 96 prosenttia vuoropuheluista johti tulipalon sammuttamiseen, kun taas joukkoistamisasetelmassa vain 9,66 prosenttia saavutti saman tavoitteen. Joukkoistamisasetelmassa robotit olivat hitaampia ja liikkuivat realistisella nopeudella, toisin kuin laboratorioasetelmassa. Suurempi bonus ja enemmän aikaa tehtävään saattaisi johtaa korkeampaan tehtävän onnistumisprosenttiin. data-analyysi ::: RajoituksetOn tärkeää ottaa huomioon, kuinka monta osallistujaa on käytettävissä, jotka ovat valmiita ja halukkaita suorittamaan tehtävän kerrallaan. Tämäntyyppinen joukkoistaminen edellyttää, että kahden osallistujan on oltava yhteydessä toisiinsa muutaman minuutin sisällä toisistaan, jotta heidät voidaan yhdistää pariksi. Kuten edellä mainittiin, joissakin tapauksissa osallistujat eivät tehneet yhteistyötä, ja nämä vuoropuhelut oli hylättävä, koska niistä ei ollut hyötyä.",
      "id": "task461-043ddf104b434bfbafed2bb824b52c26",
      "output": [
        "Käytetäänkö CRWIZ-järjestelmää jo tiedonkeruuseen, ja mitkä ovat tulokset?"
      ]
    },
    {
      "input": "Kuvassa FIGREF28 esitetään joitakin esimerkkejä CORD-19-NER:n annotaatiotuloksista. Näemme, että etäisesti tai heikosti valvotut menetelmämme tunnistavat uudet entiteettityypit laadukkaasti, kun syötteenä tarvitaan vain useita siemenesimerkkejä. Tunnistimme esimerkiksi \"SARS-CoV-2:n\" \"CORONAVIRUS\"-tyypiksi, \"lepakon\" ja \"pangoliinin\" \"WILDLIFE\"-tyypiksi ja \"Van der Waalsin voimat\" \"PHYSICAL_SCIENCE\"-tyypiksi. Tämän NER-merkinnän tulokset auttavat tekstinlouhintatehtävissä viruksen alkuperän ja fysikaalisen luonteen selvittämisessä. NER-menetelmämme ovat toimialariippumattomia, joten niitä voidaan soveltaa eri alojen korpuksiin. Lisäksi kuvassa FIGREF29 on toinen esimerkki New York Timesin NER-merkinnästä järjestelmällämme. Kuvassa FIGREF30 vertaamme merkintätuloksiamme olemassa oleviin NER/BioNER-järjestelmiin. Kuvasta FIGREF30 nähdään, että vain meidän menetelmämme pystyy tunnistamaan \"SARS-CoV-2\" koronavirukseksi. Kuvasta FIGREF30 nähdään, että menetelmämme pystyy tunnistamaan paljon muitakin entiteettejä, kuten \"pylogenetic\" evoluutioterminä ja \"bat\" villieläimenä. Kuvasta FIGREF30 nähdään myös, että menetelmämme pystyy tunnistamaan monia muita entiteettejä, kuten \"rasismi\" sosiaalisena käyttäytymisenä. Yhteenvetona voidaan todeta, että etäisesti ja heikosti valvotut NER-menetelmämme ovat luotettavia korkealaatuisen entiteettien tunnistamisen kannalta ilman, että harjoitusdatan annotointi vaatii ihmisen työtä.",
      "id": "task461-f1f91c2e2b434949b94112c6074b0a8e",
      "output": [
        "Kokeilivatko he tietokokonaisuutta?"
      ]
    },
    {
      "input": "Tutkiaksemme tarkemmin diskurssin upotuksiin koodattua tietoa suoritamme niille t-SNE-klusteroinnin BIBREF20 käyttäen parhaiten suoriutuvaa mallia CNN2-DE (globaali).",
      "id": "task461-ef8c550f4a724b0b9ecfba130290b580",
      "output": [
        "Miten diskurssin sulautumia analysoidaan?"
      ]
    },
    {
      "input": "Yrityksemme kielten esivalmennuksessa jäi odotuksistamme kaikissa muissa paitsi yhdessä testatussa tietokokonaisuudessa. Esiharjoittelumme ei onnistunut parantamaan tarkkuutta, vaikka sitä sovellettiin raportoituja verkkoja suurempiin verkkoihin.",
      "id": "task461-70fc8bdfb740482fafe6a3d359bb553e",
      "output": [
        "Parantaako esiharjoittelu yleisessä tekstikorpuksessa suorituskykyä?"
      ]
    },
    {
      "input": "Huomaamme, että kun AQA optimoi uudelleenmuotoilujaan mukautuakseen laadunvarmistusjärjestelmän kieleen, se poikkeaa hyvin jäsennellystä kielestä vähemmän sujuvien, mutta tehokkaampien klassisten tiedonhaun (IR) kyselyoperaatioiden hyväksi. ",
      "id": "task461-2cef98886bb644efbcd8f9e67952f85a",
      "output": [
        "Mitä eroa on Buckin ja muiden tutkimustuloksissa? Näyttää siltä, että Buck et al. mainitsee saman johtopäätöksen."
      ]
    },
    {
      "input": "Aktiivinen oppiminen parantaa huomattavasti iteratiivisesti koulutettujen koneoppimismallien suorituskykyä määrittelemällä valikoivasti, mitkä merkitsemättömät näytteet tulisi merkitä. ",
      "id": "task461-bb43232eecd3429eae3978eeb9ae2bbd",
      "output": [
        "Mitä on aktiivinen oppiminen?"
      ]
    },
    {
      "input": "SCA BIBREF5 lisää pehmeästi lauseen satunnaisesti valittuun sanaan sen kontekstisidonnaisen sekoituksen useista toisiinsa liittyvistä sanoista, eli korvaa sanan yhden pisteen esityksen kielimallin antamalla jakaumalla sanastosta.",
      "id": "task461-28f419890a054bf3b05d35e3a2a05a88",
      "output": [
        "Miten pehmeä kontekstisidonnainen tietojen lisääminen toimii?"
      ]
    },
    {
      "input": "Peruslauseen upotusmallina käytetään BiLSTM-mallia, joka kattaa kaikki vastaavien sekvenssien sanat ja jossa sanojen upotukset on alustettu satunnaisesti BIBREF:n30 mukaisesti. Valitsimme tämän vahvan peruslauseen koodausmallin, toisin kuin tekniset lauseen upotukset, jotka toimivat erityisen hyvin tässä tietokokonaisuudessa, jotta voimme esitellä tietokokonaisuutta. Odotamme, että valmiiksi koulutetut kontekstuaaliset koodausmallit, esimerkiksi ELMO BIBREF33 , ULMFit BIBREF34 , BERT BIBREF35 , tarjoaisivat täydentäviä suorituskykyparannuksia, kuten muutamissa viimeaikaisissa artikkeleissa BIBREF36 , BIBREF37 on osoitettu.",
      "id": "task461-ac24fee482e447d7a89b9981f59ecb87",
      "output": [
        "Mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Käytämme Universal Dependenciesin hindi-englanti-koodisekoitetietoaineistoa BIBREF9 testataksemme mallin kykyä merkitä koodisekoitetietoja. Tämä tietokokonaisuus perustuu hindi- ja englanninkielisten monikielisten puhujien koodinvaihtoon perustuviin twiitteihin. Käytämme syötemerkkeinä aineiston tarjoamia Devanagari-skriptejä.",
      "id": "task461-5c7afb8d19724d8fb5159836c40fc83c",
      "output": [
        "Mitä koodi- ja sekakielipareja arvioidaan?"
      ]
    },
    {
      "input": "Yhdistämme 11'248 saksan kielen kirjakielistä sanaa ja niiden foneettiset esitykset kuudella eri sveitsiläismurteella: Zürichin, St. Gallenin, Baselin, Bernin, Vispin ja Stansin (kuva FIGREF1).",
      "id": "task461-c6cb3349c5a54b86b979e415e874c63d",
      "output": [
        "Kuinka monta sanaa on koodattu sanakirjaan?"
      ]
    },
    {
      "input": "Kesäkuussa 2019 AA:lla oli $\\sim $50K merkintöjä, mutta tähän sisältyy joitakin merkintöjä, jotka eivät ole todellisia tutkimusjulkaisuja (esimerkiksi esipuheet, esipuheet, sisällysluettelot, ohjelmat, aikataulut, indeksit, papereita/osallistumispyynnöt, arvostelijaluettelot, luettelot tutoriaalin tiivistelmistä, kutsutut puheenvuorot, liitteet, istuntotiedot, muistokirjoitukset, kirja-arvostelut, uutiskirjeet, luettelot pöytäkirjoista, elinaikapalkinnot, erratum ja muistiinpanot). Hylkäämme ne tässä analyysissä. (Huomautus: CL-lehti sisältää kannanottoja, kuten squibs, letter to editor, opinion jne. Emme hylkää niitä.) Jäljelle jää 44 896 artikkelia.",
      "id": "task461-ac77ebc523264c31b8640da765dd1291",
      "output": [
        "Kuinka monta paperia kokeessa käytetään?"
      ]
    },
    {
      "input": "Keskitymme tässä Europarl-alueeseen, josta meillä on runsaasti tietoja useilla kielillä, ja käytämme alan sisäisenä harjoitusaineistona Europarl-korpusta BIBREF5 kahta käännössuuntaa varten: Englanti INLINEFORM0 saksa ja englanti INLINEFORM1 ranska. ",
      "id": "task461-2194c5673e854ac9870ca0b78ac1a1e6",
      "output": [
        "millä kielellä tiedot ovat?"
      ]
    },
    {
      "input": "Vaikka tässä asiakirjassa keskitymme entiteettien yhteyksiin ja nimiin, tietokirjoissa on tekstimuotoinen tietolähde, jota voimme myös hyödyntää: entiteettien kuvaukset. Poimimme FIGMENT-olioiden Wikipedian kuvaukset ja suodatamme pois ne oliot ( $\\sim $ 40 000 $ 200 000 $:sta), joilla ei ole kuvausta.",
      "id": "task461-7050049b81b6413eb7d9e9d2546db2fe",
      "output": [
        "Miten löydät kokonaisuuksien kuvaukset?"
      ]
    },
    {
      "input": "Kun kommentoimme dialogeja, meidän pitäisi lukea dialogit alusta loppuun. Jokaisesta lausumasta on löydettävä vähintään yksi vanhemman solmu kaikista sen aikaisemmista lausumista. Oletamme, että diskurssirakenne on yhdistetty graafi eikä yksikään lausuma ole eristetty. Ehdotamme kullekin dialogille kolmea kysymystä ja annotoimme vastausten vaihteluvälin syötetyssä dialogissa. Kuten tiedämme, tietokokonaisuutemme on ensimmäinen korpus moniosaisten dialogien luetun ymmärtämistä varten.Rakennamme seuraavat kysymykset ja vastaukset dialogille esimerkissä 1:Q1: Milloin Bdale lähtee?A1: Pe aamullaQ2: Miten saada ihmiset rakastamaan Markia Mjg59:n mielestä.A2: Palkkaa ihmisiä työskentelemään suljettujen ajureiden käänteistekniikan parissa.Toisaalta tehtävän vaikeuden parantamiseksi ehdotamme $ \\frac{1}{6}$:lle $ \\frac{1}{3}$ vastaamattomia kysymyksiä aineistossamme. Annotoimme vastaamattomat kysymykset ja niiden uskottavat vastaukset (PA). Kukin uskottava vastaus on peräisin syötetystä dialogista, mutta se ei ole vastaus uskottavaan kysymykseen.Q1: Whis is the email of daniels?PA: +61 403 505 896",
      "id": "task461-23a036d9309249ffa3d99e195f9b81a3",
      "output": [
        "Tehdäänkö merkinnät manuaalisesti?"
      ]
    },
    {
      "input": "Kun otetaan huomioon raa'at ääninäytteet INLINEFORM0 , sovelletaan koodausverkkoa INLINEFORM1 , joka parametrisoidaan viisikerroksiseksi konvoluutioverkoksi, joka on samanlainen kuin BIBREF15 . Seuraavaksi sovellamme kontekstiverkkoa INLINEFORM0 kooderiverkon ulostuloon sekoittaaksemme useita latentteja representaatioita INLINEFORM1 yhdeksi kontekstualisoiduksi tensoriksi INLINEFORM2 reseptiivisen kentän kokoa INLINEFORM3 varten. Kontekstiverkossa on seitsemän kerrosta, ja jokaisen kerroksen ytimen koko on kolme ja stride yksi. ",
      "id": "task461-ec6e2cbb60394979977f3d5616518576",
      "output": [
        "Kuinka monta konvoluutiokerrosta heidän mallissaan on?"
      ]
    },
    {
      "input": "Tärkein syy on se, että kun hallittavuus on vahva, valinnan muutos vaikuttaa suoraan tekstin toteutukseen, joten pieni virhe sisällön valinnassa voi johtaa epärealistiseen tekstiin. Jos valitsijaa ei ole koulutettu täydellisesti, sujuvuus kärsii väistämättä. Kun hallittavuus on heikompi, kuten RS:ssä, sujuvuus on vakaampi, koska valintamaskit eivät vaikuta siihen kovin paljon.",
      "id": "task461-4ee90b97aad141b9983d04633cef39b5",
      "output": [
        "Laskeeko suorituskyky välttämättä, kun halutaan enemmän valvontaa?"
      ]
    },
    {
      "input": "Seuraavassa kuvataan kysymysten muodostamisen todennäköisyysmallimme osatekijät.  Optimoinnin yksityiskohdat ovat seuraavat. Ensin otetaan näytteitä suuresta 150 000 kysymyksen joukosta, jotta gradienttia voidaan approksimoida kussakin vaiheessa tärkeysnäytteenoton avulla. Toiseksi suoritamme tietyn mallin ja harjoitusjoukon osalta 100 000 iteraatiota gradientin nousua oppimisnopeudella 0,1.",
      "id": "task461-e7c00a9538cb48398e91f82cc0d7f56e",
      "output": [
        "Onko se hermostollinen malli? Miten se koulutetaan?"
      ]
    },
    {
      "input": "Esimerkiksi parhaidenkin laadunvarmistusmallien suorituskyky heikkenee huomattavasti (8-15 %), kun siirrytään 1 hopin yhteyksistä 2 hopin yhteyksiin. Lisäksi parhaidenkin mallien tarkkuus WordNetQA-luotainten osalta laskee 14-44 prosenttia klusteripohjaisessa analyysissämme, jossa arvioidaan, tietääkö malli useita faktoja kustakin yksittäisestä käsitteestä sen sijaan, että se olisi vain hyvä vastaamaan yksittäisiin kysymyksiin. ",
      "id": "task461-6f63f8858bc54e0888700a0a2722c185",
      "output": [
        "Kuinka monen hyppäyksen jälkeen tarkkuus vähenee?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa käytämme Oxford-tyyppisten väittelyjen puhtaaksikirjoituksia ja tuloksia julkisesta väittelysarjasta \"Intelligence Squared Debates\" (lyhyesti IQ2).",
      "id": "task461-016530af0d7d4db1a81e387c8debbeaa",
      "output": [
        "mitä keskustelutietoaineistoa käytettiin?"
      ]
    },
    {
      "input": "Vaikka FAR:ia pitäisi suosia, koska FAM:t ovat jo manuaalisesti merkittyjä ja kertovat tarkalleen, pitäisikö yksi lause poimia (olettaen, että annotaatiomme ovat yhteneväiset), varmistaaksemme tarkemmin, että FAR korreloi ihmisen mieltymysten kanssa, asetamme UnifiedSum(E):n, NeuSum:n ja Lead-3:n paremmuusjärjestykseen taulukossa TABREF15. Ihmisten arvioinnissa 1. sijan järjestys on sama kuin FAR. FAR:lla on myös suurempi Spearmanin kerroin $\\rho $ kuin ROUGE:lla (0,457 vs. 0,44, n=30, kynnysarvo = 0,362 95 prosentin merkitsevyydellä).",
      "id": "task461-e4823fc23f7b410c939170f4381564e0",
      "output": [
        "Miten he arvioivat ehdottamaansa mittaria?"
      ]
    },
    {
      "input": "Vertaamme Blseä (jaksot UID23 - UID30 ) VecMapiin, Museen ja Baristaan (jakso \"Aikaisemmat työt\" ), joilla on samankaltaiset tietovaatimukset, sekä konekääntämiseen (MT) ja yksikieliseen (Mono) ylärajaan, jotka vaativat enemmän resursseja.",
      "id": "task461-53bad1b04cef4f4c88fed715d4055e0d",
      "output": [
        "mihin lähtötasoon niitä verrataan?"
      ]
    },
    {
      "input": "Tarkastelemme esiharjoittelua WSJ:n äänidatalla (ilman merkintöjä), osalla puhdasta Librispeechiä (noin 80 tuntia) ja täydellä Librispeechillä sekä kaikkien tietokokonaisuuksien yhdistelmällä (§ SECREF7 ).  Kokeelliset tulokset WSJ-vertailussa osoittavat, että esivalmennetut esitykset, jotka on arvioitu noin 1 000 tunnin merkitsemättömän puheen perusteella, voivat merkittävästi parantaa merkkipohjaista ASR-järjestelmää ja päihittää kirjallisuuden parhaan merkkipohjaisen tuloksen, Deep Speech 2:n. Tämän lisäksi on mahdollista, että esivalmennetut esitykset ovat parempia kuin kirjallisuuden paras merkkipohjainen tulos, Deep Speech 2. ",
      "id": "task461-d378bd4650094181a2c28e8638111540",
      "output": [
        "Minkä merkitsemättömän datan avulla ne esivalmennetaan?"
      ]
    },
    {
      "input": "Vertaamme järjestelmäämme erilaisiin perusasetuksiin. (1) Luokittelu sen mukaan, kuinka monta kertaa viittaus mainitaan asiakirjassa. (2) Sijoitus sen mukaan, kuinka monta kertaa viittausta on siteerattu kirjallisuudessa (viittausvaikutus). (3) Sijoittaminen Google Scholar Related Articlesin avulla. (4) Sijoittaminen TF*IDF-painotetun kosinimaisen samankaltaisuuden avulla. (5) Sijoittaminen käyttämällä tekstin samankaltaisuusrankingin perusteella koulutettua learning-to-rank-mallia. Kaksi ensimmäistä perusjärjestelmää ovat malleja, joissa arvot järjestetään suurimmasta pienimpään järjestyksen muodostamiseksi. Niiden taustalla on ajatus, että artikkelissa mainittujen viittausten määrä tai viittausten vaikutus voivat jo olla hyviä indikaattoreita niiden läheisyydestä. Tekstin samankaltaisuusmalli koulutetaan käyttäen samoja ominaisuuksia ja menetelmiä kuin annotaatiomalli, mutta se koulutetaan käyttäen tekstin samankaltaisuusrankingia kirjoittajan arvioiden sijasta.",
      "id": "task461-5930301eacf648c0be8a728f40f95988",
      "output": [
        "mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Koulutusaiheille on ominaista se, että niissä on monenlaisia alateemoja ja näkökulmia, sillä ne kiinnostavat tutkijoita, käytännön toimijoita, vanhempia, opiskelijoita tai poliittisia päättäjiä. Oletamme, että tämä moninaisuus johtaa koulutusaiheiden kielelliseen vaihteluun ja on siten haaste NLP:lle.",
      "id": "task461-90b4e564d84547d8810466ba4d921b3c",
      "output": [
        "Millaisia haasteita eri rekisterit ja alat asettavat tälle tehtävälle?"
      ]
    },
    {
      "input": "Enkooderi-dekooderi-kehyksessämme käytetään erillistä koodausta dialogin eri puhujille. Käyttäjän lausumat $x_t^{usr}$ ja järjestelmän lausumat $x_t^{sys}$ syötetään erikseen käyttäjän koodaimeen ja järjestelmän koodaimeen, jotta saadaan kooderin piilotetut tilat $h_{i}^{usr}$ ja $h_{i}^{sys}$ . Integroimme semanttisen slot-rakenteen suorittamalla delexikalisoinnin alkuperäisille dialogeille. Delexikalisointi on yleinen esikäsittelyvaihe dialogien mallintamisessa. Integroimme dialogialueen telineen monitehtäväkehyksen avulla. Dialogialue tarkoittaa eri keskustelutehtävien sisältöä, esimerkiksi hotellin, ravintolan ja taksin varaamista MultiWOZ-tietokannassa.",
      "id": "task461-4b190573c9414053a52fd692a649253a",
      "output": [
        "Miten SPNet hyödyntää puhujan roolia, semanttista aukkoa ja dialogialueen annotaatioita?"
      ]
    },
    {
      "input": "Visualisoinnin perusidea, joka perustuu Isaac Newtonin värispektrin visualisointiin BIBREF8 , on ilmaista seos sen ainesosien perusteella barysentrisissä koordinaateissa. Tämä visualisointi mahdollistaa intuitiivisen tulkinnan siitä, mihin maahan resepti kuuluu. Jos japanilaisuuden todennäköisyys on suuri, resepti kartoitetaan lähelle japanilaisuutta. Maat sijoitetaan Newton-diagrammissa spektrigraafin piirtämisen BIBREF9 avulla siten, että samanlaiset maat sijoitetaan ympyrän lähelle. ",
      "id": "task461-6b770a7d889346f28e9bf91a47e7c8d7",
      "output": [
        "Mikä on barysentrinen Newtonin diagrammi?"
      ]
    },
    {
      "input": "Keräsimme japanilaisia fiktiivisiä tarinoita verkosta tietokokonaisuuden rakentamiseksi.",
      "id": "task461-2d0c1d977a204e5a978d77813a327994",
      "output": [
        "Miten tietokokonaisuus luodaan?"
      ]
    },
    {
      "input": "Näiden tulosten perusteella etsimme tulkittavissa olevia piilotetun tilan ulottuvuuksia hieman järjestelmällisemmin käyttämällä päätöspuita yksittäisten piilotetun tilan ulottuvuuksien ennustamiseen (kuva 2 ). Visualisoimme piilotettujen tilojen kokonaisdynamiikan värittämällä harjoitusaineiston tilavektoreiden k-means-klustereilla (kuvat 3 , 3 ). Kuvissa 3 ja 3 värikoodaamme harjoitusdatan 10 HMM-tilan avulla. Kuvissa 3 ja 3 sovelletaan k-means-klusterointia LSTM:n tilavektoreihin ja värikoodataan harjoitusdata klustereilla.",
      "id": "task461-e5e7d800db084958b1003fac1fbe1f52",
      "output": [
        "Mitä menetelmiä kirjoittajat käyttävät päätellessään, että LSTM ja HMM oppivat täydentävää tietoa?"
      ]
    },
    {
      "input": "Vertailemme mallimme suorituskykyä (taulukko 2 ) perinteisiin Bag of Words (BoW), TF-IDF ja n-grammiominaisuuksiin perustuviin luokittelijoihin. Vertailemme myös keskimääräisiä Skip-Gram BIBREF29 , Doc2Vec BIBREF30 , CNN BIBREF23 , Hierarchical Attention (HN-ATT) BIBREF24 ja hierarkkisia verkkomalleja (HN). HN-malli on samanlainen kuin mallimme HN-SA, mutta ilman itsehuomiota. Tutkimme edelleen suorituskykyä SWBD2:ssa tarkastelemalla mallin sekoitusmatriisia. Kuvassa 2 esitetään mallin normalisoidun sekoitusmatriisin lämpökartta SWBD2:ssa.",
      "id": "task461-80de9616fbf4434ea1a5296cb82d3403",
      "output": [
        "Tekevätkö kirjoittajat manuaalista arviointia?"
      ]
    },
    {
      "input": "Hausan kieli on Afrikan toiseksi puhutuin alkuperäiskieli, jota puhuu äidinkielenään yli 40 miljoonaa ihmistä (BIBREF20), ja se on yksi Nigerian kolmesta pääkielestä yhdessä igbon ja jorùban kanssa. Kieli on kotoisin Nigerian pohjoisosasta ja Nigerin eteläosasta, ja sitä puhutaan laajalti Länsi- ja Keski-Afrikassa kauppakielenä kahdeksassa muussa maassa: Beninissä, Ghanassa, Kamerunissa, Togossa, Norsunluurannikolla, Tšadissa, Burkina Fasossa ja Sudanissa. Yorùbá-kieli on Afrikan kolmanneksi puhutuin alkuperäiskieli swahillin ja hausan jälkeen, ja sitä puhuu yli 35 miljoonaa ihmistä BIBREF20. Kieli on kotoisin Nigerian lounaisosasta ja Beninin eteläosasta, ja sitä puhutaan myös muissa maissa, kuten Togon tasavallassa, Ghanassa, Norsunluurannikolla, Sierra Leonessa, Kuubassa ja Brasiliassa.",
      "id": "task461-e338420c820849028e4aa24f7c823eb8",
      "output": [
        "Missä maissa puhutaan Hausaa ja Yor\\`ub\\'aa?"
      ]
    },
    {
      "input": "Toiseksi sanojen aistimusten epätasaisen, mutta tuntemattoman jakautumisen tunnettu ongelma on ratkaistu muuttamalla naiivia Bayesin luokittelijaa. Tämän korjauksen ansiosta luokittelija ei enää vinoutuisi niiden aistimusten suuntaan, joista on enemmän harjoitustietoa. Lopuksi sanojen kohdeaistimuksia vastaavia aggregoituja ominaisuusarvoja käytetään naivistisen Bayesin luokittimen rakentamiseen, joka on mukautettu tilanteeseen, jossa a priori tuntemattomat todennäköisyydet ovat tuntemattomia.",
      "id": "task461-526b53191da0445fa7676b41acb1e780",
      "output": [
        "Miten ne käsittelevät tuntemattomia jakeluaistimuksia?"
      ]
    },
    {
      "input": "RNN-mallien perustasona käytämme yksisuuntaista RNN-mallia, joka ennustaa suhteen koko lauseen käsittelyn jälkeen.",
      "id": "task461-d83412e85593452f84bcacf603c770a4",
      "output": [
        "Mitä rekursiivisen neuroverkon muunnosta he käyttävät?"
      ]
    },
    {
      "input": "Aiempien teosten BIBREF6, BIBREF7 ja BIBREF9 mukaisesti käytämme BLEU- ja Micro Entity F1 -mittareita arvioidaksemme mallimme suorituskykyä.  Tarjoamme ihmisarvioinnin kehyksestämme ja vertailluista malleista.  Palkkaamme useita ihmisasiantuntijoita ja pyydämme heitä arvioimaan vastausten laatua oikeellisuuden, sujuvuuden ja inhimillisyyden perusteella asteikolla 1-5.",
      "id": "task461-34aa9d4309d34109a285387d211aea87",
      "output": [
        "Mitkä olivat arviointimittarit?"
      ]
    },
    {
      "input": " Valitsimme sen sijaan automaattisen lähestymistavan, joka voidaan skaalata mielivaltaisesti ja pienin kustannuksin: luomme synteettisiä lausepareja $(, \\tilde{})$ häiritsemällä satunnaisesti 1,8 miljoonaa Wikipedia-tietokannan $$ segmenttiä. Käytämme kolmea tekniikkaa: maskin täyttäminen BERT:llä, takaisinkääntäminen ja sanojen satunnainen poisjättäminen. ",
      "id": "task461-a312a3cab93d485c967dfffdebf66b90",
      "output": [
        "Miten synteettiset esimerkit luodaan?"
      ]
    },
    {
      "input": "Peruslähtökohtana käytetään lineaarista logistista regressiota osakkeiden teknisiin signaaleihin, jotta voidaan ennustaa seuraavan päivän osaketuottojen merkit (+/-). Perusmalliin ei liitetä sentimenttiominaisuuksia.",
      "id": "task461-af66825eab204a69919a2f7ca4a04ff7",
      "output": [
        "Mikä on peruslähtökohtainen koneoppimisennuste?"
      ]
    },
    {
      "input": "Twitter-profiilien manuaalinen vahvistaminen: Tarkistimme jokaisen löydetyn profiilin manuaalisesti tarkastelemalla profiilikuvaa, profiilin taustakuvaa, viimeisimpiä twiittejä ja käyttäjän lähettämiä viimeisimpiä kuvia.",
      "id": "task461-0706715058d540559c2f9d4dbd0d717b",
      "output": [
        "Miten jengiin kuuluminen todennetaan?"
      ]
    },
    {
      "input": "NER-tehtävää varten tarkastelemme sekä kiinalaisia tietokokonaisuuksia eli OntoNotes4.0 BIBREF34 ja MSRA BIBREF35 että englantilaisia tietokokonaisuuksia eli CoNLL2003 BIBREF36 ja OntoNotes5.0 BIBREF37. Taulukossa esitetään kokeelliset tulokset NER-tietokannoilla. Englanninkielisissä tietokokonaisuuksissa, joihin kuuluvat CoNLL2003 ja OntoNotes5.0, ehdotettu menetelmämme on parempi kuin BERT-MRCBIBREF38 +0,29 ja +0,96. Kiinalaisissa aineistoissa suorituskyky paranee huomattavasti: MSRA:n F1-parannus on +0,97 ja OntoNotes4.0:n +2,36. Me saavutamme uusia SOTA-suorituksia kaikissa neljässä NER-tietokannassa.",
      "id": "task461-3ec10ddbbc024ef8aef0db901693bb94",
      "output": [
        "Mitkä ovat menetelmän F1-parannukset NER-tehtävässä englannin- ja kiinankielisten tietokokonaisuuksien osalta?"
      ]
    },
    {
      "input": "Keskustelujen tulosten ennustaminen on tapauksessamme hyvin mielenkiintoista. Suurin osa tuloksista näyttää vastaavan joidenkin asiantuntijoiden, kuten Washington Postin poliittisten asiantuntijoiden, näkemyksiä. Tämä viittaa siihen, että tietyt säännöt, joita mainitut asiantuntijat käyttivät ehdokkaiden pisteyttämiseen väittelyissä, heijastuivat itse asiassa lukemalla ihmisten sosiaalisessa mediassa ilmaisemia mielipiteitä. Tämä avaa monenlaisia oppimismahdollisuuksia käyttäjien sosiaalisessa mediassa esittämistä mielipiteistä, joita kutsutaan joskus myös joukon viisaudeksi (wisdom of crowd).",
      "id": "task461-6a180bea2cd24835afceae1abeeb3eec",
      "output": [
        "Kuka on yleisö näissä kokeissa?"
      ]
    },
    {
      "input": "Hyödyllisyydestään huolimatta ELS:istä poimittuihin linkitettyihin entiteetteihin liittyy ongelmia, jotka johtuvat alhaisista tarkkuusluvuista BIBREF11 ja koulutustietokantojen suunnitteluun liittyvistä haasteista BIBREF12 . Ensiksikin poimitut entiteetit voivat olla moniselitteisiä. Toiseksi linkitetyt entiteetit voivat olla myös liian yleisiä, jotta niitä voitaisiin pitää entiteetteinä. ",
      "id": "task461-47ecd658385f4c31a0cba7b78db2d6fa",
      "output": [
        "Miksi nykyiset ELS-järjestelmät eivät ole riittävän tehokkaita?"
      ]
    },
    {
      "input": "Tämän jälkeen yhdistämme nämä maininnat toisiinsa i) jos ne esiintyvät samassa asiakirjassa (tästä käytetään nimitystä DOC-BASED edges), ii) jos nimettyjen entiteettien mainintapari on identtinen (MATCH edges - nämä voivat yhdistää solmuja sekä asiakirjojen välillä että niiden sisällä) tai iii) jos ne ovat samassa ydinviittausketjussa ulkoisen ydinviittausjärjestelmän ennusteen mukaan (COREF edges).",
      "id": "task461-eeeeb938de424ac7a28af926ca1926aa",
      "output": [
        "Käyttivätkö he relaatioiden louhintamenetelmää rakentaakseen graafin reunat?"
      ]
    },
    {
      "input": "Siirtomallimme laajentaa alkuperäistä muuntajamallia monikooderipohjaiseen muuntajaarkkitehtuuriin. Muuntajaarkkitehtuuri BIBREF12 perustuu yksinomaan tällaisiin huomiomekanismeihin, jotka korvaavat rekursio- ja konvoluutiomekanismit kokonaan. Muuntaja käyttää sijaintikoodausta tulo- ja lähtösekvenssien koodaamiseen ja laskee sekä itse- että ristihuomiota niin sanottujen monipäähuomioiden avulla, mitä helpottaa rinnakkaistaminen. Käytämme usean pään huomiointia, jotta voimme yhdessä huomioida eri sijainneissa olevaa tietoa eri esityksen osa-alueilta.",
      "id": "task461-f3dcfd27fb8c43769edb96f3a13edd75",
      "output": [
        "Mitä algoritmia käytetään UDS-DFKI-järjestelmässä?"
      ]
    },
    {
      "input": "Vertailemme lähestymistapojamme vastaaviin lähestymistapoihin, kuten pivoting, monikielinen NMT (MNMT) BIBREF19 ja kieltenvälinen siirto ilman esivalmennusta BIBREF16.  Tulokset osoittavat, että lähestymistapamme päihittävät johdonmukaisesti muut lähestymistavat kaikissa kielissä ja tietokokonaisuuksissa, erityisesti pivotingin, joka on vahva lähtökohta nollatilanteessa, jota monikieliset NMT-järjestelmät eivät useinkaan päihitä BIBREF19, BIBREF20, BIBREF23.",
      "id": "task461-081f4b26677b4599a9ee5d61c266f70e",
      "output": [
        "mihin monikielisiin lähestymistapoihin niitä verrataan?"
      ]
    },
    {
      "input": "Kuviosta FIGREF1 voidaan nähdä, että jokaisen yksittäisen uusintakierroksen tulokset eroavat merkittävästi toisistaan. Tarkkuus voi muuttua jopa 5 prosenttiyksikköä, kun taas BLEU voi vaihdella jopa 8 prosenttiyksikköä.",
      "id": "task461-d7a28b1a8e38468c99b5801d63d46905",
      "output": [
        "Kuinka paljon tyylitarkkuuden standardimittarit vaihtelevat eri uusintakierroksilla?"
      ]
    },
    {
      "input": "Valitsimme testialustaksi uusimman Transformer BIBREF1 -mallin ja perinteisen RNN-hakumallin BIBREF0.",
      "id": "task461-98369081572e48359c9ab2a93c869984",
      "output": [
        "Millä malliarkkitehtuureilla he testaavat sanojen tärkeyttä koskevaa lähestymistapaa?"
      ]
    },
    {
      "input": "Ensimmäisessä tutkimuksessa käytimme Twitterin määritelmää vihamielisestä käytöksestä. Tämä määritelmä esitettiin alussa ja uudelleen jokaisen twiitin yläpuolella.",
      "id": "task461-4824876954ba4eb1964c8c860cf5217f",
      "output": [
        "Mikä määritelmä oli yksi ryhmistä näytettiin?"
      ]
    },
    {
      "input": "Rakensimme fraasipohjaisen kiinasta englanniksi SMT-järjestelmän Moses BIBREF18 -ohjelman avulla.  Lopulta lopullinen rinnakkaisteksti koostuu noin 8,8 miljoonasta lauseparista, 228 miljoonasta kiinankielisestä merkistä ja 254 miljoonasta englanninkielisestä merkistä (merkki voi olla sana tai välimerkki).  Sanojen kokonaismäärä näissä kahdessa korpuksessa on kiinan osalta 1,81 miljoonaa ja englannin osalta 2,03 miljoonaa.",
      "id": "task461-c7d8b2b5064a49c6b3f196c784bf4500",
      "output": [
        "Kokeilivatko he vain yhtä kieliparia?"
      ]
    },
    {
      "input": "Ensimmäinen lähestymistapa perustuu hierarkkiseen mallintamiseen BIBREF13 , jossa oletetaan, että ryhmäkohtaiset upotusrepresentaatiot on sidottu yhteen globaalin upotuksen kautta.",
      "id": "task461-1d2da1a8edcc4f1e981530033f63c5e8",
      "output": [
        "Mitä hierarkkista mallinnusmenetelmää käytetään?"
      ]
    },
    {
      "input": ". Taulukosta TABREF17 käy ilmi, että GM$\\_$KL:llä saavutetaan SCWS-tietokannassa parempi korrelaatio kuin nykyisillä lähestymistavoilla eri mittareilla.",
      "id": "task461-4bad1251026b43b39a259d50f656237e",
      "output": [
        "Miten tämä lähestymistapa vertautuu muihin WSD-lähestymistapoihin, joissa käytetään sanojen upotuksia?"
      ]
    },
    {
      "input": "Olemme osoittaneet, että neuroverkkopohjaiset mallit voivat päihittää ominaisuuksiin perustuvat mallit laajoilla marginaaleilla, ja teimme ablaatiotutkimuksen osoittaaksemme, että kontekstisidonnainen esitysoppiminen voi parantaa NN-mallien suorituskykyä.",
      "id": "task461-fef2dc3524314b1fad8c4beea63fc265",
      "output": [
        "Mitä johtopäätöksiä kirjoittajat tekevät yksityiskohtaisten analyysiensa perusteella?"
      ]
    },
    {
      "input": "Käytämme 10-kertaista ristiinvalidointia ja vain kahdenlaisia piirteitä: n-grammeja ja Word2Vec-sanan upotuksia.  N-grammiominaisuuksiin kuuluvat unigrammit, bigrammit ja trigrammit, mukaan lukien välimerkkijaksot (esimerkiksi ellipsit tai \"!!!\") ja hymiöt. Käytämme GoogleNewsin Word2Vec-ominaisuuksia BIBREF28 .",
      "id": "task461-065e88cf15594ac48b55754dff572f64",
      "output": [
        "Mitä yksinkertaisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "DSC-häviön käyttö parantaa F1-pistemäärää +0,58 MRPC:n osalta ja +0,73 QQP:n osalta.",
      "id": "task461-92e2051af25845d6906a6bbf8a33dfdb",
      "output": [
        "Mitkä ovat F1-menetelmän parannukset parafraasin tunnistamisessa?"
      ]
    },
    {
      "input": "Se, mitkä tapahtumat kirjoittajat valitsevat sisällytettäväksi historiaansa, mitkä he jättävät pois ja miten valitut tapahtumat liittyvät marssiin, ovat ratkaisevia tekijöitä puolueellisuuden välittämisessä.",
      "id": "task461-b4560a52781442fbb06da6160ea9c572",
      "output": [
        "Mitkä tekijät vaikuttavat tämän tutkimuksen mukaan tulkinnallisiin ennakkoluuloihin?"
      ]
    },
    {
      "input": "Tämän jälkeen koulutamme malleja WMT English-German (EnDe) -mallilla ilman BT-kohinaa ja sen sijaan merkitsemme synteettisen datan nimenomaisesti varatuilla tunnuksilla. Toistamme nämä kokeet WMT English-Romanian (EnRo) -menetelmällä, jossa NoisedBT alittaa tavallisen BT:n ja TaggedBT parantaa molempia tekniikoita. Suoritamme kokeet WMT18 EnDe bitextillä, WMT16 EnRo bitextillä ja WMT15 EnFr bitextillä. Käytämme WMT Newscrawlia yksikielisten aineistojen osalta (2007-2017 De:n osalta, 2016 Ro:n osalta, 2007-2013 En:n osalta ja 2007-2014 Fr:n osalta). Bitextin osalta suodatamme tyhjät lauseet ja yli 250 alasanaa pitkät lauseet pois. Poistamme parit, joiden whitespace-tokenized-pituuden suhde on yli 2. Tuloksena on noin 5,0 miljoonaa paria EnDe:lle ja 0,6 miljoonaa paria EnRo:lle. Emme suodata EnFr-purkutekstiä, jolloin tuloksena on 41 miljoonaa lauseparia.",
      "id": "task461-d92528e221694868a9c93359e05a87c9",
      "output": [
        "Millä aineistoilla menetelmä arvioitiin?"
      ]
    },
    {
      "input": "Käytämme erityisesti CORD-19-tietokokonaisuutta BIBREF2, joka sisältää yli 45 000 tieteellistä artikkelia, joista yli 33 000 on kokotekstejä COVID-19:stä, SARS-CoV-2:sta ja niihin liittyvistä koronaviruksista. Kehitämme lauseiden luokittelumenetelmiä kaikkien COVID-19:n radiologisia löydöksiä kuvaavien lauseiden tunnistamiseksi. ",
      "id": "task461-397c2ae1923342aab87dad380a24c99f",
      "output": [
        "Mikä on CORD-19-tietokanta?"
      ]
    },
    {
      "input": "Taso B luokittelee rikoksen tyypin, ja siinä käytetään kahta nimikettä: kohdennetut (TIN) ja kohdentamattomat (INT) loukkaukset ja uhkaukset.Kohdentunut loukkaus (TIN): Viestit, jotka sisältävät yksilöön, ryhmään tai muihin kohdistuvan loukkauksen/uhkauksen (ks. seuraava taso);Kohdistamaton (UNT): Viestit, jotka sisältävät ei-kohdennettuja solvauksia ja kirosanoja. Yleistä kirosanaa sisältävät viestit eivät ole kohdennettuja, mutta ne sisältävät ei-hyväksyttävää kielenkäyttöä. Taso C luokittelee loukkausten ja uhkausten kohteet yksilöihin (IND), ryhmiin (GRP) ja muihin (OTH).Yksilö (IND): Yksilöön kohdistuvat viestit. Kyseessä voi olla tunnettu henkilö, nimetty yksilö tai nimeltä mainitsematon keskustelun osanottaja. Yksilöihin kohdistuvat loukkaukset ja uhkaukset määritellään usein cyberbullingiksi. ryhmä (GRP): Näiden loukkaavien viestien kohteena on ryhmä ihmisiä, joita pidetään yhtenäisinä saman etnisen alkuperän, sukupuolen tai seksuaalisen suuntautumisen, poliittisen suuntautumisen, uskonnollisen vakaumuksen tai muun yhteisen ominaisuuden vuoksi. Monet ryhmään kohdistuvista loukkauksista ja uhkauksista vastaavat sitä, mitä yleisesti ymmärretään vihapuheeksi.Muu (OTH): Näiden loukkaavien viestien kohde ei kuulu mihinkään kahdesta edellisestä kategoriasta (esim. organisaatio, tilanne, tapahtuma tai asia).",
      "id": "task461-275dbc78683f43d381e07e99d8194b9c",
      "output": [
        "Millaista loukkaavaa sisältöä tutkitaan?"
      ]
    },
    {
      "input": "Laskemme mittarimme yhteisön käyttäjien kirjoittamista kommenteista kuukausien aikaikkunoissa jokaiselle riittävän aktiiviselle kuukaudelle ja poistamme manuaalisesti yhteisöt, joissa suurin osa kommenteista on vieraskielisiä. ",
      "id": "task461-5149cb3d2d8c4ed7b97218aad48a6658",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Käytämme oletusarvoista harjoittelu-validointi-testijakoa 70-15-15 jokaiselle tietokokonaisuudelle ja käytämme kaikkia neljää tietokokonaisuutta (BF, BA, SFU ja Sherlock).",
      "id": "task461-2e676d189de64faeb37df97d5e8f70c1",
      "output": [
        "Minkä useiden eri tietokokonaisuuksien pohjalta ne harjoittelivat yhteisen harjoittelun aikana?"
      ]
    },
    {
      "input": "Perustasomme on TransE, koska mallimme pisteytysfunktio perustuu TransE:hen.",
      "id": "task461-80c483cdf8f2468c865a8f3f74d97f64",
      "output": [
        "Mitä vertailukohtia käytetään?"
      ]
    },
    {
      "input": "Vastataksemme kysymykseen 2, joka koskee ATSC:n suorituskykyä toimialueella, näemme välilehdellä: tulokset, että toimialueella tapahtuvan harjoittelun osalta mallimme BERT-ADA Lapt ja BERT-ADA Rest saavuttavat suorituskyvyn, joka on lähellä huipputason suorituskykyä kannettavien tietokoneiden tietokokonaisuudessa, ja uuden huipputason suorituskyvyn ravintoloiden tietokokonaisuudessa, ja niiden tarkkuus on 79,19 % ja 87,14 %. Yleisesti ottaen ATSC-tehtävä yleistyy hyvin eri osa-alueiden välillä, mutta tarkkuus laskee noin 2-$3\\%$ verrattuna osa-alueen sisäiseen harjoitteluun.",
      "id": "task461-2fdda8556eef40eb94094d5a0e6e71b5",
      "output": [
        "Mitkä ovat suorituskyvyn tulokset?"
      ]
    },
    {
      "input": "Kokeissamme käytimme TF.IDF-pohjaisia piirteitä artikkelin otsikossa ja sisällössä, jotka halusimme luokitella. Käytimme näitä piirteitä kahdesti - kerran otsikon ja kerran artikkelin sisällön osalta, koska halusimme saada kaksi erilaista esitystä samasta artikkelista. Käytimme siis yhteensä 1 100 TF.IDF-painotettua piirrettä (800 sisältöä + 300 otsikkoa) ja rajasimme sanaston 800 ja 300 tärkeimpään sanaan (jotka esiintyivät yli viidessä artikkelissa).",
      "id": "task461-6c55943537064b4dbd147239a4d6ab26",
      "output": [
        "mitä leksikaalisia piirteitä he kokeilivat?"
      ]
    },
    {
      "input": "NSA:n yleisyyden osoittamiseksi esitämme lisäksi kokeita videotekstien teksteistä, konekääntämisestä ja visuaalisten kysymysten vastaamisesta VATEX-, WMT 2014 English-to-German- ja VQA-v2-tietokannoilla. ",
      "id": "task461-9227d126a0f24071bf4e174e0841f8b6",
      "output": [
        "Mitä tietokokonaisuuksia käytetään kolmea muuta tehtävää koskevissa kokeissa?"
      ]
    },
    {
      "input": "Koulutamme LSTM:ää harjoitusjoukon kanssa ja ilman huomiota. Koulutuksen jälkeen otamme kehitysjoukon parhaan mallin BLEU-pistemäärän BIBREF16 perusteella ja laskemme BLEU-pistemäärän testijoukolle. ",
      "id": "task461-ab101fad3bec48f7807b95857ab85e74",
      "output": [
        "Miten generatiivista mallia arvioidaan?"
      ]
    },
    {
      "input": "Olemme keränneet yhteensä 3500 kysymystä Internetistä ja muista lähteistä, kuten yleistietokirjoista, historiasta jne. Korpus sisältää kysymykset ja luokat, joihin kukin kysymys kuuluu.",
      "id": "task461-6cef7fc4385c4f49816f4354795bcca1",
      "output": [
        "mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "On huomattava, että BoW/SVM-malli on lineaarinen ennustaja, joka luottaa suoraan sanataajuustilastoihin, joten sen ilmaisuvoima on heikompi kuin CNN-mallilla, joka oppii lisäksi piilokerroksen välikerroksen representaatioita ja konvoluutiosuodattimia. Lisäksi CNN-malli voi hyödyntää semanttista samankaltaisuutta, joka on koodattu hajautettuihin word2vec-representaatioihin, kun taas BoW/SVM-mallissa kaikki sanat ovat \"yhtä kaukana\" sanasäkkien semanttisessa avaruudessa.",
      "id": "task461-83cfa2f3a56c4a1d8446601d9dad8da4",
      "output": [
        "Miksi CNN-malli on kirjoittajien mukaan selitettävyydeltään parempi?"
      ]
    },
    {
      "input": "Analogisesti sanojen upotusten kanssa lauseiden upotukset, esimerkiksi Universal Sentence Encoder BIBREF8 ja Sentence-BERT BIBREF6, mahdollistavat erilaisten lauseiden kosinus-muotoisen samankaltaisuuden laskemisen, kuten esimerkiksi kysymyksen ja vastaavan vastauksen samankaltaisuuden. Mitä sopivampi tietty vastaus on tiettyyn kysymykseen, sitä vahvempi on sen kosinusarvoinen samankaltaisuus. Kun tarkastellaan kahta vastakkaista vastausta, on siis mahdollista määrittää vinoutusarvo: missä $\\vec{q}$ on kysymyksen vektorimuotoinen esitys ja $\\vec{a}$ ja $\\vec{b}$ ovat kahden vastauksen/valinnan esitykset.",
      "id": "task461-6076ed840ed7448eb3c8513a3c8de3ea",
      "output": [
        "Miten moraalista puolueellisuutta mitataan?"
      ]
    },
    {
      "input": "Laajennamme Amazon Conversational Bot Toolkit (CoBot) BIBREF6 -ohjelmistoa, joka on joustava tapahtumapohjainen kehys. CoBot tarjoaa ASR-tuloksia ja luonnollisen kielen käsittelyputkia Alexa Skills Kit (ASK) BIBREF7 -paketin kautta. Gunrock korjaa ASR:n kontekstin mukaan (asr) ja luo luonnollisen kielen ymmärtämisen (NLU) (nlu) moduulin, jossa useat komponentit analysoivat käyttäjän lausumia. Dialoginhallinta (DM) (dm) käyttää NLU:n piirteitä aihekohtaisten dialogimoduulien valitsemiseen ja määrittelee yksilöllisen dialogivirran. Kukin dialogimoduuli hyödyntää useita tietopankkeja (knowledge). Tämän jälkeen luonnollisen kielen generointimoduuli (NLG) (nlg) tuottaa vastaavan vastauksen. Seuraavissa jaksoissa esitetään yleiskatsaus järjestelmästä, mutta yksityiskohtaiset tiedot järjestelmän toteutuksesta löytyvät teknisestä raportista BIBREF1.",
      "id": "task461-62387d1b11a74c28a4219f5489e831a6",
      "output": [
        "Määrittelevätkö he Gunrockin käyttämän mallin?"
      ]
    },
    {
      "input": "Sitten se valitsee osajoukon 1700 tunnin ( INLINEFORM2 1,1M instanssit) merkitsemättömästä tietokokonaisuudesta.",
      "id": "task461-09512447794340579d386efad96d0a06",
      "output": [
        "Kuinka monen datanäytteen perusteella he aloittavat ennen kuin he saavat alkuperäiset mallin merkinnät?"
      ]
    },
    {
      "input": "Äskettäin julkaistussa tietokokonaisuudessa nimeltä SCAN BIBREF2 (Simplified version of the CommAI Navigation tasks) testataan koostumuksen yleistämistä sekvenssistä sekvenssiin (seq2seq) jättämällä systemaattisesti pois harjoitusjoukosta kaikki syötteet, jotka sisältävät primitiivisen perusverbin (\"hyppää\"), ja testaamalla sekvenssejä, jotka sisältävät kyseisen verbin.",
      "id": "task461-e72eae7900c24d6cb09f0d3eb2e61386",
      "output": [
        "Miten SCAN-tietokannassa arvioidaan koostumuksen yleistämistä?"
      ]
    },
    {
      "input": "Viimeaikaisten töiden mukaisesti vertailemme kahta laajalti käytettyä tietokokonaisuutta, Penn Treebank (PTB) BIBREF28 -tietokantaa, sellaisena kuin se on laadittu BIBREF:ssä29 , ja WikiText2 (WT-2) BIBREF20 -tietokantaa.",
      "id": "task461-bd8a6688fab7448bbe5ef6e2721b7c08",
      "output": [
        "mitä tietoja he käyttivät?"
      ]
    },
    {
      "input": "Näin ollen arkkitehtuurimme perustuu Embeddings from Language Model eli ELMo BIBREF10 -malliin. Käytämme esivalmennettua ELMo-mallia, joka on saatu käyttämällä 1 Billion Word Benchmark -vertailumallia, joka sisältää noin 800 miljoonaa tokenia uutisdataa WMT 2011 BIBREF:stä24 . Tämän jälkeen kontekstualisoidut upotukset siirretään BiLSTM-malliin, jossa on 2 048 piilotettua yksikköä. Yhdistämme LSTM:n piilotetut tilat käyttämällä max-pooling-menetelmää, joka alustavissa kokeiluissamme tarjosi parempia tuloksia, ja syötämme tuloksena saadun vektorin 2-kerroksiseen feed-forward-verkkoon, jossa kussakin kerroksessa on 512 yksikköä. Tämän ulostulo syötetään sitten mallin viimeiselle kerrokselle, joka suorittaa binäärisen luokittelun.",
      "id": "task461-8aa25b2e7fc243dcafd1ee454e089c34",
      "output": [
        "Minkä tyyppisessä mallissa ELMo-esityksiä käytetään?"
      ]
    },
    {
      "input": "Kuten kohdassa SECREF15 selitetään, Doc2VecC:ssä käyttöön otettu korruptoituminen toimii datasta riippuvana regularisaationa, joka tukahduttaa usein esiintyvien mutta epäinformatiivisten sanojen upotukset. Sitä vastoin Doc2VecC onnistuu hillitsemään harjoitusjoukossa usein esiintyvien mutta epäinformatiivisten sanojen, kuten symbolien ja stop-sanojen, edustusta.",
      "id": "task461-c5b1cc8314b146aa86549f654a54bb76",
      "output": [
        "Miten he määrittelevät, mitkä sanat ovat informatiivisia?"
      ]
    },
    {
      "input": "Tässä jaksossa vertailemme empiirisesti automaattista differentiointia (AD, Cladiin perustuva toteutuksemme) ja numeerista differentiointia (ND, joka perustuu äärellinen differenssi -menetelmään) ROOTissa. Osoitamme, että AD voi parantaa huomattavasti derivaatan arvioinnin tarkkuutta ja suorituskykyä ND:hen verrattuna.",
      "id": "task461-335682df8e12483aa08248a95f9b2da4",
      "output": [
        "Miten automaattisen derivoinnin oikeellisuus todistetaan?"
      ]
    },
    {
      "input": "Käytimme joukon globaaleja verkkoindikaattoreita, joiden avulla voimme koodata jokaisen verkkokerroksen ominaisuustuplilla. Tämän jälkeen yksinkertaisesti yhdistimme tuplat toisiinsa, jotta jokainen monikerroksinen verkko voidaan esittää yhdellä ominaisuusvektorilla. Käytimme seuraavia verkon globaaleja ominaisuuksia: Strongly Connected Components (SCC): suunnatun graafin Strongly Connected Component on maksimaalinen (ali)graafi, jossa jokaiselle kärkiparille $u,v$ on polku kumpaankin suuntaan ($u\\rightarrow v$, $v\\rightarrow u$).Suurimman vahvasti kytkeytyneen komponentin koko (LSCC): tietyn graafin suurimman vahvasti kytkeytyneen komponentin solmujen lukumäärä.Heikosti kytkeytyneiden komponenttien lukumäärä (WCC): suunnatun graafin heikosti kytkeytynyt komponentti on maksimaalinen (osa)graafi, jossa jokaiselle kärkiparille $(u, v)$ on polku $u \\ vasenoikeaoikeaoikeaoikeaoikeaoikea v$, ottamatta huomioon reunojen suuntaa.Suurimman heikosti kytketyn komponentin koko (LWCC): tietyn graafin suurimman heikosti kytketyn komponentin solmujen lukumäärä.Suurimman heikosti kytketyn komponentin halkaisija (DWCC): suurin etäisyys (lyhimmän polun pituus) kahden solmun välillä graafin suurimmassa heikosti kytketyssä komponentissa (suuntaamattomassa versiossa).Keskimääräinen klusterointikerroin (Average Clustering Coefficient, CC): graafin kaikkien solmujen paikallisten klusterointikertoimien keskiarvo; solmun paikallinen klusterointikerroin ilmaisee, kuinka lähellä sen naapurit ovat täydellistä graafia (tai klikkiä). K-ydinluku (KC): Graafin K-ydin BIBREF13 on maksimaalinen osa-graafi, joka sisältää solmuja, joiden sisäinen aste on vähintään $k$; K-ydinluku on $k$:n suurin arvo (suunnatuissa graafeissa otetaan huomioon kokonaisaste).Tiheys (d): suunnattujen graafien tiheys on $d=\\frac{|E|}{|V||V-1|}$, jossa $|E|$ on reunojen lukumäärä ja $|N|$ on graafin kärkien lukumäärä; tiheys on 0, jos graafissa ei ole reunoja, ja 1, jos graafi on täydellinen.Suurimman heikosti kytketyn komponentin (SV) rakenteellinen viraliteetti: Tämä mitta määritellään BIBREF14:ssä kaskadipuun kaikkien solmuparien väliseksi keskimääräiseksi etäisyydeksi tai vastaavasti solmujen keskimääräiseksi syvyydeksi keskiarvona kaikista solmuista, jotka vuorostaan toimivat juurina; jos $|V| > 1$ kärkipistettä, $SV=\\frac{1}{|V||V-1|}\\sum _i\\sum _j d_{ij}$, jossa $d_{ij}$ tarkoittaa lyhimmän polun pituutta solmupisteiden $i$ ja $j$ välillä. Tämä vastaa sitä, että lasketaan graafin Wiener-indeksi BIBREF29 ja kerrotaan se kertoimella $\\frac{1}{|V||V-1|}$. Meidän tapauksessamme laskimme sen suurimman heikosti kytkeytyneen komponentin suuntaamattomalle vastaavalle graafille ja asetimme sen arvoksi 0 aina kun $V=1$.",
      "id": "task461-f59508e7e7a14d789811ddd1bee5fb47",
      "output": [
        "Mitkä ovat ne globaalin verkon piirteet, jotka määrittävät jakamisprosessin eri osatekijöitä?"
      ]
    },
    {
      "input": "SVM: Määritellään 3 ominaisuusjoukkoa, jotka kuvaavat kutakin kysymystä. Ensimmäinen on pelkkä sanasäkkipiirteiden joukko kysymyksen osalta (SVM-BOW), toinen on kysymyksen sanasäkkipiirteet sekä kysymyksen pituus sanoina (SVM-BOW + LEN), ja viimeiseksi poimimme kysymyksen sanasäkkipiirteet, kysymyksen pituuden sanoina sekä part-of-speech-tunnisteet kysymykselle (SVM-BOW + LEN + POS). Näin saadaan 200, 201 ja 228 ulottuvuuden vektorit, jotka annetaan SVM:lle, jossa on lineaarinen ydin. Ei vastausta -perustilanne (NA) : Useimpiin saamiimme kysymyksiin on vaikea vastata oikeudellisesti järkevällä tavalla tietosuojaselosteessa olevien tietojen perusteella. Määritämme yksinkertaisen perustason, jonka avulla voimme arvioida, miten vaikuttaisi, jos jokainen kysymys määritettäisiin vastaamattomaksi. Sanojen lukumäärän perustaso: Jotta voisimme arvioida, miten yksinkertaisen leksikaalisen yhteensovittamisen käyttäminen kysymyksiin vastaamiseen vaikuttaa, etsimme kutakin kysymystä varten parhaat ehdokkaat politiikan lauseiksi käyttämällä sanojen lukumäärän perustasoa BIBREF53, joka laskee niiden kysymyksen sanojen lukumäärän, jotka esiintyvät myös lauseessa. Otamme mukaan 2, 3 ja 5 parasta ehdokasta perusviitekehyksenä. Ihmisen suorituskyky: Valitsemme jokaisen kommentoijan antaman vertailuvastauksen ja laskemme F1-arvon suhteessa jäljelle jääviin viitteisiin, kuten kohdassa 4.2.1 on kuvattu. Kutakin vertailuvastausta käsitellään ennusteena, ja jäljelle jääviä n-1 vastausta käsitellään kultaisena vertailuna. Kaikkien referenssivastausten suurimman F1-arvon keskiarvo lasketaan ihmisen perustasona.",
      "id": "task461-5fe0cb3437854660b2b534a11936487b",
      "output": [
        "Testattiinko muita lähtötasoja, jotta niitä voitaisiin verrata neuraaliseen lähtötasoon?"
      ]
    },
    {
      "input": "On syytä mainita, että kerätyissä teksteissä on paljon erityyppisiä virheitä: ortografisia ja syntaktisia virheitä, koodinvaihdettuja sanoja (eli sanoja, jotka eivät ole vaaditulla kielellä), vitsejä jne. Alkuperäisiä kirjoitettuja lauseita on siis käsitelty \"puhtaampien\" versioiden tuottamiseksi, jotta aineisto olisi käyttökelpoinen joihinkin tutkimustarkoituksiin (esim. kielimallien kouluttamiseen, piirteiden poimimiseen taitojen arviointia varten jne...).",
      "id": "task461-e4659840378540679429ddeadf65838d",
      "output": [
        "Ovatko kaikki lausumat epäkieliopillisia?"
      ]
    },
    {
      "input": "Menetelmä ::: Se saa kysymyksen $q$ ja $K$ kohtaa $\\mathcal {P} = \\lbrace p_1, p_2 ... p_K\\rbrace $ ehdokkaiden joukosta ja tuottaa ketjun valituista kohdista. Menetelmä ::: Ehdollisen valinnan lisäksi ehdotamme lisäksi, että MatchLSTM-arkkitehtuurilla toteutettu yhteistyöhön perustuva Reasoner-malli (ks. liite SECREF6) ennustaa linkittävän kokonaisuuden valituista kohdista, jotta voidaan lieventää etävalvontasignaalin $\\mathcal {C}$ kohinaa.",
      "id": "task461-c70adbe8c8b14e8fb2aaa47d222744fe",
      "output": [
        "Mitkä ovat ehdotetun ratkaisun kaksi malliarkkitehtuuria?"
      ]
    },
    {
      "input": "Ehdotamme laajennettua keskikontekstia, uutta kontekstiedustusta CNN:lle relaatioiden luokittelua varten. Kontekstit jaetaan kahteen relaatioargumenttiin perustuvaan kolmeen erilliseen alueeseen: vasempaan kontekstiin, keskimmäiseen kontekstiin ja oikeaan kontekstiin.  Näin ollen ehdotamme kahden kontekstin käyttöä: (1) vasemman kontekstin, vasemman entiteetin ja keskimmäisen kontekstin yhdistelmä ja (2) keskimmäisen kontekstin, oikean entiteetin ja oikean kontekstin yhdistelmä. Nämä kaksi kontekstia käsitellään kahdella itsenäisellä konvoluutio- ja maksimipoolauskerroksella. Yhdistämisen jälkeen tulokset ketjutetaan lauseen esityksen muodostamiseksi.",
      "id": "task461-ccb24ad4737643b898718fd47916586f",
      "output": [
        "Miten he saavat uuden kontekstin edustuksen?"
      ]
    },
    {
      "input": "Samoin kuin BIBREF5 , ensimmäisessä aliverkossa pinyin-sekvenssi ennustetaan videosta. Toisin kuin BIBREF5 , joka ennustaa pinyin-hahmoja videosta, CSSMCM:ssä pinyin otetaan kokonaisuutena, joka tunnetaan myös tavuina. Kuten tiedämme, mandariinikiina on tavuihin perustuva kieli, ja tavut ovat niiden looginen ääntämisyksikkö.",
      "id": "task461-3271d7f9d1c346c9a33469cd59af4395",
      "output": [
        "Mitä syntaktista rakennetta käytetään sävyjen mallintamiseen?"
      ]
    },
    {
      "input": "Oikeudenmukaisten järjestelmien luomiseksi on siis otettava huomioon yhteiskunnan edustusongelmat, jotka on tarkoitus sisällyttää tietoihin.",
      "id": "task461-ebe467dc4fea4af7b8ab1cfd60b6c344",
      "output": [
        "Mikä on NLP:n sukupuoleen perustuvan ennakkoluulon tutkimisen tavoite erityisesti uutislähetysten alalla ja uutisankkurin roolissa?"
      ]
    },
    {
      "input": "Järjestelmä koostuu seuraavista osista: (i) paikallisista, pinnallisista piirteistä, jotka perustuvat pääasiassa ortografisiin, sananmuoto- ja n-grammiominaisuuksiin sekä niiden yhteyteen; ja ii) kolmenlaisista yksinkertaisista klusterointipiirteistä, jotka perustuvat unigrammaattiseen yhteensovittamiseen: i) Brown BIBREF32 -klustereista, joissa käytetään polun 4., 8., 12. ja 20. solmua; ii) Clark BIBREF33 -klustereista ja iii) Word2vec BIBREF34 -klustereista, jotka perustuvat K-menetelmään, jota sovelletaan poimittuihin sanavektoreihin skipgrammialgoritmia käyttäen.",
      "id": "task461-f2bea0a66bbb4efcab117484971cb537",
      "output": [
        "Mitä matalia paikallisia piirteitä poimitaan?"
      ]
    },
    {
      "input": "Arvioimme tietokokonaisuuttamme käyttämällä perinteisiä ja syväoppimismenetelmiä. Yksinkertaisin mallimme on lineaarinen SVM, joka on koulutettu sanojen unigrammeilla. SVM:t ovat tuottaneet huipputuloksia monissa tekstiluokittelutehtävissä BIBREF13 . Koulutamme myös kaksisuuntaisen pitkän lyhytaikaisen muistin (BiLSTM) mallin, jonka sovelsimme sentimentSystem,rasooli2018crossin sentimenttianalyysijärjestelmästä ja muutimme sen sijaan ennustamaan loukkaavia leimoja. Se koostuu (1) syötteen upotuskerroksesta, (2) kaksisuuntaisesta LSTM-kerroksesta, (3) syötteen piirteiden keskimääräisen pooling-kerroksesta. LSTM:n ja keskiarvopoolauskerroksen ketjutus johdetaan tiheän kerroksen läpi ja ulostulo johdetaan softmax-funktion läpi. Asetimme kaksi tulokanavaa tulon upotuskerroksille: valmiiksi koulutetut FastText- upotukset BIBREF14 sekä päivitettävät upotukset, jotka malli oppii koulutuksen aikana. Lopuksi sovellamme myös BIBREF15 -arkkitehtuuriin perustuvaa konvoluutiohermoverkkomallia (Convolutional Neural Network, CNN), jossa käytetään samoja monikanavaisia syötteitä kuin edellä mainitussa BiLSTM:ssä.",
      "id": "task461-549581afe7fc4b9bba5c68960f00594d",
      "output": [
        "Mitä malleja kokeessa käytetään?"
      ]
    },
    {
      "input": "Mukautimme BERTNLU:n ConvLab-2:sta.  Toteutimme sääntöpohjaisen mallin (RuleDST) ja mukautimme TRADE:n (Transferable Dialogue State Generator) BIBREF19:stä tähän kokeeseen.  Mukautimme ConvLab-2:sta valvotusti koulutetun vaniljakäytännön (SL-politiikka). ",
      "id": "task461-57ec57dd34014e93b7bdc31eac3a5e1b",
      "output": [
        "Mitkä ovat vertailumallit?"
      ]
    },
    {
      "input": "Erityisesti kootaan CommonCrawl-tietokannasta ne asiakirjat, joissa on eniten päällekkäisiä n-grammeja kysymysten kanssa. Nimeämme tämän tietokokonaisuuden STORIES, koska suurin osa sen sisältämistä asiakirjoista on tarinan muotoisia ja sisältää pitkän ketjun yhtenäisiä tapahtumia. Kuva 5 - vasemmalla ja keskellä osoittaa, että STORIES tuottaa aina korkeimman tarkkuuden molemmilla syötteen käsittelytavoilla.",
      "id": "task461-6146af55a4614d5f87ffa9aebe9dc417",
      "output": [
        "Mikä niiden koulutusaloista parantaa suorituskykyä eniten?"
      ]
    },
    {
      "input": "Ironian luokittelija: Toteutamme CNN-luokittimen, joka on koulutettu ironia-aineistollamme. Ironian aiheluokittelija: Toteutamme ensin yksikerroksisen LSTM-verkon, joka luokittelee aineistossamme olevat ironiset lauseet positiiviseen ja negatiiviseen ironiaan. Tunteiden luokittelija ei-ironiaa varten: Samoin kuin ironian tunteiden luokittelijan koulutusprosessi, toteutamme ensin yksikerroksisen LSTM-verkon, joka on koulutettu tavallisten twiittaajien tunteiden analysointia varten laaditulla tietokannalla, jotta ei-ironiset lauseet voidaan luokitella positiivisiin ja negatiivisiin ei-ironisiin lauseisiin. Tässä jaksossa kuvaamme joitakin lisäkokeita ironisten lauseiden muuntamisesta ei-ironisiksi lauseiksi.",
      "id": "task461-9df14ee97751463da454118e86547f9e",
      "output": [
        "Mitä kokeita tehdään?"
      ]
    },
    {
      "input": "Aineisto sisältää yhteensä 353 keskustelua 40 puhujalta (11 sairaanhoitajalta, 16 potilaalta ja 13 hoitajalta), jotka ovat antaneet suostumuksensa anonymisoitujen tietojen käyttöön tutkimuksessa. Jaksossa SECREF16 muodostamme mallit ja ilmaisupoolit kielellisen analyysin avulla, jota seuraa manuaalinen verifiointi.",
      "id": "task461-cbc6322e229343fe8ec5308021b06a29",
      "output": [
        "Kuinka suuri on niiden luoma tietokokonaisuus?"
      ]
    },
    {
      "input": "Kymmenkertainen ristiinvalidointi tällä asetuksella antoi noin 71 %:n tarkkuuden token-tasolla. ",
      "id": "task461-87f2ecdb725a411792642f164ee853d0",
      "output": [
        "Ilmoitetaanko artikkelissa automaattisen käännösmallin käännöstarkkuus tunisian ja arabian sanojen välillä?"
      ]
    },
    {
      "input": "Koestusmenetelmät ja mallinnus ::: : Tehtävän määrittely ja mallintaminen ::: Synteettisiä tietokokonaisuuksia luotaessa on tärkeää varmistaa, että systemaattiset vääristymät tai annotaatio-artefaktit BIBREF41 eivät päädy tuloksena syntyviin koettimiin ja että kohdetietokokonaisuudet ovat riittävän haastavia (tai hyviä, BIBREF42:n merkityksessä). Tämän testaamiseksi käytämme useita MCQA:n perusmalleja, jotka esiteltiin ensimmäisen kerran BIBREF0:ssa ja jotka perustuvat BIBREF43:ssa NLI:lle käytettyihin LSTM-pohjaisiin malleihin, sekä erilaisia näihin malleihin perustuvia osittaissyöttöisiä perusmalleja.",
      "id": "task461-10aa6ca8cda74678b8d5dcf8fdb94562",
      "output": [
        "Miten he valvovat merkintöjen keinotekoisuutta?"
      ]
    },
    {
      "input": "Kuten sen nimestä käy ilmi, Recurrent Deep Stacking Network pinoaa ja yhdistää edellisten kehysten tuotokset nykyisen kehyksen tulo-ominaisuuksiin.",
      "id": "task461-09b486558e294ed690b9423691909ebd",
      "output": [
        "Mitä rekursiivinen syvä pinoamisverkko tekee?"
      ]
    },
    {
      "input": "Kysymysten luontimalli antaa kullekin vastausehdokkaalle pistemäärän mittaamalla kysymyksen ja luodun kysymyksen semanttista vastaavuutta vastausehdokkaan semantiikan perusteella. ",
      "id": "task461-f989d62ea9cb4bf1b2a29015497207f8",
      "output": [
        "Missä käytetään kysymyksenmuodostusmallia?"
      ]
    },
    {
      "input": "ASR-järjestelmä ylläpitää sisäisesti runsaasti hypoteesiavaruutta puheverkkojen tai sekaannusverkkojen (cnets) muodossa.",
      "id": "task461-d20e3e89c0484ae89ad3f312dce8ebf4",
      "output": [
        "Mikä on sanasekaannusverkko?"
      ]
    },
    {
      "input": "Tässä työssä arvioimme kolmea julkisesti saatavilla olevaa valmista ydinviittausten erottelujärjestelmää, jotka edustavat kolmea erilaista koneoppimisparadigmaa: sääntöpohjaisia järjestelmiä, ominaisuuksiin perustuvia tilastollisia järjestelmiä ja neuraalisia järjestelmiä. Arvioimme esimerkkejä kustakin kolmesta ydinviittausjärjestelmäarkkitehtuurista, jotka on kuvattu kohdassa \"Coreference Systems\": BIBREF5-sieve-järjestelmä sääntöpohjaisesta paradigmasta (jäljempänä RULE), BIBREF6 tilastollisesta paradigmasta (STAT) ja BIBREF11-syvä vahvistusjärjestelmä neuraalisesta paradigmasta (NEURAL).",
      "id": "task461-874af8fcd10c47e78fd9fc0c72bb1570",
      "output": [
        "Mitä coreference resolution -järjestelmiä testataan?"
      ]
    },
    {
      "input": "Tarkastelemme myös seuraavia peruslinjoja. BOW-Tags edustaa sijainnit sanasäkkiedustuksen avulla käyttäen samaa tunnisteiden painotusta kuin upotusmallissa. BOW-KL(Tags) käyttää samaa esitystä, mutta termien valinnan jälkeen, käyttäen samaa KL-pohjaista menetelmää kuin upotusmalli. BOW-All yhdistää sanasäkkiedustuksen ja strukturoitua tietoa, joka on koodattu BIBREF:ssä7 ehdotetulla tavalla. GloVe käyttää alkuperäisen GloVe-mallin tavoitetta sijaintivektoreiden oppimiseen, eli tämä muunnos eroaa EGEL-Tagsista siten, että INLINEFORM1:n sijasta käytämme INLINEFORM4:llä mitattua INLINEFORM2-tunnisteen INLINEFORM2 samanaikaisten esiintymien lukumäärää sijainnin INLINEFORM3 lähellä.",
      "id": "task461-02ee092615704c2fa3e63d19fd8cdd03",
      "output": [
        "Mitkä ovat nykyiset lähestymistavat?"
      ]
    },
    {
      "input": "Lisäksi raportoimme sentimenttitarkkuuden (Senti ACC), joka mittaa, onko tulostettu lause sama sentimenttipolariteetti kuin syöttölause, joka perustuu standardoituihin sentimenttiluokittelijoihimme. Sisällön säilyttämisen suorituskyvyn arvioimiseksi lasketaan BLEU-pistemäärä BIBREF25 syöttölauseiden ja tulostuslauseiden välillä. Eri mallien kokonaissuorituskyvyn arvioimiseksi ilmoitamme myös sentimenttitarkkuuden ja BLEU-pisteiden geometrisen keskiarvon (G2) ja harmonisen keskiarvon (H2). Ironiatarkkuus ilmoitetaan vain ihmisen tekemän arvioinnin tuloksissa, koska ihmisen on tarkempi arvioida ironian laatua, koska se on hyvin monimutkainen.",
      "id": "task461-392dccaa71524a9fbcbb720181e73393",
      "output": [
        "Kuka arvioi ironian tarkkuutta, tunteiden säilymistä ja sisällön säilymistä?"
      ]
    },
    {
      "input": "Syylliset asiakirjat valittiin siten, että ne sisälsivät vain yhden täsmällisen unigrammin esiintymän: `caused', `causing' tai `causes'.",
      "id": "task461-9a4da1b9d99c4685a7a3588e01c48874",
      "output": [
        "Mitkä ovat \"syy-seuraussuhdelausuntojen\" valintakriteerit?",
        "Miten he poimivat tekstistä kausaliteetin?"
      ]
    },
    {
      "input": "Ratkaisemme tämän jännitteen kouluttamalla datan esittämiseksi vektoriavaruusmalleja, joissa jokainen suuren korpuksen sana esitetään vektorina (upotettuna) korkea-ulotteisessa avaruudessa. Tuloksena syntyvän vektoriavaruuden geometria kuvaa monia sanojen välisiä semanttisia suhteita.  Ratkaisemme tämän jännitteen kouluttamalla vektoriavaruusmalleja aineiston esittämiseksi, jossa jokainen yksittäinen sana suuressa korpuksessa esitetään vektorina (upotuksena) korkea-ulotteisessa avaruudessa. Tuloksena syntyvän vektoriavaruuden geometria kuvaa monia sanojen välisiä semanttisia suhteita. ",
      "id": "task461-52816c39ee744ae89ae37585995431a5",
      "output": [
        "Mallintavatko ne semantiikkaa "
      ]
    },
    {
      "input": "Verrattuna ulkoisten mallien käyttämiseen luottamuksen mallintamiseen ehdotetun menetelmän etuna on se, että perusmalli ei muutu: binäärinen luokitteluhäviö tarjoaa vain lisävalvontaa. Valvotuissa avoimissa IE-järjestelmissä väitteen luottamuspistemäärä lasketaan tyypillisesti mallin BIBREF3 , BIBREF5 antaman uuttamiskelpoisuuden perusteella. Seuraamme Stanovsky:2016:OIE2016:ssa kuvattuja arviointimittareita: tarkkuus-uudelleenvalintakäyrän alapuolella oleva pinta-ala (Area under the precision-recall curve, AUC) ja F1-pistemäärä.",
      "id": "task461-9ae67d5f135a4a2393b5c50c8f6d72fa",
      "output": [
        "Miten tämä vertautuu perinteisiin kalibrointimenetelmiin, kuten Platt Scalingiin?"
      ]
    },
    {
      "input": "Lopulta saamme tasapainoisen testitietokannan, jossa kullakin termi-merkitysparilla on noin 15 näytettä testausta varten (keskimäärin kullakin parilla on 14,56 näytettä ja näytteiden mediaani on 15), ja vertailu harjoitustietokantaan on esitetty kuvassa KUVA 11. Koska testitietokannan kerääminen on vaikeaa, päätimme kerätä vain satunnaisesti valitut 30 termiä. ",
      "id": "task461-b664e87e44154ee4b6074ae8cb95f3f3",
      "output": [
        "Kuinka suuri on testauksessa käytettävä tietokokonaisuus?"
      ]
    },
    {
      "input": "Depechemood on leksikoniin perustuva tunteiden tunnistusmenetelmä, joka on kerätty joukkorekisteröidyistä uutisista BIBREF24. Tutkijat käyttivät noin 23,5 000 asiakirjaa, joissa oli keskimäärin 500 sanaa asiakirjaa kohti, ja pyysivät koehenkilöitä ilmoittamaan tunteistaan kunkin artikkelin lukemisen jälkeen. Sen jälkeen he kertoivat asiakirja-tunne-matriisin ja sana-asiakirja-matriisin saadakseen näille sanoille tunne-sana-matriisin. ",
      "id": "task461-3d24a0cbbb2e488ba137d8d71e7b17a8",
      "output": [
        "Miten id Depechemood koulutettu?"
      ]
    },
    {
      "input": "Rakennamme syötteenä rinnakkaisen yksikielisen korpuksen kääntämällä sekakielisen sekvenssin Google NMT:n avulla englannin ( INLINEFORM0 ) ja mandariinin ( INLINEFORM1 ) sekvensseiksi.",
      "id": "task461-40d96aafab2e4a36b992324e32022eb5",
      "output": [
        "Mitä rinnakkaista korpusta he käyttivät?"
      ]
    },
    {
      "input": "Kolmen kommentoijan, joilla ei ole tietoa siitä, mistä järjestelmästä vastaus on peräisin, on sitten arvioitava itsenäisesti voitto (vastaus$_1$ on parempi), tappio (vastaus$_2$ on parempi) ja tasapeli (ne ovat yhtä hyviä tai huonoja) ottaen huomioon neljä näkökohtaa: johdonmukaisuus, looginen johdonmukaisuus, sujuvuus ja monipuolisuus.",
      "id": "task461-1ca261d103664ece8a5b9d1c6c97245e",
      "output": [
        "Mitä inhimillisen arvioinnin mittareita käytetään?"
      ]
    },
    {
      "input": "Tunteiden havaitsemisjärjestelmien kehittämisessä ja arvioinnissa käytetään yleisesti kolmea tunteilla annotoitua tietokokonaisuutta: Affective Text -tietokokonaisuutta, Fairy Tales -tietokokonaisuutta ja ISEAR-tietokokonaisuutta. Yhteenveto on esitetty taulukossa TABREF8 , jonka alimmalla rivillä näkyy myös, mikä rooli kullakin tietokokonaisuudella on kokeiluissamme: lukuun ottamatta Affective Text -tietokannan kehitysosaa, jota käytimme mallien kehittämiseen (SECREF4 ), kaikkia kolmea tietokantaa on käytetty arvioinnissamme vertailukohtina.",
      "id": "task461-220ba4bab1e04f3a8b25763233a761fd",
      "output": [
        "Mihin olemassa oleviin vertailuarvoihin niitä verrattiin?"
      ]
    },
    {
      "input": "Vertailemme kolmea perusmenetelmää. $({1})$ SC-LSTM BIBREF3 on kanoninen malli ja vahva perusmalli, joka käyttää ylimääräistä dialogin tekovektoria ja lukuporttia ohjaamaan lausuman tuottamista. $({2})$ GPT-2 BIBREF6:ta käytetään suoraan hienosäätöön aluespesifisten merkintöjen perusteella ilman esiharjoittelua laajamittaisella (dialogi teko, vastaus) -parien korpuksella. $({3})$ HDSA BIBREF7 on huippuluokan malli MultiWOZ:ssa. Se hyödyntää dialogin tekorakenteita, jotta siirto olisi mahdollista monialueen ympäristössä, ja osoittaa SC-LSTM:ää parempaa suorituskykyä.",
      "id": "task461-f1e8596165014d69b63b81c8619cc182",
      "output": [
        "Mihin nykyisiin menetelmiin SC-GPT:tä verrataan?"
      ]
    },
    {
      "input": "Taulukossa TABREF16 esitetään BLSTMP- ja VGG-mallia käyttävän naiivin monikielisen lähestymistavan tunnistussuorituskyky BLSTMP:llä koulutettua yksikielistä mallia vastaan. Tulokset osoittavat selvästi, että parempi arkkitehtuuri, kuten VGG-BLSTM, auttaa parantamaan monikielistä suorituskykyä. Käytimme merkkitason RNNLM:ää, joka koulutettiin 2-kerroksisella LSTM:llä merkkisekvensseihin.",
      "id": "task461-f747bc5a1e5d44a0b99fd32b47ee50ca",
      "output": [
        "Mitä arkkitehtuureja tutkitaan seq2seq-mallin parantamiseksi?"
      ]
    },
    {
      "input": "Seuraavassa tarkastelemme eri tapoja perääntyä, kun ScRNN ennustaa UNK:n (yleinen tulos harvinaisille ja tuntemattomille sanoille): Pass-through: sanantunnistaja siirtää (mahdollisesti väärin kirjoitetun) sanan sellaisenaan.Backoff neutraaliin sanaan: Vaihtoehtoisesti, huomioiden, että kulkeminen $\\colorbox {gray!20}{\\texttt {UNK}}$ -ennustettujen sanojen läpivieminen muuttumattomana altistaa myöhemmän prosessin mallin mahdollisesti korruptoituneelle tekstille, harkitaan takaisinkytkentää neutraaliin sanaan, kuten `a', jolla on samanlainen jakauma eri luokissa. takaisinkytkentä taustamalliin: Harkitsemme myös turvautumista yleisempään sanantunnistusmalliin, joka on koulutettu suuremmalla, vähemmän erikoistuneella korpuksella, aina kun etualan sanantunnistusmalli ennustaa UNK:n. Kuvassa 1 esitetään tämä skenaario kuvallisesti.",
      "id": "task461-4554b3d8382e4c52b20037202d919b43",
      "output": [
        "Miten backoff-strategiat toimivat?"
      ]
    },
    {
      "input": " Tässä skenaariossa meillä on paritettu tietokokonaisuus, joka sisältää artikkelien ja kommenttien rinnakkaisen sisällön INLINEFORM0 , ja parittamaton tietokokonaisuus, joka sisältää asiakirjat (artikkelit tai kommentit) INLINEFORM1 . Valvottu malli koulutetaan INLINEFORM2:lla, jotta voimme oppia artikkeleiden ja kommenttien välisen vastaavuuden tai yhdistämisen. Jakamalla valvotun mallin ja valvomattoman mallin koodaajan voimme kouluttaa molemmat mallit yhteisellä tavoitefunktiolla: DISPLAYFORM0",
      "id": "task461-67f152480aa5424c9d20f7268b258d48",
      "output": [
        "Mitä paritettuja korpuksia he käyttivät toisessa kokeessa?"
      ]
    },
    {
      "input": "Englanninkielisen version osalta suoritimme sekä perusteellisen manuaalisen analyysin että automaattisen arvioinnin kolmella yleisesti käytetyllä TS-tietokannalla kahdelta eri alalta arvioidaksemme kehyksemme suorituskykyä lauseiden jakamisen osatehtävän osalta. Tulokset osoittavat, että ehdotettu lauseenjakomenetelmämme on rakenteellisen TS:n nykytilaa parempi, sillä se palauttaa hienojakoisia yksinkertaistettuja lauseita, jotka ovat kieliopillisesti hyvin täsmällisiä ja säilyttävät syötteen merkityksen. Koko arviointimenetelmä ja yksityiskohtaiset tulokset on raportoitu asiakirjassa niklaus-etal-2019-transforming. Lisäksi vertaileva analyysi RST Discourse Treebankin BIBREF6 sisältämien annotaatioiden kanssa osoittaa, että pystymme vangitsemaan jaettujen lauseiden välisen kontekstuaalisen hierarkian lähes 90 prosentin tarkkuudella ja saavuttamaan noin 70 prosentin keskimääräisen tarkkuuden lauseiden välisten retoristen suhteiden luokittelussa. Saksankielisen version arviointi on käynnissä.",
      "id": "task461-4156edd731ba446588fd0373f3447a78",
      "output": [
        "Onko malli arvioitu?"
      ]
    },
    {
      "input": "Tietojen kerääminen: Tässä vaiheessa $p$ koostuu $n$ lauseesta ja nykyinen havainto vastaa lausetta $s_k,~1 \\le k \\le n$:edellinen: hyppää kohtaan $ \\small {\\left\\lbrace \\begin{array}{ll} s_n & \\text{jos $k = 1$,}\\\\\\ s_{k-1} & \\text{muussa tapauksessa;} \\end{array}\\right.} $sext: hyppää kohtaan $ \\small {\\left\\lbrace \\begin{array}{ll} s_1 & \\text{if $k = n$,}\\\\\\ s_{k+1} & \\text{muussa tapauksessa;} \\end{array}\\right.} $Ctrl+F $<$kysely$>$: hyppää lauseeseen, joka sisältää \"kyselyn\" seuraavan esiintymän;stop: lopeta tiedonkeruuvaihe.",
      "id": "task461-5308f96c0a634eef9aec82f1c6ce1ab6",
      "output": [
        "Millaisia komentoja niiden asetukset tarjoavat tietoa etsiville malleille?"
      ]
    },
    {
      "input": "Kokeissamme käytämme samoja tietokokonaisuuksia kuin muissa teoksissa BIBREF32, BIBREF23 ja BIBREF33 sekä muita tietokokonaisuuksia, jotka olemme itse keränneet käyttämällä samankaltaista kriteeriä (kuvattu kohdassa SECREF4). Käytämme kolmekymmentä erilaista keskustelua, jotka käytiin maaliskuun 2015 ja kesäkuun 2019 välisenä aikana, puolet niistä kiistanalaisia ja puolet kiistattomia. Otimme huomioon neljällä eri kielellä käytyjä keskusteluja: Ne tapahtuivat viidellä alueella eri puolilla maailmaa: Etelä- ja Pohjois-Amerikassa, Länsi-Euroopassa, Keski- ja Etelä-Aasiassa. Tutkimme näitä keskusteluja myös ottamalla ensin 140 merkkiä ja sitten 280 merkkiä kustakin twiitistä analysoidaksemme eroa suorituskyvyssä ja laskenta-ajassa viestien pituuden suhteen.",
      "id": "task461-1ee870fb2ea84bdcb7942a5760861a4a",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Oletetaan, että meille annetaan tietty kielimalli, kuten GPT-2 BIBREF6, GROVER BIBREF8 tai CTRL BIBREF7, ja sitä luonnehditaan joko risti-entropian $H(P,Q)$ tai perpleksisyyden $\\mathrm {PPL}(P,Q)$ estimaateilla.Näemme suoraan, että Neyman-Pearsonin havaintovirhe i.i.d. merkkien tapauksessa on: ja vastaavat tulokset pätevät ergodisille havainnoille.Koska pidämme $H(P)$ vakiona, havaitsemme, että päätösongelman virheeksponentti on nimenomaan risti-entropian affiininen siirtymä. Risti-entropian tai perpleksisyyden kannalta parempien mallien tuotoksia on vaikeampi erottaa aidosta tekstistä.Näin ollen näemme, että intuitiiviset generatiivisen tekstin laadun mittarit vastaavat muodollista erottamattomuuden operatiivista mittaria, joka tulee hypoteesin testauksen raja-arvosta.",
      "id": "task461-a5cbea7bb65d4e1b8d49111a7c265e58",
      "output": [
        "Mitkä kielimallit tuottavat tekstiä, joka on helpompi luokitella aidoksi tai generoiduksi?"
      ]
    },
    {
      "input": "Tässä työssä käytämme BIBREF1:n julkaisemia tietokokonaisuuksia ja BIBREF0:n toimittamaa HEOT-tietokokonaisuutta.  Sekä HEOT- että BIBREF1-tietokannat sisältävät twiittejä, jotka on annotoitu kolmeen luokkaan: loukkaavat, loukkaavat ja ei mitään (tai hyvänlaatuiset) twiitit.",
      "id": "task461-995f1de7fdfe450ca82bebfbc9a93006",
      "output": [
        "Suorittavatko ne jotain merkintöjä?"
      ]
    },
    {
      "input": " DNN-mallin joustavuus mahdollisti monien muiden pintatason piirteiden, kuten affiksien, sanojen ja kantojen etu- ja loppumerkkien sekä sanojen esiintymisen suurissa nimettyjen yksiköiden hakemistoissa, sisällyttämisen. Kuten myöhemmin osoitamme, nämä lisäominaisuudet alensivat CEER-arvoa merkittävästi.",
      "id": "task461-6daf77f85113419b9a504ddbd2da47cc",
      "output": [
        "mitä pintatason ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Analyyttisen approksimaation sijasta AEM käyttää diskriminaattoriverkkoa erottamaan latenttien tapahtumien perusteella rekonstruoidut asiakirjat ja alkuperäiset syöttöasiakirjat toisistaan. Tämä lähinnä auttaa generaattoria rakentamaan realistisemman asiakirjan Dirichlet-jakaumasta poimitusta satunnaiskohinasta. Neuroverkkojen joustavuuden ansiosta generaattori pystyy oppimaan monimutkaisia epälineaarisia jakaumia. Ja diskriminaattorin antama valvontasignaali auttaa generaattoria vangitsemaan tapahtumiin liittyvät mallit.",
      "id": "task461-69d9270a0da04f1dba5a77847c332db5",
      "output": [
        "Miten tämä malli voittaa oletuksen, jonka mukaan kaikki asiakirjan sanat syntyvät yhdestä tapahtumasta?"
      ]
    },
    {
      "input": "Taulukosta TABREF46 käy ilmi, että Open-mallimme f1-tulos on yli 3 pistettä korkeampi kuin uusimman tekniikan tason tulos, ja RelAwe ja DepPath&RelPath ovat parhaita sekä suljetuissa että avoimissa asetuksissa.",
      "id": "task461-92aacdb77b8247339b7cab58f392956d",
      "output": [
        "Kuinka suuri on parannus vanhaan huipputason suorituskykyyn verrattuna CoNLL-2009-tietokannassa?"
      ]
    },
    {
      "input": "Aluksi kokeilimme graafipohjaista yhteisön havaitsemisalgoritmia, joka maksimoi klusterien modulaarisuuden BIBREF20 , mutta emme löytäneet yksinkertaista tapaa rajoittaa tätä menetelmää tuottamaan tietty määrä samankokoisia klustereita. Kaikkien mahdollisten klusterimääritysten luetteleminen raa'alla voimalla on hankalaa, koska hakuavaruus on suuri ( INLINEFORM0 mahdollista määritystä). Kehitämme yksinkertaisen klusterointialgoritmin, jolla tätä prosessia voidaan lähentää. Aluksi aloitamme satunnaisilla klusterijaoilla ja määrittelemme klusterin vahvuuden ryhmän sisäisen euklidisen etäisyyden ja ryhmän välisen euklidisen etäisyyden suhteelliseksi erotukseksi. Sitten ehdotamme iteratiivisesti satunnaisia jäsenyyksien vaihtoja ja hyväksymme nämä ehdotukset vain, kun klusterin vahvuus kasvaa, kunnes konvergenssi on saavutettu. Arvioidaksemme laskennallisesti johdettujen klusterien laatua Calvinon klustereihin verrattuna mittaamme klusterien puhtautta BIBREF21 : kun on annettu joukko ennustettuja klustereita INLINEFORM1 ja todellisia klustereita INLINEFORM2, jotka molemmat jakavat joukon INLINEFORM3 datapisteitä, INLINEFORM4",
      "id": "task461-efde315ad82044f3b6776d304782a0da",
      "output": [
        "Mitä klusterointimenetelmää he käyttävät kaupunkikuvausten klusterointiin?"
      ]
    },
    {
      "input": "Tässä työssä tarkastelemme monia erilaisia ominaisuuksia ja raportoimme ennustustuloksia 62 demografisesta ominaisuudesta.",
      "id": "task461-f2a7f215b16543d886135f4957ef8ae3",
      "output": [
        "Kuinka monta demografista ominaisuutta he yrittävät ennustaa?"
      ]
    },
    {
      "input": "Tämän jakson päätteeksi todettakoon, että mallimme korjaa luotettavasti kielioppi-, oikeinkirjoitus- ja sanajärjestysvirheet, kun taas leksikaalisten valintavirheiden ja syötteen tarpeettoman parafrasoinnin tulokset ovat vaihtelevampia.",
      "id": "task461-cf79ecf0d73f4f8caf84c61311e97ef9",
      "output": [
        "Mitä virhetyyppejä varten heidän mallinsa on luotettavampi?"
      ]
    },
    {
      "input": "Aiempien töiden BIBREF13, BIBREF12, BIBREF10, BIBREF17, BIBREF9 ja BIBREF7 mukaisesti valitsemme SemCor3.0-korpuksen harjoituskorpukseksi, joka on laajin manuaalisesti annotoitu korpus, johon on lisätty WSD:n WordNet-merkitys.",
      "id": "task461-223ad0c660224746a42531345c8511bd",
      "output": [
        "Kuvastaako SemCor3.0 englanninkielisiä tietoja yleisesti?"
      ]
    },
    {
      "input": "BIBREF3-perusmalli on toteutettu rekursiiviseen neuroverkkoon perustuvalla koodaaja-dekooderi-kehyksellä.",
      "id": "task461-f0d263f8639a4639a58c5d688ef96d95",
      "output": [
        "Vertailevatko ne Noraset et al. 2017:ää?"
      ]
    },
    {
      "input": "Käytetyt luokittelijat ovat tukivektorikone (SVM), logistinen regressio (Log.Reg), satunnaismetsä (RF) ja gradienttihäviö (XGB).",
      "id": "task461-ea0bf71696fe4b519cae076138cd196e",
      "output": [
        "Mitä klassisia koneoppimisalgoritmeja käytetään?"
      ]
    },
    {
      "input": "INLINEFORM4 -vastaustyyppejä kuvaamaan on määritelty viisi ominaisuutta, jotka määrittelevät tiettyjä kliinisesti merkittäviä yksityiskohtia: (1) aika, jonka potilas on kokenut oireen, (2) toiminnot, jotka laukaisevat oireen (esiintyminen tai paheneminen), (3) oireen vakavuusaste, (4) oireen esiintymistiheys ja (5) oireen sijainti. Kullekin oireelle/ominaisuudelle voidaan antaa erilaisia kielellisiä ilmaisuja, jotka määritellään entiteeteiksi. Huomaa, että jos kysyttyä oiretta tai ominaisuutta ei mainita vuoropuhelussa, perustotuuden tuloste on \"No Answer\", kuten BIBREF:ssä6 .",
      "id": "task461-328f82bffba7465ab4628ea6b6388873",
      "output": [
        "Mitä merkintöjä he luovat tietokokonaisuuteensa?"
      ]
    },
    {
      "input": "Toiseksi tekstit käyvät läpi annotaatiotyökalujen kaskadin, joka rikastuttaa niitä seuraavilla tiedoilla: morfosyntaktiset tulkinnat (tagien joukot), käyttäen Morfeusz 0.82 BIBREF25 , taggaus (todennäköisimmän tulkinnan valinta), käyttäen transformaatioon perustuvaa oppivaa taggeria, PANTERA 0.9.1 BIBREF26 ,Syntaktiset ryhmät (mahdollisesti sisäkkäiset), joilla on syntaktiset ja semanttiset päät, käyttäen sääntöpohjaista matalaa jäsentäjää Spejd 1.3.7 BIBREF27 ja puolankielistä kielioppia, mukaan lukien parannettu versio BIBREF28 :n tekemistä muutoksista, joka mahdollistaa nimellisten syntaktisten ryhmien lemmatisoinnin,Nimetyt entiteetit, käyttäen kahta saatavilla olevaa työkalua: NERF 0.1 BIBREF29 ja Liner2 2.3 BIBREF30 .",
      "id": "task461-70b4329b2d2c4dcca0291013b19e26d3",
      "output": [
        "Miten RAFAELin tiedot on merkitty?"
      ]
    },
    {
      "input": "Tämän puutteen korjaamiseksi ROUGE:ssa ehdotamme uutta arviointimittaria: Critical Information Completeness (CIC). Muodollisesti CIC on ehdokasyhteenvedon ja viiteyhteenvedon välisten semanttisten tietojen muistaminen. CIC määritellään seuraavasti: missä $V$ tarkoittaa vertailun tiivistelmän delexikalisoitujen arvojen joukkoa, $Count_{match}(v)$ on niiden arvojen lukumäärä, jotka esiintyvät yhdessä ehdokastiivistelmässä ja vertailun tiivistelmässä, ja $m$ on arvojen lukumäärä joukossa $V$. Kokeiluissamme CIC lasketaan aritmeettisena keskiarvona kaikista dialogialueista kokonaissuorituskyvyn säilyttämiseksi.CIC on sopiva täydentävä mittari ROUGE:lle, koska se ottaa huomioon tärkeimmän tiedon kullakin dialogialueella. CIC:tä voidaan soveltaa mihin tahansa tiivistämistehtävään, jossa on ennalta määriteltyjä olennaisia kokonaisuuksia.",
      "id": "task461-48f418bbbaa14cd39b703cb4dcbd7365",
      "output": [
        "Miten uudessa arviointimittarissa otetaan huomioon kriittiset informatiiviset yksiköt?"
      ]
    },
    {
      "input": "Arvioimme huomiomuunnoksia kolmella kieliparilla. Käytämme IWSLT 2014 -korpusta De-En:n osalta, KFTT-korpusta Ja-En BIBREF19:n osalta ja WMT 2016 -datakokonaisuutta Ro-En:n osalta.",
      "id": "task461-b9bfc4bbf02f44d3af4925f8ca49e905",
      "output": [
        "Mitä kielipareja tässä tutkielmassa tarkastellaan?"
      ]
    },
    {
      "input": " EIN:n lisäksi loimme mallin (Emotion-based Model), joka käyttää vain tunnepiirteitä, ja vertasimme sitä kahteen perusmalliin. Tavoitteenamme on tutkia, voidaanko tunnepiirteiden avulla itsenäisesti havaita vääriä uutisia. Tämän mallin kaksi peruslinjaa ovat enemmistöluokan peruslinja (MC) ja satunnaisvalinnan peruslinja (RAN).",
      "id": "task461-34f67341f4b74ae8b38b8908792731ea",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Sisäinen tietokokonaisuutemme sisältää manuaalisesti annotoituja RE-tietoja 6 kielestä: kielet: englanti, saksa, espanja, italia, japani ja portugali.  ACE05-tietokanta sisältää manuaalisesti annotoitua RE-dataa kolmelle kielelle: Englannin, arabian ja kiinan kielillä. Se määrittelee 7 oliotyyppiä (henkilö, organisaatio, geopoliittinen yksikkö, sijainti, laitos, ase, ajoneuvo) ja 6 olioiden välistä relaatiotyyppiä (agentti-artefakti, yleinen yhteys, ORG-yhteys, osa-kokonaisuus, henkilö-sosiaalinen, fyysinen).",
      "id": "task461-673b6c7c7e474f6f96ae654f05c3f26a",
      "output": [
        "Mitä kieliä he kokeilevat?"
      ]
    },
    {
      "input": "Nämä 16 luokkaa perustuvat OntoNotes5 -korpukseen BIBREF7 sekä ACE (Automatic Content Extraction) English Annotation Guidelines for Entities Version 6.6 2008.06.13 BIBREF8.",
      "id": "task461-9567b20b211e4725ab5435634c161299",
      "output": [
        "Miten he määrittelivät eri luokat?"
      ]
    },
    {
      "input": "Jokaisen diagnoosin määrittelevän twiitin osalta haemme vastaavan Twitter-käyttäjän aikajanan Twitter user_timeline API-päätepisteen avulla. Tämän jälkeen poistamme kaikki muut kuin englanninkieliset twiitit (Twitter API:n koneellisesti havaitsema \"lang\"-kenttä), kaikki uudelleentwiittaukset ja twiitit, jotka sisältävät \"diagnos*\" tai \"depress*\", mutta eivät kelvollista diagnoosilausumaa. Tuloksena saatu Depressed-kohortti sisältää 1 207 henkilöä ja 1 759 644 twiittiä toukokuusta 2008 syyskuuhun 2018.",
      "id": "task461-93bd777f9b5f4c4e9df2fbdf5021a537",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Käsittelemme kestävyysongelmaa GE-FL BIBREF0 -menetelmällä, joka hyödyntää merkittyjä piirteitä ennakkotietona.",
      "id": "task461-f9a590084c9a49d4b71c4342d449774f",
      "output": [
        "Mitä taustatietoja he hyödyntävät?"
      ]
    },
    {
      "input": "Artikkelitason merkintöjen keräämiseksi hyödynsimme yrityksessä käytössä olevaa alustaa, jota markkinatutkimusryhmä on käyttänyt kerätäkseen kyselyitä eri uutiskustantajien tilaajilta. Kysely toimii seuraavasti: Käyttäjälle esitetään ensin joukko valittuja sivuja (yleensä 4 sivua ja noin 20 artikkelia) edellisen päivän painetusta lehdestä. Käyttäjä voi valita joka kerta artikkelin, jonka hän on lukenut, ja vastata siihen liittyviin kysymyksiin. Lisäsimme olemassa olevaan kyselyyn kolme kysymystä, joissa kysyttiin puolueellisuuden tasoa, puolueellisuuden napaisuutta ja sitä, mitä pro- tai anti-kokonaisuuksia artikkeli esittää. Kysyimme myös käyttäjän poliittista kantaa. Täydellinen kysely löytyy liitteistä.",
      "id": "task461-9e2a16b147d944d49923dbfee6be0b21",
      "output": [
        "Hankkivatko he kommentit joukkorahoituksella?"
      ]
    },
    {
      "input": "Mittasin ensin upotusten tehokkuutta skip-grammin koulutustehtävässä, jossa ennustettiin kontekstisanoja INLINEFORM0 annettujen tulosanojen INLINEFORM1 perusteella. Tämä tehtävä mittaa menetelmien suorituskykyä ennakoivassa kielimallinnuksessa. Käytin neljää yhteiskuntapoliittisesti, tieteellisesti ja kirjallisesti kiinnostavaa tietokokonaisuutta: NIPS-artikkeleiden korpus vuosilta 1987-1999 ( INLINEFORM2 miljoonaa), Yhdysvaltain presidentin puheet vuosina 1790-2015 ( INLINEFORM3 ), Shakespearen koko teos ( INLINEFORM4 ; tämä versio ei sisältänyt sonetteja) ja mustien oppineiden ja aktivistien W.E.B. Du Bois'n kirjoitukset, sellaisina kuin ne on digitoitu Project Gutenbergin toimesta ( INLINEFORM5 ). Kunkin aineiston osalta pidin 10 000 INLINEFORM6 -paria tasaisesti satunnaisesti, kun INLINEFORM7 , ja pyrin ennustamaan INLINEFORM8 -parin INLINEFORM9 (ja valinnaisesti INLINEFORM10 ) perusteella. Koska luokkia on suuri määrä, käsittelen tätä luokitusongelmana ja ilmoitan keskimääräisen vastavuoroisen sijoituksen. Kokeet toistettiin ja niiden keskiarvo laskettiin 5 train/test-jakojen aikana.",
      "id": "task461-901d935633c54e82aceacf5b7b849451",
      "output": [
        "Mikä on MRR?"
      ]
    },
    {
      "input": "Olemme arvioineet mallejamme F1-pistemäärän perusteella, joka on tarkkuuden ja palautuksen harmoninen keskiarvo. Olemme suorittaneet kymmenen kertaa kokeen kullekin mallille ja tarkastelleet F1-pisteiden keskiarvoa. Tulokset on esitetty taulukossa TABREF11. Kun otetaan huomioon F1-makro, mallit, jotka sisältävät monihuomiointimekanismin, ovat muita parempia, ja erityisesti malli, jossa on projisoitu kerros, on suorituskyvyltään paras. Kolmessa malliparissa neljästä malliparista Projected Layer -mallin sisältävä malli saavutti paremman suorituskyvyn, joten useimmissa tapauksissa Projected Layer -mallin lisääminen paransi suorituskykyä merkittävästi.",
      "id": "task461-4b0a93343be04beaaff2c338889872e7",
      "output": [
        "Millä muunnelmalla saadaan parhaat tulokset tässä tietokokonaisuudessa?"
      ]
    },
    {
      "input": "Laajennamme ensin aiempaa työtä ja yleisiä dialogitoimintataksonomioita, kehitämme hienojakoisen joukon asiakaspalvelun dialogitoimintoja ja suoritamme järjestelmällisen käyttäjätutkimuksen näiden toimien tunnistamiseksi 800 keskustelun aineistosta, joka on peräisin neljältä Twitterin asiakaspalvelutililtä (eli neljältä eri yritykseltä televiestintä-, elektroniikka- ja vakuutusalalta).",
      "id": "task461-8368a89fb7fc4dc09e88e3ae4f639be6",
      "output": [
        "Mitä Twitterin asiakaspalvelualoja tutkitaan?"
      ]
    },
    {
      "input": "Perusjärjestelmämme (Baseline_1850K) on otettu BIBREF-tietokannasta13 . Se koostuu DNN:stä, joka on koulutettu ennustamaan avainsanojen sisällä olevia alasanoja. DNN:n syötteenä on sekvenssi, jossa on INLINEFORM0-kehyksiä vasemmanpuoleisesta ja INLINEFORM1-kehyksiä oikeanpuoleisesta kontekstista; kummassakin on INLINEFORM2 . Topologia koostuu 1-D-konvoluutiokerroksesta, jossa on 92 suodatinta (muodoltaan 8x8 ja askelpituudeltaan 8x8), ja sen jälkeen kolmesta täysin yhdistetystä kerroksesta, joissa kussakin on 512 solmua ja oikaistu lineaarinen yksikköaktivointi. Lopullinen softmax-ulostulo ennustaa 7 osasanatavoitetta, jotka on saatu samasta pakotetusta kohdistusprosessista, joka on kuvattu SECREF5 -ohjelmassa. Tämä johtaa siihen, että perus-DNN sisältää 1,7 miljoonaa parametria ja suorittaa 1,8 miljoonaa kerrannais-kertymäoperaatiota päätelmää kohden (joka 30 ms:n äänivirran aikana). Avainsanojen havaitsemisen pistemäärä, joka on 0 ja 1 välillä, lasketaan tasoittamalla ensin posterioriset arvot keskiarvona 100 edellisen kehyksen liukuvassa ikkunassa suhteessa nykyiseen INLINEFORM3 ; pistemäärä määritellään sitten liukuvassa ikkunassa olevien tasoitettujen posterioristen arvojen suurimpana tulona, kuten alun perin ehdotettiin BIBREF:ssä6 .",
      "id": "task461-e2f230286203448b87c92c4c241a24cb",
      "output": [
        "Mitä aiempia lähestymistapoja on otettu huomioon?"
      ]
    },
    {
      "input": "BLEU: BLEU (Bilingual Evaluation Understudy) BIBREF34 -mittaria, jota käytetään yleisesti konekäännöstehtävissä. BLEU-mittaristoa voidaan käyttää dialogin luomismallien arviointiin, kuten BIBREF5, BIBREF35. BLEU-mittari on sanojen päällekkäisyysmittari, joka laskee N-grammien samanaikaisen esiintymisen vertailussa ja generoidussa vastauksessa ja soveltaa myös lyhyyssakkoa, jolla pyritään rankaisemaan liian lyhyistä vastauksista, joita ei yleensä haluta tehtäväkeskeisissä chat-roboteissa. Laskemme BLEU-pisteet käyttämällä kaikkia järjestelmiemme tuottamia vastauksia: Kierroskohtainen tarkkuus mittaa järjestelmän tuottaman vastauksen ja kohdevastauksen samankaltaisuutta. Eric ja Manning eric2017copy käyttivät tätä mittaria arvioidessaan järjestelmiään, joissa he pitivät vastausta oikeana, jos kaikki järjestelmän tuottaman vastauksen merkit vastasivat kohdevastauksen vastaavaa merkkiä. Tämä metriikka on hieman ankara, ja tulokset voivat jäädä alhaisiksi, koska kaikkien generoidun vastauksen sisältämien merkkien on oltava täsmälleen samassa kohdassa kuin kohdevastauksessa.Per-Dialogue Accuracy: Laskemme dialogikohtaisen tarkkuuden, jota käytetään BIBREF8:ssa ja BIBREF5:ssä. Tätä mittaria varten tarkastelemme kaikkia järjestelmän tuottamia vastauksia ja vertaamme niitä kohdevastauksiin. Dialogin katsotaan olevan oikea, jos kaikki järjestelmän tuottamien vastausten käänteet vastaavat kohdevastausten vastauksia. Huomaa, että tämä on hyvin tiukka metriikka, jossa kaikkien dialogin lausumien on oltava samoja kuin kohdevastausten ja oikeassa järjestyksessä. F1-Entity Score: Tehtäväsuuntautuneissa askareissa käytetyissä tietokannoissa on joukko entiteettejä, jotka edustavat käyttäjän mieltymyksiä. Esimerkiksi ravintola-alalla chatbottien yleisiä entiteettejä ovat ateria, ravintolan nimi, päivämäärä, kellonaika ja henkilömäärä (nämä ovat yleensä pakollisia entiteettejä, jotka ovat ratkaisevia varausten tekemisen kannalta, mutta voi olla myös valinnaisia entiteettejä, kuten sijainti tai luokitus). Jokaisessa kohdevastauksessa on joukko entiteettejä, joita järjestelmä kysyy tai ilmoittaa käyttäjälle. Mallimme on kyettävä erottamaan nämä erityiset kokonaisuudet ja sisällyttämään ne tuotettuun vastaukseen. Mallien arviointiin voidaan käyttää nimettyjen entiteettien tunnistamisen arviointimittareita BIBREF36. F1-pistemäärä on yleisimmin käytetty metriikka, jota käytetään nimitystunnistusmallien arvioinnissa ja joka on mallin tarkkuuden ja palautuksen harmoninen keskiarvo. Laskemme tämän mittarin mikrokeskiarvona kaikista järjestelmän tuottamista vastauksista.",
      "id": "task461-66262df70ede424e8801865d1eee783b",
      "output": [
        "Suoritetaanko inhimillinen arviointi?"
      ]
    },
    {
      "input": "Yhä useammat todisteet osoittavat, että nykyaikaiset mallit oppivat hyödyntämään tietokokonaisuuksien virheellisiä tilastollisia malleja BIBREF12, BIBREF13, BIBREF14, BIBREF15, BIBREF16, BIBREF17 sen sijaan, että ne oppisivat merkityksiä joustavasti ja yleistettävällä tavalla, kuten ihmiset tekevät. Tämän vuoksi ihmisen annotoijat - kokeneet NLP-tutkijat tai ei-asiantuntijat - voivat helposti rakentaa esimerkkejä, jotka paljastavat mallin haurauden.",
      "id": "task461-f8ff5f5489f0430e9f8beb287ab66d72",
      "output": [
        "Mitä heikkouksia ei-asiantuntija-annotoijat ovat havainneet nykyisissä uusimmissa NLI-malleissa?"
      ]
    },
    {
      "input": "Taulukoiden TABREF17 , TABREF18 ja TABREF19 tulosten analyysi osoittaa, että 12 parasta tulosta 15:stä saatiin käyttämällä uusia sanojen upotuksia. Taulukossa TABREF20 esitetyt arviointitulokset (taulukossa TABREF19 valitut parhaat upotusmallit ) osoittavat, että paras sanojen upotusten ryhmä on EC. Korkein F1-pistemäärä saatiin EC1-mallille, joka rakennettiin käyttämällä binääristä FastText Skip-gram -menetelmää, jossa hyödynnetään alasanatietoa, vektorin ulottuvuus on 300 ja negatiivinen näytteenotto on 10. Mallin kyky tarjota vektoriedustus tuntemattomille sanoille näyttää olevan tärkein.",
      "id": "task461-f3257be19915454f91b1971d52545fb5",
      "output": [
        "Mitä johtopäätöksiä näistä kokeista tehdään?"
      ]
    },
    {
      "input": "Teimme kokeita neljällä kiinalaisella NLP-tehtävällä, joihin kuuluvat tunteiden luokittelu (EC), nimettyjen entiteettien tunnistus (NER), lauseparien yhdistäminen (SPM) ja luonnollisen kielen päättely (NLI).",
      "id": "task461-a854d8f113a74f3dbd96a4279bf192e6",
      "output": [
        "Millä vertailuarvoilla he tekivät kokeita?"
      ]
    },
    {
      "input": "Esimerkkien tarkoituksena on tarjota asianmukainen konteksti. Ymmärtääksemme kontekstia paremmin analysoimme kokeellisesti esimerkin avulla tuotettuja kysymyksiä. Havaitsimme, että tukeva esimerkki voi todellakin tunnistaa merkitykselliset tunnisteet (lehmät kuvassa FIGREF3 ) kysymysten luomiseksi.Parannamme esimerkkien käyttöä käyttämällä triplettiverkkoa. Tämä verkko varmistaa, että kuvan ja kuvatekstin yhteinen upotus tukevan esimerkin osalta on lähempänä kohdekuvan kuvatekstin upotusta ja päinvastoin.",
      "id": "task461-4402a9e449a0485fa52dcb1b74e4a124",
      "output": [
        "Miten kirjoittajat määrittelevät esimerkit?"
      ]
    },
    {
      "input": "Kokeidemme avulla teemme hienovaraisia huomioita, jotka liittyvät seuraaviin seikkoihin: (a) ominaisuuksiemme suorituskykyyn, (b) siihen, miten lähestymistapamme vertautuu ihmisen kykyyn havaita juopuneita tekstejä, (c) kaikkein erottelevimpiin tyylillisiin ominaisuuksiin ja (d) virheanalyysiin, joka antaa viitteitä tulevaan työhön.",
      "id": "task461-86647c4ea64e41369a75fb859e20b1e9",
      "output": [
        "Mainitsevatko kirjoittajat tutkimuksessaan esiintyviä häiriötekijöitä?"
      ]
    },
    {
      "input": "FastTextin, GloVen ja word2vecin arviointi osoittaa, että muihin sanojen esittämisen oppimisalgoritmeihin verrattuna FastText toimii parhaiten.",
      "id": "task461-8a67b0194e4e42b8821f9304806d2a39",
      "output": [
        "Mitä käytät sanojen/sub-sanojen upotusten laskemiseen?"
      ]
    },
    {
      "input": "GENIA Corpus BIBREF3 sisältää biolääketieteellisiä tiivistelmiä PubMed-tietokannasta. Käytämme GENIAn teknisten termien annotaatioita 3.02, jotka kattavat molekyylibiologian kannalta kiinnostavien yksiköiden, kuten proteiinien, geenien ja solujen, kielelliset ilmaisut. CoNLL2003 BIBREF14 on vakiomuotoinen NER-tietokanta, joka perustuu Reutersin RCV-1-uutiskorpukseen. Se kattaa nimettyjä entiteettejä, jotka ovat tyypiltään henkilö, paikka, organisaatio ja muu.Yleisen annotaation suorituskyvyn testaamiseen käytämme CoNLL2003-testA:ta ja 50 asiakirjan jakoa GENIAsta. ",
      "id": "task461-371bf2cffbdf4dbaa5f4bf9f528c5c64",
      "output": [
        "mitä vakiotietoaineistoa käytettiin?"
      ]
    },
    {
      "input": "Artikkelin viimeisessä osassa pohditaan, miten mielipiteen dynamiikan teknisestä havainnoinnista saadut havainnot voivat olla hyödyksi käsitteellisessä mallintamisessa ja lähestymistavoissa, jotka koskevat mielipiteiden välittämistä verkossa. Näin ollen asiakirjassa tuodaan esiin ja arvioidaan kriittisesti perustavaa laatua oleva käsitteellinen harppaus koneohjatusta havainnoinnista keskustelun fasilitointiin ja siihen puuttumiseen.",
      "id": "task461-a7bd577d97994ac28449bcede1663ad0",
      "output": [
        "Raportoidaanko asiakirjassa samoihin tehtäviin sovellettujen aiempien mallien tulokset?"
      ]
    },
    {
      "input": "noudatamme Lapata2005Automaattista mitata koherenssia lauseiden samankaltaisuutena.",
      "id": "task461-d28ec9fea1f74bbc9aba0959bc3b4fd9",
      "output": [
        "Arvioivatko kirjoittajat järjestelmänsä tuotoksen johdonmukaisuutta?"
      ]
    },
    {
      "input": "Koulutustavoitteena on minimoida vastaamattoman kysymyksen $\\tilde{q}$ negatiivinen todennäköisyys, kun vastauskysymys $q$ ja sitä vastaava kohta $p$, joka sisältää vastauksen $a$ : L=-(q,q,p,a)DP(q|q,p,a;) missä $\\mathcal {D}$ on koulutuskorpus ja $\\theta $ tarkoittaa kaikkia parametreja. Sekvenssistä sekvenssiin ja parista sekvenssiin -mallit koulutetaan samalla tavoitteella.",
      "id": "task461-d005514d0acc412cbda2610d3255c0e1",
      "output": [
        "Mikä on heidän parisekvenssimallinsa koulutustavoite?"
      ]
    },
    {
      "input": "Yllä oleva pseudokoodi on riippumaton pirstoutumis- ja ympäristötoimintojen valinnasta; tehtäväkohtaiset valinnat kuvataan yksityiskohtaisemmin kunkin kokeen osalta jäljempänä. keskustelu.",
      "id": "task461-e4be43f930cf4c4fb949a699b1edd28b",
      "output": [
        "Mitä kieliä he testaavat?"
      ]
    },
    {
      "input": " Lopuksi arvioimme lähestymistapojamme 9:llä yleisesti käytetyllä tekstiluokitustietokannalla. Arvioimme menetelmiämme useilla yleisesti käytetyillä tietokokonaisuuksilla, joiden aiheet vaihtelevat tunnetiedoista, verkkosivuista, tieteestä lääketieteeseen ja terveydenhuoltoon.",
      "id": "task461-60c7d1b0773648d7b88df3ed9bc511cc",
      "output": [
        "Mitä NLP-tehtäviä he pitävät mielessä?"
      ]
    },
    {
      "input": "Perinteiset tekstistä puheeksi (TTS) -järjestelmät koostuvat monimutkaisista putkistoista BIBREF0 , joihin kuuluu usein akustisia frontendeja, kestomalli, akustinen ennustemalli ja vokooderimallit TTS-mallimme kouluttamiseen käytettiin avoimen lähdekoodin LJSpeech-tietoaineistoa. Mallimme arkkitehtuurissa käytetään RNN-pohjaista Seq2Seq-mallia melaspektrogrammin tuottamiseen tekstistä.",
      "id": "task461-7dca05c89ce84fce865f6bc65de72add",
      "output": [
        "Millä tietokokonaisuudella (tietokokonaisuuksilla) ne arvioidaan?"
      ]
    },
    {
      "input": "BIBREF11-funktiota käytetään laskemaan tekstien ja kysymysten välinen samankaltaisuuspistemäärä seuraavasti: INLINEFORM2",
      "id": "task461-fb5d159f71744ec09ffc71290b6c83a0",
      "output": [
        "Käyttävätkö he huomiota?"
      ]
    },
    {
      "input": "Aineiston kehittämiseksi poimimme 200 lausetta Irakin Kurdistanin alueella sijaitsevan peruskoulun ensimmäisestä kolmeen luokkaan kuuluvista sorani-kurdinkielisistä kirjoista. Loimme satunnaisesti 2000 lausetta poimituista lauseista.",
      "id": "task461-10a2db41f6e444caa3a9c1836bcc1017",
      "output": [
        "Mikä on tietokokonaisuuden koko?",
        "Miten aineisto kerättiin?"
      ]
    },
    {
      "input": "Stanford - Twitter Sentiment Corpus (STS Corpus): STS-korpus sisältää 1 600 000 harjoitustwiittiä, jotka on kerätty BIBREF0-tietokannasta. BIBREF0 rakensi manuaalisesti testijoukon, jossa oli 177 negatiivista ja 182 positiivista twiittiä. Stanfordin testijoukko on pieni. Sitä on kuitenkin käytetty laajalti eri arviointitehtävissä BIBREF0 BIBREF5 BIBREF13 .Sanders - Twitter Sentiment Corpus: Tämä tietokokonaisuus koostuu käsin luokitelluista twiiteistä, jotka on kerätty hakusanojen avulla: INLINEFORM0 , #google, #microsoft ja #twitter. Rakennamme tietokokonaisuuden BIBREF14 binääriluokittelua varten.Terveydenhuollon uudistus (HCR): Tämä tietokokonaisuus rakennettiin indeksoimalla twiitit, jotka sisälsivät hashtagin #hcr BIBREF15 . Tehtävänä on ennustaa positiiviset/negatiiviset twiitit BIBREF14 . Taulukossa IV esitetään tunteisiin perustuvan luokittelumallimme tulokset verrattuna muihin malleihin. Vertaamme mallimme suorituskykyä BIBREF0 BIBREF5:n lähestymistapoihin STS-korpuksella.  Sanders- ja HCR-tietokokonaisuuksien osalta vertaamme tuloksia BIBREF14-malliin, jossa käytettiin useiden perusluokittelijoiden (ENS) yhdistelmää, kuten NB, Random Forest (RF), SVM ja Logistic Regression (LR). ",
      "id": "task461-ad3f124a84fe41189ae85f8cc949f84e",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Jotta voidaan valita sopivimmat lauseet suuresta määrästä merkitsemättömiä korpuksia, ehdotamme aktiivisen oppimisen näytteenottostrategiana informaatioentropiaan ja neuroverkkoon perustuvaa pisteytysmallia, joka on Cain ja Zhaon BIBREF32 innoittama. Segmentoidun lauseen pistemäärä lasketaan seuraavasti. Ensin segmentoitu lause kartoitetaan ehdollisten sanojen upotusten sarjaksi. Tämän jälkeen pisteytysmalli ottaa sanojen upotussarjan syötteenä ja pisteyttää jokaisen yksittäisen ehdokkaan sanan kahdesta näkökulmasta: (1) mahdollisuus, että ehdokkaan sanaa itsessään voidaan pitää laillisena sanana; (2) sen linkin järkevyys, että ehdokkaan sana seuraa suoraan aiempaa segmentointihistoriaa. Kuvassa FIGREF10 havainnollistetaan koko pisteytysmalli. Merkkien upotusten yli käytetään porttiverkkoa luomaan hajautettuja esityksiä ehdokassanoista, jotka lähetetään LSTM-malliin.",
      "id": "task461-3d106fe92d7d4643b387492b29576eb3",
      "output": [
        "Miten pisteytysmalli toimii?"
      ]
    },
    {
      "input": "D2V-malli on arvioitu 80 kertaa \"huonosti relevantiksi\", kun taas pmra palautti vain 24 kertaa huonosti relevantteja asiakirjoja. ",
      "id": "task461-d0c57ef61e3b404d905726c85a7560b2",
      "output": [
        "Kuinka paremmat tulokset pmra-algoritmi kuin Doc2Vec antaa ihmisen arvioinnissa? "
      ]
    },
    {
      "input": "Ottaaksemme huomioon sanojen ja merkkien sarjat, jotka saattavat sisältää hyödyllistä tietoa, poimimme ominaisuuksiksi sanojen unigrammit, bigrammit ja trigrammit.",
      "id": "task461-e6af755d0c78493a8f2b877c0a61527c",
      "output": [
        "Mitä ominaisuuksia he käyttävät Twitter-viestien mallintamiseen?"
      ]
    },
    {
      "input": "Sen vuoksi otamme käyttöön differentiaalisen yksityisyyden suojan (DP) menetelmän, jotta ennustemallin kestävyyttä voidaan parantaa. DP on järjestelmä, jossa tietoa tietokokonaisuudesta jaetaan julkisesti kuvaamalla ryhmien malleja tietokokonaisuuden sisällä ja salaamalla samalla tietoa tietokokonaisuuteen kuuluvista yksilöistä. DP voidaan saavuttaa, jos olemme valmiita lisäämään tulokseen satunnaista kohinaa. Esimerkiksi sen sijaan, että ilmoitettaisiin vain summa, voidaan lisätä kohinaa Laplace- tai gaussin jakaumasta, jolloin saadaan tulos, joka ei ole aivan tarkka ja joka peittää minkä tahansa rivin sisällön.  Se edellyttää intuitiivisesti, että mekanismi, joka tuottaa tietoa taustalla olevasta tietokokonaisuudesta, on kestävä yhden näytteen mille tahansa muutokselle, mikä suojaa yksityisyyttä. Mekanismi ${f}$ on satunnaisfunktio, joka ottaa syötteenä tietokokonaisuuden $\\mathcal {N}$ ja tuottaa satunnaismuuttujan ${f}(\\mathcal {N})$. Jos esimerkiksi oletetaan, että $\\mathcal {N}$ on uutisartikkelitietokanta, niin funktio, joka antaa $\\mathcal {N}$:n artikkelien yhdistelmäpisteet ja normaalijakauman kohinan, on mekanismi [7].",
      "id": "task461-9c3a752cd11a43aaa52150410095569c",
      "output": [
        "Miten eriytetty yksityisyysmekanismi toimii?"
      ]
    },
    {
      "input": "Reddit-tiedot kerättiin Redditin julkisen API:n avulla, ja niihin kerättiin viimeisimmät vitsit. Aina kun scraper ajettiin, se päivitti myös aiemmin kerättyjen vitsien upvote-pisteet. Tämä tiedonkeruu tapahtui tunnin välein maalis- ja huhtikuun 2019 aikana. Koska tiedot oli jo jaettu Redditistä runko- ja iskulauseosioihin, loimme erilliset tietokokonaisuudet, jotka sisälsivät yksinomaan vitsin rungon ja yksinomaan vitsin iskulauseen. Lisäksi loimme tietokokonaisuuden, joka yhdisti vitsin rungon ja iskulauseen yhdessä.\" Joitakin esimerkkivitsejä on esitetty taulukossa 1, yllä. Vitsien pistemäärien jakauma vaihtelee rajusti, vaihdellen 0:sta 136 354 upvoteen. Huomasimme, että 0-200 upvote-arvon välillä on suuri hyppäys 200:n ja siitä ylöspäin, ja vain 6 prosenttia vitseistä sai 200-20 000 pistettä. Käytimme tätä luonnollista jakoa raja-arvona päättäessämme, mikä katsotaan hauskaksi vitsiksi, ja saimme tulokseksi 13884 ei-hauskaa vitsiä ja 2025 hauskaa vitsiä.",
      "id": "task461-f45f6ae2a3884e3b865662d04c4bc35d",
      "output": [
        "Miten he arvioivat, onko vitsi humoristinen vai ei?"
      ]
    },
    {
      "input": "(2) LEM:stä ja DPEMM:stä poiketen AEM käyttää generaattoriverkkoa tapahtumiin liittyvien mallien tallentamiseen ja pystyy louhimaan tapahtumia eri tekstilähteistä (lyhyistä ja pitkistä). Lisäksi toisin kuin LEM:ssä ja DPEMM:ssä käytetyt perinteiset päättelymenetelmät, kuten Gibbsin näytteenotto, AEM pystyy louhimaan tapahtumia tehokkaammin CUDA-kiihdytyksen ansiosta;",
      "id": "task461-49069c34e1bf431c8bc0b6498818bdf9",
      "output": [
        "Mitä vaihtoehtoa Gibbsin otannalle käytetään?"
      ]
    },
    {
      "input": "Keräsimme Streaming API:n avulla kymmeneen yhdysvaltalaiseen valtavirtauutissivustoon eli BIBREF18:ssa kuvattuihin luotettavimpiin lähteisiin liittyviä twiittejä, ja viittasimme Hoaxy API:n BIBREF16:een niiden twiittien osalta, jotka sisälsivät linkkejä yli 100 yhdysvaltalaiseen disinformaatiopisteeseen. Suodatimme pois alle 50 twiittiin liittyvät artikkelit. Tuloksena saatu tietokokonaisuus sisältää yhteensä $\\sim 1,7 miljoonaa twiittiä valtavirtauutisia varten, jotka on kerätty kolmen viikon aikana (25. helmikuuta 2019 - 18. maaliskuuta 2019) ja jotka liittyvät 6 978 uutisartikkeliin, ja $\\sim 1,6 miljoonaa twiittiä disinformaatiota varten, jotka on kerätty kolmen kuukauden aikana (1. tammikuuta 2019 - 18. maaliskuuta 2019) näiden kahden luokan tasapainon vuoksi, ja niihin sisältyy 5 775 erillistä artikkelia. Diffuusion sensurointivaikutukset BIBREF14 otettiin oikein huomioon molemmissa keruumenetelmissä. Kuvassa FIGREF4 esitetään artikkelien jakautuminen lähteen ja poliittisen puolueellisuuden mukaan molemmilla uutisalueilla. Italian skenaarion osalta keräsimme ensin twiittejä Streaming API:n avulla kolmen viikon aikana (19. huhtikuuta 2019 - 5. toukokuuta 2019) ja suodatimme ne twiitit, jotka sisälsivät URL-osoitteita, jotka viittasivat italialaisten virallisten sanomalehtien verkkosivuille, kuten BIBREF22 kuvailee; nämä vastaavat Italian sanomalehtien levikkiä tarkistavan yhdistyksen (Accertamenti Diffusione Stampa) toimittamaa luetteloa. Sen sijaan viittasimme BIBREF23:n tarjoamaan tietokokonaisuuteen saadaksemme joukon twiittejä, jotka on kerätty jatkuvasti tammikuusta 2019 lähtien käyttämällä samaa Twitter-päätepistettä ja jotka sisältävät URL-osoitteita yli 60 italialaiselle disinformaatiosivustolle. Tasapainoisten luokkien saamiseksi (5. huhtikuuta 2019 - 5. toukokuuta 2019) säilytimme tiedot, jotka oli kerätty pidemmällä ajanjaksolla valtavirtauutisten osalta. Molemmissa tapauksissa suodatimme pois artikkelit, joissa oli alle 50 twiittiä; kaiken kaikkiaan tämä tietokokonaisuus sisältää $\\sim $160k valtavirran twiittejä, jotka vastaavat 227 uutisartikkelia, ja $\\sim $100k disinformaatioviestien twiittejä, jotka vastaavat 237 uutisartikkelia. Kuvassa FIGREF5 esitetään artikkelien jakautuminen eri lähteiden mukaan molemmilla uutisalueilla. ",
      "id": "task461-cb6dc522e0db4b8398837c10b25eda16",
      "output": [
        "Mitkä kaksi uutisaluetta ovat maakohtaisesti riippumattomia?"
      ]
    },
    {
      "input": "Asiakirja $d$ voidaan määritellä termien (itsenäiset tekstikokonaisuudet asiakirjan sisällä, esimerkiksi sanat) rajallisena sarjana, nimittäin $d=(t_1,t_2,\\dots ,t_n)$.",
      "id": "task461-015cf498b1f841889d9176f5d89e4492",
      "output": [
        "Millaisia esitystapoja ne käyttävät tekstidokumenteille?"
      ]
    },
    {
      "input": "Toinen on ensimmäinen satunnainen siemen, joka on valittu luokittimelle, joka tuottaa tuloksen 0,8083. Vaikka se on parempi kuin NBSVM-ratkaisu, valitsemme parhaan validoinnin F1:n kokeilemistamme 20 siemenestä. Tämä tuotti lopullisen tuloksemme 0,8099. Paras mallimme saavutti kuvassa FIGREF27 esitetyllä validointijoukolla viisinkertaisen keskimääräisen F1-arvon 0,8254, mutta testijoukon F1-arvo oli 0,8099 - F1-arvon lasku oli 0,0155 todellista otoksen ulkopuolista dataa varten.",
      "id": "task461-f20e13f4ffee4f6c8ddbd37479b7957c",
      "output": [
        "Mitkä olivat heidän tuloksensa luokittelu- ja regressiotehtävissä?"
      ]
    },
    {
      "input": "Yahoo! Answersista poimituilla termeillä on yleensä enemmän korreloivien termien lukumäärän perusteella yhteyttä uskontoon tai etnisyyteen liittyviin ominaisuuksiin kuin Twitteristä poimituilla termeillä. Kahden tietyn ominaisuuden (hinta ja buddhalainen) osalta Twitteristä saatujen korreloivien termien määrä on kuitenkin suurempi kuin Yahoo! Answersista saatujen termien määrä. ",
      "id": "task461-9b87358d97084dbc8229a8c5c91c9b4b",
      "output": [
        "Onko Twitterissä demografisten ominaisuuksien ja vastausten välillä enemmän korrelaatioita kuin Yahoo! Answersissa?"
      ]
    },
    {
      "input": "Arvioinnissa on käytetty seuraavia eri aistiluetteloita: Watlink, automaattisesti rakennettu sanojen merkitysverkko. Se käyttää Watset[CWnolog, MCL]-menetelmällä BIBREF2 valvomattomasti indusoituja synsettejä ja semanttisia suhteita sellaisista sanakirjoista kuin Wiktionary, joihin viitataan Ustalov:17:dialogissa Joint INLINEFORM0 Exp INLINEFORM1 SWN.",
      "id": "task461-5859c44b01dc4824927c3884a093e6be",
      "output": [
        "Mitä synsettien korpusta käytetään?"
      ]
    },
    {
      "input": "Käytimme alustavissa kokeissa fastText- ja SVM BIBREF16 -menetelmää. ",
      "id": "task461-5ef1c5a7408a4c26bd510767b11a7d26",
      "output": [
        "Mitä luokittelumalleja käytettiin?"
      ]
    },
    {
      "input": "Annotoitujen twiittien perusteella halusimme selvittää, miten loukkaava kielenkäyttö jakautuu: loukkaavan kielenkäytön tyypit, genret, joissa sitä käytetään, käytetyt murteet ja tällaista kieltä käyttävien käyttäjien sukupuoli. Kuten kuviosta käy ilmi, urheilussa ja politiikassa käytetään eniten loukkaavaa kieltä, mukaan lukien mautonta ja vihapuhetta. Murteiden osalta tarkasteltiin MSA:ta ja neljää päämurretta, nimittäin egyptiläistä (EGY), leventiiniläistä (LEV), maghrebilaista (MGR) ja gulfilaista (GLF). Kuvasta FIGREF14 käy ilmi, että 71 prosenttia mauttomista twiiteistä oli kirjoitettu EGY:llä ja seuraavaksi eniten GLF:llä, jonka osuus oli 13 prosenttia mauttomista twiiteistä. MSA:ta ei käytetty yhdessäkään mauttomassa twiitissä. Mitä tulee loukkaaviin twiitteihin yleensä, EGY:tä käytettiin 36 prosentissa ja GLF:ää 35 prosentissa loukkaavista twiiteistä. Toisin kuin mauttoman kielen tapauksessa, jossa MSA:ta ei ollut lainkaan, 15 prosenttia loukkaavista twiiteistä oli itse asiassa kirjoitettu MSA:lla. Vihapuheen osalta GLF ja EGY olivat jälleen hallitsevia, ja MSA:n osuus oli 21 prosenttia twiiteistä. Tämä on yhdenmukaista muiden kielten, kuten englannin ja italian, havaintojen kanssa, joissa mauton kieli liittyi useammin puhekieleen BIBREF24, BIBREF25. Sukupuolen osalta kuvio FIGREF15 osoittaa, että valtaosa loukkaavista twiiteistä, mukaan lukien mauttomuus ja vihapuhe, oli miesten kirjoittamia. Naispuolisten Twitter-käyttäjien osuus oli 14 prosenttia loukkaavista twiiteistä yleensä ja vastaavasti 6 prosenttia mauttomista twiiteistä ja 9 prosenttia vihapuheista. Kuviossa FIGREF16 esitetään vihapuheiden tyyppien yksityiskohtainen luokittelu, jossa kolmeen tärkeimpään kuuluvat poliittisen ideologian, alkuperän ja urheiluun kuulumisen perusteella loukkaavat ryhmät. Uskonnollista vihapuhetta esiintyi vain 15 prosentissa kaikista vihapuheviestien twiiteistä.",
      "id": "task461-9bf803bfc1374aa9a14898caaf0538ca",
      "output": [
        "Miten he analysoivat, mitkä aiheet, murteet ja sukupuoli liittyvät eniten twiitteihin?"
      ]
    },
    {
      "input": "Käytimme seuraavia eri tunnemalleihin perustuvia affektiivisia resursseja: Emolex: se sisältää 14 182 sanaa, jotka liittyvät kahdeksaan ensisijaiseen tunteeseen Plutchikin mallin BIBREF10 , BIBREF11 perusteella.EmoSenticNet(EmoSN): se on rikastettu versio SenticNetistä BIBREF12 , joka sisältää 13 189 sanaa, jotka on merkitty kuuden Ekmanin perustunteen mukaan BIBREF13 , BIBREF14 .Dictionary of Affect in Language (DAL): se sisältää 8742 englanninkielistä sanaa, jotka on merkitty kolmella pisteytyksellä, jotka edustavat kolmea ulottuvuutta: Affective Norms for English Words (ANEW): sisältää 1 034 englanninkielistä sanaa BIBREF16 , jotka on luokiteltu Valence-Arousal-Dominance (VAD) -malliin perustuvilla luokituksilla BIBREF17 Linguistic Inquiry and Word Count (LIWC): tämä psykolingvistinen resurssi BIBREF18 sisältää 4 500 sanaa, jotka on jaettu 64 tunnekategoriaan, mukaan lukien positiiviset (PosEMO) ja negatiiviset (NegEMO).",
      "id": "task461-1308eded137c4c5f8d61b5dd4fdf901a",
      "output": [
        "Millaisia affektiivisia piirteitä käytetään?"
      ]
    },
    {
      "input": "Taulukossa TABREF19 ilmoitettu kokonaistarkkuuden kokonaispistemäärä koko ominaisuusjoukon avulla on 549. ",
      "id": "task461-8de3dce0bbdd48dc852a9109a8267022",
      "output": [
        "Kokeilevatko he tietokokonaisuutta?"
      ]
    },
    {
      "input": "Tässä vaiheessa laaditaan vaatimuksesta kysely ja tehdään hakukoneelle (tässä kokeilemme Googlen ja Bingin käyttöä) hakuasiakirjojen hakemista varten. Sen sijaan, että hakukoneelta kysyttäisiin koko väitettä (koska väite on keskimäärin kaksi lausetta pitkä), luodaan lyhyempi kysely BIBREF0:ssa esitettyjen opetusten mukaisesti. Asetamme sanat paremmuusjärjestykseen tf-idf:n avulla. Laskemme idf-arvot vuoden 2015 Wikipedia-dumpista ja englanninkielisestä Gigawordista. BIBREF0 ehdotti, että hyvä tapa suorittaa laadukas haku on ottaa huomioon vain väitteen verbit, substantiivit ja adjektiivit; jätämme siis väitteestä pois kaikki sanat, jotka kuuluvat muihin sananosiin. Lisäksi väittämät sisältävät usein nimettyjä entiteettejä (esim. henkilöiden, paikkojen ja organisaatioiden nimiä), joten täydennämme alkuperäistä kyselyä kaikilla väittämän tekstissä olevilla nimetyillä entiteeteillä. Käytämme IBM:n AlchemyAPI:tä nimettyjen entiteettien tunnistamiseen. Lopulta luomme 5-10 merkin kyselyitä, jotka suoritamme hakukoneella. Sen jälkeen keräämme hakutulosten pätkät ja URL-osoitteet ja jätämme väliin kaikki tulokset, jotka viittaavat epäluotettavaksi katsottuun verkkotunnukseen.",
      "id": "task461-0caea4e40b54447091adc62be8ca2397",
      "output": [
        "Miten mahdollisesti merkitykselliset tekstikatkelmat tunnistetaan?"
      ]
    },
    {
      "input": "Toinen näistä kaavioista saatu oivallus on, että satunnainen yhteenvetomalli johti yli 50 prosentin tuloksiin kaikissa mittareissa, ja ilman dokumenttitietoisia ominaisuuksia malli saavuttaa vain pienen parannuksen satunnaiseen yhteenvetomalliin verrattuna.",
      "id": "task461-1d306c4a75d4487d926c2f46ad115465",
      "output": [
        "Onko uusi lähestymistapa testattu verrattuna uusimpaan tekniikkaan?"
      ]
    },
    {
      "input": "Tämä malli koostuu kahdesta identtisestä RNN-kooderista, joilla ei ole yhteisiä parametreja, sekä tavallisesta RNN-dekooderista. Kutakin kohdelausetta varten käytetään kahta versiota lähdelauseesta: peräkkäistä (vakioversiota) ja linearisoitua jäsennystä (leksikalisoitua tai leksikalisoimatonta).",
      "id": "task461-b42a1188efd44d9297142d1637f1affe",
      "output": [
        "Minkälaisia koodaajia käytetään jäsennellyssä lähdelauseessa?"
      ]
    },
    {
      "input": "Aineistomme koostuu kahdesta aineistosta, joita käytetään automaattisen puheentunnistusjärjestelmän harjoitteluun ja arviointiin. Neljä suurta arviointikampanjaa on mahdollistanut laajan korpuksen luomisen ranskankielisestä lähetyspuheesta: ESTER1 BIBREF13, ESTER2 BIBREF14, ETAPE BIBREF15 ja REPERE BIBREF16.",
      "id": "task461-df437b0028e64e9fb35983cf82140a10",
      "output": [
        "Mitä korpuksia tässä asiakirjassa analysoidaan?"
      ]
    },
    {
      "input": "Lisäksi käytämme ominaisuuksina väitteen, parhaimman pistemäärän saaneen pätkän ja parhaimman pistemäärän saaneen lauseen kolmion upotuksia verkkosivulta. Laskemme nämä upotukset (i) tekstin sanojen upotusten keskiarvona ja (ii) käyttämällä LSTM-koodauksia, jotka koulutamme tehtävään osana syvää neuroverkkoa (NN). Käytämme myös tehtäväkohtaista väitteen upotusta yhdessä kaikkien edellä mainittujen sitä koskevien todisteiden kanssa, jotka tulevat NN:n viimeiseltä piilokerrokselta.",
      "id": "task461-4157efa4203646e08b6b45eff0ae6b65",
      "output": [
        "Mitä algoritmia ja sulautusulottuvuuksia käytetään tehtäväkohtaisten sulautusten muodostamiseen?"
      ]
    },
    {
      "input": "BIBREF21:ssä ja BIBREF22:ssa ehdotettu RKS-lähestymistapa kartoittaa tietovektorit avaruuteen, jossa lineaarinen erottelu on mahdollista. RKS-menetelmällä saadaan likimääräinen ydinfunktio eksplisiittisen kartoituksen avulla.",
      "id": "task461-516e22e40c7540e9bad6a7f2c2ad2414",
      "output": [
        "Mikä on Random Kitchen Sink -lähestymistapa?"
      ]
    },
    {
      "input": "BIBREF17: Lemming-malli on log-lineaarinen malli, joka suorittaa yhteisen morfologisen merkinnän ja lemmatisoinnin. ",
      "id": "task461-5db6608e98464775be5b046852d361ab",
      "output": [
        "Mitä muita kuin neurologisia perusarvoja käytettiin tehtävässä?"
      ]
    },
    {
      "input": "Tarkastelimme UD1.2-korporaatioita seuraaville 16 kielelle: Englanti, bulgaria, englanti, espanja, indonesia, italia, kroatia, norja, persia, portugali, ranska, ruotsi, portugali, ranska, saksa, sloveeni, tanska, tšekki ja ruotsi.",
      "id": "task461-926a1a47a9e849e1a74753bc4db9ba49",
      "output": [
        "mitä kieliä tutkitaan?"
      ]
    },
    {
      "input": "Yhdistämme vakiomuotoisia kielellisiä piirteitä, kuten POS (Part-Of-Speech) ja chunk tag, useisiin erityisesti klassista musiikkia varten kehitettyihin hakemistoihin sekä useisiin piirteisiin, jotka kuvaavat merkkien vasenta ja oikeaa kontekstia.",
      "id": "task461-d1daae8368144e4fbfbacd593c06b98a",
      "output": [
        "Millaisia korpuspohjaisia ominaisuuksia otetaan huomioon?"
      ]
    },
    {
      "input": "Lyhyesti sanottuna B4MSA:ssa käytetään ensin tekstimuunnoksia viesteihin, sitten muunnettu teksti esitetään vektoriavaruusmallissa (ks. SECREF13 ), ja lopuksi luokittelijana käytetään tukivektorikonetta (lineaarisella ytimellä).",
      "id": "task461-70301893c3544965813b6d00c5dbbbb5",
      "output": [
        "Mitkä ovat monikielisen kehyksen osatekijät?"
      ]
    },
    {
      "input": "Tutkimuksessamme käytimme uudelleentwiittausten lukumäärää poimimaan ne, jotka muuttuivat virukseksi otoksessamme. Tähän osajoukkoon kuuluvat twiitit (jäljempänä \"virustwiitit\") ovat erilaisia ja liittyvät eri aiheisiin. Katsomme, että twiitti sisältää valeuutisia, jos sen teksti kuuluu johonkin seuraavista Rubin et al. BIBREF7 kuvaamista kategorioista (ks. seuraavassa jaksossa yksityiskohtaiset tiedot näistä kategorioista): vakava väärennös, laajamittaiset huijaukset, nimensä mukaisesti otetut vitsit, todellisten tosiseikkojen vinoutunut raportointi ja tarinat, joissa totuus on kiistanalainen. Asiantuntijan manuaalisesti merkitsemä tietokokonaisuus BIBREF8 on julkaistu julkisesti, ja se on tutkijoiden ja asianosaisten käytettävissä.",
      "id": "task461-39646f415331403c905ce194c36618ed",
      "output": [
        "Miten he määrittelivät valeuutistwiitit?"
      ]
    },
    {
      "input": "Saavutetun parannuksen luotettava arviointi edellyttää määrällistä mittausta. Yksi tulkittavuuden mittaamiseen ehdotetuista menetelmistä on sanojen tunkeutumistesti BIBREF41 . Tämän menetelmän soveltaminen on kuitenkin kallista, koska se edellyttää useiden ihmisarvioijien arviointeja kunkin upotusulottuvuuden osalta. Tässä tutkimuksessa käytämme tulkittavuuden kvantifioimiseksi semanttiseen kategoriaan perustuvaa lähestymistapaa, joka perustuu BIBREF:ssä27 esiteltyyn menetelmä- ja kategoria-aineistoon (SEMCAT). Sovellamme erityisesti muutettua versiota BIBREF40:ssä esitetystä lähestymistavasta, jotta voimme ottaa huomioon mahdolliset alaryhmittelyt SEMCAT:n luokkien sisällä. ",
      "id": "task461-1d3c9801c6ec4953b684ed523bfe79de",
      "output": [
        "Millaisia kokeita he käyttävät tulkinnanvaraisuuden laajuuden kvantifioimiseksi?"
      ]
    },
    {
      "input": "Tästä huolimatta kaikki kirjallisuudessa esitetyt mallit perustuvat sanatason esityksiin, minkä vuoksi mallit eivät pysty helposti tallentamaan joitakin leksikaalisia ja morfosyntaktisia vihjeitä, joiden tiedetään ilmaisevan ironiaa, kuten isoja isoja kirjaimia, lainausmerkkejä ja hymiöitä sekä Twitterissä myös hymiöitä ja hashtageja.",
      "id": "task461-ba0bcd2fb99345dd9fdd8ceccb6fac6c",
      "output": [
        "Minkä morfosyntaktisten piirteiden ajatellaan osoittavan ironiaa tai sarkasmia?"
      ]
    },
    {
      "input": "Myrkyllisten kommenttien havaitsemisen vertailemiseksi Wikipedian myrkyllisiä kommentteja koskeva tietokokonaisuus (jota tutkimme tässä työssä) kerättiin ja poimittiin Wikipedian keskustelusivuilta ja esiteltiin Kaggle-kilpailussa BIBREF12, BIBREF15. ",
      "id": "task461-c85fd39a9d0342cdb8d9662d66f4170d",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Wikipedia-aineisto koostuu englanninkielisen Wikipedian artikkeleista, joille Wikipedia-yhteisö on antanut laatuluokkamerkinnät.",
      "id": "task461-b6c47a53297d44d68c9a59c9112955fb",
      "output": [
        "Mitä kieliä he käyttävät?"
      ]
    },
    {
      "input": "Ymmärtääksemme, mitä mallissa saattaa tapahtua, käytimme vain runko- ja iskulauseaineistoja selvittääksemme, mikä osa vitsistä oli huumorin kannalta tärkein. Havaitsimme, että kaikki mallit, myös ihmiset, tukeutuivat ennusteissaan enemmän vitsin punchlineen (taulukko 2). Vaikuttaa siis siltä, että vaikka vitsin molemmat osat ovat välttämättömiä, jotta se olisi humoristinen, iskulauseella on suurempi painoarvo kuin vartalolla. Oletamme, että tämä johtuu eri vitsirunkojen vaihtelusta: joidenkin vitsien kohdalla vitsin rakentamiseen tarvitaan kappaleita, kun taas toisissa vitsi on alle lauseen mittainen.",
      "id": "task461-179cc5abe834470c9baad25c9e0fcca9",
      "output": [
        "Kumpi osa vitsistä on tärkeämpi huumorissa?"
      ]
    },
    {
      "input": "Tässä menetelmässä yksinkertaisesti yhdistämme useiden eri toimialueiden korporaatiot kahdella pienellä muutoksella: a. Lisäämme toimialuetunnisteen \"<2domain>\" vastaavien korporaatioiden lähdelauseisiin. ",
      "id": "task461-1aeebd2e20964d1cb0d37af3381c911b",
      "output": [
        "Miten he käyttivät verkkotunnuksia?"
      ]
    },
    {
      "input": "Perusarvot. Vertaamme lähestymistapaamme (FacTweet) seuraaviin perusjoukkoihin:[leftmargin=4mm]LR + Bag-of-words: Tweet2vec: Yhdistämme syötteen twiitit ja käytämme sanasäkki-edustusta logistisen regression (LR) luokittelijan kanssa: Käytämme BIBREF20:ssä ehdotettua Bidirectional Gated recurrent neural network -mallia. Pidämme oletusarvoiset parametrit, jotka toimitettiin toteutuksen mukana. Twiittien esittämiseen käytämme mallin tuottamaa dekoodattua upotusta. Tämän perustason avulla pyrimme arvioimaan, voivatko twiittien hashtagit auttaa havaitsemaan ei-todennäköiset tilit.LR + All Features (twiittitaso): Poimimme jokaisesta twiitistä kaikki piirteemme ja syötämme ne LR-luokittimeen. Tässä tapauksessa emme aggregoi twiittejä ja tarkastelemme näin ollen jokaista twiittiä itsenäisesti.LR + All Features (chunk-level): Yhdistämme chunkissa olevien twiittien piirrevektorit ja syötämme ne LR-luokittimeen.FacTweet (twiittitaso): Samanlainen kuin FacTweet-lähestymistapa, mutta twiittitasolla; twiittien peräkkäistä kulkua ei hyödynnetä. Tavoitteena on tutkia twiittien peräkkäisen virtauksen merkitystä. top-$k$ vastaukset, tykkäykset tai uudelleentwiittaukset: Jotkut huhujen havaitsemiseen liittyvät lähestymistavat käyttävät vastausten, tykkäysten ja uudelleentwiittausten määrää huhujen havaitsemiseen BIBREF21. Näin ollen poimimme kustakin tilistä parhaat $k$ vastatut, tykätyt tai uudelleentwiittaamat twiitit arvioidaksemme tilien asiallisuutta. Testasimme eri $k$-arvoja, jotka vaihtelivat 10 twiitin ja kunkin tilin twiittien enimmäismäärän välillä. Kuvassa FIGREF24 esitetään makro-F1-arvot eri $k$-arvoilla. Vaikuttaa siltä, että $k=500$ vastaa parhaiten vastattujen twiittien osalta saavuttaa parhaan tuloksen. Siksi pidämme tätä perustasona.",
      "id": "task461-ae70099ff62f41afbca25bc277d6efb1",
      "output": [
        "Mihin perusarvoihin niitä verrataan?"
      ]
    },
    {
      "input": "Raportoimme kokeelliset tulokset kahdesta tehtävästä oikean luokittelun osuuden (CCR) osalta. Tunneanalyysissä meillä on kolmen luokan ongelma (positiivinen, negatiivinen ja neutraali), jossa luokat ovat toisensa poissulkevia. CCR, joka on keskiarvo twiittien joukosta, määritellään oikein ennustettujen tunnetilojen lukumääräksi suhteessa näissä twiiteissä esiintyvien perustodellisuuden mukaisten tunnetilojen lukumäärään. NER:ää varten katsomme, että kukin twiitti voi viitata enintään neljään ehdokkaaseen eli kohdejoukkoon. CCR, joka on keskiarvo twiittien joukosta, on oikein ennustettujen entiteettien (ehdokkaiden) määrä suhteessa kyseisessä joukossa olevien groundtruth-entiteettien (ehdokkaiden) määrään.",
      "id": "task461-dd4b82414d994e25921b6dcf2377e244",
      "output": [
        "Mitä toimenpiteitä käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Kasvu on havaittavissa Yhdysvaltain presidentinvaalien esivaalien päätyttyä sekä demokraattien ja republikaanien puoluekokousten aikana, eikä se vähene edes 8. marraskuuta pidettyjen Yhdysvaltain presidentinvaalien päätyttyä.",
      "id": "task461-a8b98d7b70cd4a099774debcb401200b",
      "output": [
        "Mitä muita poliittisia tapahtumia tietokanta sisältää?"
      ]
    },
    {
      "input": "Aiemmin Twitterin väärinkäytösten havaitsemista koskevassa tutkimuksessa avoimesti saatavilla olleet tietokokonaisuudet olivat kooltaan 10 000 - 35 000 BIBREF9 , BIBREF11 . Tämä määrä ei riitä syväoppimismallien merkittävän määrän parametrien kouluttamiseen. Tästä syystä näitä tietokokonaisuuksia on tutkittu pääasiassa perinteisillä koneoppimismenetelmillä. Viimeisimpänä Founta et al. founta2018large esitteli Hate and Abusive Speech on Twitter -tietokannan, joka sisältää 100 000 twiittiä ristiinvalidoitujen merkintöjen kanssa. Vaikka tällä korpuksella on merkittävän kokonsa ansiosta suuri potentiaali syvämallien kouluttamiseen, tähän mennessä ei ole olemassa perusraportteja.Tässä artikkelissa tutkitaan erilaisten oppimismallien tehokkuutta loukkaavan kielen havaitsemisessa. Vertailemme tarkkuutta käyttämällä yleisimmin tutkittuja koneoppimisen luokittelijoita sekä uusimpia neuroverkkomalleja. Luotettavat perustulokset esitetään ensimmäisenä vertailututkimuksena tällä tietokokonaisuudella. Lisäksi osoitamme erilaisten ominaisuuksien ja varianttien vaikutuksen ja kuvaamme mahdollisuutta lisäparannuksiin ensemble-mallien avulla.",
      "id": "task461-64869e32d8694abab5f51dd1bbc13b3d",
      "output": [
        "Sisältääkö tietokokonaisuus vain englanninkielisiä tietoja?"
      ]
    },
    {
      "input": "Kehittääksemme yleistettävän mallin, jossa vältetään ylisovittaminen, suoritamme ominaisuuksien valinnan käyttämällä tilastollisia testejä ja kaikkia asiaankuuluvia ensemble-oppimismalleja. Se lisää satunnaisuutta dataan luomalla sekoitettuja kopioita kaikista piirteistä (varjo-ominaisuus) ja kouluttaa sitten Random Forest -luokittimen laajennettuun dataan.",
      "id": "task461-fc1940a323604c419acf4644025b3096",
      "output": [
        "Minkä mallin avulla saavutetaan 5 prosentin parannus F1:hen masentuneiden henkilöiden tunnistamisessa Twitterissä?"
      ]
    },
    {
      "input": "Tietoaineistot: Kokeilimme neljällä vakiotietoaineistolla: WN18 ja FB15k on poimittu BIBREF5:llä Wordnet BIBREF32:sta Freebase BIBREF33:sta.",
      "id": "task461-7dcc0cf3bf6c425e8d11a05cbec70911",
      "output": [
        "Mitä tietokokonaisuuksia käytetään mallin arvioinnissa?"
      ]
    },
    {
      "input": "Käytimme BIBREF-tietokannan Reuters-8-tietokokonaisuutta ilman stop-sanoja27 , jonka tavoitteena on yhden merkin luokittelu ja joka on esikäsitelty Reuters-21578-tietokokonaisuuden muoto.",
      "id": "task461-8394b3d0cf9e40d9a633bfc9477ba41a",
      "output": [
        "Mitä tietokokonaisuutta tässä työssä on käytetty?"
      ]
    },
    {
      "input": "Tieto-ongelman ratkaisemiseksi esittelemme Taskmaster-1:n, joka koostuu 13 215 dialogista, joista 5 507 on puhuttua ja 7 708 kirjoitettua dialogia, jotka on luotu kahdella eri menettelyllä. Kukin keskustelu kuuluu johonkin kuudesta alueesta: pizzan tilaaminen, autokorjaamon ajanvarauksen luominen, kyytipalvelun järjestäminen, elokuvalipun tilaaminen, kahvijuomien tilaaminen ja ravintolavarausten tekeminen. ",
      "id": "task461-bd9dab633ca04d5a86a1da9d45fddc57",
      "output": [
        "Mitkä kuusi osa-aluetta sisältyvät tietokokonaisuuteen?"
      ]
    },
    {
      "input": "Keskitymme ensisijaisesti sanavektoriedustuksiin (word embeddings), jotka on luotu nimenomaan Twitter-tietokannan avulla. GloVe BIBREF13 on valvomaton oppimisalgoritmi sanojen vektoriedustusten saamiseksi. Integroidaan 200-dimensionaaliset GloVe-sanojen upotukset, jotka on koulutettu 2 miljardin twiitin perusteella. Edinburghin upotukset BIBREF14 saadaan kouluttamalla skip-gram-malli Edinburghin korpukseen BIBREF15 . Koska twiitit sisältävät runsaasti emojeja, on käytetty emoji-kuvauksista opittuja Emoji embeddings BIBREF16 . Kunkin twiitin upotukset saadaan laskemalla yksittäiset sanavektorit yhteen ja jakamalla ne twiitin sisältämien merkkien lukumäärällä.",
      "id": "task461-7fc7ee3c519749e08831817db0f76fb6",
      "output": [
        "mitä esivalmisteltuja sanasulkeumia käytettiin?"
      ]
    },
    {
      "input": "Tekstin esittäminen.Syvänä neuroverkkona toteutettu malli oppii vastaamaan harjoittelemalla satoja miljoonia konteksti-vastaus $(c,r)$ -pareja. Ensin, samoin kuin Henderson:2017arxiv, sekä $c$:n että $r$:n raakateksti muunnetaan unigrammiksi ja bigrammiksi. Valokuvien esittäminen: Valokuvat esitetään käyttämällä CNN-malleja (convolutional neural net), jotka on esivalmennettu ImageNet BIBREF17 -tietokannassa. Käytämme MobileNet-mallia, jonka syvyyskerroin on 1,4 ja syöttöulottuvuus on $224 \\ kertaa 224$ pikseliä, kuten BIBREF18:ssa.",
      "id": "task461-00d880a54eff4a52bffbe6108b3cdbc7",
      "output": [
        "Miltä PolyResponsen arkkitehtuuri näyttää?"
      ]
    },
    {
      "input": "Kukin annotoija merkitsi 90 referenssilauseeseen (eli harjoitusjoukkoon) sen, minkä tyylin hän uskoi lauseen olevan peräisin. Annotaattoreiden A1, A2 ja A3 tarkkuus tässä perustehtävässä oli 80 %, 88 % ja 80 %, mikä antaa odotetun ylärajan ihmisen suorittamalle arvioinnille.",
      "id": "task461-b524a7396c344ec698c1f2eb8e3678eb",
      "output": [
        "Miten he suorittavat manuaalisen arvioinnin, mitkä ovat kriteerit?"
      ]
    },
    {
      "input": "Kysymys on koodattu 1024-ulotteisella LSTM-mallilla, joka ottaa vastaan yhden hots-kuvauksen jokaisesta kysymyksen sanasta. Kuva kuvataan 4096-ulotteisella ulostulolla, joka on peräisin konvolutiohermoverkon (CNN) viimeisestä täysin kytketystä kerroksesta, VGG16 BIBREF25 . Järjestelmä suorittaa kuvan ja kysymyksen ominaisuuksien elementtiviisaasti kerrottuna sen jälkeen, kun kuvan kuvaaja on muunnettu lineaarisesti 1024 ulottuvuuteen. Arkkitehtuurin viimeinen kerros on softmax-kerros.",
      "id": "task461-e622f58a20974b8f84929490e7f1c42a",
      "output": [
        "Mitä malliarkkitehtuuria käytetään?"
      ]
    },
    {
      "input": "On kuitenkin mahdollista, että tässä mitatut tarkat tulkittavuuspisteet ovat vääristyneitä käytetyn aineiston vuoksi. On kuitenkin huomattava, että tulkinnanvaraisuuspisteiden muutokseen eri sanapeittävyyksillä saattaa vaikuttaa luokan sanojen epäideaalinen osavalinta. Vaikka sanojen etäisyyksiin kategorioiden keskuksista perustuvan sanojen otantamenetelmämme odotetaan tuottavan paremmin edustettuja kategorioita verrattuna kategoriasanojen satunnaisotantaan, kategorioiden representaatiot saattavat olla epäoptimaalisia verrattuna ihmisen suunnittelemiin kategorioihin.",
      "id": "task461-d9b89c35974a43a1ae760f05ca87f2ba",
      "output": [
        "Mitkä ovat heidän ehdottamansa tulkittavuuden kvantifiointimenetelmän heikkoudet?"
      ]
    },
    {
      "input": "Kun otetaan huomioon joukko arviointidokumentteja, joilla kullakin on tunnetusti oikea merkintä suljetusta merkintäjoukosta (jota usein kutsutaan \"kultaiseksi standardiksi\"), ja jokaiselle dokumentille ennustettu merkintä samasta joukosta, dokumenttitason tarkkuus on niiden dokumenttien osuus, jotka on merkitty oikein koko arviointikokoelmasta. Tämä on useimmin raportoitu mittari, ja se välittää saman tiedon kuin virheprosentti, joka on yksinkertaisesti niiden asiakirjojen osuus, jotka on merkitty väärin (eli INLINEFORM0 ). Tulokset esitetään yleensä kielikohtaisesti kahdella eri tavalla: (1) tarkkuus, jossa asiakirjat ryhmitellään niiden ennustetun kielen mukaan, ja (2) palautus, jossa asiakirjat ryhmitellään sen mukaan, millä kielellä ne on todellisuudessa kirjoitettu. Yleinen käytäntö on myös ilmoittaa F-pistemäärä INLINEFORM0 , joka on tarkkuuden ja palautuksen harmoninen keskiarvo.",
      "id": "task461-b3dab065bd2448c5b413f24290b51807",
      "output": [
        "mitä arviointimenetelmiä käsitellään?"
      ]
    },
    {
      "input": " Saamme aineistomme uutisjulkaisuista, viinikritiikeistä ja Redditistä, joiden suuren volyymin lisäksi voimme myös luonnehtia binomeja uusilla tavoilla ja analysoida binomijärjestelyjen eroja eri yhteisöjen välillä ja ajassa. ",
      "id": "task461-50c3788468164d5d90b23baf83398eac",
      "output": [
        "Mitä verkkotekstilähteitä käytetään binomilistojen testaamiseen?"
      ]
    },
    {
      "input": "Keräämme lausumia $\\mathbf {C}$hiinan $\\mathbf {A}$tekoäly $\\mathbf {I}$älykielisiltä $\\mathbf {S}$puhujilta (CAIS) ja annotoimme niihin slot-tagit ja intent-merkinnät. Harjoitus-, validointi- ja testijoukot on jaettu aikomusten jakautumisen mukaan, ja yksityiskohtaiset tilastotiedot on esitetty lisäaineistossa. Koska lausumat on kerätty reaalimaailman kaiutinjärjestelmistä, aikomusmerkinnät ovat osittaisia PlayMusic-vaihtoehdolle. Otamme käyttöön BIOES-merkintäjärjestelmän lähtö- ja saapumisaikoihin ATIS:ssä käytetyn BIO2:n sijasta, koska aiemmissa tutkimuksissa on tuotu esiin, että tällä järjestelmällä BIBREF30 on saavutettu merkittäviä parannuksia sekvenssien merkitsemisessä.",
      "id": "task461-be1314049bda44aba270057443016855",
      "output": [
        "Mikä on heidän keräämänsä korpuksen ala?",
        "Mikä on CAIS-tietokannan lähde?"
      ]
    },
    {
      "input": "Saadaksemme tietoa siitä, miksi hienojakoisempi bi-sense-emoji-kuviointi auttaa ymmärtämään twiittien taustalla olevia monimutkaisia tunteita, visualisoimme ATT-E-LSTM:n ja MATT-BiE-LSTM:n huomiopainot vertailun vuoksi. Rakennamme siis uuden syötteen INLINEFORM0 kullekin LSTM-yksikölle yhdistämällä alkuperäisen sanan upotuksen ja huomiovektorin yhtälössä EQREF21, jotta senti-emoji-tieto voidaan jakaa kullekin vaiheelle. Tätä mallia kutsutaan monitasoiseksi Attention-based LSTM with Bi-sense Emoji Embedding (MATT-BiE-LSTM) Attention-based LSTM with emojis: Käytämme myös sana-emoji-kasautusta emoji-sanan huomion laskemiseen yhtälön EQREF20 ja EQREF21 mukaisesti, ja ainoa ero on se, että korvaamme huomiosta johdetun sentti-emoji-kasautuksen nopean tekstin avulla valmiiksi koulutetulla sana-emoji-kasautuksella, jota kutsutaan nimellä ATT-E-LSTM. Kuvassa FIGREF27 (a) ATT-E-LSTM-malli (peruslinja) antaa suhteellisesti enemmän painoja sanoille \"ei\" ja \"paine\", kun taas MATT-BiE-LSTM kiinnittää huomiota lähinnä sanoihin \"happy\" ja \"lovely\". Erilaiset huomiojakaumat viittaavat siihen, että ehdotettu senti-emoji-kasauttaminen pystyy tunnistamaan sanoja, joilla on vahva tunne, joka liittyy läheisesti todelliseen tunteeseen, vaikka läsnä olisi sanoja, joilla on ristiriitaisia tunteita, kuten \"paine\" ja \"onnellinen\". kun taas ATT-E-LSTM pyrkii poimimaan kaikki tunnepitoiset sanat, jotka voivat aiheuttaa sekaannuksia. Senti-emoji-kasauttaminen kykenee poimimaan monimutkaisen semantiikan ja tunteiden representaatioita, jotka auttavat ohjaamaan huomioita myös silloin, kun sanan sentimentti ja emoji-tentimentti ovat hieman ristiriidassa keskenään. Kuvasta FIGREF27 (b) ja (c) voidaan havaita, että ATT-E-LSTM antaa enemmän painoja tunteen kannalta epäolennaisille sanoille kuin MATT-BiE-LSTM, kuten \"hupparit\", \"odota\" ja \"jälkeen\", mikä osoittaa, että ehdotettu malli on kestävämpi epäolennaisille sanoille ja keskittyy paremmin tärkeisiin sanoihin. Koska bi-sense-emoji-koodauksen avulla saatu senti-emoji-koodaus ja lauseen tason LSTM-koodaus tekstinsyötteessä (kuvattu kohdassa SECREF13 ), pystymme rakentamaan vankemman koodauksen, joka perustuu koko kontekstin semanttiseen ja tunnetietoon verrattuna ATT-E-LSTM:ssä käytettyyn sana-emoji-koodaukseen, joka ottaa huomioon vain sanatason tiedon.",
      "id": "task461-a80cbb0193c64a009814cf4a43280548",
      "output": [
        "Mitä todisteita huomion visualisointi antaa siitä, että se auttaa saamaan vankemman käsityksen semantiikasta ja tunteista?"
      ]
    },
    {
      "input": "Vaikka muissa NLG-tehtävissä, kuten tekstin tiivistämisessä (BIBREF24 ), kuvatekstien tuottamisessa (BIBREF25 ) ja taulukoiden tuottamisessa tekstiksi (BIBREF26 ), on otettu huomioon monia eri syötemodaliteetteja, perinteisessä QG:ssä on keskitytty lähinnä tekstimuotoisiin syötteisiin, erityisesti deklaratiivisiin lauseisiin, mikä selittyy alkuperäisillä sovellusalueilla, kuten kysymyksiin vastaamisessa ja koulutuksessa, joissa myös syötteet ovat tyypillisesti tekstimuotoisia.Viime aikoina erilaisten kysymyksenasettelusovellusten, kuten tietopohjakysymyksiin vastaamisen (KBQA, Knowledge Base Question Answering) BIBREF27 ja visuaalisten kysymysten vastaamisen (VQA, Visual Question Answering) BIBREF28 , lisääntyessä myös NQG-tutkimus on laajentanut lähteiden kirjoa sisällyttämällä tietopohjat BIBREF29 ja kuvat BIBREF10 .",
      "id": "task461-c460fdae19484bae8f315fa5b405fd10",
      "output": [
        "Mitkä ovat kaikki kysymysten tuottamiseen liittyvässä aiemmassa työssä huomioon otetut syöttömuodot?"
      ]
    },
    {
      "input": "Mallin suorituskyvyn arvioinnissa käytetään BLEU-mittaria.",
      "id": "task461-e2d5dde101224002993703ea5aab2e45",
      "output": [
        "Mitä arviointimittaria käytetään?"
      ]
    },
    {
      "input": "Arvioimme malliamme kahdella vertailutietoaineistolla BIBREF9 . Homografinen tietokokonaisuus sisältää 2 250 kontekstia, joista 1 607 sisältää sanaleikin. Heterografinen tietokokonaisuus koostuu 1 780 kontekstista, joista 1 271 sisältää sanaleikin. Huomaamme, että kummastakaan tietokokonaisuudesta ei ole annettu vakiomuotoista jakotietoa. Näin ollen käytämme 10-kertaista ristiinvalidointia. Jotta voisimme tehdä suoria vertailuja aiempiin tutkimuksiin, BIBREFin4 mukaisesti keräsimme kaikkien kymmenen kertauksen ennusteet ja laskimme lopuksi pisteet.",
      "id": "task461-2c2a6f982e404628be8610f03e5d6b1c",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Visual Dialog -tehtävässä käytetään arvioinnissa neljää mittaria. NDCG on visuaalisen dialogin tehtävän ensisijainen mittari, jossa useita samanlaisia vastauksia pidetään oikeina. Muut kolme ovat MRR, recall@k ja mean rank, joissa otetaan huomioon vain yhden vastauksen arvo.",
      "id": "task461-745f3ed75d0941388b4f25d5e0282d74",
      "output": [
        "Mitä mittareita haasteessa käytetään?"
      ]
    },
    {
      "input": "Mallimme syötteenä ovat syötetekstin $x[1], ... sanat. , x[n]$ ja kysely $q[1], ... , q[n]$ . Yhdistämme GloVe BIBREF40 -ohjelmasta valmiiksi koulutetut sanasulkeumat ja CharCNN BIBREF41 -ohjelmalla koulutetut merkkisulkeumat edustamaan syötesanoja. Syötetyn tekstin $x_1, ... , x_n$ ja kyselyn $q_1, ... , q_n$ syötetään sitten Highway-kerrokseen BIBREF42 sanojen upotusten ja merkkien upotusten kyvykkyyden parantamiseksi seuraavasti: $$$\\begin{split} g_t &= {\\rm sigmoid}(W_gx_t+b_g) \\\\\\\\ s_t &= {\\rm relu } (W_xx_t+b_x) \\\\ u_t &= g_t \\odot s_t + (1 - g_t) \\odot x_t~. \\end{split}$$ (Yht. 18) Samaa Highway-kerrosta sovelletaan $q_t$:hen ja saadaan $v_t$ . Seuraavaksi $u_t$ ja $v_t$ syötetään vastaavasti kaksisuuntaiseen BiLSTM-verkkoon (BiLSTM, Bi-Directional Long Short-Term Memory Network) BIBREF44 , jotta voidaan mallintaa sekvenssisanojen väliset ajalliset vuorovaikutukset: Sitten syötetään $\\mathbf {U}$ ja $\\mathbf {V}$ huomiovirtakerrokseen BIBREF27, jolla mallinnetaan syöttötekstin ja kyselyn välisiä vuorovaikutuksia. Siksi otamme malliimme käyttöön itsesovituskerroksen BIBREF29 seuraavasti: $$$\\begin{split} o_t &= {\\rm BiLSTM}(o_{t-1}, [h_t, c_t]) \\\\\\ s_j^t &= w^T {\\rm tanh}(W_hh_j+\\tilde{W_h}h_t)\\\\\\ \\alpha _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\\\\\ c_t &= \\Sigma _{i=1}^n\\alpha _i^th_i ~. \\end{split}$$ (yhtälö 20) Lopuksi syötetään sulautumat $\\mathbf {O} = [o_1, ... , o_n]$ osoitinverkkoon BIBREF39 vastaussekvenssin dekoodaamiseksi seuraavasti$$\\\\begin{split} p_t &= {\\rm LSTM}(p_{t-1}, c_t) \\\\\\ s_j^t &= w^T {\\rm tanh}(W_oo_j+W_pp_{t-1})\\\\ \\beta _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\\\ c_t &= \\Sigma _{i=1}^n\\beta _i^to_i~. \\end{split}$$ (Yht. 21) Näin ollen todennäköisyys tuottaa vastausjakso $\\textbf {a}$ on seuraava$$${\\rm P}(\\textbf {a}|\\mathbf {O}) = \\prod _t {\\rm P}(a^t | a^1, ... , a^{t-1}, \\mathbf {O})~.$$ (Yht. 23)",
      "id": "task461-39467cd13618494db5c87eeb30c721c6",
      "output": [
        "Mitä laadunvarmistusmalleja käytettiin?"
      ]
    },
    {
      "input": "Koska kaikkia kommentteja ei ole mahdollista kommentoida manuaalisesti, käsittelemme tätä tietokokonaisuutta poimimalla niistä viestiketjut, joihin liittyy epäiltyjä trollausyrityksiä, ja niihin annetut suorat vastaukset.  Käytössämme oli kaksi inhimillistä annotoijaa, jotka koulutettiin 200 keskustelusta otetuilla katkelmilla (eli (epäilty trollausyritys, vastaukset) -pareilla), ja he saivat keskustella havainnoistaan. Tämän koulutusvaiheen jälkeen pyysimme heitä merkitsemään itsenäisesti neljä näkökohtaa kustakin katkelmasta. ",
      "id": "task461-51b1904c6b924119add9309595e26e91",
      "output": [
        "Käyttävätkö he kommentointiin joukkoistamisalustaa?"
      ]
    },
    {
      "input": " Tässä työssä kehitämme tekniikan, jolla olemassa oleva esivalmennettu malli voidaan nopeasti siirtää englannista muille kielille energiatehokkaasti BIBREF8. Ensimmäisessä vaiheessa keskitymme rakentamaan kaksikielisen kielimallin englannin ja kohdekielen välillä. Englanninkielisestä esivalmennetusta LM-mallista lähtien opitaan kohdekielelle ominaiset parametrit (esim. sanojen upotukset) samalla kun englanninkielisen esivalmennetun LM-mallin koodauskerrokset pidetään kiinteinä. Sen jälkeen hienosäädämme sekä englannin- että kohdemallia, jotta saamme kaksikielisen LM:n. ",
      "id": "task461-a2fdd2db30b44405972afaa9539d0336",
      "output": [
        "Miten malli siirretään muihin kieliin?"
      ]
    },
    {
      "input": "Tuoreessa turkkilaisen BIBREF10-julkaisun tunneanalyysia käsittelevässä työssä he opettelevat upotuksia käyttäen turkkilaista sosiaalista mediaa. He käyttävät word2vec-algoritmia, luovat useita käsin muodostettuja, valvomattomia piirteitä, luovat asiakirjavektoreita ja syöttävät ne syötteenä tukivektorikoneisiin (SVM). Me päihitämme tämän peruslähestymistavan käyttämällä tehokkaampia sanojen upotuksia ja valvottuja käsin luotuja piirteitä.",
      "id": "task461-972bee83844a4affacfb7f1155e91c86",
      "output": [
        "Mitä perustason menetelmää käytetään?"
      ]
    },
    {
      "input": "Käytämme 300-ulotteista Glove Common Crawl Embeddings (840B Token) BIBREF11 -ohjelmaa ja hienosäädämme ne tehtävään sopiviksi.",
      "id": "task461-f43ad46491754db38042ea229500613b",
      "output": [
        "Millä datalla sulautumat on koulutettu?"
      ]
    },
    {
      "input": "Seuraavaksi vertasimme VTN-malliamme RNN-pohjaiseen seq2seq VC-malliin nimeltä ATTS2S BIBREF8. Tämä malli perustuu Tacotron-malliin BIBREF32, jossa käytetään kontekstin säilyttämishäviötä ja ohjattua huomiohäviötä harjoittelun vakauttamiseksi ja kielellisen johdonmukaisuuden säilyttämiseksi muuntamisen jälkeen. Noudatimme BIBREF8:n konfiguraatioita, mutta käytimme WORLD-piirteiden sijasta melaspektrogrammeja.",
      "id": "task461-349022d16955400494c2ea3a003a212a",
      "output": [
        "Mikä on perusmalli?"
      ]
    },
    {
      "input": "Keskitymme kolmeen pääkysymykseen, kuten siihen, miten sisällyttää affektiivista tietoa chat-robotteihin, mitä resursseja on saatavilla ja mitä voidaan käyttää EAC:n rakentamiseen ja miten EAC:n suorituskykyä voidaan arvioida.",
      "id": "task461-603e147fb25d47f7a59ed5c2dde03a87",
      "output": [
        "Mitkä ovat asiakirjassa esitetyt tutkimuskysymykset, jotka koskevat EAC-tutkimuksia?"
      ]
    },
    {
      "input": "Taulukossa TABREF14 esitetään pääkokeidemme tulokset vuosien 2016 ja 2018 testijoukoissa ranskan ja saksan osalta. Käytämme päämittarina Meteor BIBREF31 -mittaria, kuten WMT-tehtävissä BIBREF25 . Vertaamme muuntajiemme perustasoa kuvainformaatiolla rikastettuihin muuntajamalleihin sekä deliberaatiomalleihin, kuvainformaatiolla tai ilman sitä. toteamme ensinnäkin, että multimodaaliset mallimme saavuttavat muuntajaverkkojen (rajoitetut mallit) uusimman tason suorituskyvyn englannin ja saksan tietokokonaisuudessa verrattuna BIBREF30 -malliin. Toiseksi harkintamallimme johtavat merkittäviin parannuksiin tähän perustasoon verrattuna kaikissa testijoukoissa (keskimäärin INLINEFORM0 , INLINEFORM1 ).",
      "id": "task461-0065dbf08ee840498dd27544c1eeba75",
      "output": [
        "Millä tietokokonaisuudella tämä lähestymistapa saavuttaa uusimmat tulokset?"
      ]
    },
    {
      "input": "Käytämme perusmallina siamilaisneuroverkkoa, jonka on osoitettu suoriutuvan huippuluokan muutaman otoksen oppimisesta BIBREF11. Muokkaamme alkuperäistä mallia siten, että se ottaa huomioon peräkkäiset tiedot, ja jokainen kaksonen koostuu sulauttamiskerroksesta, LSTM-kerroksesta (Long-Short Term Memory) BIBREF12 ja syöttö eteenpäin -kerroksesta, jossa on ReLU-aktivoinnit (ReLU = Rectified Linear Unit).",
      "id": "task461-883b9319ba014065aa94fe2fdb495236",
      "output": [
        "Mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Ihmisten suorittamassa arvioinnissa noudatamme konekäännösjärjestelmien BIBREF23 -arvioinnissa vakiintunutta lähestymistapaa, jota BIBREF9 käyttää kysymysten luomisessa. Pyysimme kolmea työntekijää arvioimaan 300 generoitua kysymystä välillä 1 (huono) ja 5 (hyvä) kahdella erillisellä kriteerillä: käytetyn kielen sujuvuus ja kysymyksen relevanssi asiayhteysasiakirjan ja vastauksen kannalta.",
      "id": "task461-312cad912a1740e0937443fe07ed6ea6",
      "output": [
        "Mitä inhimillisen arvioinnin mittareita paperissa käytettiin?"
      ]
    },
    {
      "input": "DBpedian SPARQL-päätepistettä käytetään kyselyihin vastaamiseen ja päättelyyn.",
      "id": "task461-e3f0a8152dd6444b8d5935318516d684",
      "output": [
        "Mitä päättelymenetelmää käytetään?"
      ]
    },
    {
      "input": "Parhaiten menestyvät lähestymistavat Caravel, COAV ja NNCD ansaitsevat tarkempaa huomiota.",
      "id": "task461-dcc0f1c28f1841089a3d3283bd1b214a",
      "output": [
        "Mikä on parhaiten toimiva menetelmä?"
      ]
    },
    {
      "input": "Tässä jaksossa analysoimme enwik9-tietokannan lauseiden projektioiden ja samojen lauseiden vastaavien projektioiden välistä Hammingin etäisyyttä sen jälkeen, kun merkkitason häiriöitä on sovellettu. Kokeilemme kolmenlaisia merkkitason häiriötoimintoja BIBREF11 ja kahdenlaisia sanatason häiriötoimintoja.Häiriötutkimus ::: Merkkitason häiriötoiminnotinsert(word, n) : Valitaan satunnaisesti n merkkiä merkkisanastosta ja lisätään ne satunnaisiin paikkoihin syötettyyn sanaan. Säilytämme kuitenkin sanan ensimmäisen ja viimeisen merkin sellaisenaan. Esim. muunnos: $sample \\rightarrow samnple$.swap(word, n): Vaihdamme satunnaisesti kahden merkin paikkaa sanassa n kertaa. Kuten insert-operaatiossa, säilytämme sanan ensimmäisen ja viimeisen merkin sellaisenaan ja sovellamme swap-operaatiota vain jäljellä oleviin merkkeihin. Esim. muunnos: $sample \\rightarrow sapmle$.duplicate(word, n): Kaksinkertaistamme satunnaisesti yhden merkin sanassa n kertaa. Esim. muunnos: $sample \\rightarrow saample$.Perturbation Study ::: Character Level Perturbation Operations ::: Pudotus(lause, n): Pudotamme satunnaisesti n sanaa lauseesta. Esim. muunnos: Tämä on iso kissa. $\\rightarrow $ Tämä on kissa.duplicate(lause, n): Samanlainen kuin duplicate(word, n) edellä, toistamme satunnaisesti sanan lauseessa n kertaa. Esim. muunnos: Tämä on iso kissa. $\\rightarrow $ Tämä on iso iso kissa.swap(lause, n): Vaihdetaan satunnaisesti kahden sanan paikkaa lauseessa n kertaa. Esim. muunnos: Tämä on iso kissa. $\\rightarrow $ Tämä kissa on iso.",
      "id": "task461-1b97fe1586334a56a2bc1bef86199443",
      "output": [
        "Miten heidän häiriöalgorihminsa toimii?"
      ]
    },
    {
      "input": "Käytämme BIBREF4:n julkaisemaa julkisia talousuutisia koskevaa tietokokonaisuutta, joka on kerätty Reutersista ja Bloombergista lokakuun 2006 ja marraskuun 2013 väliseltä ajalta. Teemme kokeita Standard & Poor's 500 -osakeindeksin (S&P 500) ja sen valittujen yksittäisten osakkeiden ennustamiseksi, ja saamme indeksit ja hinnat Yahoo Financesta. Koulutus-, kehitys- ja testijoukkojen yksityiskohtaiset tilastot esitetään taulukossa TABREF8. Raportoimme lopulliset tulokset testijoukosta sen jälkeen, kun olemme käyttäneet kehitysjoukkoa joidenkin hyperparametrien virittämiseen.",
      "id": "task461-469e1b7c2b664508982ad91dbc0d063a",
      "output": [
        "Mitä tietokokonaisuutta käytetään uutisohjattujen osakkeiden liikkeiden ennustamiseen?"
      ]
    },
    {
      "input": "Monitehtävämalli on parempi kuin yhden tehtävän malli kaikilla datakokoluokilla, ja suhteellinen suorituskyky kasvaa harjoitusdatan koon pienentyessä. Kun harjoitusdataa käytetään vain 200 lauseen verran, monitehtävämallin suorituskyky on noin 60 prosenttia parempi kuin yhden tehtävän mallin sekä Airbnb- että Greyhound-sovelluksissa. OpenTable-sovelluksen suhteellinen parannus on 26 %. Tulokset vaihtelevat tehtävien välillä, mutta yhdessäkään ei ole yleistä hyötyä avoimen sanaston järjestelmästä.",
      "id": "task461-57058e94679c48f196554e34d87f1b08",
      "output": [
        "Lisääntyykö suorituskyky heidän menetelmällään?"
      ]
    },
    {
      "input": "(1) AutoJudge päihittää johdonmukaisesti ja merkittävästi kaikki vertailumallit, mukaan lukien RC-mallit ja muut neuraaliset tekstiluokitusmallit, mikä osoittaa mallimme tehokkuuden ja kestävyyden. (2) RC-mallit saavuttavat paremman suorituskyvyn kuin useimmat tekstinluokittelumallit (GRU+Attentionia lukuun ottamatta), mikä osoittaa, että lukumekanismi on parempi tapa integroida heterogeenisistä mutta toisiaan täydentävistä syötteistä saatua tietoa. (3) Verrattuna perinteisiin RC-malleihin AutoJudge saavuttaa merkittävän parannuksen, kun otetaan huomioon lisää lakiartikkeleita.",
      "id": "task461-2ba5dd27796e4cafb29000cf46fbf89e",
      "output": [
        "mitkä ovat niiden tulokset rakennetulla tietokokonaisuudella?"
      ]
    },
    {
      "input": "Sanamerkityksen induktio (WSI) voidaan nähdä WSD:n valvomattomana versiona. WSI:n tarkoituksena on klusteroida sanojen aistimuksia, eikä jokaisen klusterin tarvitse vastata ennalta määriteltyä aistimusta. Sen sijaan sanamerkitysluettelot muodostetaan automaattisesti klustereista siten, että kutakin klusteria käsitellään sanan yksittäisenä merkityksenä. Ehdotamme edistyneempää graafin rakentamismenettelyä, jossa käytetään vektorien yhteen- ja vähennysoperaatioiden tulkittavuutta sanojen sulautumisavaruudessa BIBREF6 , kun taas aiempi algoritmi perustuu vain lähimpien naapureiden luetteloon sanojen sulautumisavaruudessa. Algoritmimme keskeinen innovaatio on vektorin vähennyslaskun käyttö, jonka avulla löydetään parit, joissa on kaikkein erilaisimmat graafin solmut, ja rakennetaan graafi vain solmuista, jotka sisältyvät tällaisiin \"antisärmiöihin\".",
      "id": "task461-ca4cc0d94b214e4c8e26145c9544d062",
      "output": [
        "Onko tässä työssä kuvattu menetelmä klusterointiin perustuva menetelmä?"
      ]
    },
    {
      "input": "Yhdessä nämä käyttäjät antoivat Gunrockille keskimäärin 3,65 arvosanan (mediaani: 4,0), joka saatiin keskustelun lopussa (\"Asteikolla 1-5 tähteä, miltä tuntuisi keskustella tämän sosiaalibotin kanssa uudelleen?\").",
      "id": "task461-c0481fa846d349e9af3189e3c0fba4b0",
      "output": [
        "Keräävätkö ne Gunrockista nimenomaisia käyttäjätyytyväisyystietoja?"
      ]
    },
    {
      "input": "Varmistaaksemme olettamuksemme, että kohteen koodaus ja ortogonaalinen regularisointi auttavat lisäämään generoitujen sekvenssien monimuotoisuutta, käytämme kahta mittaria, yhtä kvantitatiivista ja toista kvalitatiivista, mittaamaan generoinnin monimuotoisuutta. Ensinnäkin laskemme yksinkertaisesti sekä INLINEFORM0:n että INLINEFORM1:n tuottamien ainutlaatuisten ennusteiden keskiarvon jaksossa SECREF36 esitetyissä kokeissa.  Tässä esimerkissä on 29 pohjatodellisuuslausetta. Kumpikaan malleista ei pysty tuottamaan kaikkia avainsanoja, mutta on selvää, että INLINEFORM0:n ennusteet alkavat kaikki sanalla \"test\", kun taas INLINEFORM1:n ennusteet ovat monipuolisia.",
      "id": "task461-7ffe43c8b7e24561ad62f831dce12c57",
      "output": [
        "Miten avainsanojen monimuotoisuutta mitataan?"
      ]
    },
    {
      "input": "Tämä arkkitehtuuri perustuu sogaard2016deepiin, mutta sitä on mukautettu kahdella tavalla: ensinnäkin lisäämme siihen valvomattoman sekvenssin merkintätehtävän (Language Modeling) ja toiseksi lisäämme hierarkiassa tehtävien väliin matalaulotteisen sulauttamiskerroksen, jonka avulla opimme tiheitä merkintätunnisteiden representaatioita.",
      "id": "task461-4a40aebe67954c3bbce07ca7b3ff7367",
      "output": [
        "Mikä on viimeisen kerroksen valvomaton tehtävä?"
      ]
    },
    {
      "input": "Ensin poimimme useita suhteita käyttämällä OpenIE-työkalupakettia (OpenIE, Open Information Extraction) BIBREF7 , ja sitten valitsemme vastauksen kannalta olennaisimman suhteen huolellisesti suunniteltujen heurististen sääntöjen avulla.",
      "id": "task461-8f5798b0478e498ba80966898823c4f3",
      "output": [
        "Miten he poimivat \"jäsennellyn vastauksen kannalta merkityksellisen suhteen\"?"
      ]
    },
    {
      "input": "Laskemme kunkin käyttäjän osalta niiden twiittien osuuden, jotka on arvioitu positiivisesti kussakin LIWC-kategoriassa. ",
      "id": "task461-ac119ea663d841ec9010662f057f7c69",
      "output": [
        "Miten LIWC on sisällytetty tähän järjestelmään?"
      ]
    },
    {
      "input": "Arvioimme ehdotettuja mallejamme kolmella yleisesti käytetyllä tietograafitietoaineistolla: WN18RR BIBREF26, FB15k-237 BIBREF18 ja YAGO3-10 BIBREF27.",
      "id": "task461-dd7efb683d834ca286a62de0fe179544",
      "output": [
        "Mitä vertailutietoaineistoja käytetään linkkien ennustamiseen?"
      ]
    },
    {
      "input": "Nämä tunnepisteet saatiin automaattisesti aiemmassa työssämme BIBREF15 esitellyn aiheen poiminta- ja tunneanalyysiputken avulla, ja ne harjoitteltiin ennalta talon sisäisellä psykiatrisella EHR-tekstillä.",
      "id": "task461-8caf72d48e2d420283fdcbf3039630f3",
      "output": [
        "Miten he poimivat aiheita?"
      ]
    },
    {
      "input": "Jotta luotujen sekvenssien laatua voitaisiin arvioida sekä tarkkuuden että palautuksen osalta, arviointimittareina käytetään BLEU- ja ROUGE (1, 2, L) -pisteitä, joissa on useita viitteitä BIBREF22 .",
      "id": "task461-1f6b9e99d0974335b748dcd83018cd99",
      "output": [
        "Mitä arviointimittareita käytetään?"
      ]
    },
    {
      "input": "PlEWi toimitti 550 755 [virhe, korjaus]-paria, joista 298 715 oli yksilöllisiä.",
      "id": "task461-ee43d04470c443bc8ffc3a692b27b072",
      "output": [
        "Miten PIEWi on kommentoitu?"
      ]
    },
    {
      "input": "Ensimmäinen malli, jota kutsutaan seuraavissa jaksoissa nimellä `LSTM (PTB)', koulutettiin Penn Treebank BIBREF12 -tietokannan lauseilla. Toinen malli, jota kutsutaan nimellä `LSTM (FTB)', koulutettiin French Treebank BIBREF13 -tietokannan lauseilla. Käytämme kahta esivalmisteltua englanninkielistä mallia: toinen on koulutettu BIBREF14:n Billion Word -vertailumallilla (nimellä `LSTM (1B)') ja toinen BIBREF3:n englanninkielisellä Wikipedialla (nimellä `LSTM (enWiki)'). Ranskan kielen osalta koulutimme suuren LSTM-kielimallin (nimellä `LSTM (frWaC)') frWaC-tietokannan BIBREF15 satunnaisella osajoukolla (noin 4 miljoonaa lausetta, 138 miljoonaa sanamerkkiä).",
      "id": "task461-af58b987c30540329cd5b9ddcb57f54f",
      "output": [
        "Mikä on käytettyjen tietokokonaisuuksien koko?"
      ]
    },
    {
      "input": "Yhdistämällä moduuliosan ja vaiheosan HAKE kartoittaa kokonaisuudet polaarikoordinaatistoon, jossa säteittäinen koordinaatti vastaa moduuliosaa ja kulmakoordinaatit vaiheosaa.",
      "id": "task461-c8c3c470921b4c65b20a952b3ae8d480",
      "output": [
        "Miten entiteetit kartoitetaan napakoordinaattijärjestelmään?"
      ]
    },
    {
      "input": "Viimeaikaiset edistysaskeleet syväoppimistekniikoissa ovat kuitenkin osoittaneet, että NER-tehtävässä voidaan hyödyntää neuroarkkitehtuureja, kuten biLSTM-verkkoja BIBREF3 , BIBREF4 . Käytämme BIBREF24:ssä ehdotettua toteutusta kolmen eri kokeen suorittamiseen.",
      "id": "task461-c9a0ec8eb3824f07b17d819471448a45",
      "output": [
        "Mitä koneoppimisalgoritmeja tutkittiin?"
      ]
    },
    {
      "input": "Käytimme Shortirin, indonesialaisen uutisaggregaattori- ja tiivistämisyrityksen, tarjoamaa aineistoa. Tietokanta sisältää noin 20 000 uutisartikkelia. Jokaisessa artikkelissa on otsikko, kategoria, lähde (esim. CNN Indonesia, Kumparan), alkuperäisen artikkelin URL-osoite ja tiivistelmä, jonka on laatinut manuaalisesti kaksi indonesian kielen äidinkielistä puhujaa.",
      "id": "task461-911ae58d1b194f5d8114016c7bd583bc",
      "output": [
        "Käyttivätkö he yhteenvetojen tekemiseen joukkoistamisalustaa?"
      ]
    },
    {
      "input": "Verrattaessa perusratkaisuihin, joissa yksi naapureista valitaan satunnaisesti tai joissa oletetaan, että alhaisimman pistemäärän omaava fakta on virheellinen, havaitaan, että virheiden havaitsemisessa saavutetaan 42 \\%$ ja 55 \\%$ tarkkuus, mikä on huomattavan suuri ero.",
      "id": "task461-45e4b8e1febc49c1a936c7ede0380cf5",
      "output": [
        "Voidaanko tätä vastakkainasettelua käyttää suoraan parantamaan mallin tarkkuutta?"
      ]
    },
    {
      "input": "Lisäksi seq2seq-perusmallissa oletetaan, että generoitujen merkkien välillä on tiukka järjestys, mutta todellisuudessa mallia ei pitäisi rangaista ankarasti siitä, että se ennustaa oikeat merkit väärässä järjestyksessä.",
      "id": "task461-861f6b4d075a4a7582d68f66621e058c",
      "output": [
        "Asettavatko ne mitään kieliopillisia rajoituksia tuotetulle tulosteelle?"
      ]
    },
    {
      "input": "Käyttäjien havaittua käyttäytymistä paremmin vastaava esitys on käsitekartta BIBREF5 , joka on merkitty graafi, jossa käsitteet esitetään solmuina ja niiden väliset suhteet reunoina (kuva KUVA 2 ).",
      "id": "task461-eb0b509c771b4217869a644c5876b241",
      "output": [
        "Miten kirjoittajat määrittelevät käsitekartan?"
      ]
    },
    {
      "input": "Toteutamme uudelleen BIBREF3:ssa ehdotetun mallin ja käytämme sitä ongelmamme lähtökohtana. Perusteena tämän mallin valinnalle perustasoksi on sen todistetusti hyvä ennustuskyky monikielisen tekstin luokittelussa.",
      "id": "task461-fd66857f4d2a49f6b77fa5a248eed877",
      "output": [
        "Mikä on heidän perusmallinsa?"
      ]
    },
    {
      "input": " Käytimme uusimpia ominaisuuksia, jotka ovat osoittautuneet hyödyllisiksi tunnistamisessa: osa niistä on kielestä riippumattomia (esim. välimerkit, positiiviset ja negatiiviset hymiöt, sitaatit, persoonapronominit, twiitin pituus, nimetyt entiteetit), kun taas osa on kielestä riippuvaisia ja perustuu erityisiin sanakirjoihin (esim. negaatio, mielipidesanakirjat, oppositiosanat).",
      "id": "task461-5c53da9a4846446f98f105e344f12068",
      "output": [
        "Mitä tekstipohjaisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Tässä luvussa esitämme neuroprojektorillemme käänteisehdon, jonka avulla voimme ratkaista optimointiongelman. Erityisesti rajoitamme neuraaliprojektoriamme kahdella vaatimuksella: (1) INLINEFORM0 ja (2) INLINEFORM1 on olemassa. ",
      "id": "task461-103b760e1ea54c418e82c3a8b2781c90",
      "output": [
        "Mikä on käänteisehto?"
      ]
    },
    {
      "input": "Jotta voitiin testata ehdotetun menetelmän kykyä tuottaa sanoja ilman valvontaa, oli tarpeen kehittää menetelmä sanojen merkityksellisyyden mittaamiseksi. Käytettiin aihepiirien mallintamista, joka perustuu oletukseen, että samasta aihepiiristä löytyvät sanat ovat merkityksellisempiä toisilleen kuin eri aihepiirien sanat BIBREF14. Koko 200 000 otsikon aineisto BIBREF11 mallinnettiin Naïve Bayes -algoritmilla BIBREF15 sanojen ja luokkien yhteisesiintymismallin luomiseksi. Tämän jälkeen löydettiin 200 tärkeintä sanaa kustakin kategoriasta ja niitä käytettiin aihepiiritaulukon SECREF12 luomiseen. Oletettiin, että kukin luokka edustaa omaa ainutlaatuista aihettaan. Relevanttien tulossanojen määrä mitattiin otsikon luokkamerkinnän funktiona, ja se on esitetty kuvassa SECREF4. Tulokset osoittavat, että ehdotetulla menetelmällä pystyttiin tunnistamaan oikein uudet sanat, jotka liittyvät syötettyyn aiheeseen, kun signaali-kohinasuhde oli 4:1.",
      "id": "task461-b3c11d534de14bbb9bde729c599392a5",
      "output": [
        "Miten ne määrittävät samankaltaisuuden ennustetun sanan ja aiheiden välillä?"
      ]
    },
    {
      "input": "Kokeilimme Glove BIBREF2- ja Twitter word2vec BIBREF3 -koodia käsiteltyjen twiittien upotusten kouluttamiseksi.",
      "id": "task461-ef7931ca32ea46738a8c35abf4895afc",
      "output": [
        "Mitä sulautumia he käyttävät?"
      ]
    },
    {
      "input": "Työhömme liittyy useita varoituksia: ensinnäkin twiitti-tunnelmat ovat harvoin binäärisiä (tätä työtä voitaisiin laajentaa moninomiaaliseen tai jatkuvaan malliin). Toiseksi, tuloksemme rajoittuvat Twitterin käyttäjiin, joiden tiedetään olevan negatiivisempia kuin Yhdysvaltain väestön BIBREF9 . Kolmanneksi emme ota huomioon jatkuvien luonnonkatastrofien kokonaisvaikutuksia ajan mittaan. Jatkossa on selvää kysyntää selvittää, voivatko sosiaaliset verkostot osoittaa ympäristöä koskevia mittareita \"ennakoivalla\" tavalla. Ilmastonmuutoksen muuttuessa yhä äärimmäisemmäksi jää nähtäväksi, millainen ennustevoima nykyisellä mallillamme on ilmastonmuutosta ja luonnonkatastrofeja koskevien mielipiteiden osalta.",
      "id": "task461-6e5f95fdd93e4090aa180f7e8f9babef",
      "output": [
        "Mainitsevatko kirjoittajat tutkimuksessaan esiintyviä häiriötekijöitä?"
      ]
    },
    {
      "input": "Syöttöasiakirjaa/yhteenvetoa, jossa voi olla järjestämättömiä lauseita, käsitellään siten, että lauseet ryhmitellään yhteen. Testataksemme lähestymistapaamme sekoitamme asiakirjan lauseiden järjestyksen, käsittelemme järjestämättömän asiakirjan ja vertaamme tulostusasiakirjan samankaltaisuutta alkuperäisen asiakirjan kanssa. Järjestämättömän asiakirjan jäsentäminen on olennainen tehtävä monissa sovelluksissa. Se on jälkivaatimus sellaisissa sovelluksissa kuin useiden asiakirjojen tekstin tiivistäminen, joissa on esitettävä yhteenveto useista asiakirjoista. Se on ennakkoedellytys sovelluksissa, kuten kysymysten vastaaminen useista asiakirjoista, joissa on esitettävä vastaus käsittelemällä useita asiakirjoja.",
      "id": "task461-57fbdea7c5e649678bb119dc5d54799a",
      "output": [
        "Mikä on järjestämätön tekstidokumentti, esiintyykö niitä reaalimaailman korpuksissa?"
      ]
    },
    {
      "input": "Vertailussa on mukana myös RNNLM BIBREF11 , joka on rekursiiviseen neuroverkkoon perustuva kielimalli.",
      "id": "task461-cc486a995d34474f80e474af778addb4",
      "output": [
        "Mihin kielimalleihin niitä verrataan?"
      ]
    },
    {
      "input": "Kun sanaa $y_t$ luodaan aika-askeleella $t$, konteksti $\\mathbf {X}$ koodataan kiinteän kokoiseksi dialogikontekstivektoriksi $\\mathbf {c}_t$ noudattamalla hierarkkista huomiorakennetta HRAN BIBREF13:ssa. Lisäksi poimimme tunteisiin liittyvän tiedon $\\mathbf {X}$:n lausunnoista ulkoisen tekstianalyysiohjelman avulla ja koodaamme sen RNN:n avulla tunnekontekstivektoriksi $\\mathbf {e}$, joka yhdistetään $\\mathbf {c}_t$:n kanssa jakauman tuottamiseksi.",
      "id": "task461-263db667b2d44662ae59e5df32731655",
      "output": [
        "Miten monikierroksinen dialogijärjestelmä oppii?"
      ]
    },
    {
      "input": "Määritellään STransE-pisteytysfunktio $\\mathcal {R}$1 seuraavasti:$ f_r(h, t) & = & \\Vert \\textbf {W}_{r,1}\\textbf {h} + \\textbf {r} - \\textbf {W}_{r,2}\\textbf {t}\\Vert _{\\ell _{1/2}} $ käyttäen joko $\\ell _1$- tai $\\ell _2$ -normia (valinta tehdään validointidatan avulla; kokeiluissamme havaitsimme, että $\\ell _1$ -normi antoi hieman parempia tuloksia).",
      "id": "task461-d8750b037d9d44dca294230d29d41db9",
      "output": [
        "Mitä pisteytysfunktiota malli käyttää kolmikoiden pisteyttämiseen?"
      ]
    },
    {
      "input": "Taulukossa TABREF14 esitetään twiittien jakautuminen maittain ennen ja jälkeen suodatusprosessin. Suuri osa näytteistä on Intiasta, koska MeToo-liike on saavuttanut huippunsa Intiassa vuoden 2018 loppupuolella. Venäjältä on hyvin vähän näytteitä, mikä johtuu todennäköisesti sisällön moderoinnista ja sosiaalisen median käyttöä koskevista säännöksistä maassa.",
      "id": "task461-b94c237118f24f069bdf4c81c3aaa68e",
      "output": [
        "Tulevatko twiitit tietyltä alueelta?"
      ]
    },
    {
      "input": "Tässä osassa käsitellään kolmea BLEU:n ja ROUGE:n merkittävää rajoitusta. Näillä mittareilla voidaan määrittää: BLEU:n ja ROUGE:n haasteet ::: Oletetaan, että meillä on viiteyhteenveto s1. Lisäämällä s1:een muutamia negaatio-termejä voidaan luoda tiivistelmä s2, joka on semanttisesti vastakkainen kuin s1, mutta jolla on silti korkea BLEU/ROUGE-pistemäärä.Challenges with BLEU and ROUGE ::: Sen lisäksi, että BLEU- ja ROUGE-pisteet eivät ole herkkiä negaatiolle, BLEU- ja ROUGE-pisteet voivat antaa alhaiset pisteet merkitykseltään vastaaville lauseille. Jos s2 on parafraasi s1:stä, merkitys on sama ;s1:n ja s2:n sanojen päällekkäisyys ei kuitenkaan välttämättä ole merkittävä.BLEU:n ja ROUGE:n haasteet ::: Kolmas BLEU:n ja ROUGE:n heikkous on se, että yksinkertaisimmissa toteutuksissaan ne eivät ole herkkiä sanojen permutaatiolle, ja ne voivat antaa hyvin korkeat pisteet käsittämättömille lauseille. Olkoon s1 \"Aamulla a näin miehen juoksevan kadulla.\" ja s2 \"Aamulla a näin juoksevan miehen kadulla\". s2 ei ole ymmärrettävä lause. ROUGE:n ja BLEU:n unigram-versio antaa näille kahdelle lauseelle pistemäärän 1.",
      "id": "task461-de07e1ed28b84a309c10cfd9c4af20a7",
      "output": [
        "Mitkä ovat nämä kolme rajoitusta?"
      ]
    },
    {
      "input": "Jaksossa SECREF5 käsitellään kysymysten, tekstien ja vastausten keräämistä Amazon Mechanical Turk -palvelun (jäljempänä MTurk) avulla.",
      "id": "task461-2e679eb85fac49a7a15b423156be7ca5",
      "output": [
        "mitä joukkoistamisalustaa käytettiin?"
      ]
    },
    {
      "input": "Kaikkien kielten osalta 145 ihmisannotoijaa pyydettiin pisteyttämään kaikki 1 888 paria (omalla kielellään). Lopulta keräsimme vähintään kymmenen pätevää annotaatiota jokaiselle sanaparille kullakin kielellä. Kaikkien annotoijien oli noudatettava seuraavia ohjeita: 1. Kunkin annotoijan oli annettava kokonaispistemäärä väliltä 0-6 (mukaan lukien), joka osoittaa, kuinka semanttisesti samankaltaisia tietyn sanaparin kaksi sanaa ovat. Pistemäärä 6 tarkoittaa erittäin suurta samankaltaisuutta (eli täydellistä synonymiaa), kun taas nolla tarkoittaa, että samankaltaisuutta ei ole.2. Kunkin kommentoijan on pisteytettävä koko aineiston 1 888 sanaparin joukko. Pareja ei saa jakaa eri annotoijien kesken.3. Annotoijat voivat jakaa työmäärän noin 2-3 viikon ajalle, ja he voivat tarvittaessa käyttää ulkoisia lähteitä (esim. sanakirjoja, tesauruksia, WordNet).4. Annotoijat pidetään nimettöminä, eivätkä he voi kommunikoida toistensa kanssa annotointiprosessin aikana.",
      "id": "task461-ee75dc44592b42788395363862859f82",
      "output": [
        "Miten tietokokonaisuuksia kommentoitiin?"
      ]
    },
    {
      "input": "Olemme havainneet, että konfliktimalli on hyvin herkkä pienillekin eroille ja kompensoi niitä sellaisissa tapauksissa, joissa huomio kohdistuu voimakkaasti samankaltaisuuksiin, jotka ovat jo olemassa sekvensseissä.Sekvenssi 1: Mitkä ovat parhaat tavat oppia ranskaa?Sekvenssi 2: Miten opettelen ranskan sukupuolet?Vain huomio: 1Ahuomio+konflikti: 0Pohjatotuus: 0Sekvenssi 1: Miten estän rintasyövän?Sekvenssi 2: Onko rintasyöpä estettävissä?Vain huomio: 1Ahuomio+konflikti: 0Pohjatotuus: 0Toimitamme kaksi esimerkkiä, joissa on ennusteita malleista, joissa on vain huomio ja huomion ja konfliktin yhdistelmä. Kunkin esimerkin mukana on aineistomme pohjatotuus.",
      "id": "task461-990b47cb595d4ad0b43c5f3647b468fe",
      "output": [
        "Näyttävätkö he, missä esimerkeissä konflikti toimii paremmin kuin huomio?"
      ]
    },
    {
      "input": "Olemme myös tehneet alustavia kokeita SemEval-2016 cQA -tehtävän arabian kielen osuudella. ",
      "id": "task461-753a832e6e92410e81e390b38b284477",
      "output": [
        "Kokeilivatko he muilla kielillä?"
      ]
    },
    {
      "input": "Osoitimme kuitenkin myös, että joissakin tapauksissa saliaatiokartat eivät näytä vangitsevan tärkeitä syötteen piirteitä.  Toinen havainto, jonka voimme tehdä, on se, että saliaatiokartta ei näytä korostavan syötteessä oikeita asioita sen tuottaman yhteenvedon kannalta.",
      "id": "task461-2c00645345e64b0fbffafd63d83833d9",
      "output": [
        "Onko selitys saliaatiokartasta oikea?"
      ]
    },
    {
      "input": " Käytimme upotuksissa $AraVec$ BIBREF30 arabian kielelle, FastText BIBREF31 ranskan kielelle ja Word2vec Google News BIBREF32 englannin kielelle. ",
      "id": "task461-b8f46b6021e94220be6f6deb3d0103e4",
      "output": [
        "Mitä yksikielisiä sanaesityksiä käytetään?"
      ]
    },
    {
      "input": "Kontekstualisoidut sanojen upotukset, lauseiden upotukset, kuten syvät kontekstualisoidut sanaesitykset BIBREF20 , BERT BIBREF22 , koodaavat sanojen monimutkaiset ominaisuudet ja merkitykset eri yhteyksissä kouluttamalla yhdessä kaksisuuntaista kielimallia.  Toinen menetelmä on käyttää lauseen upotuksia, BERT. Sen avulla luodaan yksi 786-ulotteinen lauseen sulautuma 10k-dimensionaalisesta yhden hotsin vektorista tai jakaumasta edellisiin sanoihin ja yhdistetään sitten yhdeksi kontekstivektoriksi kahdella eri yhdistämismenetelmällä. Tämän lähestymistavan avulla saadaan tiheämpi, informatiivisempi, kiinteäpituinen vektori koodaamaan keskusteluyhteyteen liittyvää informaatiota, $e^k_{context}$, jota voidaan käyttää seuraavan $k$ -kymmenennen lausuman ennustamisessa. Käytämme dekooderiverkossamme kontekstuaalista gating-mekanismia yhdistääksemme keskustelukontekstin upotukset tehokkaasti puheen ja sanojen upotuksiin. Porttiarvomme on kontekstisidonnainen siinä mielessä, että useat upotukset laskevat porttiarvon, joka riippuu useiden keskustelussa esiintyvien lausumien kontekstista.  Olkoon $e_w = e_w(y_{u-1})$ edellinen sanan upotus sanalle $y_{u-1}$ , ja olkoon $e_s = e_s(x^k_{1:T})$ puheen upotus nykyisen $k$ -ennen lausuman $x^k_{1:T}$ ja $e_c = e_c(s_{k-1-n:k-1})$ on keskustelukontekstin upotus $n$ -lukua edeltäville lausumille ${s_{k-1-n:k-1}}$ . Käytetään sitten porttimekanismia: $$g = \\sigma (e_c, e_w, e_s)$$ (Yht. 15)jossa $\\sigma $ on 1 piilokerroksen DNN, jolla on $\\texttt {sigmoid}$-aktivointi, porttikytkentä $e$ lasketaan seuraavasti: $$$e = g \\odot (e_c, e_w, e_s) \\\\\\ h = \\text{LSTM}(e)$$ (Yht. 16)$$ (Yht. 16)$$ ja syötetään LSTM-dekooderin piilokerrokseen.  Dekooderin $h$ ulostulo yhdistetään sitten keskusteluyhteyden upottamiseen $e_c$ jälleen porttausmekanismin avulla,$$g = \\sigma (e_C, h) \\\\\\ \\hat{h} = g \\odot (e_c, h)$$ (yhtälö 17)Sitten seuraava piilokerros ottaa nämä portatut aktivoinnit, $\\hat{h}$ , ja niin edelleen.",
      "id": "task461-159570236516476db44e739b9f09d937",
      "output": [
        "Miten lauseen sulautukset sisällytetään puheentunnistusjärjestelmään?"
      ]
    },
    {
      "input": "Arvioimme malliamme julkisesti saatavilla olevalla aineistolla, KARA ONE BIBREF17 , joka koostuu multimodaalisesta aineistosta ärsykkeisiin perustuvasta, kuvitellusta ja artikuloidusta puhetilasta, joka vastaa 7:ää foneemista/syllabista ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) sekä 4:ää sanaa (pat, pot, knew ja gnaw). Aineisto koostuu 14 osallistujasta, ja jokainen kehote esitettiin 11 kertaa kullekin yksilölle. ",
      "id": "task461-daa51875eae549bdabe3819cfb178ee6",
      "output": [
        "Kuinka monesta koehenkilöstä EEG-tiedot ovat peräisin?",
        "Mitä tietoja koehenkilöille esitettiin tapahtumiin liittyvien reaktioiden aikaansaamiseksi?"
      ]
    },
    {
      "input": "Lähestymistapamme parantaa LR:ää keskimäärin 5,17 % (tarkkuus) ja 18,38 % (AUC) ja MLP:tä 10,71 % (tarkkuus) ja 30,27 % (AUC). Tällaiset merkittävät parannukset osoittavat selvästi, että lähestymistapamme parantaa tehokkaasti mallien suorituskykyä.",
      "id": "task461-bc2b4c786b2d47639868e95350f5906a",
      "output": [
        "Miten lähestymistavan tarkkuus on osoitettu?"
      ]
    },
    {
      "input": "DrQA on CRC-perustaso, joka on tulossa CoQA-tietokannan kanssa. Huomaa, että tämä DrQA-toteutus eroaa SQuAD BIBREF8:n DrQA-toteutuksesta siten, että se on muutettu tukemaan vastaamattomien kysymysten vastaamista siten, että asiakirjan lopussa on erityinen tuntematon merkki.  DrQA+CoQA on edellä mainittu perustaso, joka on esiviritetty CoQA-tietokannalla ja sitten hienosäädetty $(\\text{RC})_2$ -tietokannalla.  BERT on vanilla BERT-malli, joka on hienosäädetty suoraan $(\\text{RC})_2$:lle. Käytämme tätä perustasoa ablaatiotutkimukseen esivirityksen tehokkuudesta. BERT+review virittää ensin BERT:n toimialueen arvosteluihin käyttäen samoja tavoitteita kuin BERT:n esivalmennuksessa ja hienovirittää sitten $(\\text{RC})_2$ . Käytämme tätä perustasoa osoittaaksemme, että yhteistyöelimen pelkkä toimialueen mukauttaminen ei ole hyvä. BERT+CoQA hienosäätää ensin yhteistyöelimen valvotun CoQA-datan perusteella ja hienosäätää sitten $(\\text{RC})_2$:n perusteella. Käytämme tätä perustasoa osoittaaksemme, että esiviritys on erittäin kilpailukykyinen jopa verrattuna malleihin, jotka on koulutettu laajamittaisesta valvotusta datasta.",
      "id": "task461-2a5b368f441e46bbbb74f4186e1e33ef",
      "output": [
        "Mikä on käytetty perusmalli?"
      ]
    },
    {
      "input": "Suoritimme ehdotetun järjestelmän luotettavuustutkimuksen käyttäen kahta asiantuntijalausunnonantajaparia, P1 ja P2.  Arvioinnissa käytettiin Cohenin kappaa, joka on painottamaton argumentoinnin ja tietämysalueen osalta, mutta kvadraattipainotettu spesifisyyden osalta, kun otetaan huomioon sen järjestetyt merkinnät.",
      "id": "task461-69ca6399a7ef4cedb290b88af0460e61",
      "output": [
        "mitä kokeita tehdään?"
      ]
    },
    {
      "input": "Sanan kontekstittomat ominaisuudet. Nämä ominaisuudet johdetaan suoraan sanasta, ja ne kuvaavat yleistä taipumusta siihen, että sana kaikuu selityksissä.",
      "id": "task461-93ac9c31bf4647b097a903a9ebd44987",
      "output": [
        "Mihin kontekstittomiin ominaisuuksiin ne viittaavat?"
      ]
    },
    {
      "input": " Lähes kaikissa genreissä DenseNMT-mallit ovat huomattavasti parempia kuin perusmallit.",
      "id": "task461-7e7b0db971cd4d6cbf754638e64a7762",
      "output": [
        "Ovatko ne olleet parempia kuin aiemmat menetelmät?"
      ]
    },
    {
      "input": "Pyrimme löytämään tällaista sisältöä sosiaalisesta mediasta keskittyen twiitteihin.",
      "id": "task461-7b7f97da1e564aedb57858234f5e7f29",
      "output": [
        "Sisältääkö tietokokonaisuus sisältöä eri sosiaalisen median alustoilta?"
      ]
    },
    {
      "input": "LDA-mallia käytettäessä jokaisella henkilöllä aineistossa on aiheen todennäköisyysvektori $X_i$ . Oletetaan, että $x_{ik}\\in X_{i}$ tarkoittaa todennäköisyyttä sille, että $\\emph {i}^{th}}$ twiittitili suosii $\\emph {k}^{th}$ aihetta datasetissä. Aiheeseen perustuvat ominaisuutemme voidaan laskea seuraavasti. Global Outlier Standard Score mittaa sitä, missä määrin käyttäjän twiittisisältö liittyy tiettyyn aiheeseen verrattuna muihin käyttäjiin. Local Outlier Standard Score mittaa sitä, kuinka kiinnostunut joku on tietystä aiheesta, kun otetaan huomioon vain hänen oman kotisivunsa sisältö. Kolme perustason luokittelumenetelmää: SVM, Adaboost ja Random Forests -luokitusmenetelmiä käytetään arvioimaan poimittuja ominaisuuksia.",
      "id": "task461-6e84e1f04e9643f59e2cca4b80f97031",
      "output": [
        "Miten he havaitsevat roskapostittajat?"
      ]
    },
    {
      "input": "Kehitämme nollamallin määrittääksemme, kuinka paljon vaihtelua binomijärjestelyissä voitaisiin odottaa eri yhteisöjen välillä ja eri aikoina, jos binomijärjestelyt järjestettäisiin satunnaisesti globaalien epäsymmetria-arvojen mukaan. ",
      "id": "task461-7d264054151d48b9a5eaeeb81086d072",
      "output": [
        "Mitä uutta mallia ehdotetaan binomilistoille?"
      ]
    },
    {
      "input": " Alustan käyttäjät antavat vaikuttavuusääniä arvioidakseen, kuinka vaikuttava tietty väite on. Käyttäjät voivat valita yhden viidestä mahdollisesta väitteen vaikutusmerkinnästä: ei vaikutusta, vähäinen vaikutus, keskisuuri vaikutus, suuri vaikutus ja erittäin suuri vaikutus. Arvioidessaan väitteen vaikutusta käyttäjät voivat tutustua väitteen koko asiayhteyteen, joten he voivat arvioida, kuinka vaikuttava väite on väitteen tietyssä asiayhteydessä.",
      "id": "task461-2f129a169bd5495289f825871d00aaef",
      "output": [
        "Mitä merkintöjä tietokokonaisuudessa on saatavilla?"
      ]
    },
    {
      "input": "Analyysissämme havaittiin, että jengiläiset käyttävät mielellään vain pientä joukkoa emoji-symboleita, jotka välittävät vihaa ja väkivaltaista käyttäytymistä twiiteissään. Kuvassa FIGREF24 on havainnollistettu aineistomme jengiläisprofiilien 20 yleisimmin käyttämän emojin jakauma. Polttoainepumppuemoji oli jengiläisten useimmin käyttämä emoji, jota käytetään usein marihuanan myynnin tai kulutuksen yhteydessä. Pistooli-emoji on aineistossamme toiseksi yleisin emoji, jota käytetään usein yhdessä vartijaemojin tai poliisi-emojin kanssa \"emojiketjussa\". Kuvassa FIGREF28 esitetään joitakin prototyyppisiä jengiläisten käyttämiä emojien \"ketjuja\". Ketjut saattavat kuvastaa heidän vihaansa lainvalvontaviranomaisia kohtaan, sillä poliisi-emojia seuraa usein aseen, pommin tai räjähdyksen emoji. Havaitsimme, että 32,25 prosenttia aineistomme jengiläisistä on ketjuttanut poliisi- ja pistooli-emojin yhteen, kun taas jengiin kuulumattomista vain 1,14 prosenttia. Lisäksi vain 1,71 % ei-jengiläisistä on käyttänyt sadan pisteen emojia ja pistooli-emojia yhdessä twiiteissä, kun taas 53 % jengiläisistä on käyttänyt niitä. Erilaiset vihaiset kasvot-emojit, kuten pirun kasvot-emoji ja imp-emoji, olivat myös yleisiä jengiläisten twiiteissä.",
      "id": "task461-1f15535588db449b9fa9149e05c47058",
      "output": [
        "Mitä eroja emojien käytössä on jengiläisten ja muun Twitter-väestön välillä?"
      ]
    },
    {
      "input": "Arvioidaksemme lähestymistapamme suorituskykyä käytimme osajoukkoa SNIPS BIBREF12 -tietokannasta, joka on helposti saatavilla RASA nlu -muodossa.  Tehtävänä ja mittarina käytämme tarkoituksen ja entiteetin tunnistamisen tarkkuutta. ",
      "id": "task461-71b2ad8bb80c45e287c696a67e45de07",
      "output": [
        "Miten niiden muutoksia arvioidaan?"
      ]
    },
    {
      "input": "Mallissa on noin 836 miljoonaa parametria, joista vain 66 000 on tavun upotuksia.",
      "id": "task461-716de9634ec14eb995341f5cce2c05c4",
      "output": [
        "Kuinka monta parametria mallissa on?"
      ]
    },
    {
      "input": "Opi jokaiselle koodausjoukon muuttujalle uudet upotukset käyttäen upotusten harjoittelusarjaa . Koska upotusten koulutusmallissa on stokastisuutta, toistamme edellä esitetyn useita kertoja eri kokeita varten (ja ilmoitamme vastaavat keskiarvo- ja keskihajontatilastot).",
      "id": "task461-835a31a0213144abad6fdd55d4b879a0",
      "output": [
        "Miten he harjoittelevat upotuksiaan?"
      ]
    },
    {
      "input": "Sen jälkeen koulutamme sensaatiohakuisuuden pisteytyksen luokittelemalla sensaatiohakuiset ja ei-sensaatiohakuiset otsikot käyttämällä yksikerroksista CNN:ää, jossa on binäärinen ristikkäisentropiahäviö $L_{\\text{sen}}$. Ensin käytetään 1-D-konvoluutiota sanaominaisuuksien poimimiseen otsikon syötteestä. Tämän jälkeen seuraa ReLU-aktivointikerros ja maksimipoolauskerros aikaulottuvuutta pitkin. Kaikki eri kanavista saadut piirteet yhdistetään ja projisoidaan sensationalismipisteytykseen lisäämällä toinen täysin kytketty kerros, jossa on sigmoidiaktivointi. Binääristä ristiinentropiaa käytetään tappion $L_{\\text{sen}}$ laskemiseen.",
      "id": "task461-a5f2741f4a5c428aa1fd5f580e3921ed",
      "output": [
        "Miten sensaatiohakuisuus on koulutettu?"
      ]
    },
    {
      "input": "Kaavan mukaisesti voimme laskea jokaisen syötesanan osuuden jokaisesta tulossanasta, jolloin muodostuu osuustaulukko, jonka koko on $M \\ kertaa N$, jossa $N$ on tulostetun lauseen pituus. Kun otetaan huomioon kontribuutiomatriisi, saadaan kunkin syötetyn sanan merkitys koko tuloslauseen kannalta. Tätä varten kunkin syötesanan osalta lasketaan ensin yhteen sen kontribuutioarvot kaikkiin tulossanoihin summaoperaatiolla ja normalisoidaan sitten kaikki summat Softmax-funktion avulla.",
      "id": "task461-5f8be80971cf4056ba940d7e865f9a64",
      "output": [
        "Miten heidän mallinsa päättävät, kuinka paljon parannusta annetaan tulossanoille?"
      ]
    },
    {
      "input": "Seq2seq-malli globaalilla huomiolla antaa parhaat tulokset, kun keskimääräinen BLEU-pistemäärä on 29,65 tyylinsiirtotietokannassa, kun keskimääräinen BLEU-pistemäärä on 26,97 käytettäessä seq2seq-mallia osoitinverkkojen kanssa.",
      "id": "task461-aa0e480c31d84788aa87ec5e8d632bf2",
      "output": [
        "Mikä on paras BLEU-pistemäärä, jonka kielityylinsiirron tekijät saivat?"
      ]
    },
    {
      "input": "Tässä asiakirjassa käytämme kolmea kirjallisuudesta löytyvää aineistoa oman luokittelijamme kouluttamiseen ja arviointiin. BIBREFin3 keräämät tiedot, joita kutsumme Sexist/Racist (SR) -datajoukoksi, kerättiin alustavalla Twitter-haulla, jonka jälkeen kirjoittajat ja heidän tiiminsä analysoivat ja suodattivat ne. He tunnistivat 17 yleistä lausetta, hashtagia ja käyttäjää, jotka viittasivat loukkaavaan puheeseen. BIBREF4 keräsi HATE-tietoaineiston etsimällä twiittejä Hatebase.orgin tarjoaman sanaston avulla. Lopullisen käyttämämme aineiston, jota kutsumme nimellä HAR, keräsi BIBREF9 ; poistimme kaikki uudelleentwiittaukset ja pienensimme aineiston 20 000 twiittiin. Twiitit merkittiin \"häiritseviksi\" tai \"ei-häiritseviksi\"; vihapuhetta ei nimenomaisesti merkitty, vaan sitä käsiteltiin merkitsemättömänä osajoukkona laajemmasta \"häiritsevä\"-luokasta BIBREF9 .",
      "id": "task461-7300ae361de242219cb3398466728e53",
      "output": [
        "Mitä julkisesti saatavilla olevia tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Huomasimme kuitenkin kaikkien multimodaalisten mallien kohdalla yhteisen virhekäyttäytymisen: jos huomio katoaa kuvassa olevista kohteista ja \"eksyy\", malli ottaa sen silti huomioon ja jotenkin ohittaa tekstipohjaisten merkintöjen tuoman informaation. Käännös on tällöin täysin harhaanjohtava. ",
      "id": "task461-e955d05b65f2421cb60acd54076a5520",
      "output": [
        "Mitä väärinkäytöksiä on havaittu?"
      ]
    },
    {
      "input": "Yhdistämme 13 000 kysymystä, jotka on kerätty tästä putkesta, ja 3 000 kysymystä, joihin on annettu kyllä/ei-vastauksia NQ-harjoitusjoukosta, jotta saamme yhteensä 16 000 kysymystä. ",
      "id": "task461-c24ac5e551aa4225a96f2f8b0c9a61ac",
      "output": [
        "Mikä on BoolQ-tietokannan koko?"
      ]
    },
    {
      "input": "Tässä artikkelissa ehdotamme, että jokainen sana esitetään ilmeikkäällä multimodaalisella jakaumalla, joka mahdollistaa useat eri merkitykset, seuraussuhteet, epävarmuuden ja paremman tulkittavuuden. Esimerkiksi sanan \"pankki\" yksi moodi voisi olla päällekkäinen sellaisten sanojen kuin \"rahoitus\" ja \"raha\" jakaumien kanssa, ja toinen moodi voisi olla päällekkäinen sanojen \"joki\" ja \"puro\" jakaumien kanssa. Väitämme, että tällainen joustavuus on ratkaisevan tärkeää sekä sanojen merkitysten laadullisen oppimisen että optimaalisen suorituskyvyn kannalta monissa ennustustehtävissä.",
      "id": "task461-d3ba103f2d7b496fa5d1698e67126baa",
      "output": [
        "Miten tämä vertautuu kontekstuaalisiin upotusmenetelmiin?"
      ]
    },
    {
      "input": "Arvioimme lauseiden spesifisyyttä joukolla kolmen kohdealueen osalta: Twitter, Yelp-arvostelut ja elokuva-arvostelut.",
      "id": "task461-ed0f5244003240ceb9d7c747789864f3",
      "output": [
        "Millä aloilla he kokeilevat?"
      ]
    },
    {
      "input": "Tässä yhteydessä päätimme tutkia kolmea tärkeintä arkkitehtuurityyppiä, jotka ovat osoittaneet lupaavia tuloksia perinteisiin järjestelmiin verrattuna: 1) Connectionist Temporal Classification (CTC) BIBREF5, BIBREF6 , joka käyttää Markov-oletuksia (ts. ehdollinen riippumattomuus ennusteiden välillä kullakin aika-askeleella) ratkaistakseen tehokkaasti peräkkäisiä ongelmia dynaamisen ohjelmoinnin avulla, 2) Huomioon perustuvat menetelmät BIBREF7, BIBREF8, jotka luottavat huomiomekanismiin suorittaakseen ei-monotonisen yhdenmukaistamisen akustisten kehysten ja tunnistettujen akustisten yksiköiden välillä, ja 3) RNN-tulkki BIBREF0, BIBREF9, BIBREF10, joka laajentaa CTC:tä siten, että se mallintaa lisäksi eri vaiheissa tapahtuvien ulostulojen väliset riippuvuudet käyttämällä kielimallin kaltaista ennustusverkkoa.",
      "id": "task461-1e4004acf5964617a3f16bd6b6581c93",
      "output": [
        "Mitkä ovat nykyiset end-to-end ASR-lähestymistavat ranskan kieltä varten?"
      ]
    },
    {
      "input": "Näin ollen kartoissa voidaan erottaa kaksi pääaluetta tai klusteria. Violetti tausta peittää suurimman osan kartasta ja edustaa maaseutualueita, joilla on pieni, hajallaan oleva väestö. Analyysimme osoittaa, että tällä soluryhmällä on enemmän erityisiä sanoja sanastossaan. Vihreät ja keltaiset solut sen sijaan muodostavat toisen klusterin, joka on suurelta osin keskittynyt keskustaan ja rannikolle, jotka vastaavat suurkaupunkeja ja teollisuusalueita.  Näissä soluissa espanjan kielen vakiokielen käyttö on yleistä, mikä johtuu todennäköisesti kouluopetuksesta, tiedotusvälineistä, matkailijoista jne.",
      "id": "task461-382bf83d121a4d8999a3b79ba7775895",
      "output": [
        "Mainitsevatko kirjoittajat tutkimuksessaan mahdollisia sekaannuksia?"
      ]
    },
    {
      "input": " Yleensä virheellisen puhuja- ja/tai yleisötiedon antaminen laskee BLEU-pistemäärää, kun taas oikean tiedon antaminen parantaa sitä huomattavasti - jopa 2,3 BLEU:n lisäys perustasoon verrattuna. Näemme, että perusjärjestelmä ennustaa verbien feminiinimuodon huomattavasti liian huonosti vertailuun verrattuna. \"Hän sanoi\" -ehdot vähentävät feminiinisten verbien määrää entisestään, kun taas \"Minä sanoin\" -ehdot palauttavat sen takaisin perustasolle. Lopuksi \"Hän sanoi\" -prefiksit lisäävät huomattavasti feminiinimerkittyjen verbien määrää, jolloin niiden osuus on paljon lähempänä vertailua (vaikkakin osa feminiinisistä tapauksista on edelleen aliennustettuja).",
      "id": "task461-45a113a09ff3481985413a83957d7618",
      "output": [
        "Miten osoitetaan, että tässä järjestelmässä syötetään oikeat sukupuoli- ja numerotiedot?"
      ]
    },
    {
      "input": "Testataksemme ehdotetun MWA-huomion soveltuvuutta valitsemme kolme julkisesti saatavilla olevaa kiinalaista esivalmennettua mallia peruskooderiksi: BERT, ERNIE ja BERT-wwm. Oikeudenmukaisen vertailun tekemiseksi pidämme samat hyperparametrit (kuten enimmäispituus, lämmittelyvaiheet, alkuperäinen oppimisnopeus jne.), joita ehdotetaan BERT-wwm BIBREF13 -mallissa, sekä perusmalleille että menetelmällemme kussakin tietokokonaisuudessa.",
      "id": "task461-c5a5dd6298e64740b4824b30cc36e007",
      "output": [
        "Mihin esivalmennettuihin malleihin niitä verrattiin?"
      ]
    },
    {
      "input": " Toisin kuin useimmat koodaaja-dekooderiarkkitehtuurit, jotka perustuvat puhtaasti rekursiivisiin neuroverkkoihin (RNN), me rakennamme koodaimen, jossa on useita konvoluutiokerroksia BIBREF14 ja sen jälkeen NIN-kerroksia BIBREF15 koodaimen alempana ja yhdistämme ne syvään kaksisuuntaiseen kaksisuuntaiseen pitkäkestoiseen lyhytkestoiseen muistiin (Bi-LSTM)16 ylemmässä osassa. Dekooderin puolella käytämme tavallista syvää yksisuuntaista LSTM:ää, jossa on globaali huomio BIBREF13 ja joka lasketaan monikerroksisen perceptronin (MLP) avulla yhtälössä EQREF2 kuvatulla tavalla.",
      "id": "task461-dfa99df0227943499d319a9afbfd4c86",
      "output": [
        "Mitä arkkitehtuuria ne käyttävät kooderissa ja dekooderissa?"
      ]
    },
    {
      "input": "Tarkistimme manuaalisesti 1177 paria järjestelmän tuottamia entiteettejä ja viittausilmauksia. Kaiken kaikkiaan 73,3 prosenttia entiteettien muista kuin ensimmäisistä maininnoista korvattiin sopivilla lyhyemmillä ja sujuvammilla ilmauksilla.",
      "id": "task461-b6eee8b4bef84fd1bd708f27172940c2",
      "output": [
        "Miten tuotetun tekstin sujuvuutta arvioidaan?"
      ]
    },
    {
      "input": "Kielen mallintamisen arviointia varten arvioimme myös perustasoa ilman tiedon tislausta (NoKD), jossa malli on parametrisoitu samalla tavalla kuin tislattujen oppilasmallien parametrit, mutta se on koulutettu suoraan opettajan mallin tavoitteeseen tyhjästä. Jälkikäsiteltävien tehtävien osalta vertaamme NoKD:hen sekä BIBREF34:n Patient Knowledge Distillation (PKD) -menetelmään, joka tislaa 12-kerroksisen BERTBASE-mallin 3- ja 6-kerroksisiksi BERT-malleiksi käyttämällä opettajamallin piilotettuja tiloja.",
      "id": "task461-763131aa4b854dd499f9e2983d1c6ebb",
      "output": [
        "Mitä uusimpia pakkaustekniikoita vertailussa käytettiin?"
      ]
    },
    {
      "input": "Taulukossa TABREF11 on esitetty muutamia esimerkkejä englanninkielisistä neuvontasäännöistä (jotka on muunnettu ensimmäisen kertaluvun logiikan muotoon ja annettu algoritmimme syötteenä).  Muokkasimme Odom et al. odomAIME15,odomAAAI15:n työtä oppiaksemme RDN-sääntöjä neuvojen läsnä ollessa. Keskeinen ajatus on edustaa neuvoja eksplisiittisesti gradientteja laskettaessa.",
      "id": "task461-6d5071c98e9a48879b449fe4cd847808",
      "output": [
        "Miten ne sisällyttävät inhimilliset neuvot?"
      ]
    },
    {
      "input": "Yksi ratkaisu, jota on ehdotettu sukupuoleen perustuvan vinoutuman lieventämiseksi sanojen upottamisen tasolla, on Counterfactual Data Augmentation (CDA) BIBREF25. Sovellamme tätä menetelmää täydentämällä tietokokonaisuuttamme kopiolla jokaisesta vuoropuhelusta, jossa sukupuolittuneet sanat on vaihdettu käyttäen BIBREF21:n toimittamaa sukupuolittuneiden sanaparien luetteloa.",
      "id": "task461-7bc71338bf6b49e6a410a77734567331",
      "output": [
        "Miten kontrafaktuaalisen tiedon lisäämisen avulla pyritään torjumaan harhaa?"
      ]
    },
    {
      "input": "Tämän artikkelin koeasetukset ja Mboshi-korpuksen arviointiprotokolla (Boundary F-pisteet käyttäen ZRC-puheviitettä) ovat samat kuin BIBREF8:ssa. Taulukossa esitetään tulokset kaksikielisen UWS:n ja monikielisen vivutuksen osalta. Ensin mainitussa tapauksessa saavutamme parhaan tuloksemme käyttämällä yhdenmukaistettuna tietona ranskaa, joka on tämän tietokokonaisuuden alkuperäinen yhdenmukaistettu kieli.  Monikielistä valintaa varten kokeilimme kielten yhdistämistä ylhäältä alaspäin, kuten ne näkyvät taulukossa (paremmuusjärjestyksessä suorituskyvyn mukaan; esim. 1-3 tarkoittaa FR(1), EN(2) ja PT(3) yhdistelmää). Huomasimme, että suorituskyvyn paraneminen on pienempi kuin aiemmassa BIBREF10-työssä, mikä johtuu siitä, että tietokokonaisuuttamme on lisätty keinotekoisesti. Lopuksi, BIBREF8:n menetelmää noudattaen, poimimme kaksikielisten mallien löytämät varmimmat linjaukset (ANE:n suhteen). Taulukossa esitetään 10 varminta (löydetty tyyppi, käännös) paria. Kun tarkastellaan kaksikielisten mallien varmimpia pareja, havaitaan, että kaikki kaksikieliset mallit ovat löytäneet joitakin tyyppejä (esim. Mboshi-sana itua ja yhdistelmä oboá+ngá).",
      "id": "task461-540d17d454754aa4a7f14f00eaaa9edb",
      "output": [
        "Miten mallin suorituskykyä arvioidaan?"
      ]
    },
    {
      "input": "Valvontakriteerit lasketaan heuristisesti. Tämän jälkeen kaikki kontrollisanaluetteloista löytyneet sanat poistetaan vertailulauseesta. Jäljelle jääviä sanoja, jotka edustavat sisältöä, käytetään mallin syötteenä yhdessä niiden POS-tunnisteiden ja lemman kanssa.Tällä tavoin rohkaisemme malleja rakentamaan lauseen sisällön ja tyylin avulla itsenäisesti.",
      "id": "task461-ee50e1fd31ab47298636eb86365dd015",
      "output": [
        "Mistä he tietävät, mitkä ovat sisällön sanoja?"
      ]
    },
    {
      "input": "E2ECM BIBREF11: Vuoropuhelupolitiikassa se käyttää klassista luokittelua luurankomallin lauseen mallin osalta. Toteutuksessamme rakennamme useita binääriluokituksia kullekin teolle lauseen mallin etsimistä varten BIBREF11:n ehdottaman työn mukaisesti. CDM BIBREF10: Tässä lähestymistavassa suunnitellaan joukko luokituksia (kaksi moniluokkaista luokitusta ja joitakin binääriluokituksia) dialogipolitiikan mallintamiseksi.",
      "id": "task461-ade8e5df81014a058e995da87e4c4973",
      "output": [
        "Mitä ovat uusimmat peruslähtökohdat?"
      ]
    },
    {
      "input": "ConMaskissa käytämme samankaltaista ideaa valitaksemme eniten toisiinsa liittyvät sanat, kun jokin suhde on annettu, ja peittääksemme epäolennaiset sanat antamalla suhteesta riippuvaisen samankaltaisuuspisteytyksen sanoille annetussa olion kuvauksessa. ConMask valitsee sanat, jotka liittyvät annettuun suhteeseen, jotta epäolennaisten ja häiriöalttiiden sanojen sisällyttämistä voidaan vähentää.",
      "id": "task461-94b3cf1dcdc640e9aec78944cd4acc69",
      "output": [
        "Voiko malli lisätä tietämysgraafiin uusia suhteita vai vain uusia entiteettejä?"
      ]
    },
    {
      "input": "Lisäksi arvioimme esivalmennuksen tehokkuutta vertaamalla sitä yhdessä koulutettuun malliin, joka koostuu etukääntämisestä ja takakääntämisestä. Kokeelliset tulokset osoittavat, että koodaaja-dekooderi-rekonstruktori tarjoaa merkittävän parannuksen BLEU-pisteisiin ja lieventää englannin ja japanin käännöstehtävän toistuvien ja puuttuvien sanojen ongelmaa käännöksessä, eikä koodaaja-dekooderi-rekonstruktoria voida kouluttaa hyvin ilman esivalmennusta, joten se osoittaa, että meidän on koulutettava eteenpäin kääntämisen malli perinteisen tarkkaavaisuuspohjaisen NMT:n kaltaisella tavalla esivalmennuksena.",
      "id": "task461-16689126d5d2495e84d3b8cb1b66f7ad",
      "output": [
        "Onko esivalmennus tehokasta niiden arvioinnissa?"
      ]
    },
    {
      "input": "Mallinnamme ympäristöstä, tavoitteesta ja asiakirjasta tehtyjen havaintojen välistä vuorovaikutusta kerrosten avulla. Ensin koodaamme tekstisisällöt käyttämällä kaksisuuntaisia LSTM:iä, sitten laskemme yhteenvedot käyttämällä itsehuomiota ja ehdolliset yhteenvedot käyttämällä huomiota. Yhdistämme tekstin yhteenvedot tekstin ominaisuuksiksi, joita käsitellään yhdessä visuaalisten ominaisuuksien kanssa peräkkäisten kerrosten kautta. Tässä tekstiympäristön tapauksessa pidämme sanojen upotusten ruudukkoa visuaalisina piirteinä . Lopullinen tuloste käsitellään edelleen MLP:llä toimintatapajakauman laskemiseksi toimille ja perustason laskemiseksi etujen arviointia varten. ",
      "id": "task461-9da060fa479c4a16a63d7eff428c1455",
      "output": [
        "Miten ehdotetaan mallia, joka kaappaa kolmisuuntaiset vuorovaikutussuhteet?"
      ]
    },
    {
      "input": "Tässä asiakirjassa käytämme kolmea koodaajaa (NBOW, LSTM ja Attentive LSTM) tekstikuvausten mallintamiseen.",
      "id": "task461-12441ea54fd74bc89edb0647ed1761e9",
      "output": [
        "Mitä neuraalisia malleja käytetään tekstin koodaamiseen?"
      ]
    },
    {
      "input": "Twitter-tiedot: Käytimme Twitterin API:ta hakusanoja sisältävien twiittien keräämiseen. API suodatti kaikki muut kuin englanninkieliset twiitit pois.",
      "id": "task461-46e2d57715b241f4b51a1e757ce4c022",
      "output": [
        "Arvioidaanko ne vain englanninkielisillä tietokokonaisuuksilla?"
      ]
    },
    {
      "input": "Käytämme ceccarelli2013learning-ohjelmalla luotua vertailutietoaineistoa CoNLL 2003 -aineistosta. ",
      "id": "task461-c45b6997642c4ccd96082a97b8c20307",
      "output": [
        "Mikä on vertailutietokanta?"
      ]
    },
    {
      "input": "(Tiedonhaku). Tätä perustasoa on käytetty menestyksekkäästi vastaavissa tehtävissä, kuten kysymyksiin vastaamisessa BIBREF39 . Luomme kaksi versiota tästä perustasosta: toinen, jossa on INLINEFORM0-näkökulmia ja toinen, jossa on INLINEFORM1-todisteet.",
      "id": "task461-521e0fa69aca4256978d2f181318f080",
      "output": [
        "Mitä koneen peruslinjoja käytetään?"
      ]
    },
    {
      "input": "Taulukossa IV esitetään tunteisiin perustuvan luokittelumallimme tulokset verrattuna muihin malleihin. Vertaamme mallimme suorituskykyä BIBREF0- ja BIBREF5-menetelmiin STS-korpuksella. BIBREF0 raportoi Maximum Entropy (MaxEnt), NB ja SVM -mallien tulokset STS-korpuksen osalta, ja niiden suorituskyky oli hyvä aiemmalla kerralla. BIBREF5:n malli on toistaiseksi huippuluokkaa käyttämällä CharSCNN:ää. Kuten voidaan nähdä, 86,63 on toistaiseksi paras ennustustarkkuus, jonka mallimme on saavuttanut STS-korpuksen osalta. Sanders- ja HCR-tietokokonaisuuksien osalta vertaamme tuloksia BIBREF14-malliin, jossa käytettiin useiden perusluokittelijoiden (ENS), kuten NB, Random Forest (RF), SVM ja Logistic Regression (LR), muodostamaa kokonaisuutta. ENS-malliin on yhdistetty sanasäkki (BoW), ominaisuuksien hassaus (FH) ja leksikonit. BIBREF14-malli on huippuluokkaa Sanders- ja HCR-tietoaineistoissa. Mallimme ovat parempia kuin BIBREF14:n malli Sanders- ja HCR-tietokannoissa.",
      "id": "task461-9ebd3ee3006747098756392fe7c09a78",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Molemmissa tietokokonaisuuksissa noudatamme alkuperäisissä BIBREF13 -arviointitehtävissä käytettyjä arviointimittareita. DBQA:n osalta käytetään P@1 (Precision@1), MAP (Mean Average Precision) ja MRR (Mean Reciprocal Rank). Koska KBRE:ssä kullekin kysymykselle merkitään vain yksi kultainen ehdokas, käytetään vain P@1- ja MRR-arvoja.",
      "id": "task461-fc4044a4897b4528b4f2533506557ee6",
      "output": [
        "Mitä mittareita he käyttävät arvioitaessa yhteensopivuutta?"
      ]
    },
    {
      "input": "Teimme myös laadullisen tutkimuksen Starbucksin (SBUX) osakkeen liikkeistä tämän tapahtuman aikana. Kuvio FIGREF12 on SBUXin ja NASDAQ-indeksin päivittäinen prosentuaalinen muutos 11. huhtikuuta ja 20. huhtikuuta välisenä aikana. SBUX ei seurannut koko markkinoiden noususuuntausta ennen 17. huhtikuuta, ja sitten sen muutos 20. huhtikuuta, INLINEFORM0 , on melko merkittävä historiallisista normeista. Keräsimme historialliset 52 viikon osakekurssit ennen tätä tapahtumaa ja laskimme päivittäisen osakekurssimuutoksen. Edellisten 52 viikon päivittäisen kurssimuutoksen jakauma on kuvio KUVIO FIGREF13, jonka keskiarvo on INLINEFORM1 ja keskihajonta INLINEFORM2 . ",
      "id": "task461-2fc5e017898140c2939357a5fc760ec0",
      "output": [
        "Miten menetelmällä mitataan tapahtuman vaikutusta markkinahintoihin?"
      ]
    },
    {
      "input": "Enintään kolme osallistujaa kuuntelee minkä tahansa äänileikkeen. Jos $<$audio,transkriptio$>$ -parille annetaan ensin kaksi ääntä ylöspäin, leike merkitään kelvolliseksi. Jos sen sijaan klippi saa ensin kaksi kielteistä ääntä, se merkitään mitättömäksi. Osallistuja voi halutessaan vaihtaa tallennuksen ja validoinnin välillä. Vain kelvollisiksi merkityt klipit sisällytetään kunkin kielen virallisiin koulutus-, kehitys- ja testisarjoihin. Klipit, jotka eivät ole saaneet riittävästi ääniä validointia tai mitätöintiä varten julkaisuhetkellä, julkaistaan nimellä \"muut\". Koulutus-, testi- ja kehitysjoukot on jaoteltu siten, että yksittäinen puhuja voi esiintyä vain yhdessä niistä. Näin varmistetaan, että harjoitusaikana nähtyjä avustajia ei nähdä testiaikana, mikä vääristäisi tuloksia. Lisäksi tekstilauseiden toistot poistetaan korpuksen harjoitus-, testi- ja kehitysjoukoista.",
      "id": "task461-cc96d25b7c88481e98899f3ea0b2c5e6",
      "output": [
        "Miten tiedot validoidaan?"
      ]
    },
    {
      "input": "Tämän mielenkiintoisen ominaisuuden tallentamiseksi ehdotamme uutta merkintäjärjestelmää, joka koostuu kolmesta tunnisteesta, nimittäin { INLINEFORM0 }.INLINEFORM0-tunniste osoittaa, että nykyinen sana esiintyy ennen sanaleikkiä kyseisessä kontekstissa.INLINEFORM0-tunniste korostaa, että nykyinen sana on sanaleikki.INLINEFORM0-tunniste osoittaa, että nykyinen sana esiintyy sanaleikin jälkeen.",
      "id": "task461-3eaebc38372d4116bfcfac94890c9c5b",
      "output": [
        "Mikä on käytetty merkintäjärjestelmä?"
      ]
    },
    {
      "input": "Tarkemmin sanottuna käytämme kutakin Q_\\mathit {tr}$:n monivalintakysymystä $(q,A) \\in Q_\\mathit {tr}$ ja kutakin A$:n valintaa $a \\in A$ varten kaikkia $q$:n ja $a$:n sisältämiä muita kuin pysähtymättömiä sanamerkkejä ElasticSearch-kyselynä S:lle. Otamme 200 suurinta osumaa, ajamme Open IE v4:n ja yhdistämme tuloksena saadut tuplat kaikkien $a \\in A$:n ja kaikkien Q_\\mathit {tr}$:n sisältämiin kysymyksiin luodaksemme tuplan KB (T).",
      "id": "task461-3bf5fee680b44f3583d908e38a0cfd2b",
      "output": [
        "Mitä OpenIE-menetelmää käytettiin uutteiden tuottamiseen?"
      ]
    },
    {
      "input": "Tärkeimmät tuloksemme esitetään taulukossa TABREF6 viranomaisilmoitusten testijoukon osalta ja taulukossa TABREF7 kiinteistöjen vuokrasopimusten testijoukon osalta; F$_1$, tarkkuus ja palautus lasketaan edellä kuvatulla tavalla.",
      "id": "task461-9c5394fc5b904633bb3b9a89829c3f6f",
      "output": [
        "Mitä arviointimittareita käytettiin tulosten esittämiseen? "
      ]
    },
    {
      "input": "Se alkaa tavallisena turnausvalinnan evoluutioarkkitehtuurihakuna, jossa on varhainen pysäytys, jolloin jokainen lapsimalli harjoittelee suhteellisen pienen $s_0$ määrän askelia ennen kuin sen soveltuvuus arvioidaan. Kun ennalta määrätty määrä lapsimalleja, $m$ , on arvioitu, luodaan kuitenkin este, $h_0$ , laskemalla nykyisen populaation keskimääräinen kunto. Seuraaville $m$ tuotetuille lapsimalleille, joiden kunto on suurempi kuin $h_0$ $s_0$ koulutusvaiheen jälkeen, annetaan $s_1$ lisäkoulutusvaihetta, minkä jälkeen ne arvioidaan uudelleen lopullisen kuntonsa määrittämiseksi. Kun toiset $m$ mallia on tarkasteltu tällä tavalla, muodostetaan toinen este, $h_1$ , laskemalla kaikkien niiden nykyisen populaation jäsenten keskimääräinen kunto, joita on koulutettu maksimimäärän askelia. Seuraavien $m$$ lapsimallien kohdalla koulutus ja arviointi jatkuu samalla tavalla, paitsi että malleille, joiden kunto on suurempi kuin $m$0 $m$1 koulutusaskeleen jälkeen, annetaan $m$2 lisää koulutusaskelia, ennen kuin niiden lopullinen kunto arvioidaan. Tätä prosessia toistetaan, kunnes saavutetaan tyydyttävä määrä maksimikoulutusaskeleita.",
      "id": "task461-96ad6ea9c30e426fb3026d7616abac9c",
      "output": [
        "Miten Progressive Dynamic Hurdles toimii?"
      ]
    },
    {
      "input": "Taulukon TABREF64 tulokset osoittavat näiden skenaarioiden oikeellisuusasteet. Käyttäjän oikeellisuus on 7,5 % parempi kuin perusanalysaattorin (37,1 %:sta 44,6 %:iin), kun taas hybridimenetelmä päihittää molemmat, sillä sen oikeellisuus on 48,7 % ja parantaa perusanalysaattoria 11,6 %.",
      "id": "task461-2fb7a80225da4b5585d33ce40736ce6d",
      "output": [
        "Mitä kyselyjen selitysmenetelmää käyttäjät suosivat oikeellisuuden kannalta?"
      ]
    },
    {
      "input": "Ehdotetut fuusiotekniikat ::: Ensimmäinen ehdottamamme tekniikka on visuaalisten piirteiden vaiheittainen dekooderifuusio jokaisen ennustusvaiheen aikana, eli yhdistämme visuaalisen koodauksen kontekstiksi jokaisessa dekoodausprosessin vaiheessa. Ehdotetut fuusiotekniikat :::: Multimodaalinen huomiomodulaatioHyvin samanlainen kuin yleinen huomiomodulaatio BIBREF8, jossa vaihtelevan pituinen kohdistusvektori $a_{th}(s)$, jonka koko on yhtä suuri kuin lähdepuolen aika-askeleiden määrä, saadaan vertaamalla nykyistä piilotettua tavoitetilaa $h_{t}$ kuhunkin piilotettuun lähdetilaan $\\overline{h_{s}}}$; tarkastelemme muunnelmaa, jossa visuaalista koodausta $v_{t}$ käytetään laskemaan huomiojakauma $a_{ttv}(s)$ myös lähdekoodausten yli. Ehdotetut fuusiotekniikat ::: Visual-Semantic (VS) RegularizerVisuaalisen modaliteetin hyödyntämisessä valvonnassa BIBREF1 käyttää monitehtäväoppimista oppiakseen maadoitettuja representaatioita kuvarepresentaation ennustamisen avulla.",
      "id": "task461-4b10cd1d4b0a465f92b41e0cdab5006d",
      "output": [
        "Mitä kolmea uutta fuusiotekniikkaa on ehdotettu?"
      ]
    },
    {
      "input": "Tietokokonaisuuksien luotaus ja rakentaminenLuotausmenetelmämme alkaa rakentamalla haastetietokokonaisuuksia (kuva FIGREF1, keltainen laatikko) tietoresurssien kohdejoukosta. Kukin koettelemamme tietokokonaisuus koostuu monivalintakysymyksistä, jotka sisältävät kysymyksen $\\textbf {q}$ ja joukon vastausvaihtoehtoja tai ehdokkaita $\\lbrace a_{1},...a_{N}\\rbrace $. Tässä luvussa kuvataan yksityiskohtaisesti viisi erilaista tietokokonaisuutta, jotka muodostamme kahdesta asiantuntijatiedon lähteestä, nimittäin WordNet BIBREF35 ja GNU Collaborative International Dictionary of English (GCIDE). Kuvaamme kutakin tietolähdettä vuorollaan ja selitämme, miten tuloksena syntyvät tietokokonaisuudet, joita kutsumme WordNetQA:ksi ja DictionaryQA:ksi, rakennetaan.Yksinkertaisuuden vuoksi kuvaamme kutakin asiantuntijatiedon lähdettä suunnattuna, reunoilla merkitynä graafina $G$. Tämän graafin solmut ovat $\\mathcal {V} = \\mathcal {C} \\cup \\mathcal {W} \\cup \\mathcal {W} \\cup \\mathcal {S} \\cup \\mathcal {D}$, jossa $\\mathcal {C}$ on joukko atomisia käsitteitä, $\\mathcal {W}$ joukko sanoja, $\\mathcal {S}$ joukko lauseita ja $\\mathcal {D}$ joukko määritelmiä (ks. taulukko Taulukko TABREF4, jossa on yksityiskohtaiset tiedot WordNetistä ja GCIDE:stä). Jokainen $G$:n reuna on suunnattu $\\mathcal {C}$:n atomisesta käsitteestä $\\mathcal {C}$:n toiseen solmuun $V$:ssä, ja se on merkitty relaatiolla, kuten hypernymillä tai isa$^\\uparrow $:lla, relaatiojoukosta $\\mathcal {R}$ (ks. taulukko TABREF4).Määriteltäessä koekysymysmalleja on hyödyllistä tarkastella $G$:tä joukkona (relaatio-lähde-kohde-kohde) -kolmioita $\\mathcal {T}} \\subseteq \\mathcal {R} \\times \\mathcal {C} \\times \\mathcal {V}$. Koska tällaiset kolmikot ovat peräisin asiantuntijatietolähteestä, niiden semanttinen johdonmukaisuus säilyy. Esimerkiksi kun kolmion relaatio on def, vastaava reuna kuvaa $\\mathcal {C}$:n käsitettä $\\mathcal {D}$:n määritelmään.Luotaustietokokonaisuuksien rakentamisessa turvaudumme kahteen heuristiseen funktioon, jotka määritellään jäljempänä kullekin yksittäiselle luotaukselle: $\\textsc {gen}_{\\mathcal {Q}}(\\tau )$, joka tuottaa kultaisia kysymys-vastauspareja $(\\textbf {q},\\textbf {a})$ joukosta kolmioita $\\tau \\subseteq \\mathcal {T}$ ja kysymysmalleja $\\mathcal {Q}$, ja $\\textsc {distr}(\\tau ^{\\prime })$, joka tuottaa häiritseviä vastausvaihtoehtoja $\\lbrace a^{\\prime }_{1},...a^{{\\prime }_{N-1} \\rbrace $ perustuu toiseen kolmiojoukkoon $\\tau ^{\\prime }$ (jossa yleensä $\\tau \\subset \\tau ^{\\prime }$). Lyhyyden vuoksi käytämme $\\textsc {gen}(\\tau )$ kuvaamaan $\\textsc {gen}_{\\mathcal {Q}}(\\tau )$, jolloin kysymysmallit $\\mathcal {Q}$ jäävät implisiittisiksi.Dataset Probes and Construction ::: WordNetQAWordNet on englanninkielinen sanastotietokanta, joka koostuu noin 117 000 käsitteestä, jotka on järjestetty synsettien ryhmiin, joista kukin sisältää glossin (eli kohdekäsitteen määritelmän), joukon edustavia englanninkielisiä sanoja (ns. lemmat) ja noin 33 000 synsetissä esimerkkilauseet. Lisäksi monissa synseteissä on ISA-linkkejä muihin synsetteihin, jotka ilmaisevat monimutkaisia taksonomisia suhteita. Kuvassa FIGREF6 on esimerkki, ja taulukossa TABREF4 on yhteenveto siitä, miten WordNet on muotoiltu erilaisten kolmioiden $\\mathcal {T}$ joukoksi. Nämä kolmikot muodostavat yhdessä suunnatun, reunoilla merkityn graafin $G$. Tärkein motivaatiomme WordNetin käyttämiselle ConceptNetin BIBREF36 kaltaisen resurssin sijaan on se, että WordNetissä on saatavilla glosseja ($\\mathcal {D}$) ja esimerkkilauseet ($\\mathcal {S}$), joiden avulla voimme laatia luonnollisen kielen kysymyksiä, jotka kontekstualisoivat käsitteiden tyypit, joita haluamme kartoittaa.Tietokokonaisuuden kartoitukset ja rakentaminen ::: WordNetQA ::: Esimerkkien tuottaminen @!START@$\\textsc {gen}(\\tau )$@!END@.Rakennamme neljä yksittäistä tietokokonaisuutta, jotka perustuvat WordNetille ominaiseen semanttiseen suhteeseen (ks. BIBREF37): hypernymia (eli yleistäminen tai ISA-pohdinta taksonomiasta ylöspäin, ISA$^\\uparrow $), hyponyymia (ISA$^{\\downarrow }$), synonyymia ja määritelmät. Kussakin tapauksessa kysymysten tuottamiseksi käytämme useita sääntömalleja $\\mathcal {Q}$, jotka toimivat tupleihin. Osajoukko tällaisista malleista on esitetty taulukossa TABREF8. Mallit on suunniteltu jäljittelemään luonnontieteellisissä vertailuanalyyseissä havaitsemiamme naturalistisia kysymyksiä.Oletetaan esimerkiksi, että haluamme luoda kysymyksen $\\textbf {q}$ kohdekäsitteen $c \\in \\mathcal {C}$ määritelmästä. Valitaan ensin kysymysmalli $\\mathcal {Q}$:sta, jossa ensin esitellään käsite $c$ ja sen lemma $l \\in \\mathcal {W}$ asiayhteydessä esimerkkilauseen $s \\in \\mathcal {S}$ avulla ja sitten pyydetään tunnistamaan vastaava WordNet-kiilto $d \\in \\mathcal {D}$, joka toimii kultaisena vastauksena $\\textbf {a}$. Samoin toimitaan ISA-järkeilyn osalta; jokainen kysymys kahden käsitteen välisestä hypernym/hyponyymisuhteesta $c \\rightarrow ^{\\uparrow /\\downarrow } c^{\\prime } c^{\\prime} \\ in \\mathcal {T}_{i}$ (esim. $\\texttt {koira} \\rightarrow ^{\\uparrow /\\downarrow } \\texttt {eläin/terrieri}$) esittelee ensin kontekstin $c$:lle ja kysyy sitten vastausta, joka tunnistaa $c^{\\prime }$ (joka on myös varustettu glossilla, jotta se sisältää kaiken saatavilla olevan kontekstin).Jälkimmäisessä tapauksessa säännöt $(\\texttt {isa}^{r},c,c^{\\prime }) \\ in \\mathcal {T}_i$ taulukossa TABREF8 kattavat vain suorat ISA-linkit $c$:stä $r:n suuntaan \\ in \\lbrace \\uparrow ,\\downarrow \\rbrace $. Käytännössä jokaiselle $c$:lle ja suunnalle $r$ rakennamme testit, jotka kattavat kaikkien $c$:n suorien ja johdettujen ISA-suhteiden joukon HOPS$(c,r)$:Näin voimme arvioida, missä määrin mallit pystyvät käsittelemään monimutkaisia päättelymuotoja, jotka vaativat useita päättelyvaiheita tai hyppyjä: WordNetQA ::: Distractor Generation: Esimerkki distraktoreiden tuottamisesta on esitetty kuvassa FIGREF6, joka perustuu samanlaisiin periaatteisiin kuin edellä. Kullekin käsitteelle $c$ valitaan 4 häiritsevää vastausta, jotka ovat lähellä toisiaan WordNetin semanttisessa avaruudessa. Kun esimerkiksi rakennetaan hypernymiatestejä $c$:lle joukosta hops$(c,\\uparrow )$, muodostetaan distraktorit poimimalla $\\textsc {hopsc}(c,\\downarrow )$:sta (ja päinvastoin) sekä $c$:n $\\ell$-syvästä sisarperheestä, joka määritellään seuraavasti. 1-syvä sisarusperhe on yksinkertaisesti $c$:n sisarukset tai sisarukset eli muut lapset $\\tilde{c} \\ne c$ ja $c$:n vanhemman solmun $c^{\\prime }$ muut lapset. Jos $\\ell > 1$, $\\ell $-syvään sisarperheeseen kuuluvat myös jokaisen $\\tilde{c}$:n kaikki jälkeläiset aina $\\ell -1$ -tasolle asti, joita merkitään $\\textsc {hops}_{\\ell -1}(\\tilde{c},\\downarrow )$. Muodollisesti: Määritelmiä ja synonyymejä varten muodostamme distraktorit kaikista näistä joukoista (ja sisar distraktoreiden syvyyttä rajoitetaan samalla tavalla kuin edellä). Näin voimme systemaattisesti tutkia mallin suorituskykyä laajalla valikoimalla distraktorijoukkoja.Dataset Probes and Construction ::: WordNetQA ::: Häiriöt ja semanttiset klusteritKunkin käsitteen $c$ (eli atomisen WordNet-synsetin) ja koettimen tyypin (eli määritelmät, hypernymiat jne.) osalta meillä on aineiston tuottamistavan perusteella monenlaisia $c$:hen liittyviä kysymyksiä, jotka manipuloivat 1) johtopäätösten monimutkaisuutta (esim. johtopäätösten hyppyjen määrää) ja 2) käytettyjen häiriötekijöiden tyyppejä (tai häiriötekijöiden häiriötekijöitä). Kutsumme tällaisia joukkoja semanttisiksi klustereiksi. Kuten kuvaamme seuraavassa jaksossa, semanttisten klustereiden avulla voimme kehittää uudenlaisia arviointitapoja, jotka paljastavat, onko malleilla kattava ja johdonmukainen tietämys kohdekäsitteistä (esim. arvioimalla, pystyykö malli vastaamaan oikein useisiin käsitteeseen liittyviin kysymyksiin, toisin kuin muutamaan erilliseen tapaukseen).Yksittäisten tietokokonaisuuksien yksityiskohdat esitetään taulukossa TABREF12. Noudatamme BIBREF22:ta ja käytämme näistä joukoista enintään 3 000 esimerkkiä harjoitteluun ja varaamme loput kehitykseen ja testaukseen. Koska olemme kiinnostuneita koettelemisesta, suurten pidätettyjen joukkojen avulla voimme tehdä yksityiskohtaista analyysia ja klusteripohjaista arviointia. datasetin koetteleminen ja rakentaminen ::: Se on kattava avoimen lähdekoodin englanninkielinen sanakirja, joka on rakennettu pitkälti Webster's Revised Unabridged Dictionary BIBREF38 -sanakirjan pohjalta. Kukin merkintä koostuu sanasta, sen puhekielestä, määritelmästä ja valinnaisesta esimerkkilauseesta (ks. taulukko TABREF14). Kaiken kaikkiaan 33k merkintää (yhteensä 155k:sta) sisältää esimerkkilauseita/käyttötarkoituksia. Kuten WordNetin koeasetusten kohdalla, keskitymme tähän osajoukkoon, jotta voimme kontekstualisoida jokaisen koekäytettävän sanan. Toisin kuin WordNetissä, GCIDE:ssä ei ole ISA-suhteita tai eksplisiittisiä synsettejä, joten pidämme jokaista yksittäistä merkintää erillisenä merkityksenä. Tämän jälkeen käytämme sanakirjamerkintöjä luodaksemme koettimen, joka keskittyy sanan merkityksen erotteluun, kuten jäljempänä kuvataan. datasetin koettimet ja rakentaminen ::: DictionaryQA ::: Esimerkkien ja häiriötekijöiden tuottaminen: Kultakysymysten ja -vastausten tuottamiseen käytämme samoja määritelmien tuottamismalleja kuin kuvassa TABREF8 on esitetty WordNetQA:lle. Häiritsevien tekijöiden tuottamiseksi otamme yksinkertaisesti kohdesanoille vaihtoehtoisia määritelmiä, jotka edustavat eri sanamerkitystä (esim. taulukossa TABREF14 esitetyt lahjan vaihtoehtoiset määritelmät), sekä satunnaisesti valitut määritelmät, jos ne ovat tarpeen viisitahoisen monivalintakysymyksen luomiseksi. Kuten edellä, varaamme harjoitteluun enintään 3k esimerkkiä. Koska tässä tietokokonaisuudessa on yhteensä vain 9k esimerkkiä (ks. WordSense taulukossa TABREF12), varaamme myös 3k kutakin kehittämistä ja testausta varten. Huomaa, että ensimmäiset yritykset rakentaa tämä tietokokonaisuus tavanomaisen satunnaisen jakamisen avulla johtivat tiettyihin systemaattisiin vääristymiin, joita seuraavassa jaksossa kuvatut vain valintamahdollisuuksiin perustuvat perusmallit käyttivät hyväkseen ja jotka siten paisuttivat mallien kokonaispistemääriä. Useiden suodatusyritysten jälkeen havaitsimme, että muiden tekijöiden ohella määritelmien käyttäminen häiritsevinä tekijöinä merkinnöistä, joissa ei ole esimerkkilauseet (esim. taulukon TABREF14 kaksi ensimmäistä merkintää), korreloi yllättävästi tällaisten vääristymien kanssa. Tämä viittaa siihen, että mahdolliset vääristymät, jotka liittyvät esimerkkejä sisältävien ja ilman esimerkkejä olevien sanakirjamerkintöjen välisiin eroihin, voivat pilata tuloksena syntyvän automaattisesti luodun MCQA-aineiston (lisätietoja automaattiseen tietokokonaisuuksien luomiseen liittyvistä sudenkuopista on kohdassa SECREF5).",
      "id": "task461-e6c91e118ad041388eecc9f9cd4a05b8",
      "output": [
        "Valvotaanko automaattisesti muodostettujen tietokokonaisuuksien laatua?"
      ]
    },
    {
      "input": "Vastausten hakua varten luodaan INLINEFORM4 -tietokanta, joka antaa INLINEFORM5 -tarkkuuden ja INLINEFORM6 -kattavuuden.",
      "id": "task461-9dd59e942e014d1fbf62e4bf01a698bc",
      "output": [
        "Käyttävätkö he indeksointiin perustuvaa menetelmäänsä luodakseen näytteen QA-Wikipedian tietokokonaisuudesta?"
      ]
    },
    {
      "input": "Yksi esimerkki havainnollistaa, että mallin tekemät virheet voivat liittyä puoluepolitiikan muutoksiin.",
      "id": "task461-c807b33f770a487998bab2699d735e10",
      "output": [
        "Selittävätkö poliittisten toimijoiden politiikkojen muutokset kaikki mallin tekemät virheet?"
      ]
    },
    {
      "input": "GANN on uusi neuroverkkomalli APC-tehtävää varten, jonka tarkoituksena on ratkaista perinteisten RNN- ja CNN-verkkojen puutteet. GANN sovelsi Gate Truncation RNN (GTR) -menetelmää oppiakseen informatiivisia, aspektiriippuvaisia sentimenttivihjeiden representaatioita. GANN saavutti parhaan mahdollisen APC-suorituskyvyn kiinalaisissa arvostelutietoaineistoissa.",
      "id": "task461-7975115550024df2b8070c044033c344",
      "output": [
        "Mikä oli neljän kiinalaisen arviointiaineiston aiempi taso?"
      ]
    },
    {
      "input": "Raakakorpuksena käytimme japanilaista web-korpusta, joka koottiin BIBREF13:n ehdottamien menettelyjen avulla.  Noin 100 miljoonan lauseen korpuksesta saatiin 1,4 miljoonaa tapahtumaparia AL:lle, 41 miljoonaa CA:lle ja 6 miljoonaa CO:lle.",
      "id": "task461-06a1b6da31cd4f318a81da72100a9a90",
      "output": [
        "Kuinka suuri on koulutukseen käytettävä raakakorpus?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme on kommentoitu Ruijinin sairaalan ruoansulatuskanavan kirurgian osaston toimittamien kiinalaisten patologisten raporttien perusteella. Se sisältää 17 833 lausetta, 826 987 merkkiä ja 2 714 kysymys-vastausparia.",
      "id": "task461-0f3a574eee544ab2ad1fec8fcc027689",
      "output": [
        "Kuinka monta kysymystä tietokokonaisuudessa on?",
        "Kuinka suuri on Ruijingin sairaalasta kerättyjen patologisten raporttien tietokanta?"
      ]
    },
    {
      "input": "Kaikkien sarjojen tulokset osoittavat merkittävän eron tarkkuuden ja palautuksen välillä, sillä tarkkuus on huomattavasti suurempi kuin palautus. Myös kehitys- ja testijoukosta saatujen tulosten (F1 = 89,60, F1 = 87,82) ja täydentävästä testijoukosta saatujen tulosten (F1 = 71,49) välillä on merkittävä ero. Nämä erot selittyvät todennäköisesti lisätestijoukon ja kehitys- ja testijoukon välisellä aikaerolla (lisätestijoukon otsikot ovat eri ajanjaksolta kuin harjoitusjoukko).",
      "id": "task461-8990f21e71e647dda9f3046d9d54c3da",
      "output": [
        "Mikä on CRF-mallin suorituskyky kuvatussa tehtävässä?"
      ]
    },
    {
      "input": "Korpusten monipuolisuuden lisäämiseksi valitsimme 4 englanninkielistä korpusta ja 4 mandariininkielistä korpusta vähäisten resurssien kielikorpusten lisäksi.",
      "id": "task461-847ca293174a412bbc79ad40bcc85dd6",
      "output": [
        "Testaavatko ne lähestymistapaansa suurten resurssien tehtävissä?"
      ]
    },
    {
      "input": " Jotta koulutettua mallia voidaan käyttää, testisarjat käännetään ensin englanniksi konekääntämisen avulla, minkä jälkeen tehdään päättely.   Konekääntämisessä käytetään Googlen käännösrajapintaa.",
      "id": "task461-5962354cdc1b4f4cbefeabd5601b81fb",
      "output": [
        "miten kirjoittajat käänsivät arvostelut muille kielille?"
      ]
    },
    {
      "input": "Kokeilemme viittä vertailuanalyysimenetelmää tekstien hyökkäämiseksi: FGM, FGVM, DeepFool BIBREF5, HotFlip BIBREF3) ja TYC BIBREF4.",
      "id": "task461-c30c2e6bcc6d4e81b16050f1d4167ab7",
      "output": [
        "Mitkä ovat vertailukohtana käytettävät hyökkäysmenetelmät?"
      ]
    },
    {
      "input": "Työskentelemme tietokokonaisuuden kanssa, joka koostuu 3 206 uutisartikkelista, joista jokainen on merkitty joko oikeaksi tai väärennetyksi, ja 1 603 oikeaa ja väärennettyä artikkelia on jaettu täydellisesti 50/50.",
      "id": "task461-c9a1d511fb344dedbe7894122d7ae406",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Raportoimme segmentointituloksen tarkkuuden, palautuksen ja F-mitan avulla rajojen (BP, BR, BF) ja merkkien (WP, WR, WF) osalta. Raportoimme myös tarkan vastaavuuden (X) mittarin, joka laskee oikein segmentoitujen lausumien osuuden.",
      "id": "task461-888d17ea0d934e33b3f638fc4fad3fca",
      "output": [
        "Miten sanojen segmentointitehtävä arvioidaan?"
      ]
    },
    {
      "input": "Luotettavaa usean matkan päättelyä varten OpenIE-tupeleiden avulla voimme lisätä tukigraafihakuun kuplettien välisiä yhteyksiä, joita ohjataan pienellä määrällä OpenIE-predikaatteja koskevia sääntöjä. Tällaisten sääntöjen oppiminen tieteen alaa varten on avoin ongelma ja mahdollinen tulevan työn kohde.",
      "id": "task461-2b9360d4a3104b13887cc50ee9e09a51",
      "output": [
        "Voidaanko menetelmän avulla vastata monihyppykysymyksiin?",
        "Pystyykö heidän menetelmänsä päättelemään usean matkan kautta?"
      ]
    },
    {
      "input": "Käytimme kokeissa kahta eri korpusta: small_parallel_enja ja Asian Scientific Paper Excerpt Corpus (ASPEC) BIBREF5.",
      "id": "task461-fa7eaadf471d42619217dee1a7b0141e",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Molemmissa tapauksissa käytämme sanaa malli, joka on yksi klassisen/tilastollisen LSA:n ja luokittelijan mahdollisista yhdistelmistä. Käytetyt luokittelijat ovat tukivektorikone (SVM), logistinen regressio (Log.Reg), satunnainen metsä (RF) ja gradienttihäviö (XGB). Tarvittaessa tuloksia verrataan kirjallisuudessa jo esitettyihin tuloksiin.",
      "id": "task461-84fa0926937a4a28bd5b3a248e28900c",
      "output": [
        "Mitä eri menetelmiä käytetään eri korporaatioihin?"
      ]
    },
    {
      "input": "Käytämme Gaussin prosesseja, koska tämä todennäköisyysperusteinen kerneloitu kehys välttää kalliin ristiinvalidoinnin tarpeen hyperparametrien valinnassa.",
      "id": "task461-fa4b941c20c84037ae31644004432084",
      "output": [
        "Miksi Gaussin prosessi on erityisen sopiva menetelmä tähän luokitusongelmaan?"
      ]
    },
    {
      "input": "Osoittaaksemme, että yhteistyöelimen ranskankielisen version luominen on hyödyllistä, vertaamme ensin CamemBERTiä monikieliseen yhteistyöelimen koteloituun versioon (mBERT).",
      "id": "task461-ed9d3a7d6577455ca278899477c046a1",
      "output": [
        "Verrattiinko CamemBERTiä monikieliseen yhteistyöelimeen näissä tehtävissä?"
      ]
    },
    {
      "input": "Vertailemme ja analysoimme huolellisesti eri kontekstin mallintamismenetelmien suorituskykyä kahdella suurella, monimutkaisella ja monialaisella tietokokonaisuudella, SParC BIBREF2:lla ja CoSQL BIBREF6:lla, tehtyjen kokeiden avulla. ",
      "id": "task461-daaba9b1304e40bb97ed5f4f1d53f6b3",
      "output": [
        "Mitä kahta suurta tietokokonaisuutta käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Julkisessa tulostaulukossa ilmoitettu lopputulos on 0,73019 ja yksityisessä tulostaulukossa 0,58455. Se on melko erilainen huonolla tavalla. Tämä saattaa johtua siitä, että malli on sovitettu liikaa harjoitusjoukkoon ja viritetty julkiseen testijoukkoon.",
      "id": "task461-fd42acd185b84062b3fb1b26fa61ad1e",
      "output": [
        "Mikä on julkinen kojelauta?",
        "Mikä on yksityinen kojelauta?"
      ]
    },
    {
      "input": "hierarkkinen Tässä asiakirjassa käytämme vuoden 2019 GermEvalin hierarkkisen tekstiluokittelun jaetun tehtävän BIBREF0 tietokokonaisuutta ja käytämme ennalta määriteltyä merkintäjoukkoa arvioidaksemme lähestymistapaamme tähän luokittelutehtävään.",
      "id": "task461-cbee6fa56d14407a820a80ec96f57d79",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "n-grammi: Tarkastelemme 3-grammaista ja 4-grammaista ehdollista kielimallin perustasoa interpoloinnin kanssa. Interpoloidun mallin parhaat kertoimet etsitään satunnaisruutujen avulla: Käytämme fconv-arkkitehtuuria BIBREF24 ja oletushyperparametreja fairseq BIBREF25 -kehyksestä. Koulutamme verkon ADAM-optimointilaitteella BIBREF26 oppimisnopeuden ollessa 0,25 ja keskeytystodennäköisyyden ollessa 0,2. LSTM: Tarkastelemme LSTM-malleja BIBREF27 huomion kanssa ja ilman huomiota BIBREF28 ja käytämme tensor2tensor BIBREF29 -puitteistoa LSTM-peruslinjoihin. Käytämme kaksikerroksista LSTM-verkkoa sekä koodaimessa että dekoodaimessa 128-ulotteisilla piilovektoreilla: Kuten LSTM-verkoissa, käytämme tensor2tensor-kehystä Transformer-malliin. Transformer BIBREF21 -mallimme käyttää 256 ulottuvuutta sekä syötteen upottamiseen että piilotetilaan, 2 kerrosta ja 4 huomiopäätä. Sekä LSTM:n että Transformerin osalta koulutamme mallin ADAM-optimoijalla ($\\beta _{1} = 0.85$, $\\beta _{2} = 0.997$) ja pudotustodennäköisyys on asetettu 0.2.GPT-2: Valvottujen seq2seq-mallien lisäksi otamme mukaan myös tuloksia valmiiksi koulutetusta GPT-2 BIBREF30 -mallista, joka sisältää 117 miljoonaa parametria.",
      "id": "task461-151fe5a0d1f04080b2a51e95c4690eca",
      "output": [
        "Mitä perusmalleja on tarjolla?"
      ]
    },
    {
      "input": "Tieteellisen julkaisun koko tekstin perusteella haluamme asettaa sen viittaukset paremmuusjärjestykseen kirjoittajan arvioiden mukaan. Keräsimme viimeaikaisia julkaisuja avoimista PLoS-lehdistä ja pyysimme kirjoittajia asettamaan läheisyyden mukaan paremmuusjärjestykseen viisi viittausta, jotka valitsimme heidän julkaisustaan.",
      "id": "task461-0ab7d66f64fe4f9f9901dff7c17a877b",
      "output": [
        "mitä joukkoistamisalustaa käytetään?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa keskitytään Switchboard-300:een, joka on 300 tuntia kestävä englanninkielinen puheentunnistustehtävä. Switchboard-300:lla saamiemme parhaiden tulosten vastakohtana koulutamme seq2seq-mallin myös 2000 tunnin Switchboard+Fisher -aineistolla. ",
      "id": "task461-8f8b120a0e62468dbb36b65ee2ff3057",
      "output": [
        "Kuinka paljon suurempi Switchboard-2000 on kuin Switchboard-300-tietokanta?"
      ]
    },
    {
      "input": "Teksti- ja kuvakoodaukset yhdistettiin ketjuttamalla, jolloin saatiin 4 864 ulottuvuuden ominaisvektori. Tämä multimodaalinen esitys syötettiin sen jälkeen syötteenä monikerroksiseen perceptroniin (MLP), jossa oli kaksi piilokerrosta, joissa oli 100 neuronia ja ReLU-aktivointifunktio.",
      "id": "task461-f8842a590ae845718754d8ba4d1a9473",
      "output": [
        "Onko tietokokonaisuus multimodaalinen?"
      ]
    },
    {
      "input": " Pyramidipisteytyksessä kultaisen ihmisen kirjallisten tiivistelmien sisältöyksiköt järjestetään pyramidin muotoon. Tässä pyramidissa sisältöyksiköt on järjestetty tasoihin, ja pyramidin korkeammat tasot merkitsevät suurempaa tärkeyttä. ",
      "id": "task461-3e0861be0de341f0b338919a39a4c4ce",
      "output": [
        "Mitä manuaalisia Pyramid-pisteitä käytetään?"
      ]
    },
    {
      "input": "SemEval-2010-vertailutietokanta BIBREF0 koostuu 244 tieteellisestä artikkelista, jotka on kerätty ACM Digital Library -kirjastosta (konferenssi- ja seminaariasiakirjat).",
      "id": "task461-10754b4976a3472aa78d6c3d1cad09f7",
      "output": [
        "kuinka monta artikkelia aineistossa on?"
      ]
    },
    {
      "input": "Esittelemme uuden 23 700 kyselystä koostuvan joukkoistetun tietokokonaisuuden, johon sisältyy 22 500 kattavaa kyselyä, jotka kattavat 150 tarkoitusta ja jotka voidaan ryhmitellä 10 yleiseen alaan. ",
      "id": "task461-5506d0904a834787b5ed10dca954dbf2",
      "output": [
        "Mistä tiedot ovat peräisin?"
      ]
    },
    {
      "input": " Katunäkymäympäristömme integroitiin ParlAI BIBREF6 -ohjelmaan, ja sitä käytettiin Mechanical Turk -palvelussa laajamittaisen tietokokonaisuuden keräämiseen, joka koski ihmisten havaitsemista, toimintaa ja viestintää.",
      "id": "task461-bbfc888cf3d2412e93e6c53e1afb144d",
      "output": [
        "Mitä tietoja he käyttivät?"
      ]
    },
    {
      "input": "BIBREF5 käyttää koneoppimista NER:ää varten. Heidän NER-järjestelmänsä poimii lääketieteellisiä ongelmia, testejä ja hoitoja kotiutusyhteenvedoista ja potilaskertomuksista. Käytetty tietokokonaisuus on i2b2 2010 challenge -tietokokonaisuus. ",
      "id": "task461-517e927d3b0b4519ae1ca25b8bf7f629",
      "output": [
        "Tutkitaanko asiakirjassa sähköisistä terveyskertomuksista poimittua tietoa?"
      ]
    },
    {
      "input": "Tässä asiakirjassa kokeillaan kahta eri mallia ja verrataan niitä toisiinsa. ",
      "id": "task461-e42f94df12c44149b40aefc15e2cc188",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Parafraasin tunnistaminen (PI) on tehtävä, jolla määritetään, ovatko kaksi lausetta parafraasia vai eivät. Olemme toteuttaneet kernelfunktioiden kieltenvälisen muunnoksen PI- ja RE-tehtäviä varten SECREF3-jaksossa kuvatulla tavalla ja mitanneet mallien tarkkuutta testaamalla niitä rinnakkaisella aineistolla.",
      "id": "task461-862828193c354048997c644bb2828dfb",
      "output": [
        "Mitä luokittelutehtävää käytettiin tässä työssä kuvatun monikielisen mukauttamismenetelmän arvioinnissa?"
      ]
    },
    {
      "input": "Toisen esityksemme tulos on 82,4 $F_1$ virallisessa testijoukossa, ja se sijoittuu neljänneksi $4$ tässä jaetussa tehtävässä.",
      "id": "task461-179e4927fba74d70a73653f2b1366320",
      "output": [
        "Mihin tämä malli sijoittui jaetun tehtävän lopullisessa arvioinnissa?"
      ]
    },
    {
      "input": "Tästä syystä otamme käyttöön ratkaisutapamuuttujat $\\Pi = \\lbrace \\pi _1, \\ldots , \\pi _n\\rbrace $ , jossa kunkin maininnan $j$ osalta muuttuja $\\pi _j \\in \\lbrace str, prec, attr\\rbrace $ osoittaa, missä tilassa maininta olisi ratkaistava. Mallissamme määritellään kolme ratkaisutapaa - merkkijonojen täsmäytys (str), täsmällinen rakenne (prec) ja attribuuttien täsmäytys (attr) - ja $\\Pi $ on deterministinen, kun $D$ on annettu (eli $P(\\Pi |D)$ on pistejakauma). Määritämme $\\pi _j$ kullekin maininnalle $m_j$ seuraavasti: $\\pi _j = str$ , jos on olemassa sellainen maininta $m_i, i < j$ , että nämä kaksi mainintaa täyttävät Stanfordin BIBREF1 -monisieppijärjestelmän merkkijono-oikaisun seulan (String Match sieve), rennon merkkijono-oikaisun (Relaxed String Match seulan) tai tiukan pää-oikaisun (Strict Head Match A seulan).$\\pi _j = prec$ , jos on olemassa maininta $m_i, i < j$ , jonka molemmat maininnat täyttävät Speaker Identification -seulan tai Precise Constructs -seulan.$\\pi _j = attr$ , jos mikään maininta $m_i, i < j$ ei täytä edellä mainittuja kahta ehtoa.",
      "id": "task461-2ffa62b4973c462e84b9e1b54390e58c",
      "output": [
        "Mitä ovat resoluutiomallin muuttujat?",
        "Ovatko resoluutiotilan muuttujat käsityönä tehtyjä?"
      ]
    },
    {
      "input": "Pystyimme jo yhdellä tekstillä ennustamaan sähkönkulutuksen alle 5 prosentin suhteellisella virheellä molemmissa aineistoissa.",
      "id": "task461-aa595e4546294ee78a8cb9ad75e25722",
      "output": [
        "Kuinka tarkka malli on koulutettu yksinomaan tekstin perusteella?"
      ]
    },
    {
      "input": "Tämä dekoodausmenetelmä vastaa hyvin pitkälti algoritmia SECREF7 , mutta pehmeiden takaisinkytkentöjen lisäksi lasketaan myös kovat takaisinkytkennät jokaisella aika-askeleella. Kun kaikki merkitykselliset suureet, kuten mallin pisteet, häviöt jne. on laskettu, seuraamme kovia takaisinsoittimia saadaksemme parhaan sekvenssin INLINEFORM0 .",
      "id": "task461-7c8ed00e6cd84bf0a5d6fb6f02c34fd3",
      "output": [
        "Vertailevatko ne osittain valmiita sekvenssejä (jotka on luotu säteenhaun vaiheiden aikana) kulta-/kohdesekvensseihin?"
      ]
    },
    {
      "input": "Lauseiden luokittelussa yhdistetään luonnollisen kielen käsittely (NLP) ja koneoppiminen lauseiden rakenteen suuntausten tunnistamiseksi, BIBREF14 , BIBREF15 . Kukin twiitti muunnetaan numeeriseksi sanavektoriksi, jotta voidaan tunnistaa erottelevat piirteet kouluttamalla NLP-luokittimen validoidulle joukolle relevantteja twiittejä. Luokittelija toimii välineenä, jolla seulotaan mainokset, uutiset ja kommentit, jotka eivät liity potilaisiin. Järjestelmässämme yhdistetään logistinen regressioluokittelija, BIBREF16 , ja konvolutiivinen neuroverkko (Convolutional Neural Network, CNN), BIBREF17 , BIBREF18 , tunnistamaan itse ilmoitetut diagnoositwiititit.On tärkeää varoa automaattisia tilejä (esim. botteja, roskapostia), joiden suuri määrä twiittejä saastuttaa asiaankuuluvan orgaanisen sisällön, BIBREF19 , ja voi vääristää sentimenttianalyysejä, BIBREF20 . Ennen lauseiden luokittelua poistimme hyperlinkkejä sisältävät twiitit automaattisen sisällön poistamiseksi (osa orgaanisesta sisällöstä häviää väistämättä tällä tiukalla rajoituksella). Twitter antaa käyttäjille mahdollisuuden levittää toisten käyttäjien sisältöä \"uudelleentwiittaamalla\". Poistimme myös nämä viestit ennen luokittelua, jotta potilaiden kirjoittamat twiitit saatiin eristettyä. Otimme huomioon myös epäolennaisen astrologisen sisällön poistamalla kaikki twiitit, jotka sisälsivät jonkin seuraavista horoskooppi-indikaattoreista: `astrologia', `zodiac', `astronomia', `horoskooppi', `aquarius', `pisces', `aries', `taurus', `leo', `virgo', `libra' ja `scorpio'. Esikäsittelimme twiitit pienentämällä kirjaimia ja poistamalla välimerkit. Analysoimme myös vain sellaiset twiitit, joiden kohdalla Twitter oli tunnistanut `en' englannin kieleksi.",
      "id": "task461-7ab9344796e142548de0063031f6a143",
      "output": [
        "Mitä koneoppimis- ja NLP-menetelmiä käytettiin rintasyöpäkokemuksiin liittyvien twiittien seulomiseen?"
      ]
    },
    {
      "input": "Olemme arvioineet Nefnirin tulosta 21 093 merkkiä ja niiden oikeita lekseemejä sisältävää vertailukorpusta vastaan.Vertailukorpuksen näytteet poimittiin kahdesta suuremmasta korpuksesta, jotta saatiin monipuolinen sanavarasto:",
      "id": "task461-5b1e24f76338472ca79b889eaecb39e4",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Käytämme BIBREF12:n huipputason lähestymistavan ohjeita, sillä se saavutti parhaan taivutustarkkuuden viimeisimmässä SIGMORPHON 2019 -morfologisen taivutuksen jaetussa tehtävässä. Mallimme on toteutettu DyNet BIBREF13 -ohjelmalla. Koulutimme koodaaja-dekooderimallin, joka vastaanottaa lomakkeen merkkitason syötteenä, koodaa sen BiLSTM-koodaajalla ja sitten huomiolla parannettu dekooderi BIBREF14 tuottaa vastaavan morfologisten tunnisteiden sarjan, joka on toteutettu DyNetissä. Koulutimme merkkitason koodaaja-dekooderimallin, joka on samanlainen kuin edellä mainittu taivutusjärjestelmä ja joka on toteutettu DyNetissä.",
      "id": "task461-9dcfea5f50114a73ae11d29509bb1c96",
      "output": [
        "Mitä arkkitehtuureja käytetään näihin kolmeen tehtävään?",
        "Mitä järjestelmää käytetään perustasona?"
      ]
    },
    {
      "input": "Ariston nykyisessä kokoonpanossa on kahdeksan ratkaisijaa, jotka kuvataan lyhyesti ja joista jokainen yrittää vastata monivalintakysymykseen. Tiettyjen ilmiöiden tutkimiseksi ja ratkaisijoiden kehittämiseksi hankkeessa on luotu suurempia tietokokonaisuuksia erilaisten ongelmien monistamiseksi ja tutkimiseksi, minkä tuloksena on syntynyt 10 uutta tietokokonaisuutta ja 5 suurta tietovarantoa yhteisölle.ratkaisijat voidaan ryhmitellä löyhästi seuraaviin ryhmiin:Tilastolliset ja tiedonhakumenetelmätJärkeilevät menetelmätSuurten kielimallien menetelmät Hankkeen keston aikana menetelmien suhteellinen painoarvo on siirtynyt suurten kielimallien menetelmiin. NLP:n ala on kehittynyt huomattavasti, kun on tullut käyttöön suuren mittakaavan kielimalleja, kuten ELMo (BID6), ULMFit (BID37), GPT (BID38), BERT (BID7) ja RoBERTa (BID8). Nämä mallit on koulutettu suorittamaan erilaisia kielen ennustustehtäviä, kuten ennustamaan puuttuva sana tai seuraava lause, käyttäen suuria tekstimääriä (esim. BERT koulutettiin Wikipedian ja Googlen 10 000 kirjasta koostuvan kirjakorpuksen avulla). Niitä voidaan myös hienosäätää uusiin kielen ennustustehtäviin, kuten kysymyksiin vastaamiseen, ja ne ovat menestyneet erinomaisesti niiden muutaman kuukauden aikana, jotka ne ovat olleet käytettävissä. Sovellamme BERTiä monivalintakysymyksiin käsittelemällä tehtävää luokitteluna: Kun annetaan kysymys $q$, jossa on vastausvaihtoehdot $a_{i}$ ja valinnainen taustatieto $K_{i}$, annamme sen BERT:lle muodossa: [CLS] $K_i$ [SEP] $q$ [SEP] $a_{i}$ [SEP] AristoBERT-ratkaisija käyttää kolmea menetelmää BERT:n soveltamiseksi tehokkaammin. Ensinnäkin haemme ja annamme taustatietoa kysymyksen mukana, kun käytämme BERTiä. Tämä antaa yhteistyöelimelle mahdollisuuden \"lukea\" tätä taustatietoa ja soveltaa sitä kysymykseen, vaikka taustatiedon käytön tarkka luonne onkin monimutkaisempi ja vaikeammin tulkittavissa. Toiseksi hienosäädämme yhteistyöelintä käyttämällä useiden tietokokonaisuuksien opetussuunnitelmaa, mukaan lukien joitakin, jotka eivät liity luonnontieteisiin. Lopuksi kootaan yhteen yhteistyöjärjestelmän eri muunnelmia.",
      "id": "task461-78635092630e4eb69a6aa33515e70166",
      "output": [
        "Onko Aristo vain jokin moderni NLP-malli (esim. BERT), joka on hienosäädetty tätä tehtävää varten?"
      ]
    },
    {
      "input": "Lisäksi käytämme BLEU-pistemäärää BIBREF21-sukupolvien tarkkuuden arvioimiseksi ja erillisten n-grammien lukumäärää BIBREF6-sukupolvien monimuotoisuuden arvioimiseksi. ",
      "id": "task461-a67c3cf89ece4d3d8e64274ba0617c3e",
      "output": [
        "Miten ne mittaavat johtopäätösten monimuotoisuutta?"
      ]
    },
    {
      "input": "Apulauseen rakentaminen Yksinkertaisuuden vuoksi kuvaamme menetelmäämme pääasiassa TABSA:n avulla.Tarkastelemme seuraavia neljää menetelmää TABSA-tehtävän muuntamiseksi lauseparien luokittelutehtäväksi:Lause, jonka haluamme tuottaa kohde- ja näkökulmaparista, on kysymys, ja sen muodon on oltava sama. Esimerkiksi kohde-näkökulmaparin (SIJAINTI1, turvallisuus) joukosta generoimamme lause on \"mitä mieltä olet sijainnin - 1 turvallisuudesta?\" NLI-tehtävässä ehdot, jotka asetamme lauseita generoitaessa, eivät ole yhtä tiukkoja, ja muoto on paljon yksinkertaisempi. Tällä kertaa luotu lause ei ole tavallinen lause, vaan yksinkertainen pseudolause, jonka esimerkkinä on (SIJAINTI1, turvallisuus) -pari: apulause on: \"sijainti - 1 - turvallisuus\". QA-B:tä varten lisätään etikettitieto ja muunnetaan TABSA väliaikaisesti binääriseksi luokitusongelmaksi ( INLINEFORM0 ) todennäköisyysjakauman saamiseksi. Tällä hetkellä kukin kohde-aspekti - pari tuottaa kolme sekvenssiä, kuten \"sijainti - 1:n turvallisuusaspektin polariteetti on positiivinen\", \"sijainti - 1:n turvallisuusaspektin polariteetti on negatiivinen\", \"sijainti - 1:n turvallisuusaspektin polariteetti ei ole mikään\". Käytämme INLINEFORM1:n todennäköisyysarvoa vastaavuuspistemääränä. Sellaisen kohde-aspekti-parin kohdalla, joka tuottaa kolme sekvenssiä ( INLINEFORM2 ), otamme sen sekvenssin luokan, jolla on korkein vastaavuuspistemäärä ennustettua luokkaa varten. NLI-B:n ja QA-B:n ero on siinä, että apulause muuttuu kysymyksestä pseudolauseeksi. Apulauseet ovat: \"sijainti - 1 - turvallisuus - positiivinen\", \"sijainti - 1 - turvallisuus - negatiivinen\" ja \"sijainti - 1 - turvallisuus - ei mitään\".Kun olemme rakentaneet apulauseen, voimme muuttaa TABSA-tehtävän yhden lauseen luokittelutehtävästä lauseparien luokittelutehtäväksi. Kuten taulukosta TABREF19 käy ilmi, tämä on välttämätön toimenpide, joka voi parantaa merkittävästi TABSA-tehtävän kokeellisia tuloksia.",
      "id": "task461-949ecbd818054f6b951ab065c30abd36",
      "output": [
        "Miten ne tuottavat apulauseen?"
      ]
    },
    {
      "input": "Olemme ladanneet julkisesti saatavilla olevasta resurssista 1 873 Twitter-keskusteluketjua, noin 14 000 twiittiä, jotka on aiemmin esikäsitelty ja joista on poimittu keskusteluketjut.",
      "id": "task461-6165e1941403467f8c62a92e03d9344f",
      "output": [
        "Kuinka suuri Twitter-tietokanta on?"
      ]
    },
    {
      "input": "Lisäksi testaamme heidän suorituskykyään vain Zürichin ja Vispin murteella, koska suurin osa näytteistä on näistä kahdesta murteesta. Taulukossa TABREF15 esitetään näiden kahden mallin vertailun tulokset.",
      "id": "task461-01ddb05439fc4ac294dac3f5f80c69ab",
      "output": [
        "Arvioidaanko mallia grafeemien ja foneemien välisessä tehtävässä?"
      ]
    },
    {
      "input": "Perusarvot. Vertaamme lähestymistapaamme (FacTweet) seuraaviin perusasetuksiin: LR + Bag-of-words: Tweet2vec: Käytämme BIBREF20:ssä ehdotettua Bidirectional Gated recurrent neural network -mallia. Pidämme oletusarvoiset parametrit, jotka toimitettiin toteutuksen mukana. Twiittien esittämiseen käytämme mallin tuottamaa dekoodattua upotusta. Tämän perustason avulla pyrimme arvioimaan, voivatko twiittien hashtagit auttaa havaitsemaan ei-todennäköiset tilit.LR + All Features (twiittitaso): Poimimme jokaisesta twiitistä kaikki piirteemme ja syötämme ne LR-luokittimeen. Tässä tapauksessa emme aggregoi twiittejä ja tarkastelemme näin ollen jokaista twiittiä itsenäisesti.LR + All Features (chunk-level): Yhdistämme chunkissa olevien twiittien piirrevektorit ja syötämme ne LR-luokittimeen.FacTweet (twiittitaso): Samanlainen kuin FacTweet-lähestymistapa, mutta twiittitasolla; twiittien peräkkäistä kulkua ei hyödynnetä. Tavoitteena on tutkia twiittien peräkkäisen virtauksen merkitystä. top-$k$ vastaukset, tykkäykset tai uudelleentwiittaukset: Jotkut huhujen havaitsemiseen liittyvät lähestymistavat käyttävät vastausten, tykkäysten ja uudelleentwiittausten määrää huhujen havaitsemiseen BIBREF21. Näin ollen poimimme kustakin tilistä parhaat $k$ vastatut, tykätyt tai uudelleentwiittaamat twiitit arvioidaksemme tilien asiallisuutta. Testasimme eri $k$-arvoja, jotka vaihtelivat 10 twiitin ja kunkin tilin twiittien enimmäismäärän välillä. Kuvassa FIGREF24 esitetään makro-F1-arvot eri $k$-arvoilla. Vaikuttaa siltä, että $k=500$ vastaa parhaiten vastattujen twiittien osalta saavuttaa parhaan tuloksen. Siksi pidämme tätä perustasona.",
      "id": "task461-1734c26ed9134fbf838ba5fe147b0120",
      "output": [
        "Mitä perustasoja tässä työssä käytettiin?"
      ]
    },
    {
      "input": "Perinteisen VAE-rakenteen lisäksi otamme CWVAE:ssa käyttöön ylimääräisen kontekstitietoisen latentin muuttujan, jolla opitaan tapahtumien taustatietoa. Esiharjoitteluvaiheessa CWVAE koulutetaan aputietoaineistolla (joka koostuu kolmesta tarinakorpuksesta ja sisältää runsaasti tapahtumataustatietoa) tapahtumataustatiedon oppimiseksi kontekstin huomioon ottavan latentin muuttujan avulla. Tämän jälkeen, hienosäätövaiheessa, CWVAE:tä koulutetaan tehtäväkohtaisella tietokokonaisuudella, jotta tapahtumataustatieto voidaan mukauttaa kuhunkin erityiseen Jos-Tällöin-tapauksen päättelykohteen osa-alueeseen (esim. aikomukset, reaktiot jne.).",
      "id": "task461-6d0d889a007248cc9dc6fb129e1d3fe9",
      "output": [
        "Miten kontekstitietoinen varioiva autokooderi oppii tapahtuman taustatiedot?"
      ]
    },
    {
      "input": "Tässä työssä käytämme BIBREF1:n julkaisemia tietokokonaisuuksia ja BIBREF0:n toimittamaa HEOT-tietokokonaisuutta.  Tämän jälkeen tehtiin translitterointi Xlit-Crowd-muunnossanakirjan avulla ja kunkin sanan kääntäminen englanniksi hindi-englanti-sanakirjan avulla. ",
      "id": "task461-bb93114c515b42acbd562b16e66ed55e",
      "output": [
        "Sisältävätkö kaikki tapaukset koodinvaihtoa?"
      ]
    },
    {
      "input": "Twitterissä olevien viestien haku poimittujen leksikoiden avulla johti 19 300 dollarin twiittikokoelmaan. Leksikaalisen monimuotoisuuden saavuttamiseksi lisäsimme tietokantaamme 2500 satunnaisesti poimittua twiittiä.",
      "id": "task461-10fbe7ba139541ada6326381724eaa45",
      "output": [
        "Kuinka monta twiittiä kerättiin?"
      ]
    },
    {
      "input": "Kuten alaluvussa: tietokokonaisuudet mainittiin, kaikki sanojen samankaltaisuutta koskevat tietokokonaisuudet sisältävät sanapareja, joihin on merkitty samankaltaisuus- tai sukulaisuuspisteet, vaikka tämä ero ei aina olekaan selvä. MEN sisältää 3000 annotoitua sanaparia, joiden pistemäärät vaihtelevat 0:sta 50:een. Sanat vastaavat ESP-Game- ja MIRFLICKR-1M-kuva-aineistoissa esiintyviä kuvamerkintöjä.MTurk287 sisältää 287 annotoitua sanaparia, joiden pistemäärät vaihtelevat välillä 1,0-5,0. Se luotiin sanoista, jotka esiintyvät sekä DBpedian että The New York Timesin uutisartikkeleissa.MTurk771 sisältää 771 annotoitua sanaparia, joiden pisteet vaihtelevat 1,0-5,0. Sanat, joilla on synonyymi-, holonyymi- tai meronyymisuhteita, on poimittu WordNet BIBREF56:stä.RG sisältää 65 annotoitua sanaparia, joiden pisteet vaihtelevat 0,0-4,0 ja jotka edustavat \"merkityksen samankaltaisuutta\".RW sisältää 2034 sanaparia, joiden samankaltaisuuspisteet on annotoitu asteikolla 0-10. Tähän tietokokonaisuuteen sisältyvät sanat saatiin Wikipediasta niiden esiintymistiheyden perusteella, ja myöhemmin ne suodatettiin WordNet-synsettien mukaan, mukaan lukien synonymia, hyperonymia, hyponymia, holonymia ja meronymia. Tämä tietokokonaisuus luotiin testaamaan, kuinka hyvin mallit pystyvät edustamaan harvinaisia ja monimutkaisia sanoja.SimLex999 sisältää 999 sanaparia, jotka on merkitty samankaltaisuuspisteillä, jotka vaihtelevat välillä 0-10. Tässä tapauksessa kirjoittajat ottivat nimenomaisesti huomioon samankaltaisuuden eikä sukulaisuutta, mikä on vastoin niiden tietokokonaisuuksien puutteita, joissa ei oteta huomioon samankaltaisuutta, kuten MEN ja WS353. Sanat sisältävät substantiivit, adjektiivit ja verbit. SimVerb3500 sisältää 3500 verbiparia, joiden samankaltaisuuspisteet vaihtelevat 0-10. Verbit saatiin USF:n vapaiden assosiaatioiden tietokannasta BIBREF66 ja VerbNet BIBREF63 . Tämä tietokokonaisuus luotiin, jotta voitaisiin puuttua verbien puutteelliseen edustavuuteen SimLex999:ssä ja siihen, että luomisajankohtana parhaiten suoriutuvat mallit olivat jo ylittäneet kommentoijien välisen yhteisymmärryksen verbien samankaltaisuuden arviointiresursseissa. SimLex999:n tavoin myös tässä tietokokonaisuudessa tarkastellaan nimenomaisesti samankaltaisuutta eikä sukulaisuutta.WS353 sisältää 353 sanaparia, jotka on annotoitu samankaltaisuuspisteillä 0-10.WS353R on WS353:n osajoukko, joka sisältää 252 sanaparia, jotka on annotoitu sukulaisuuspisteillä. Tämä tietokokonaisuus luotiin pyytämällä ihmisiä luokittelemaan jokainen WS353-sanapari johonkin seuraavista luokista: synonyymit, antonyymit, identtiset, hyperonyymi-hyponimi, hyponimi-hyperonyymi, holonyymi-meronyymi, meronyymi-holonyymi ja mikään edellä mainituista. Näitä merkintöjä käytettiin myöhemmin parien ryhmittelyyn seuraaviin ryhmiin: samankaltaiset parit (synonyymit, antonyymit, identtiset, hyperonyymi-hyponimi ja hyponimi-hyperonyymi), toisiinsa liittyvät parit (holonyymi-meronyymi, meronyymi-holonyymi ja none-of-the-above, joiden inhimillinen samankaltaisuuspistemäärä oli suurempi kuin 5) ja toisiinsa liittymättömät parit (jotka luokiteltiin none-of-the-above-luokkaan ja joiden samankaltaisuuspistemäärä oli enintään 5). WS353S on WS353:n toinen osajoukko, joka sisältää 203 sanaparia, jotka on merkitty samankaltaisuuspisteillä. Tämä tietokokonaisuus muodostuu samankaltaisten ja epäsuhtaisten sanaparien liitosta, kuten edellä on kuvattu.",
      "id": "task461-5dbaf2a501004c6f80ad6a7eefc43d02",
      "output": [
        "Mitä samankaltaisuustietokantoja ne käyttävät?"
      ]
    },
    {
      "input": "Vaikka neuraalinen konekääntäminen (NMT) on saavuttanut vaikuttavan suorituskyvyn suuren tietoresurssin olosuhteissa, ja siitä on tullut alan hallitseva tekijä BIBREF0 , BIBREF1 , BIBREF2 , viimeaikaisessa tutkimuksessa on väitetty, että nämä mallit ovat erittäin datatehottomia ja että ne alittavat suorituskyvyn fraasipohjaisessa tilastollisessa konekääntämisessä (PBSMT) tai valvomattomissa menetelmissä pienen datan olosuhteissa BIBREF3 , BIBREF4 . ",
      "id": "task461-e36b0439be7d4489920abe0c9f743f04",
      "output": [
        "mitä sudenkuoppia asiakirjassa mainitaan?"
      ]
    },
    {
      "input": "Kokeilussamme käytämme keskusteluaineistona mandariini-englanti-koodinvaihtopuhekorpusta nimeltä SEAME Phase II (South East Asia Mandarin-English). ",
      "id": "task461-f229733b8eaf408b9e423983b1ba14d1",
      "output": [
        "Mitä kieliä tässä asiakirjassa tarkastellaan?"
      ]
    },
    {
      "input": " UutisartikkelitTietokantamme uutisartikkelien lähde on kuvattu BIBREF2:ssa. Tämä tietokokonaisuus muodostettiin kahdesta eri lähteestä: luotettavia uutisia (oikeita uutisia) varten otettiin uutisartikkeleita englanninkielisestä Gigaword-korpuksesta. Vääriä uutisia varten kerättiin artikkeleita seitsemältä eri epäluotettavalta uutissivustolta. TwitterTässä tietokokonaisuudessa käytettiin BIBREF6:sta saatua luetteloa useista Twitter-tileistä kutakin väärän tiedon tyyppiä varten. Tämä luettelo luotiin julkisten resurssien perusteella, joissa kommentoitiin epäilyttäviä Twitter-tilejä. BIBREF6:n kirjoittajat ovat rakentaneet tietokokonaisuuden keräämällä twiittejä näistä tileistä ja antaneet sen saataville. ",
      "id": "task461-25dbd166bf894b0f8e606610673a1caa",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Käsittelemme kutakin yksittäistä kieltä tehtävänä ja koulutamme yhteisen mallin kaikille tehtäville. Pyrimme oppimaan joukon yhteisiä merkkien upotuksia molempien kielten taggereille yhdessä optimoimalla yhteistä häviöfunktiota, joka yhdistää korkean resurssin taggerin ja matalan resurssin taggerin.",
      "id": "task461-67f454932eab44f59493fcb0aa5b5f96",
      "output": [
        "Miten eri kielten merkkiedustukset ovat yhteisiä?"
      ]
    },
    {
      "input": "Mallimme saavuttaa CNN/Daily Mail -lehdessä ROUGE-1:n, ROUGE-2:n ja ROUGE-L:n keskiarvon 33,33, mikä on huippuluokkaa.",
      "id": "task461-710bcfedb5be4b6db5f31412a9f66940",
      "output": [
        "Mikä on suorituskykyisimmän mallin ROUGE-pistemäärä?"
      ]
    },
    {
      "input": "LRP antaa jokaiselle syötetietopisteelle ja mahdolliselle kohdeluokalle yhden skalaarisen relevanssiarvon jokaista syötemuuttujaa kohti, mikä osoittaa, onko kyseinen syötteen osa luokittelijan tietyn päätöksen puolesta vai sitä vastaan vai onko kyseinen syötemuuttuja luokittelutehtävän kannalta melko vähämerkityksinen ja merkityksetön.",
      "id": "task461-ec8b5432a1364657a0f95546f554259d",
      "output": [
        "Toimiiko LRP-menetelmä tilanteissa, joissa sanat suhteutetaan toisiinsa?"
      ]
    },
    {
      "input": "Puolivalvottu lähestymistapamme on melko yksinkertainen: ensin koulutetaan malli harjoitusjoukkoon, ja sitten tätä mallia käytetään ennustamaan hopeadatan merkinnät. Tämä hopeadata yksinkertaisesti lisätään koulutusjoukkoon, minkä jälkeen malli koulutetaan uudelleen. On kuitenkin otettava ylimääräinen vaihe sen varmistamiseksi, että hopeadata on laadultaan kohtuullista.",
      "id": "task461-6aaefab78e414d18a84705c9967fd652",
      "output": [
        "Mitä puolivalvottua oppimista sovelletaan?"
      ]
    },
    {
      "input": "esivalmennetut sanasulkeumat (WE): PDT-kokeita varten luomme word2vec-ohjelmalla sanojen upotukset LINDAT/CLARIN-tietokannasta saatavilla olevien suurten tšekkiläisten raakakorpusten yhdistelmällä. UD Tšekin kielessä käytämme FastText-sanan upotuksia BIBREF27, joiden ulottuvuus on 300 ja jotka esivalmennamme Tšekin Wikipediassa käyttämällä UD-tietueesta koulutettua segmentointia ja tokenisointia.BERT BIBREF1: Esikoulutetut kontekstuaaliset sanojen upotukset, joiden ulottuvuus on 768 Base-mallista. BERT-mallin neljä viimeistä kerrosta keskiarvoistetaan upotusten tuottamiseksi. Koska BERT käyttää sanapaloja, hajotamme UD-sanat sopiviksi alasanoiksi ja sitten keskiarvoistamme tuotetut upotukset samaan sanaan kuuluvien alasanojen osalta.Flair BIBREF2: Esiharjoittelemamme kontekstuaaliset sanojen upotukset, joiden ulottuvuus on 4096.",
      "id": "task461-743988ba4da64857b72df51301482160",
      "output": [
        "Mitä tietoja käytetään upotusten rakentamiseen?"
      ]
    },
    {
      "input": "HotpotQA:ssa löydämme keskimäärin 6 ehdollista ketjua (2-hop), ja ihmisen leimaama todellinen päättelyketju on ainutlaatuinen. Ennustettu ketju on oikea, jos ketju sisältää vain kaikki sitä tukevat kohdat (kohdat täsmäävät täsmälleen).MedHop-ohjelmassa löydetään keskimäärin 30 ehdollista ketjua (3-hop). Jokaisen ehdokasketjun kohdalla inhimilliset kommentoijamme merkitsivät, onko se oikea vai ei, ja oikea päättelyketju ei ole ainutkertainen. Ennustettu ketju on oikea, jos se on yksi niistä ketjuista, jotka ihmiset ovat merkinneet oikeiksi.Tarkkuus määritellään suhdelukuna: Tarkkuus määritellään suhteena:",
      "id": "task461-1b2c81c95e144815843c0368c1243850",
      "output": [
        "Mitä vertailuarvoja luodaan?"
      ]
    },
    {
      "input": "Määritämme näiden strategioiden käytön vertailemalla keskustelijoiden puheenaiheille käyttämää lähetysaikaa. Olkoon puolen INLINEFORM0 oma kattavuus INLINEFORM1 se osuus INLINEFORM2:n kierroksella INLINEFORM3 lausumista sisällön sanoista, jotka kuuluvat sen omiin puheenaiheisiin INLINEFORM4 , ja vastustajan kattavuus INLINEFORM5 se osuus sen sisällön sanoista, jotka kattavat vastustajan puheenaiheet INLINEFORM6 .  Käytämme kaikkia edellä käsiteltyjä keskusteluominaisuuksia. Kunkin puolen INLINEFORM0:n osalta otamme mukaan INLINEFORM1 , INLINEFORM2 ja niiden summan. Käytämme myös itsekattavuuden laskua, joka saadaan vähentämällä vastaavat arvot INLINEFORM3 :sta ja kunkin osapuolen hyväksymien keskustelupisteiden määrästä.",
      "id": "task461-999ded5addf94a0a813848a620bc6300",
      "output": [
        "mitä keskustelun sujuvuuteen liittyviä näkökohtia he tarkastelevat?"
      ]
    },
    {
      "input": "Syy-yhteyden määritystietokanta on kokoelma tekstipareja, jotka kuvastavat ihmisten ehdottamia syy-seuraussuhteita (esimerkiksi \"virus aiheuttaa sairauden\"). Nämä kirjalliset lausumat tunnistavat verkon solmut (katso myös graafin fuusioalgoritmi semanttisesti vastaavien lausumien käsittelyä varten), kun taas syy-seuraussuhteet muodostavat kausaalisen attribuutioverkon suunnatut reunat (\"virus\" $\\rightarrow $ \"sairaus\").",
      "id": "task461-4f813da1f53c401581a3d51c71e22870",
      "output": [
        "Mitä ovat syy-yhteysverkot?"
      ]
    },
    {
      "input": "Arvioimme monitehtäväistä lähestymistapaa ja kolmea algoritmia, jotka mallintavat nimenomaisesti tehtävien riippuvuudet.",
      "id": "task461-5163f54aae9246a7932ff37b7aeae4f9",
      "output": [
        "Ovatko nämä havainnot kestäviä eri tietokokonaisuuksissa ja erilaisissa kysymysten vastausalgoritmeissa?"
      ]
    },
    {
      "input": "Menetelmät ::: Keräsimme Streaming API:n avulla kymmeneen yhdysvaltalaiseen valtavirtaiseen uutissivustoon eli BIBREF18:ssa kuvattuihin luotettavimpiin lähteisiin liittyviä twiittejä, ja viittasimme Hoaxy API:n BIBREF16:een niiden twiittien osalta, jotka sisälsivät linkkejä yli 100 yhdysvaltalaiseen disinformaatiopalveluun.  Menetelmä ::: Italian tietokokonaisuus Italian skenaarion osalta keräsimme ensin twiittejä Streaming API:n avulla kolmen viikon aikana (19. huhtikuuta 2019 - 5. toukokuuta 2019) ja suodatimme ne, jotka sisälsivät URL-osoitteita, jotka osoittavat italialaisten virallisten sanomalehtien verkkosivustoille, kuten BIBREF22:ssa on kuvattu; nämä vastaavat Italian sanomalehtien levikin todentamiseen tarkoitetun yhdistyksen (Accertamenti Diffusione Stampa) toimittamaa luetteloa. Sen sijaan viittasimme BIBREF23:n tarjoamaan tietokokonaisuuteen saadaksemme joukon twiittejä, jotka on kerätty jatkuvasti tammikuusta 2019 lähtien käyttämällä samaa Twitter-päätepistettä ja jotka sisältävät URL-osoitteita yli 60 italialaiselle disinformaatiosivustolle.",
      "id": "task461-848b55b4b40b4e76a93958dd4d852e95",
      "output": [
        "Mitä kahta laajamittaista tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Mittaamme myös ihmisten perusarvoihin liittyvien sanojen käyttöä Boydin ym. boyd2015 mukaan. Sanakokonaisuudet eli teemat kaivettiin esiin käyttämällä Meaning Extraction Method (MEM) BIBREF10 -menetelmää.",
      "id": "task461-f9344ec61d4b4feebe6aaed36547a384",
      "output": [
        "Miten he saavat ihmisistä psykologisia ulottuvuuksia?"
      ]
    },
    {
      "input": "Aloitamme yleensä määrittelemällä kysymykset, joita haluamme tutkia. Voiko tekstianalyysi tarjota uuden näkökulman \"suureen kysymykseen\", joka on herättänyt kiinnostusta jo vuosia? Vai voimmeko nostaa esiin uusia kysymyksiä, jotka ovat nousseet esiin vasta äskettäin, esimerkiksi sosiaalisesta mediasta? Laskennallisen analyysin parissa työskentelevien yhteiskuntatieteilijöiden kysymykset pohjautuvat usein teoriaan, jossa kysytään: Miten voimme selittää havaitsemamme? Näiden kysymysten motivoima tekstin laskennallinen analyysi on oivalluslähtöistä: pyrimme kuvaamaan ilmiötä tai selittämään, miten se on syntynyt. Mitä voimme esimerkiksi oppia siitä, miten ja miksi vihapuhetta käytetään tai miten se muuttuu ajan myötä? Onko vihapuhe yksi asia vai sisältääkö se useita ilmaisumuotoja? Onko vihapuheen ja muunlaisen puheen välillä selkeä raja, ja mitkä piirteet tekevät siitä enemmän tai vähemmän moniselitteistä? Joskus toivomme myös yhteyttä useisiin tieteenaloihin. Vaikka esimerkiksi keskitymme arkiston humanistisiin kysymyksiin, voisimme myös esittää yhteiskunnallisia kysymyksiä, kuten \"onko tässä arkistossa kyse enemmän yhteistyöprosesseista, kulttuurin rakentamisesta vai normien luomisesta?\" tai \"kuinka hyvin tämä arkisto heijastaa yhteiskuntaa, johon se on upotettu?\". BIBREF3:ssa käytettiin kvantitatiivisia menetelmiä kertomaan tarina Darwinin älyllisestä kehityksestä - olennainen elämäkerrallinen kysymys tieteen historian avainhenkilölle.",
      "id": "task461-e8ae4dcdd5f64ef9824120bf4fc34aad",
      "output": [
        "Millaisiin kysymyksiin (jotka eivät ole tietokoneavusteisen tekstianalyysin eturintamassa) he puuttuvat?"
      ]
    },
    {
      "input": "Koska aiemmat järjestelmät keräävät asiaankuuluvia tietoja tietopankeista sen jälkeen, kun ne ovat havainneet kysymyksiä arvioinnin aikana (BIBREF24 , BIBREF25 ), tutkimme myös tämän vaihtoehdon käyttöä. Rakennamme nimittäin räätälöidyn tekstikorpuksen, joka perustuu maalaisjärjellä päättelytehtävissä esitettyihin kysymyksiin. ",
      "id": "task461-48050eb8f1064cf391351eaf763fe143",
      "output": [
        "Hienosäätävätkö he malliaan lopputehtävän perusteella?"
      ]
    },
    {
      "input": "Kokeet suoritettiin käyttäen AMI IHM:n kokouskorpusta BIBREF18 eri kielimallien puheentunnistussuorituskyvyn arvioimiseksi. ",
      "id": "task461-a9a9c79027bb49649693887df29394d2",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Hakuavaruutemme koostuu kahdesta pinottavasta solusta, joista toinen on mallin kooderia ja toinen dekooderia varten Kukin solu sisältää NASNet-tyyppisiä lohkoja, jotka saavat kaksi piilotettua tilaa syötteenä ja tuottavat uusia piilotettuja tiloja tuotoksina Hakuavaruutemme sisältää viisi haara-tason hakukenttää (syöttö, normalisointi, kerros, ulostulon ulottuvuus ja aktivaatio), yhden lohkotason hakukentän (yhdistinfunktio) ja yhden solutasoisen hakukentän (solujen lukumäärä).",
      "id": "task461-5057d9c90ffc4e3aa7ab204b1e6634a8",
      "output": [
        "Mitä mallin hakuavaruudessa on?"
      ]
    },
    {
      "input": "Teimme kuitenkin muutakin, ja saavutimme myös toisen ja kolmannen tason aistien osalta erinomaisia tuloksia, koska vaadimme itse korkeaa laatua. Saavutimme lopulta yhteisymmärryksen 0,85 ja Kappa-arvon 0,83 näillä kahdella syvemmällä aistitasolla.",
      "id": "task461-69e679fc62db4f739fa2bc2e86183afb",
      "output": [
        "Kuinka suuri on kommentoijien välinen yhteisymmärrys?"
      ]
    },
    {
      "input": "Käytämme kahta uusinta neuraalista ydinviittausten erottelumallia, joita kuvaavat BIBREF2 ja BIBREF1 .",
      "id": "task461-b1bef18f82844c55b46c1e470588f78d",
      "output": [
        "Mikä on uusin neuraalinen ydinviittausten ratkaisumalli?"
      ]
    },
    {
      "input": "Tarkastelemme QA PGNet- ja Multi-decoder QA PGNet -malleja, joissa on hakutaulukoiden upotus, perusmalleina ja parannamme perusmalleja muilla jäljempänä kuvatuilla muunnelmilla.",
      "id": "task461-9531bf4c6ef34fc6825c5748328638f1",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Kokeet ::: Arviointimittarit ::: Automaattisen arvioinnin asetukset ::: Hienosäädimme GPT-2 keskipitkän mallin BIBREF51 kerättyihin otsikoihin ja käytimme sitä sitten mittaamaan tuotettujen tuotosten perpleksisyyttä (PPL).",
      "id": "task461-e7405d2a1e6642178f5b848ce7f69f03",
      "output": [
        "Miten sujuvuutta arvioidaan automaattisesti?"
      ]
    },
    {
      "input": "Kaikki aineistot koostuvat videoista, joissa vain yksi puhuja on kameran edessä. Kullekin modaliteetille käyttämämme kuvaajat ovat seuraavat: Kieli Kaikki tietokokonaisuudet sisältävät manuaalisia transkriptioita. Visio Facet BIBREF26:n avulla poimitaan joukko piirteitä, joihin kuuluvat kehyskohtaiset perus- ja edistyneet tunteet ja kasvojen toimintayksiköt kasvolihasten liikkeiden indikaattoreina. Akustiikka Käytämme COVAREP BIBREF27 -ohjelmaa matalan tason akustisten piirteiden poimimiseen, mukaan lukien 12 melataajuuskeptraalikertoimen (MFCC), sävelkorkeuden seurannan ja äänteellisen/äänettömän segmentoinnin piirteet, glottaalilähteen parametrit, huipun kaltevuusparametrit ja maksimihajontakertoimet.",
      "id": "task461-a0db852974bf473b8d8dfcded1f653e2",
      "output": [
        "Millaisia modaliteetteja käytetään eri tietokokonaisuuksissa?"
      ]
    },
    {
      "input": "Kokeiden avulla tutkimme empiirisesti DIRL-analyysiämme ja ehdotetun ratkaisun tehokkuutta sen ongelman ratkaisemisessa. Lisäksi tutkittiin, miten kukin §SECREF10:ssä ja §SECREF14:ssä kuvattu vaihe vaikuttaa ehdotettuun ratkaisuun. Tutkimuksen toteuttamiseksi suoritimme suorituskykyvertailun seuraavien mallien välillä: SO: vain lähdealueelle koulutettu malli, jossa käytetään lähdealueen leimattua dataa ilman mitään alueellista mukauttamista CMD: alkuperäisen DIRL-kehyksen keskipisteeseen perustuva alueellinen mukauttamismalli BIBREF3, joka toteuttaa $\\mathcal {L}_{inv}$:n $\\text{CMD}_K$:lla.DANN: alkuperäisen DIRL-kehyksen BIBREF2:n vastakkaisoppimiseen perustuva toimialueen mukauttamismalli, joka toteuttaa $\\mathcal {L}_{inv}$ ja $\\text{JSD}(\\rm {P}_S, \\rm {P}_T)$.$\\text{CMD}^\\dagger $: CMD-mallin painotettu versio, jossa sovelletaan vain ehdotetun menetelmän ensimmäistä vaihetta (kuvattu kohdassa SECREF10).$\\text{DANN}^\\dagger $: DANN-mallin painotettu versio, joka soveltaa vain ehdotetun menetelmän ensimmäistä vaihetta.$\\text{CMD}^{\\dagger \\dagger }$: CMD-mallin painotettu versio, joka soveltaa sekä ehdotetun menetelmän ensimmäistä että toista vaihetta (kuvattu §SECREF14).$\\text{DANN}^{\\dagger \\dagger }$: DANN-mallin painotettu versio, joka soveltaa sekä ehdotetun menetelmän ensimmäistä että toista vaihetta.$\\text{CMD}^{*}$: $\\text{CMD}^{\\dagger \\dagger }$:n muunnos, jossa $\\mathbf {w}^*$ (kohdemerkityistä tiedoista saatu estimaatti) määritetään $\\mathbf {w}$:lle ja vahvistetaan tämä arvo mallin harjoittelun aikana.$\\text{DANN}^{*}$: $\\text{DANN}^{\\dagger \\dagger }$:n muunnos, joka määrittää $\\mathbf {w}^*$:n $\\mathbf {w}$:lle ja vahvistaa tämän arvon mallin harjoittelun aikana. Suoritimme kokeita Amazonin arvostelutietokannalla BIBREF9, joka on vertailuarvotietokanta monialaisen tunneanalyysin alalla.  Rakensimme tästä tietokokonaisuudesta 12 binääriluokiteltua toimialarajat ylittävää tunneanalyysitehtävää: B$\\rightarrow $D, B$\\rightarrow $E, B$\\rightarrow $K, D$\\rightarrow $B, D$\\rightarrow $E, D$\\rightarrow $K, D$\\rightarrow $K, E$\\rightarrow $B, E$\\rightarrow $D, E$\\rightarrow $K, K$\\rightarrow $B, K$\\rightarrow $D, K$\\rightarrow $E.  Lisäksi rakensimme 12 moniluokkaista, eri alojen välistä tunteiden luokittelutehtävää. Tehtävät suunniteltiin erottamaan 1 tai 2 tähteä (luokka 1) saaneet arvostelut 4 tähteä (luokka 2) ja 5 tähteä (luokka 3) saaneista arvosteluista.  Taulukossa TABREF27 esitetään mallin suorituskyky 12 kaksiluokkaisessa ristikkäisaluetehtävässä. Taulukosta voidaan tehdä seuraavat havainnot. ",
      "id": "task461-764f63bbabbb40269fb48eacc185a31d",
      "output": [
        "Miten DIRL arvioidaan?"
      ]
    },
    {
      "input": "Arvioimme malliamme simuloidussa keräilytehtävässä, jossa robotin tehtävänä on sijoittaa kuutio kulhoon sanallisen käskyn mukaisesti. Kukin ympäristö sisältää kolmesta viiteen esinettä, jotka eroavat toisistaan koon (pieni, suuri), muodon (pyöreä, neliö) ja värin (punainen, vihreä, sininen, keltainen, vaaleanpunainen) mukaan, eli yhteensä 20 erilaista esinettä. Luodusta skenaariosta riippuen näiden kolmen ominaisuuden yhdistelmät ovat tarpeen kohteiden erottamiseksi toisistaan, mikä mahdollistaa eritasoisen monimutkaiset tehtävät.",
      "id": "task461-61a7ddc1d3e648088cc836246be9c04c",
      "output": [
        "Millaisia simulaatioita kirjoittajat ovat tehneet lähestymistapansa validoimiseksi?"
      ]
    },
    {
      "input": "Harjoittelussa käytetty epätäydellinen tietokokonaisuus koostuu pienaakkosista epätäydellisistä tiedoista, jotka on saatu alkuperäisiä korpuksia manipuloimalla.",
      "id": "task461-0b6cc2f35be64dca8a36812dc13d31ce",
      "output": [
        "Testaavatko he lähestymistapaansa tietokokonaisuudella, jossa ei ole epätäydellisiä tietoja?"
      ]
    },
    {
      "input": " Taulukossa TABREF19 verrataan BLEU-pistemäärän tuloksia mallimme ja Googlen neuraalisen konekäännöksen välillä.",
      "id": "task461-394b087e55734f88bf436633eca0a0d7",
      "output": [
        "Mikä on heidän perustasonsa?"
      ]
    },
    {
      "input": "Tutkimuksessamme keskityttiin ensisijaisesti englanninkielisiin twiitteihin, koska se oli diagnostisen koulutusnäytteen kieli.",
      "id": "task461-1ad40e2b9dc04634814e3d6bb85a2f3c",
      "output": [
        "Raportoivatko kirjoittajat tulokset vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Taulukossa TABREF34 esitetään menetelmämme päättelynopeus, kun sekvenssimallinnuskerros toteutetaan LSTM-pohjaisella, CNN-pohjaisella ja Transformer-pohjaisella arkkitehtuurilla.  Taulukosta nähdään, että menetelmämme päättelynopeus on paljon nopeampi kuin Lattice-LSTM:llä, kun käytetään LSTM-pohjaista sekvenssimallinnuskerrosta, ja se oli myös paljon nopeampi kuin LR-CNN, jossa sekvenssimallinnuskerros toteutettiin CNN-arkkitehtuurilla. Ja kuten odotettua, menetelmämme, jossa on CNN-pohjainen sekvenssimallinnuskerros, osoitti jonkin verran etua päättelynopeudessa verrattuna menetelmiin, joissa on LSTM-pohjainen ja Transformer-pohjainen sekvenssimallinnuskerros.",
      "id": "task461-a4516d86bc5a4d518e602b4107904892",
      "output": [
        " Kuinka monta prosenttia ehdotettu menetelmä parantaa päätelmän nopeutta uusimpiin uusimpiin menetelmiin verrattuna?"
      ]
    },
    {
      "input": "Monipuolisen harjoitusaineiston keräämiseksi olemme poimineet satunnaisotannalla 1000 viestiä politiikan, liike-elämän, tieteen ja AskRedditin alaryhmistä ja lisäksi 1000 viestiä Redditin etusivulta.",
      "id": "task461-d6081ca4fce049a8adfb7cfed6c10fc6",
      "output": [
        "mitä aiheita vedetään Redditistä?"
      ]
    },
    {
      "input": "Peruslähestymistapa perustuu BIBREFiin20 . Se jakaa käyttäytymisnavigointia varten annettujen komentojen tulkinnan kahteen vaiheeseen: polun luomiseen ja polun todentamiseen. Polkujen luomisessa käytetään tavanomaista sekvenssistä sekvenssiin -mallia, jota on täydennetty huomiomekanismilla, joka on samanlainen kuin BIBREF23 ja BIBREF6 . Polun todentamiseen käytetään syvyyssuuntaista hakua, jolla graafista etsitään reitti, joka vastaa ennustettujen käyttäytymismallien sekvenssiä. Jos mikään reitti ei täsmää täydellisesti, peruslinja muuttaa enintään kolmea käyttäytymistä ennustetussa järjestyksessä yrittäen muuttaa sen kelvolliseksi poluksi.",
      "id": "task461-6e45cc81333044fd97ed992cdcb394af",
      "output": [
        "Mihin lähtökohtiin he vertasivat malliaan?"
      ]
    },
    {
      "input": " Siirto-oppimiseen perustuvat lähestymistavatMathur et al. ehdottivat artikkelissaan loukkaavien twiittien havaitsemiseksi ternaarista Trans-CNN-mallia, jossa he kouluttavat malliarkkitehtuurin, joka koostuu kolmesta konvoluution 1D-kerroksesta, joiden suodatinkoot ovat 15, 12 ja 10 ja ytimen koko 3, ja sen jälkeen kahdesta tiheästä täysin kytketystä kerroksesta, joiden koko on 64 ja 3. Ensimmäisessä tiheässä FC-kerroksessa on ReLU-aktivointi ja viimeisessä tiheässä kerroksessa Softmax-aktivointi. He pystyivät kouluttamaan tämän verkon Davidsonin et al. toimittamalla rinnakkaisella englanninkielisellä tietokokonaisuudella. Kirjoittajat pystyivät saavuttamaan 83,9 %:n tarkkuuden, 80,2 %:n tarkkuuden ja 69,8 %:n palautuksen.Lähestymistapa näytti lupaavalta, kun otetaan huomioon, että tietokokonaisuus koostui vain 3189 lauseesta, jotka oli jaettu kolmeen luokkaan, ja näin ollen toistimme kokeen, mutta emme onnistuneet toistamaan tuloksia. Tulokset olivat heikompia kuin alkuperäisten tekijöiden saavuttamat tulokset. Suurin osa mallin hyperparametrien valinnoista oli kuitenkin peräisin tästä työstä: Nguyen et al. ehdottivat vuonna 2017 hybridiä monikanavaista CNN- ja LSTM-mallia, jossa he rakentavat vietnamin kielen ominaisuuskarttoja käyttämällä CNN:ää lyhytaikaisten riippuvuuksien ja LSTM:ää pitkäaikaisten riippuvuuksien tallentamiseen ja yhdistävät nämä molemmat ominaisuussarjat oppiakseen yhtenäisen ominaisuuksien joukon viesteistä. Nämä yhdistetyt ominaisuusvektorit lähetetään sitten muutamalle täysin yhdistetylle kerrokselle. Tällä arkkitehtuurilla saavutettiin 87,3 prosentin tarkkuus.",
      "id": "task461-42a287a4b9044697867e4bc71c05a4b2",
      "output": [
        "Mitä malleja aiemmat työt käyttävät?"
      ]
    },
    {
      "input": "Tämän työn panos on siis kaksitahoinen: (1) kehitämme kielellisen neuroverkkomallin, jolla voidaan luokitella sosiaalisen median viesteissä esiintyviä reaktioita, ja (2) sovellamme malliamme 10,8 miljoonan Twitter-viestin ja 6,2 miljoonan Reddit-kommentin merkitsemiseen arvioidaksemme eri uutislähteisiin kohdistuvien käyttäjien reaktioiden nopeutta ja tyyppiä. Kehitämme neuroverkkoarkkitehtuurin, joka perustuu reaktioista ja vanhemmista viesteistä poimittuihin sisältöön ja muihin kielellisiin signaaleihin, ja hyödynnämme \"myöhäisfuusion\" lähestymistapaa, jota on aiemmin käytetty tehokkaasti näkötehtävissä BIBREF13 , BIBREF14 . Tarkemmin sanottuna yhdistämme tekstisekvenssin aliverkon ja vektoriesityksen aliverkon, kuten kuvassa FIGREF5 on esitetty. Tekstisekvenssin aliverkko koostuu sulauttamiskerroksesta, joka on alustettu 200-ulotteisilla GloVe-sulautumilla BIBREF15 ja jota seuraa kaksi 1-ulotteista konvoluutiokerrosta, sitten max-pooling-kerros ja sen jälkeen tiheä kerros. Vektoriesityksen aliverkko koostuu kahdesta tiheästä kerroksesta. Sisällytämme molemmista aliverkoista saatua tietoa ketjutetuilla pehmustetuilla tekstisekvensseillä ja normalisoitujen LIWC-ominaisuuksien (Linguistic Inquiry and Word Count) vektoriedustuksilla BIBREF16 kunkin viestin ja sen vanhemman tekstin osalta.",
      "id": "task461-0f8dd20bb4ed453b8e7807f9b249a3b4",
      "output": [
        "Mikä on heidän mallinsa arkkitehtuuri?"
      ]
    },
    {
      "input": "300 testikyselyä valitaan satunnaisesti, ja kommentoijia pyydetään arvioimaan itsenäisesti näiden kyselyjen tulokset eri pisteillä niiden laadun perusteella: (1) Hyvä (3 pistettä): Vastaus on kieliopillinen, semanttisesti relevantti kyselyn kannalta ja ennen kaikkea informatiivinen ja mielenkiintoinen. (2) Hyväksyttävä (2 pistettä): Vastaus on kieliopillisesti ja semanttisesti relevantti, mutta liian triviaali tai yleinen (esim. \"我不知道(En tiedä)\", \"我也是(Minäkin)\", \"我喜欢(Pidän siitä)\" jne.); (3) Hylätty (1 piste): Vastauksessa on kielioppivirheitä tai se ei liity kyselyyn.",
      "id": "task461-6cda6019eb724846a897d5f9f772d51b",
      "output": [
        "Miten ihmisten arviointi suoritetaan, mitkä olivat kriteerit?"
      ]
    },
    {
      "input": "Kaikissa tapauksissa tulokset ovat korkeat - valtaosassa tapauksista huomattavasti korkeammat kuin aiemmissa töissä on raportoitu. Erityisesti BIBREF1:ssä arvioidaan LSTM:ien kykyä oppia englannin kielen subjekti-verbisopimuskuvioita ja arvioidaan luonnossa esiintyvillä wikipedia-lauseilla.  BIBREF2:ssa tarkastellaan myös subjekti-verbisopimusta, mutta \"värittömissä vihreissä ideoissa\", joissa luonnossa esiintyvien lauseiden sisältösanat korvataan satunnaisilla sanoilla, joilla on sama puhekielinen osa ja taivutus, jolloin varmistetaan, että keskitytään syntaksiin pikemminkin kuin valintaan perustuviin preferensseihin perustuviin vihjeisiin.  BIBREF3:ssa tarkastellaan laajempaa valikoimaa syntaktisia ilmiöitä (subjektin ja verbin välinen sopimus, refleksiivinen anafora, negatiivisen polariteetin elementit) käyttämällä manuaalisesti rakennettuja ärsykkeitä, mikä mahdollistaa laajemman kattavuuden ja valvonnan kuin luonnollisessa ympäristössä.",
      "id": "task461-5a09d7dbc91f4b22bd9055a2596e1d2d",
      "output": [
        "Onko näitä tehtäviä arvioitu aiemmissa töissä?"
      ]
    },
    {
      "input": "Näin ollen SIM-mallissa on paljon vähemmän parametreja kuin nykyisissä dialogitilan seurantamalleissa. Kompensoidaksemme aukkokohtaisten parametrien poisjättämisen, käytämme parempaa ominaisuuksien esittämistä käyttäjän lausumasta ja dialogin tiloista käyttämällä syntaktista tietoa ja konvoluutio-neuraaliverkkoja (CNN, convolutional neural networks). ",
      "id": "task461-cf350fdec2c342bc82faac91ad510561",
      "output": [
        "Miten estetään se, että mallin monimutkaisuus kasvaa lähtö- ja saapumisaikojen määrän kasvaessa?"
      ]
    },
    {
      "input": "Jokaisen testitapauksen parina oli 99 satunnaisesti poimittua negatiivista tapausta. Kukin suositusmalli asettaa 100 tapausta paremmuusjärjestykseen ennustettujen tulostensa mukaan. Järjestyksessä olevaa luetteloa arvioidaan osumaprosentilla (HR) BIBREF49 ja normalisoidulla kumulatiivisella voitolla (NDCG) BIBREF50 sijalla 10. HR@10 on recall-pohjainen metriikka, joka mittaa, kuinka monta prosenttia testattavasta kohteesta suositellaan oikein 10 parhaan joukossa. NDCG@10 on paremmuusjärjestykseen perustuva arviointimittari, jossa otetaan huomioon oikean osuman sijainti paremmuusjärjestykseen sijoitetussa tuloksessa. Kaiken kaikkiaan AMRAN-ohjelmamme on kaikkia perusratkaisuja parempi, sillä sen HR@10-arvo on 0,657 ja NDCG@10-arvo 0,410. Se parantaa HR@10:tä 5,3 % ja NDCG@10:tä 3 % verrattuna parhaaseen perustasoon (eli $NAIS_{concat}$).",
      "id": "task461-b82db3188d20486bb64ea3314a992574",
      "output": [
        "Mikä on mallin tarkkuus?"
      ]
    },
    {
      "input": "TietokannatKokeilemme kahdella kiinalaisella kysymysvastaustietokannalla NLPCC-2016-arviointitehtävästä BIBREF13 . DBQA on dokumenttipohjainen kysymysten vastaustietokanta.  KBRE on tietoon perustuva relaatioiden poimintatietokanta.",
      "id": "task461-bf56980ff908437b91ec05c838926f16",
      "output": [
        "Millä tietokokonaisuudella (tietokokonaisuuksilla) ne arvioidaan?"
      ]
    },
    {
      "input": "Toteuttaaksemme kehyksemme ensimmäisen tason ja havaitaksemme moraalisen relevanssin, täydennämme moraalisesti relevantteja siemensanoja vastaavalla siemensanojen joukolla, joka likimain vastaa moraalista epärelevanssia ja perustuu valenssin käsitteeseen eli ärsykkeen miellyttävyyden tai epämiellyttävyyden asteeseen. Viittaamme BIBREF-tietokannan28 keräämiin noin 14 000 englanninkielisen sanan emotionaaliseen valenssiluokitukseen ja valitsemme moraalisesti merkityksettömien ydinsanojen joukkoon sanat, joilla on neutraalimmat valenssiluokitukset ja jotka eivät esiinny MFD:ssä, jotta moraalisesti merkityksellisten ja moraalisesti merkityksettömien sanojen kokonaismäärä olisi yhtä suuri.",
      "id": "task461-1724caee639b4013b6aed200941db9ea",
      "output": [
        "Miten he määrittävät moraalisen merkityksen?"
      ]
    },
    {
      "input": "Aiempien töiden mukaisesti raportoimme tarkkuuden ($P.$), palautuksen ($R.$) ja $F_1$-pisteet kohteen tunnistusta ja kohdistettua tunnetta varten. ",
      "id": "task461-8c9c48aab22c4fdbaf0b7dc94141d6d2",
      "output": [
        "Miten mallin tehokkuutta arvioidaan?"
      ]
    },
    {
      "input": "IWSLT14:n saksan-englannin ja turkin-englannin perusmallina (BASE-4L) käytämme 4-kerroksista koodaajaa, 4-kerroksista dekooderia, jäännösyhteydellä varustettua mallia, jossa upotuksen ja piilotetun koon oletusarvona on 256.",
      "id": "task461-1ca54870c2a940e892eb1c8db635d1a9",
      "output": [
        "mitkä ovat peruslinjat?"
      ]
    },
    {
      "input": "SPNetin tehokkuuden osoittamiseksi vertaamme sitä kahteen uusimpaan menetelmään, Pointer-Generator BIBREF5:een ja Transformer BIBREF6:een.",
      "id": "task461-1d6d2e4ea48247c1a8caeffc4cf086af",
      "output": [
        "Mitä aiempia nykyaikaisia asiakirjojen tiivistämismenetelmiä on käytetty?"
      ]
    },
    {
      "input": "Hiljattain bhat-EtAl:2017:EACLshort toimitti CS-tietokannan jäsentelymalliensa arviointia varten, jonka he kouluttivat hindi- ja englanninkielisillä Universal Dependency (UD) -puupankeilla. Laajennamme tätä tietokokonaisuutta annotoimalla 1448 uutta lausetta.",
      "id": "task461-868aa5c5b5ad45998fbc9be4cc816209",
      "output": [
        "Kuinka suuri on toimitettu puupankki?"
      ]
    },
    {
      "input": "Lisäksi käytämme vertailussa kahta erilaista jäsentäjää: 1) PCFGLA:han perustuvaa jäsentäjää eli Berkeley-jäsennystä BIBREF5 ja 2) minimaaliseen spaniin perustuvaa neurologista jäsentäjää BIBREF6 .",
      "id": "task461-bebea98d86044390ad6fbcdbdc8dd37d",
      "output": [
        "Mikä on sopimukseen perustuvan tilan perusmalli?"
      ]
    },
    {
      "input": "ACL-ARC on BIBREFin7 julkaisema tietokokonaisuus viittausintentioista. Tietokokonaisuus perustuu otokseen ACL Anthology Reference Corpus BIBREF15 -tietokannasta, ja se sisältää 1 941 viittaustapausta 186 artikkelista, ja NLP-alan asiantuntijat ovat kommentoineet sen.",
      "id": "task461-0359c643583447dc85b53717a0d55fce",
      "output": [
        "Mikä on ACL-ARC-tietoaineistojen koko?"
      ]
    },
    {
      "input": "Mallimme koodaa ääni- ja tekstisekvensseistä saadun tiedon käyttämällä kaksois-RNN:iä ja yhdistää sitten näistä lähteistä saadun tiedon feed-forward-neuraalisen mallin avulla tunneluokan ennustamiseksi.",
      "id": "task461-d61d08566d954e3d89b16ae192b44239",
      "output": [
        "Miten he yhdistävät ääni- ja tekstisekvenssit RNN:ssä?"
      ]
    },
    {
      "input": "Abstrakti merkitysesitys BIBREF0 , tai lyhyesti AMR, mahdollistaa tämän sisällyttämällä siihen useimmat matalan semanttisen luonnollisen kielen prosessoinnin (NLP) tehtävät, joita käsitellään yleensä erikseen, kuten nimettyjen entiteettien tunnistaminen, semanttisten roolien merkitseminen ja rinnakkaisviittausten erottaminen.",
      "id": "task461-1c4c2cde988d47c989c5ee25af7177c5",
      "output": [
        "Mitä osatehtäviä he arvioivat?"
      ]
    },
    {
      "input": "Tulokset osoittavat, että eniten suorituskykyä parantavat sanojen upotukset, tyyli ja moraalin piirteet. Muiden piirteiden (tunteet ja tunne) merkitys on vähäisempi, mutta ne parantavat silti järjestelmän kokonaissuorituskykyä (keskimäärin 0,35 % Macro-F$_1$ parannus).",
      "id": "task461-8e30b42d87aa47b89bf42dcee2720a61",
      "output": [
        "Mikä on tämän asiakirjan perusteella ennakoivampi joukko ominaisuuksia valeuutisten havaitsemiseksi?"
      ]
    },
    {
      "input": "Esimerkiksi lause \"Tytöt lauloivat laulun ja tanssivat\" on käännetty ranskaksi muotoon \"Les filles ont chanté une chanson et ils ont dansé\" Google Translate (GT), Bing Translate ja Yandex.",
      "id": "task461-7a4c89e4295544b5a3142623d4612d72",
      "output": [
        "Tekevätkö kirjoittajat kokeita mainituista tehtävistä?"
      ]
    },
    {
      "input": "Suoritimme kokeilumme Universal Dependencies v1.2 -pankilla BIBREF21 , jäljempänä UD1.2, josta voidaan triviaalisti poimia morfosyntaktisesti annotoituja korpuksia.  Tarkastelimme UD1.2:n korpuksia seuraavista 16 kielestä: Englanti, bulgaria, englanti, espanja, indonesia, italia, kroaatti, norja, persia, puola, portugali, ranska, ruotsi, saksa, sloveeni, tanska, tšekki ja ruotsi. ",
      "id": "task461-37abc2ee9b7247fa8c1ac3fc9d1fcaf3",
      "output": [
        "millä tietokokonaisuuksilla he tekivät kokeita?"
      ]
    },
    {
      "input": "Käytämme LSTM-verkkoa seuraavasti. Vektori $x$ syötetään LSTM-verkon läpi, joka tuottaa vektorin $\\overrightarrow{h_i}$ jokaiselle aika-askeleelle $i$ välillä 0 - $n-1$. Tämä on eteenpäin suuntautuva LSTM. Koska meillä on käytössämme koko vektori $x$, voimme käsitellä myös taaksepäin suuntautuvaa LSTM:ää. Tämä tapahtuu laskemalla vektori $\\overleftarrow{h_i}$ jokaiselle aika-askeleelle $i$ välillä $n-1$ ja 0. Lopuksi yhdistämme takaperin LSTM:n ja eteenpäin LSTM:n: Sekä $\\overrightarrow{h_i}$ että $\\overleftarrow{h_i}$:n ulottuvuus on $l$, joka on optimoitu hyperparametri. BiLSTM:n ulostulon $h$ ulottuvuus on siis $2l\\ kertaa n$.",
      "id": "task461-8e2c10ce42af4a73aab9ff398be21a33",
      "output": [
        "Onko LSTM kaksisuuntainen?"
      ]
    },
    {
      "input": "Kilpailun suurimmat haasteet johtuvat suoraan mahdollisuudesta käydä jatkuvia monivaiheisia vuoropuheluja, joissa ei noudateta tiettyä suunnitelmaa tai pyritä tiettyyn kiinteään tiedontarpeeseen.  Tässä asiakirjassa kuvataan joitakin kokemuksia, joita saimme rakentaessamme SlugBotia vuoden 2017 Alexa-palkintoa varten, ja keskitytään erityisesti haasteisiin, jotka liittyvät haun kautta löydetyn sisällön integroimiseen strukturoidusta datasta peräisin olevaan sisältöön, jotta voidaan käydä jatkuvaa, johdonmukaista, avoimen alueen seka-aloitteista keskustelua Haasteellisempaa on se, että jokaisessa järjestelmäkierroksessa on suuri määrä mahdollisia keskustelun siirtoja.  Lisäksi useimmilla muilla aloilla ei ole saatavilla yhtä korkealaatuista strukturoitua dataa, joten meidän on kehitettävä yleisempiä malleja diskurssin koherenssista tai yritettävä luottaa niihin.  Hakua ei voida käyttää tehokkaasti tässä yhteydessä ilman, että laaditaan sopiva kysely tai tiedetään etukäteen, mistä juonitietoa on mahdollisesti saatavilla. Reaaliaikaisessa järjestelmässä reaaliaikaisella haulla ei välttämättä saavuteta vaadittua nopeutta ja tehokkuutta, joten olennaisen tiedon esikäsittely tai välimuistiin tallentaminen voi olla tarpeen. ",
      "id": "task461-27b566fe99c04cc59e43e11f7c3dd896",
      "output": [
        "Miksi monivaiheiset dialogit ovat suurin haaste avoimen alueen keskusteluagenttien rakentamisessa?"
      ]
    },
    {
      "input": "Tässä työssä sovellamme automatisoitua neuraalista annotaatioprosessia dialogin tekojen merkitsemiseen. Useita neuraalisia malleja koulutetaan Switchboard Dialogue Act (SwDA) -korpuksella BIBREF9, BIBREF10, ja niitä käytetään dialogitekojen päättelyyn emootiotietokannoissa. Kokoonpanemme viisi mallin tulostusmerkintää tarkistamalla enemmistöesiintymät (useimmat mallin merkinnät ovat samat) ja asettamalla mallien luottamusarvot paremmuusjärjestykseen. Otimme käyttöön neuraaliset arkkitehtuurit, jotka perustuvat Bothe et al. bothe2018discourseen, jossa on kaksi muunnelmaa: ei-kontekstimalli (luokittelu lausetasolla) ja kontekstimalli (nykyisen lausuman dialogitekojen tunnistaminen muutaman edeltävän lausuman perusteella).",
      "id": "task461-4d15cad6ddc2400a945caa35dfc796c7",
      "output": [
        "Kuinka monta mallia käytettiin?"
      ]
    },
    {
      "input": "Koska sisällön ulkopuoliset sanat ovat riittävän erottuvia, jotta luokittelija voi määrittää tyylin, ehdotamme matalan tason kielellisten ominaisuuksien laskentaa (jäljempänä \"kontrollit\") muodolliseksi, sisällöltään sokeaksi tyylin määritelmäksi. Lauseen tyyli esitetään vektorina, joka koostuu suljettujen sanaluokkien (kuten persoonapronominien) lukumääristä sekä syntaktisten piirteiden lukumääristä, kuten SBAR-ei-terminaalien määrästä lauseenjäsennyksessä, sillä lauserakenteen on osoitettu olevan osoitus tyylistä BIBREF20. Ohjausmerkit poimitaan heuristisesti, ja lähes kaikki perustuvat ennalta määriteltyjen sanaluetteloiden lukumääriin. Käytämme vaalipiiriparsissa Stanford Parser BIBREF21. table:controlexamples sisältää kaikki kontrollit esimerkkeineen.",
      "id": "task461-ba4202ccd84d4f48be2d419ff5f80a40",
      "output": [
        "Miten he mallintavat tyyliä matalan tason kielellisistä kontrolleista koostuvana kokonaisuutena, kuten pronominien, prepositioiden ja sivulauseen rakenteiden yleisyydestä?"
      ]
    },
    {
      "input": "Käytämme Ultrax Typically Developing -tietokokonaisuutta (UXTD) julkisesti saatavilla olevasta UltraSuite-tietokannasta BIBREF19 . Tämä tietokokonaisuus sisältää synkronoituja akustisia ja ultraäänitietoja 58 tyypillisesti kehittyvältä 5-12-vuotiaalta lapselta (31 naista, 27 miestä). ",
      "id": "task461-5db7fe831a894309824d997bf9a13b06",
      "output": [
        "Kuinka monta puhujaa tietokannassa on?"
      ]
    },
    {
      "input": "Käytämme BLEU BIBREF30 -mittaria validointijoukkoon VQG-mallin koulutuksessa. BLEU on luonnollisen kielen prosessoinnissa laajalti käytetty mittari, jolla mitataan tuotettujen ja kohdesanojen samankaltaisuutta. Siinä oletetaan, että kelvollisissa generoiduissa vastauksissa on merkittävää sanojen päällekkäisyyttä perustotuuden vastausten kanssa. Käytämme sitä, koska tässä tapauksessa meillä on viisi erilaista viitettä jokaiselle generoidulle kysymykselle. BLEU-pistemääräksi saadaan 2,07. Chatbot-mallissamme on sen sijaan vain yksi viite-maatotuus koulutuksessa, kun se luo sanasarjan. Katsoimme, että se ei ole hyvä metriikka, koska joissakin tapauksissa vastauksilla on sama merkitys, mutta niillä ei ole yhteisiä sanoja. Tallennamme siis useita malleja eri hyperparametreilla ja eri harjoitteluiteraatioiden määrällä ja vertailemme niitä ihmisen arvioinnin avulla valitaksemme mallin, joka toimii paremmin keskustelussa.",
      "id": "task461-5e8a2ab08d1e49b29e012fcb9952ff3f",
      "output": [
        "Miten järjestelmän suorituskykyä mitataan?"
      ]
    },
    {
      "input": "Opiskelijoiden pohdintatietokannan koko-ongelman ratkaisemiseksi tutkimme ensin, mitä vaikutuksia on toimialan siirron sisällyttämisellä äskettäiseen abstraktiiviseen yhteenvetomalliin: kattavuusmekanismilla varustettuihin osoitinverkkoihin (PG-net)BIBREF0. ",
      "id": "task461-e3e524365cd84f2194de994cebbb63dc",
      "output": [
        "Mikä on tämän asiakirjan tuore abstrakti tiivistämismenetelmä?"
      ]
    },
    {
      "input": "NLG-malli on seq2seq-malli, jossa on huomio, kuten kohdassa SECREF2 on kuvattu.",
      "id": "task461-ea27f8f2f7d24ab9a361ca88e309becf",
      "output": [
        "Käyttävätkö he huomiota?"
      ]
    },
    {
      "input": "Viimeaikaiset yritykset voidaan jakaa kahteen luokkaan: i) ne, joissa yritetään sisällyttää lisätietoa tietämysgraafin upottamisen suorituskyvyn parantamiseksi edelleen, esimerkiksi oliotyypit tai käsitteet BIBREF13, relaatiopolut BIBREF17, tekstikuvaukset BIBREF11, BIBREF12 ja loogiset säännöt BIBREF23; ii) ne, joissa yritetään suunnitella monimutkaisempia strategioita, esimerkiksi syvät neuroverkkomallit BIBREF24.",
      "id": "task461-306548a445d540678c3aaa2ba21415c0",
      "output": [
        "Mitä viimeaikaisia teoksia knowedge-graafien sulautuksista kirjoittajat mainitsevat?"
      ]
    },
    {
      "input": "Tässä asiakirjassa tutkimme todennettavissa olevaa kestävyyttä eli todistuksen antamista siitä, että tietyn verkon ja testitulon osalta mikään hyökkäys tai häiriö ei voi muuttaa ennusteita. Esimerkkinä käytetään tekstiluokittelutehtäviä, Stanford Sentiment Treebank (SST) BIBREF15 ja AG News BIBREF16. ",
      "id": "task461-309d5e5e7d4e452cb04c52c7e21c2a7e",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Kasvojen läsnäolon tallentamisessa turvaudumme BIBREF56 -lähestymistapaan, jossa käytetään monitasoista konvolutiivista karkeasta hienoon -verkkokaskadia kasvojen maamerkkien paikantamiseen. Kasvojen ilmeet: BIBREF8:n lähestymistavan mukaisesti otamme käyttöön Ekmanin mallin kuudesta tunteesta: viha, inho, pelko, ilo, suru ja yllätys, ja käytämme Face++ API:ta niiden automaattiseen kuvaamiseen jaetuista kuvista. Yleiset kuvaominaisuudet: Tulkittavien laskennallisten esteettisten piirteiden merkitys käyttäjien verkkokäyttäytymisen tutkimisessa on korostunut useissa toimissa BIBREF55 , BIBREF8 , BIBREF57 .  Laadullinen kielianalyysi: Tuoreessa LIWC-versiossa tiivistetään tekstisisältöä kielellisten muuttujien, kuten analyyttisen ajattelun, vaikuttavuuden, autenttisuuden ja emotionaalisen sävyn, perusteella.  Se mittaa myös muita kielellisiä ulottuvuuksia, kuten kuvailuluokkia (esim. sanakirjasta poimittujen tai yli kuuden kirjaimen pituisten kohdesanojen prosenttiosuus - Sixltr) ja epävirallisia kielimerkkejä (esim. kirosanat, netspeak) sekä muita kielellisiä näkökohtia (esim. 1. persoonan yksikön pronominit).",
      "id": "task461-a5d6fe0063364aeebb39240e7af2230f",
      "output": [
        "Minkälaisia ominaisuuksia kussakin tietotyypissä käytetään?"
      ]
    },
    {
      "input": " Vaikka toimialueen siirto ei ole uutta, verrattuna aiempiin yhteenvetotutkimuksiin BIBREF6, BIBREF7, harjoitusalueemme (uutiset) ja viritysalueemme (opiskelijoiden pohdinta) ovat varsin erilaisia, ja toimialueen sisäiset tiedot ovat pieniä.",
      "id": "task461-4d79cf1970534dde8faf6aa177f6ba8a",
      "output": [
        "Poikkeavatko opiskelijoiden pohdintatiedot suuresti sanomalehden tiedoista?  "
      ]
    },
    {
      "input": "Tehtävässä 1 käytämme arviointimittarina F1-tulosta. Tehtävässä 2 käytämme manuaalista arviointia. Tehtävää 2 varten on viisi arviointimittaria, jotka ovat seuraavat: Tehtävän suorittamisaste: Käyttäjätyytyväisyysaste: Suoritettujen tehtävien määrä jaettuna tehtävien kokonaismäärällä: On viisi pistemäärää -2, -1, 0, 1, 2, jotka tarkoittavat vastaavasti erittäin tyytymätöntä, tyytymätöntä, neutraalia, tyytyväistä ja erittäin tyytyväistä.Vastauksen sujuvuus: Kolme pistemäärää -1, 0, 1, jotka ilmaisevat sujumattomuutta, neutraaliutta ja sujuvuutta.Vuoropuhelukierrosten määrä: Tehtävässä suoritetun dialogin lausumien määrä.Guidance ability for out of scope input: On kaksi pistemäärää 0, 1, jotka kuvaavat ohjauskykyä tai ohjauskyvyttömyyttä.",
      "id": "task461-20c8dea5ffb044b5823fc47f17b2a583",
      "output": [
        "Mitä mittareita arvioinnissa käytetään?"
      ]
    },
    {
      "input": "Käytimme Visual storytelling (VIST) -tietokokonaisuutta, joka koostuu Flickr-albumeista saaduista kuvasarjoista ja niihin liittyvistä kommentoiduista kuvauksista, jotka on kerätty Amazon Mechanical Turk BIBREF1 -palvelun kautta. Jokaisessa sarjassa on 5 kuvaa ja niitä vastaavat kuvaukset, jotka yhdessä muodostavat tarinan. Lisäksi jokaisessa Flickr-albumissa on 5 permutaatiota sen kuvista valitusta joukosta. Käytettävissä olevassa kokonaisaineistossa on 40 071 harjoitus-, 4 988 validointi- ja 5 050 käyttökelpoista testitarinaa.",
      "id": "task461-a3eb671e8054447189f093e0555e2452",
      "output": [
        "Mitä tilastoja VIST-tietokannasta raportoidaan?"
      ]
    },
    {
      "input": "Nopeuden ja suorituskyvyn välisen kompromissin tutkimiseksi vertaamme tekniikkaamme vakiomalleihin, joissa on huomio ja joissa ei ole huomiointia, BIBREF:in14 kaltaisessa eri pituisessa sekvenssikopiointitehtävässä. Tähän tarkoitukseen käytämme WMT'17:n neljää suurta konekäännöstietokokonaisuutta, jotka koskevat seuraavia kielipareja: (en-cs, 52 miljoonaa esimerkkiä), englanti-saksa (en-de, 5,9 miljoonaa esimerkkiä), englanti-suomi (en-fi, 2,6 miljoonaa esimerkkiä) ja englanti-turkki (en-tr, 207 373 esimerkkiä).",
      "id": "task461-3e7e3024c61c44b8b64cd7e01953f201",
      "output": [
        "Mitä tietokokonaisuuksia kokeissa käytetään?"
      ]
    },
    {
      "input": "Arvioimme kaikkia viittä mallia myös VecEval-paketin BIBREF13 myöhemmissä tehtävissä käyttäen vain sellaisia tehtäviä, joiden koulutus- ja arviointidata on vapaasti saatavilla: klusterien muodostaminen, tunteiden ja kysymysten luokittelu sekä luonnollisen kielen tunnistaminen (NLI). Käytetään paketin oletusasetuksia, mutta ajetaan vain kiinteitä asetuksia, joissa upotukset eivät ole mallien viritettävissä olevia parametreja, mikä pakottaa järjestelmän käyttämään vain upotuksissa jo olevaa tietoa. Lopuksi käytetään LV-N:ää, LV-M:ää ja FT:tä tuottamaan OOV-sanarepresentaatioita seuraaville sanoille: 1) \"hellooo\": pikaviesteissä yleisesti käytetty tervehdys, jossa korostetaan tavua. 2) \"marvelicious\": keksitty sana, joka saadaan yhdistämällä \"marvelous\" ja \"delicious\". 3) \"louisana\": oikean nimen \"Louisiana\" kirjoitusvirhe. 4) \"rereread\": etuliitteen \"re\" rekursiivinen käyttö. 5) \"tuzread\": keksitty etuliite \"tuz\".",
      "id": "task461-5cd6f41b526146708daa0ca5c038e4c3",
      "output": [
        "Miten he arvioivat tuloksena syntyviä sanojen upotuksia?"
      ]
    },
    {
      "input": "Dekooderi on toinen LSTM-verkko, joka käyttää kooderista saatua tietoa sekvenssin tarinan luomiseen. Dekooderin ensimmäinen syötetieto $x_0$ on kuva, jolle teksti luodaan. Kooderin viimeistä piilotettua tilaa $h_e^{(t)}$ käytetään dekooderin ensimmäisen piilotetun tilan $h_d^{(0)}$ alustamiseen. Tällä strategialla annamme dekooderille koko sekvenssin kontekstin ja nykyisen kuvan sisällön (eli globaalin ja paikallisen tiedon), jotta se voi tuottaa vastaavan tekstin, joka edistää kokonaistarinaa.",
      "id": "task461-71bacd424e8741cbac0ba2673f4847db",
      "output": [
        "Miten tarinan peräkkäinen luonne on kuvattu?"
      ]
    },
    {
      "input": "Opimme, että useat tekijät voivat vaikuttaa vastahyökkäysten suorituskykyyn, kuten luokittelijan arkkitehtuuri, lauseen pituus ja syöttöalue.",
      "id": "task461-51a4f177f3d54207866ff13e22f7bb39",
      "output": [
        "Mitkä muut tekijät vaikuttavat suorituskykyyn?"
      ]
    },
    {
      "input": "Kehittyneiden merkkien syöttöön perustuvien neuroarkkitehtuurien (CNN, BPE jne.) oletetaan pystyvän oppimaan itse, miten oikeinkirjoituksen ja morfologian vaihtelut käsitellään, jopa kielissä, joissa on rikas morfologia: \"lisää vain kerroksia!\". Kontekstualisoidut upotusmallit noudattavat tätä perinnettä: ne koulutetaan pääsääntöisesti raakatekstikokoelmilla, joissa on vain vähän kielellistä esikäsittelyä. Jäljempänä osoitamme, että tämä ei ole täysin totta.",
      "id": "task461-a8393eff01e74ef4a729c3c61a304f97",
      "output": [
        "Miksi lemmatisointi ei ole välttämätöntä englannissa?"
      ]
    },
    {
      "input": "Muut Timex3-maininnat ovat epäselvempiä, joten käytämme etävalvontaa. Lauseet kuten \"currently\" ja \"today's\" esiintyvät yleensä lähellä Tapahtumia, jotka ovat päällekkäisiä nykyisen asiakirjan luomisen ajankohdan kanssa, kun taas \"ago\" tai \" INLINEFORM0 -years\" viittaavat menneisiin tapahtumiin. Nämä hallitsevat ajalliset assosiaatiot voidaan oppia harjoitusaineistosta ja käyttää sitten Timex3:n merkitsemiseen. Lopuksi määrittelemme logistisen regressiosäännön ennustamaan olioiden DocRelTime-arvoja sekä määrittelemme lineaarisen hyppyketjutekijän Tapahtumamainintojen ja niiden lähimmän Timex3-naapurin välille, mikä koodaa perusjärjestelmän heuristiikan suoraan päättelysääntönä.",
      "id": "task461-e00980198fc94988980ed32fb930fca4",
      "output": [
        "Miten he saavat kaukovalvontasäännöt suhteiden ennustamista varten?"
      ]
    },
    {
      "input": "Tiedot kerättiin 10 prosentin yhtenäisestä otoksesta vuoden 2013 aikana tehdyistä Twitter-viesteistä, erityisesti Gardenhose API:sta. Lisäksi valittiin kontrolliasiakirjoja. Nämä asiakirjat eivät sisältäneet yhtään sanaa `caused', `causing' tai `causes', eivätkä mitään kaksisuuntaisia sanoja, ja ne sovitettiin edelleen ajallisesti yhteen, jotta saatiin sama määrä kontrolliasiakirjoja kuin kausaalisia asiakirjoja kullakin viidentoista minuutin jaksolla vuoden 2013 aikana. Kontrollidokumentit valittiin muuten satunnaisesti; kausaalisynonyymit voivat olla läsnä. ",
      "id": "task461-7bcdc56e19dd44ca8d3c903189095d13",
      "output": [
        "Miten he keräävät valvontakorpuksen?"
      ]
    },
    {
      "input": "Asiakirjan ominaisuuksien sisällyttäminen ::: Oppimisvaihe ::: Ominaisuuksien poiminta ::: Document-unware FeaturesOrdinal position: On osoitettu, että lauseen sisällyttäminen tiivistelmään on merkityksellistä sen sijainnin kannalta asiakirjassa tai jopa kappaleessa. Intuitiivisesti voidaan todeta, että tekstin alussa tai lopussa olevat lauseet sisällytetään todennäköisemmin tiivistelmään. Riippuen siitä, miten tämä ominaisuus määritellään, se voi olla asiakirjasta riippumaton tai ei. Esimerkiksi BIBREF29:ssä ja BIBREF37:ssä se on määritelty seuraavasti: $\\frac{5}{5}$ ensimmäiselle lauseelle, $\\frac{4}{5}$ toiselle lauseelle ja niin edelleen $\\frac{1}{5}$ viidennelle lauseelle ja nolla muille lauseille. Toisessa Wong et al. BIBREF9:n tutkimuksessa se on määritelty muotoon $\\frac{1}{lauseen numero}$. Tällaisella määritelmällä meillä voi olla useita lauseita, joiden asema on esimerkiksi $\\frac{1}{5}$, mutta näillä lauseilla ei välttämättä ole samaa aseman merkitystä. Vaikka lause position=$\\\\frac{1}{5}}$ tarkoittaa \"ensimmäisten joukossa\" asiakirjassa, jossa on 40 lausetta, sillä on täysin erilainen merkitys \"keskellä\" toisessa asiakirjassa, jossa on 10 lausetta. Hyödyllisen ominaisuuskaavan tulisi siis sisältää asiakirjojen välisiä eroja, jotka voivat muuttaa siinä olevan tiedon merkitystä. Kokeissamme käytimme BIBREF9:n määritelmää. Asiakirjatietoinen versio sijainnista esitellään kohdassa (SECREF6). lauseen pituus: tämän ominaisuuden taustalla on intuitio, jonka mukaan liian pitkät tai liian lyhyet lauseet sisällytetään harvemmin tiivistelmään. Kuten lauseen sijainti, myös tämä ominaisuus on väärän määritelmän alainen, mikä tekee siitä asiakirjasta tietämättömän. Esimerkiksi BIBREF9:ssä se on määritelty lauseen sanojen lukumääräksi. Tällaisessa määritelmässä ei oteta huomioon sitä, että esimerkiksi 15 sanaa sisältävää lausetta voidaan pitää pitkänä, jos asiakirjan kaikissa muissa lauseissa on vähemmän sanoja. Toista lausetta, jossa on sama määrä sanoja, voidaan pitää lyhyenä, koska asiakirjan muissa lauseissa on enemmän kuin 15 sanaa. Tämä voi johtua erilaisista kirjoitustyyleistä. Otimme tämän kuitenkin mukaan kokeiluihimme, jotta voimme verrata sen vaikutusta sen dokumenttitietoisen vastineen vaikutukseen, joka luetellaan kohdassa (SECREF6). Substantiivien suhde: määritellään BIBREF30:ssä substantiivien lukumääräksi jaettuna lauseen sanojen kokonaislukumäärällä sen jälkeen, kun stop-sanat on poistettu. Kolme muuta ominaisuutta, verbejä, adjektiiveja ja adverbejä, määritellään samalla tavalla, ja niillä on osoittautunut olevan myönteinen vaikutus ranking-tulokseen. Meidän näkökulmastamme katsottuna lause, jonka substantiivien suhde on = 0,5, esimerkiksi asiakirjassa, jossa on paljon substantiiveja, on kuitenkin erotettava harjoitusjoukossa toisesta lauseesta, jossa on sama substantiivien suhde ja joka esiintyy toisessa asiakirjassa, jossa on vähemmän substantiiveja. Tämä ominaisuus ei kuvaa sitä, kuinka monta substantiivia asiakirjassa on, mikä on tärkeää lauseiden luokittelussa. Samassa keskustelussa perustellaan myös tarvetta ottaa huomioon verbien, adjektiivien ja adverbien määrä asiakirjassa. Näiden ominaisuuksien vaikutusta tutkitaan kokeiluissamme ja verrataan niiden dokumenttitietoisten vastineiden vaikutukseen. numeeristen yksiköiden suhde: Olettaen, että lauseet, jotka sisältävät enemmän numeerista tietoa, antavat meille todennäköisesti enemmän tietoa, tämä ominaisuus voi auttaa meitä sijoittamaan BIBREF31, BIBREF32. Laskennassa lasketaan numeroiden ja numeroiden esiintymät suhteessa lauseen pituuteen. Tätä ominaisuutta on painotettava vähemmän, jos lähes kaikissa asiakirjan lauseissa on numerotietoja. Se ei kuitenkaan laske numeroita ja numeroita asiakirjan muissa lauseissa. Cue Words: Jos lause sisältää erityisiä lauseita, kuten \"in conclusion\", \"overall\", \"to summarize\", \"in a nutshell\" ja niin edelleen, sen valinta tiivistelmän osaksi on todennäköisempää kuin muiden. Näiden lauseiden määrä lasketaan tätä ominaisuutta varten.Asiakirjan ominaisuuksien sisällyttäminen ::: Oppimisvaihe ::: Ominaisuuksien louhinta ::: Asiakirjatietoiset piirteetKosinuksen sijainti: Kuten kohdassa (SECREF5) mainittiin, hyvässä aseman määritelmässä olisi otettava huomioon asiakirjan pituus. Kirjallisuudessa käytetty tunnettu kaava BIBREF38, BIBREF7 on, jossa indeksi on kokonaisluku, joka kuvaa lauseiden järjestystä, ja T on asiakirjan lauseiden kokonaismäärä. Tämä ominaisuus vaihtelee välillä 0-1, ja mitä lähempänä alkua tai loppua se on, sitä suuremman arvon se saa. $\\alpha $ on viritysparametri. Kun se kasvaa, tämän ominaisuuden arvo jakautuu tasaisemmin lauseiden kesken. Tällä tavoin tämän ominaisuuden yhtäläiset arvot harjoitusjoukossa edustavat yhtenäistä käsitystä sijainnista asiakirjassa, joten siitä tulee asiakirjatietoinen. suhteellinen pituus: Tämän ominaisuuden taustalla oleva intuitio on selitetty kohdassa (SECREF5). Siellä keskusteltiin siitä, että pelkkä sanojen laskeminen ei ota huomioon sitä, että tietyn sanamäärän sisältävää lausetta voidaan pitää pitkänä tai lyhyenä asiakirjan muiden lauseiden perusteella. Tämä huomioon ottaen jaoimme lauseen sanamäärän asiakirjan lauseiden keskimääräisellä pituudella. Muodollisemmin kaava on: jossa n on asiakirjan lauseiden lukumäärä ja $s_i$ on asiakirjan i:s lause. Arvot, jotka ovat suurempia kuin 1, voidaan tulkita pitkiksi ja päinvastoin.TF-ISF: Tämä ominaisuus laskee termien frekvenssiä asiakirjassa ja antaa korkeampia arvoja lauseille, joissa on useammin esiintyviä termejä. Se myös vähentää termejä, jotka esiintyvät useammassa lauseessa. Koska se on selitetty hyvin kirjallisuudessa, emme ole ottaneet mukaan yksityiskohtia ja kaavaa, jotka löytyvät viitteistä BIBREF34 ja BIBREF39. Keskustelumme kannalta on kuitenkin olennaista, että sekä frekvenssi että käänteinen lauseen frekvenssi ovat termejä, joihin liittyy asiayhteyden ominaisuuksia ja jotka näin ollen ovat dokumenttitietoisia.POS-ominaisuuksia: Tässä esitellään toinen tapa sisällyttää POS-yksiköiden (part of speech) suhde piirteisiin ja pitää ne asiakirjanormalisoituina. Tätä varten kunkin POS-yksikön esiintymien määrä jaetaan niiden määrällä asiakirjassa sen sijaan, että ne esiintyisivät lauseessa. Uusien dokumenttitietoisten piirteiden muodollinen määritelmä on seuraava: Incorporating Document Features ::: Oppimisvaihe ::: Ominaisuuksien louhinta :::: Eksplisiittiset dokumenttiominaisuudetTutkittaessa tarkemmin, kuinka tehokkaita dokumenttikohtaiset ominaisuudet ovat lauseiden luokittelussa, määrittelimme useita dokumenttiominaisuuksia. Nämä ominaisuudet lasketaan kullekin asiakirjalle ja toistetaan kyseisen asiakirjan jokaisen lauseen ominaisuusvektorissa. Niiden muodollinen määritelmä kuvataan jäljempänä, ja niiden vaikutusta tarkastellaan tulos- ja keskusteluosassa (SECREF5): Asiakirjan lauseet: Tärkeä tiivistämiseen vaikuttava asiakirjan ominaisuus on lauseiden luokitteluun osallistuvien lauseiden kokonaismäärä. Kun tämä määrä kasvaa, tiivistelmän pitäisi olla valikoivampi ja tarkempi. Myös jotkin lauseiden ominaisuudet, kuten vihjesanat, saattavat painottua enemmän pidemmissä asiakirjoissa. Lisäksi tärkein asiayhteyteen liittyvä tieto on luultavasti jakautunut enemmän lauseisiin. Tällöin muiden ominaisuuksien pienempiä arvoja olisi pidettävä tärkeinä. Asiakirjan sanat: Asiakirjan sanojen määrä on toinen asiakirjan pituutta kuvaava käsite. Koska lauseiden määrä ei yksin riitä kuvaamaan asiakirjan pituutta, tämä ominaisuus olisi myös otettava huomioon. aihepiiriluokka: eri aihealueilla, kuten poliittisilla, taloudellisilla jne. aiheilla on erilaiset kirjoitustyylit, mikä saattaa vaikuttaa lauseiden sijoittumiseen. Esimerkiksi numeeriset yksiköt saattavat esiintyä enemmän talous- tai urheiluraporteissa kuin uskonnollisissa tai yhteiskunnallisissa uutisissa. Siksi tämän ominaisuuden painoarvon tulisi olla suurempi tai pienempi asiakirjan kategorian perusteella. Se on siis sisällytettävä.",
      "id": "task461-bf7a7d4da34d4ffcbe33697a5a6f2ec9",
      "output": [
        "Mitä asiakirjan piirteitä on integroitu jokaisen lauseen vektoreihin?"
      ]
    },
    {
      "input": "Kun suunnittelimme uusia arviointimittareita, joiden avulla vertaillaan viitteellisiä tiivistelmiä/käännöksiä hypoteeseihin, laadimme ensimmäiset periaatekriteerit sille, mitä hyvän arvioijan tulisi tehdä. Ensimmäinen niistä on se, että sen pitäisi korreloida vahvasti ihmisen tekemän samankaltaisuusarvion kanssa. Toinen kriteeri on, että sen pitäisi pystyä erottamaan lauseet, jotka ovat loogisesti ristiriidassa keskenään, jotka eivät liity loogisesti toisiinsa tai jotka ovat loogisesti samaa mieltä. Kolmanneksi vankan arvioijan pitäisi pystyä tunnistamaan myös käsittämättömät lauseet. Viimeisenä kriteerinä on, että hyvä arviointimittari ei saisi antaa korkeita pistemääriä semanttisesti kaukana toisistaan oleville lauseille ja alhaisia pistemääriä semanttisesti toisiinsa liittyville lauseille.",
      "id": "task461-d8ddce14bf814118b59237e0386d2b68",
      "output": [
        "Mitkä ovat hyvän mittarin kriteerit?"
      ]
    },
    {
      "input": "Kokeilemme kahta kuvatekstimallia: Show&Tell-mallia BIBREF0 ja LRCN1u-mallia BIBREF1. Molemmissa malleissa noudatetaan koodaaja-dekooderi-arkkitehtuurin perusrakennetta, jossa CNN-kooderi tiivistää visuaalisen informaation kuvakoodaukseksi, joka puolestaan antaa LSTM-dekooderille edellytykset luonnollisen kielen kuvatekstin tuottamiseen. Suurin ero näiden kahden mallin välillä on tapa, jolla ne ehdollistavat dekooderia. Show&Tell-malli syöttää kuvan upotuksen \"edeltävän sanan upotuksena\" ensimmäiselle tuotetulle sanalle, kun taas LRCN1u-malli yhdistää kuvan piirteet ja upotetun edellisen sanan sekvenssimallin syötteeksi kullakin aika-askeleella.",
      "id": "task461-8d6741af40ea41859719f96f6721c3d0",
      "output": [
        "Mitä olemassa olevia malleja arvioidaan?"
      ]
    },
    {
      "input": "Tässä työmuistiossa esitellään RNN- ja LSTM-pohjainen upotusjärjestelmä sosiaalisen median terveystekstien luokittelua varten. Vaikka tehtävän 1 ja tehtävän 2 tietokokonaisuudet ovat rajalliset, tässä työpaperissa ehdotetaan RNN- ja LSTM-pohjaista upotusmenetelmää.",
      "id": "task461-f0f1b7c5ec594dc5b0794b4eb6d4eb05",
      "output": [
        "Minkä tyyppistä RNN:ää käytetään?"
      ]
    },
    {
      "input": "Kaikissa kokeissamme käytimme BERT-Base BIBREF2:ta, joka tarjoaa uusinta mahdollista kontekstualisoitua mallinnusta syötetylle tekstille.Semanttinen haku: Käsittelimme neuraalista semanttista hakua sekä kappale- että lausetasolla binäärisinä luokitusongelmina, joissa mallien parametrit päivitetään minimoimalla binäärinen ristiinentropiahäviö.",
      "id": "task461-6d3b8a445ee644d4b230f18e6878e3e3",
      "output": [
        "Miten ne mallintavat neuraalisia hakumoduuleja?"
      ]
    },
    {
      "input": "MCTest-tietokannan osalta kuvassa FIGREF30 verrataan ehdottamiamme malleja käsin laadittujen syntaktisten ja kehyssemanttisten piirteiden nykyiseen huipputason kokonaisuuteen BIBREF16 sekä kirjallisuuden aiempiin neuromalleihin, jotka kaikki käyttävät huomiomekanismeja - BIBREF26 Attentive Reader, BIBREF27 Neural Reasoner ja BIBREF17 HABCNN-malliperhe. ",
      "id": "task461-82c307b484384b459eb9d560b79a58d5",
      "output": [
        "Mikä on mc-testien vastausten luokittelun nykytilanne?"
      ]
    },
    {
      "input": "Kukin luokittelija on toteutettu seuraavilla määrittelyillä: Naïve Bayes (NB): Logistinen regressio (LR): Lineaarinen LR, L2-regularisointivakio 1 ja rajoitetun muistin BFGS-optimointiTukivektorikone (SVM): Lineaarinen SVM, L2-regularisointivakio 1 ja logistinen häviöfunktioSattumanvaraiset metsät (RF): 10 satunnaistetun päätöspuun todennäköisyysennusteiden keskiarvoistaminenGradient Boosted Trees (GBT): Tree boosting oppimisnopeudella 1 ja logistisella häviöfunktiolla Perinteisten koneoppimismenetelmien ohella tutkimme neuroverkkoihin perustuvia malleja arvioidaksemme niiden tehokkuutta suuremmassa tietokokonaisuudessa. Tutkimme erityisesti konvolutiivisia neuroverkkoja (Convolutional Neural Networks, CNN), toistuvia neuroverkkoja (Recurrent Neural Networks, RNN) ja niiden muunnosmalleja.",
      "id": "task461-8934938ecaf3492498982917315a5d54",
      "output": [
        "Mitä oppimismalleja tietokokonaisuuteen käytetään?"
      ]
    },
    {
      "input": "Taulukossa TABREF15 vertaillaan SimCluster-algoritmin ja K-means-algoritmin tuloksia. Tässä SimCluster-algoritmimme parantaa F1-pistemäärää 0,412:sta ja 0,417:stä 0,442:een ja 0,441:een kahdella alueella. Myös ARI-pisteet paranevat 0,176:sta ja 0,180:sta 0,203:een ja 0,204:een.",
      "id": "task461-dbb71bf664b24c1a96057fea21eb1736",
      "output": [
        "Käytetäänkö SimCluster- ja K-means-algoritmissa samaa etäisyysmittaria?"
      ]
    },
    {
      "input": "Tehtävä on laadittu jäljittelemään (vaikkakin liian yksinkertaistetusti) tulo- ja lähtösymbolien kohdistuksia ja paikallisia syntaktisia ominaisuuksia, jotka mallien on opittava monissa luonnollisen kielen tehtävissä, kuten käännöksissä, merkinnöissä ja yhteenvedoissa.",
      "id": "task461-9f1f2644423343d9a2ceb40fa11cbadd",
      "output": [
        "Miksi ehdotettu tehtävä on hyvä korvike yleiskäyttöiselle sekvenssille sekvenssitehtäville?"
      ]
    },
    {
      "input": "Teimme siis myös ihmiskokeita Amazon MTurk -palvelussa arvioidaksemme tuotettuja vastauksia pareittain vertailemalla vuoropuhelun laatua. Vertaamme mallejamme kehittyneeseen dekoodausalgoritmiin MMI BIBREF2 ja kahteen malliin, nimittäin LSTM BIBREF0 ja VHRED BIBREF7, jotka molemmat käyttävät additiivista huomiota. Parhaan tietämyksemme mukaan LSTM ja VHRED olivat ensisijaiset mallit, joilla F1-tuloksia raportoitiin Ubuntu-tietokannassa. BIBREF5:n (BIBREF5) mukaisesti käytämme kahta kriteeriä: Uskottavuus ja sisällön rikkaus. Ensimmäinen kriteeri mittaa sitä, onko vastaus uskottava asiayhteys huomioon ottaen, kun taas toinen mittaa sitä, onko vastaus monipuolinen ja informatiivinen. ",
      "id": "task461-15c6991e0f5b4baea3a5d4fa95c19b97",
      "output": [
        "Miten ihmisten arviointi suoritetaan, mitkä olivat arviointiperusteet?"
      ]
    },
    {
      "input": "Analysoimme laajennetuilla piirteillä koulutetun luokittimen virheet neljässä ennustustehtävässä, jotta voimme antaa suuntaa tulevalle työlle.Virheet aikomuksen (I) ennustamisessa: Taustan puute on suuri ongelma trollauskommenttien tunnistamisessa. Muut kuin kiroilevat hyökkäykset ja loukkaukset Tämä on haastava ongelma, koska suurin osa loukkaavista ja loukkaavista kommenteista perustuu kirosanoihin ja kiroiluun.  Toinen virhelähde on trollien yleisesti käyttämät kiistanalaiset sanat, kuten \"musta\", \"feminismi\", \"tappaminen\", \"rasismi\", \"ruskea\" jne. Virheitä julkistamisen (D) ennusteessa: Tärkein julkistamiseen vaikuttava virhelähde on BOW-mallista saatava pinnallinen merkityskuvaus, vaikka sitä täydennettäisiinkin hansikasvektoreiden antamilla jakauman ominaisuuksilla. Tulkinnan (R) ennustamiseen liittyvät virheet: Monilla käyttäjillä on yleinen käytäntö kysyä suoraan epäillyltä trollilta, trollaako hän vai ei.  Vastausstrategiaa (B) koskevat virheet: Joissakin tapauksissa \"turhauttamisen\" ja \"neutralisoinnin\" välinen raja on häilyvä.  Toinen haastava ongelma on luokkien \"Trolli\" ja \"Osallistu\" erottaminen toisistaan. ",
      "id": "task461-6daa4dc92c64409bb65e542c6aa248b3",
      "output": [
        "Mikä on esimerkki vaikeasti luokiteltavasta tapauksesta?"
      ]
    },
    {
      "input": "Käytämme Kyubyong Parkin ja Edouard Graven osoitteessa al:Kyubyong Park luomia vietnaminkielisiä sanasulkeumia: Hänen projektissaan hän käyttää kahta menetelmää, mukaan lukien fastText ja word2vec, luodakseen sanojen upotuksia wikipedia-tietokannan varmuuskopioista. Edouard Grave et al BIBREF11: He käyttävät fastText-työkalua sanojen upotusten tuottamiseen Wikipediasta.",
      "id": "task461-b09a0d5b3ec94bb3b3a2a04258274304",
      "output": [
        "Mitä sanasulkeumia käytettiin?"
      ]
    },
    {
      "input": "Arvioijia ohjeistettiin arvioimaan vastausten laatua kolmen kriteerin perusteella: (1) kieliopillinen oikeellisuus - onko vastaus sujuva ja kielioppivirheetön; (2) kontekstuaalinen johdonmukaisuus - onko vastaus kontekstisidonnainen edelliseen dialogihistoriaan nähden; (3) emotionaalinen sopivuus - välittääkö vastaus oikean tunteen ja tuntuuko se siltä, että sen on tuottanut ihminen. Arvioijat antoivat kullekin kriteerille joko 0, 1 tai 2 pistettä, jossa 0 tarkoittaa huonoa, 2 hyvää ja 1 neutraalia.",
      "id": "task461-d755fd5d52424944bbb400f315933aea",
      "output": [
        "Miten ihmisen arviointi suoritetaan?"
      ]
    },
    {
      "input": "Arvioimme menetelmäämme kolmessa merkintätehtävässä: POS-tunnisteiden (Pos), morfologisten tunnisteiden (Morph) ja supertunnisteiden (Stag) tekemistä. Valitsimme nämä tehtävät esimerkkeinä merkintäsovelluksista, koska ne eroavat toisistaan voimakkaasti merkintäjoukkojen koon suhteen. Näiden kolmen tehtävän testitulokset esitetään taulukossa TABREF17 kolmessa ryhmässä. Ensimmäisessä seitsemän sarakkeen ryhmässä ovat tulokset Pos-tehtävässä, jossa sekä LSTM:llä että CNN:llä on kolme variaatiota syöttöominaisuuksista: vain sana ( INLINEFORM0 ), vain merkki ( INLINEFORM1 ) ja molemmat ( INLINEFORM2 ). Morphin ja Stagin osalta käytämme vain INLINEFORM3-asetusta sekä LSTM:ssä että CNN:ssä.",
      "id": "task461-c6d32bc9545a41bf8f79cb512d22138f",
      "output": [
        "Selvittävätkö ne yhdessä useita merkintäongelmia?"
      ]
    },
    {
      "input": "Online Retail Data Set koostuu puhtaasta 25873 laskun luettelosta, jossa on yhteensä 541909 riviä ja 8 saraketta. InvoiceNo, CustomerID ja StockCode ovat enimmäkseen 5- tai 6-numeroisia kokonaislukuja, joissa on satunnaisesti kirjaimia. Quantity on enimmäkseen 1-3-numeroisia kokonaislukuja, joista osa on negatiivisia, ja UnitPrice koostuu 1-6-numeroisista liukuluvuista. InvoiceDate on päivämääriä, jotka ovat kaikki samassa muodossa, Country sisältää merkkijonoja, jotka edustavat 38 maata, ja Description on 4224 merkkijonoa, jotka edustavat tuotteiden nimiä. Näistä tiedoista muodostetaan tekstiviestit erottamalla jokainen merkki tyhjällä välilyönnillä ja pinoamalla tietyn laskun rivit, jotka on ryhmitelty InvoiceNo:n mukaan.",
      "id": "task461-1d41c48f691d4327adce0b3e678a6980",
      "output": [
        "Mikä on taulukoiden lähde?"
      ]
    },
    {
      "input": "Offline-vaiheessa järjestämme kunkin tapauksen sisällön graafiksi, jossa jokainen solmu edustaa lausetta tekstistä ja kysymystä. Tämän jälkeen lisäämme solmujen väliset reunat seuraavan topologian mukaisesti: yhdistämme täysin solmut, jotka edustavat saman tekstikappaleen lauseita (katkoviiva-musta); yhdistämme täysin solmut, jotka edustavat kunkin tekstikappaleen ensimmäistä lausetta (katkoviiva-punainen); lisäämme reunan kysymyksen ja kunkin tekstikappaleen jokaisen solmun välille (katkoviiva-sininen).",
      "id": "task461-095cfef92a1f469a863a168a43ff83aa",
      "output": [
        "Miten jotkin solmut ovat alun perin yhteydessä toisiinsa tekstin rakenteen perusteella?"
      ]
    },
    {
      "input": " Jotta vertailua aiempaan työhön voitaisiin tehdä, koulutamme perus-muotoisen tekstinmuunnosjärjestelmän BIBREF11:n julkaisemilla tiedoilla. ",
      "id": "task461-8edee13093594135b11f767939428a4e",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Tässä artikkelissa esittelemme työmme, joka on osa ECML PKDD 2019 -konferenssin SociaL Media And Harassment -kilpailua.   Käytämme kilpailun tietokokonaisuutta, joka sisältää tekstiä twiiteistä, joilla on edellä mainitut kategoriat.",
      "id": "task461-151cd64169d440ea9103d204c7d22b33",
      "output": [
        "Mitä tietokokonaisuuksia tässä asiakirjassa käytettiin?"
      ]
    },
    {
      "input": "Samanlainen suuntaus on nähtävissä myös kahden muun uusimman lähestymistavan, BIBREF9 ja BIBREF8 , suorituskyvyssä.",
      "id": "task461-8d2605ff084844939450511589ac71ac",
      "output": [
        "Mitkä ovat uusimmat mallit?"
      ]
    },
    {
      "input": "Edellä esitetyllä hyperparametriasetuksella hybridi-NER-malli saavutti F1-pistemäärän $0,995$ syntetisoidussa kyselyssä ja $0,948$ kliinisissä muistiinpanoissa, kun taas i2b2-NER-malli saavutti F1-pistemäärän $0,441$ syntetisoidussa kyselyssä ja $0,927$ kliinisissä muistiinpanoissa (ks. taulukko TABREF23).",
      "id": "task461-e32c66891ef843b3aa99222ccf950c91",
      "output": [
        "mitkä olivat heidän suorituskykytuloksensa?"
      ]
    },
    {
      "input": "Tutkimme, miten voidaan hyödyntää maalaisjärjellä saatavaa lisätietoa (eli rationaalisia perusteluja) tehtävän syötteenä. Kuten kohdassa SECREF6 mainitsimme, etsimme OMCS-korpuksesta relevantteja lauseita ylimääräisiksi etäisiksi järkiperusteluiksi ja perustotuusperustelujen lauseita dev/testidataa varten. Syötteet eivät enää ole itse käsitejoukkoja, vaan muodossa \"[rationales$|$concept-set]\" (eli perustelulauseiden ja alkuperäisten käsitejoukkojen merkkijonojen ketjuttaminen).",
      "id": "task461-70b6f6c599904357b89e3015d7be98e7",
      "output": [
        "Pitääkö mallien tuottaa myös rationaalisia perusteluja?"
      ]
    },
    {
      "input": "Taulukossa TABREF44 esitetään automaattisten ja inhimillisten arviointien keskimääräiset tulokset.",
      "id": "task461-634c852a07db46dabbbf3d8dbc55bde7",
      "output": [
        "Kuinka suuri ero ehdotetun mallin ja perusmallin suorituskyvyssä on?"
      ]
    },
    {
      "input": "Porttimekanismi oppii toimialueiden väliset representaatiot. Ne yhdessä ohjaavat tietoa, jonka on kuljettava täysin kytketyn ulostulokerroksen läpi maksimipoolauksen jälkeen. Porttiarkkitehtuurien tehokkuus perustuu ajatukseen, jonka mukaan portti koulutetaan ainoastaan painotuksen määrittämiseksi. Tunneanalyysin tehtävässä tämä painotus vastaa sitä, mitkä painot johtavat lopullisen tappion pienenemiseen tai toisin sanoen tarkimpaan tunteen ennustamiseen. Näin tehdessään porttiarkkitehtuuri oppii, mitkä sanat tai n-grammit vaikuttavat eniten sentimenttiin, ja nämä sanat tai n-grammit ovat usein yhteydessä toimialasta riippumattomiin sanoihin. Toisaalta portti antaa vähemmän painoarvoa n-grammeille, jotka ovat suurelta osin joko alalle ominaisia tai funktionaalisia sanakokonaisuuksia, joiden osuus yleiseen sentimenttiin on vähäinen. Tämä tekee porttiarkkitehtuurista tehokkaan toimialueen mukauttamisessa. Näemme, että porttiarkkitehtuurit ovat lähes aina parempia kuin toistuvat, huomio- ja lineaariset mallit BoW, TFIDF ja PV. Tämä johtuu pitkälti siitä, että kun näitä malleja koulutetaan ja testataan samoilla aloilla, erityisesti toistuvat ja huomiopohjaiset mallit saattavat suoriutua paremmin. Domain Adaptation -mallit eivät kuitenkaan suoriudu kohdealueesta huonosti verrattuna gated-arkkitehtuureihin, koska niistä puuttuu gated-rakenne, jota koulutetaan rinnakkain tärkeyden oppimiseksi. Koska gated-arkkitehtuurit perustuvat konvoluutioihin, ne hyödyntävät rinnakkaistamista ja lisäävät huomattavasti aikakompleksisuutta muihin malleihin verrattuna. ",
      "id": "task461-a57cda728b9549018734840dd3643cbc",
      "output": [
        "Onko GCN:n käyttämisessä konseptuaalisia etuja verrattuna monimutkaisempiin arkkitehtuureihin, kuten huomio?"
      ]
    },
    {
      "input": "FBFans-tietokanta sisältää tietoja ydinvoiman vastaisista kiinalaisista Facebook-faniryhmistä syyskuusta 2013 elokuuhun 2014, mukaan lukien viestit sekä niiden kirjoittajan ja tykkääjän tunnukset.",
      "id": "task461-428f1c87884e417e889f5e408dc30d91",
      "output": [
        "Mikä aihe sisältyy Kiinan Facebook-tietoihin? "
      ]
    },
    {
      "input": "Tällainen virhe vaikuttaa \"trolli\"- ja \"engage\"-luokkien tarkkuuteen ja palautukseen. Ratkaisu tähän ongelmaan voi olla pidempien keskusteluosuuksien sisällyttäminen. ",
      "id": "task461-6f801fe4b38744ab8e44fe8c22a992f0",
      "output": [
        "Mitä mahdollisia ratkaisuja ehdotetaan?"
      ]
    },
    {
      "input": "Otamme tiedot WMT'14:n englannin ja ranskan (En-Fr) sekä englannin ja saksan (En-De) tietokokonaisuuksista. ",
      "id": "task461-698ce93a983649d2a8de4b3726b32f66",
      "output": [
        "Käytetäänkö näitä tekniikoita monikielisten mallien kouluttamiseen ja millä kielillä?"
      ]
    },
    {
      "input": "Tähän työhön on useita mahdollisia laajennuksia. Esimerkiksi kaikkien puhelimelle osoitettujen kehysten käyttäminen sen sijaan, että käytettäisiin vain keskimmäistä kehystä.",
      "id": "task461-b042c43b31df4c4086746a25221c9385",
      "output": [
        "Ehdottavatko he lisäyksiä, joilla voitaisiin parantaa yleistämistä näkymättömiin puhujiin?"
      ]
    },
    {
      "input": "Arvioimme ehdotettuja siirto-oppimistekniikoita kahdessa WMT 2019 -uutiskäännöstehtävän ei-englanninkielisessä kieliparissa: ja saksan$\\rightarrow $ tšekin$\\rightarrow.",
      "id": "task461-3c540e6cf0a145cfa6ea6c1e0d8e1a01",
      "output": [
        "Suoritetaanko kokeita muilla kielipareilla, miten ehdotettu menetelmä suoriutuu muihin malleihin verrattuna?"
      ]
    },
    {
      "input": "Puhujan kanssa suljetussa tilassa kustakin puhujasta erotettiin kaksi jaksoa kehitys- ja testisarjoiksi. Tämän jälkeen kehitys- ja testijoukkojen kokonaiskoot ovat 1585 IPU:ta, jotka kestävät 2 tuntia 23 minuuttia, ja 1841 IPU:ta, jotka kestävät 2 tuntia ja 48 minuuttia. ASR-malli koulutetaan lopuilla tiedoilla. Koska mallin kouluttaminen olisi vaikeaa, jos kaikki KM:n tai UT:n puhujan tiedot poistettaisiin, kokeita, joissa käytettäisiin niiden puhujia, ei suoritettu.",
      "id": "task461-f266858511d94b839f92ec8c323a48aa",
      "output": [
        "Mitä eroa on kaiutin auki ja kaiutin kiinni -asetuksilla?"
      ]
    },
    {
      "input": " Lauseiden esittämisen jälkeen käytämme joitakin luokittelumalleja syötettyjen lauseiden luokitteluun. Nämä mallit kuvataan yksityiskohtaisesti kohdassa SECREF13. Ensimmäinen malli on BIBREF11:ssä ehdotettu TextCNN (kuva FIGREF2). Se sisältää vain CNN-lohkoja, joita seuraa joitakin tiheitä kerroksia. Useiden CNN-lohkojen, joissa on eri kokoiset ytimet, ulostulot on yhdistetty toisiinsa. Toinen malli on VDCNN (kuva KUVA 5), joka on saanut inspiraationsa BIBREF12:ssa tehdystä tutkimuksesta. TextCNN-mallin tavoin se sisältää useita CNN-lohkoja. Kolmas malli on yksinkertainen kaksisuuntainen LSTM-malli (kuva FIGREF15). Se sisältää useita LSTM- kaksisuuntaisia lohkoja pinottuna toisiinsa.Neljäs malli on LSTMCNN (kuva FIGREF24). Ennen CNN-lohkojen läpikäyntiä sanojen upotussarjat muunnetaan LSTM- kaksisuuntaisella lohkolla. Viimeinen malli on järjestelmä nimeltä SARNN (kuva FIGREF25). Se lisää huomiolohkon LTSM-lohkojen väliin. Tässä järjestelmässä käytetään pinoamismenetelmää. Tässä menetelmässä kunkin mallin tuloksena ei ole ainoastaan luokan tunnus vaan myös kunkin luokan todennäköisyys kolmen luokan joukossa. Tästä todennäköisyydestä tulee ensemble-mallin ominaisuus. Tässä pinoava ensemble-malli on yksinkertainen täysyhteysmalli, jossa syötteenä on kaikki todennäköisyydet, jotka tulostuvat alamalleista. Tuloksena on kunkin luokan todennäköisyys.",
      "id": "task461-927dc3da286d40a1bbc113cc3fcbb36b",
      "output": [
        "Mitä luokittelijaa he käyttävät?"
      ]
    },
    {
      "input": "ISIS:n englanninkielinen verkkolehti nimeltä Dabiq ilmestyi ensimmäisen kerran pimeässä verkossa heinäkuussa 2014 ja jatkoi julkaisemista 15 numeron ajan. Tätä julkaisua seurasi Rumiyah, joka tuotti 13 englanninkielistä numeroa syyskuuhun 2017 asti. Sekä Dabiqia että Rumiyahia tarkasteltaessa monissa lehtien numeroissa on erityisesti naisia käsitteleviä artikkeleita, joiden otsikkoon on yleensä sisällytetty \"sisarillemme\".",
      "id": "task461-96d031b9006e4e33b2468dd540385651",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Tämän artikkelin koeasetukset ja Mboshi-korpuksen arviointiprotokolla (Boundary F-pisteet käyttäen ZRC-puheviitettä) ovat samat kuin BIBREF8:ssa. Taulukossa esitetään tulokset kaksikielisen UWS:n ja monikielisen vivutuksen osalta. Ensin mainitussa tapauksessa saavutamme parhaan tuloksemme käyttämällä yhdenmukaistettuna tietona ranskaa, joka on tämän tietokokonaisuuden alkuperäinen yhdenmukaistettu kieli. Ranskaa lähellä olevat kielet (espanja ja portugali) sijoittuivat paremmiksi, kun taas huonoin tulos oli saksan kieli. Myös englanti suoriutuu kokeissamme erityisen hyvin. Uskomme tämän johtuvan tuloksena olevan tekstin tilastollisista ominaisuuksista. Taulukossa havaitaan, että englannin kieli sisältää kaikista kielistä pienimmän sanaston. Koska koulutamme järjestelmiämme hyvin niukkaresurssisissa ympäristöissä, sanastoon liittyvät piirteet voivat vaikuttaa suuresti järjestelmän kykyyn mallintaa kieltä ja näin ollen myös tuotettujen linjausten lopulliseen laatuun. Jopa runsaasti resursseja sisältävissä ympäristöissä on jo todettu, että jotkin kielet ovat vaikeampia mallintaa kuin toiset BIBREF9.",
      "id": "task461-6aea625d5b7943e495a123a3a606cd3a",
      "output": [
        "Arvioidaanko mallia suhteessa johonkin perustasoon?"
      ]
    },
    {
      "input": "Ensimmäinen on turkkilainen uutisverkkokorpus, joka sisältää 423 miljoonaa sanaa ja 491 miljoonaa merkkiä, eli BOUN Web Corpus BIBREF9 , BIBREF10 . Toinen koostuu 21 miljoonasta turkkilaisesta twiitistä, joissa on 241 miljoonaa sanaa ja 293 miljoonaa merkkiä, ja siihen on yhdistetty 1 miljoona twiittiä TS TweetS:stä, jonka on laatinut Sezer-2013, ja 20 miljoonaa turkkilaista twiittiä, jonka ovat laatineet Bolat ja Amasyalı.",
      "id": "task461-eaf9a6a0cbc04b1686797f753693013d",
      "output": [
        "Mitä tietoja käytettiin sanojen upotusten muodostamiseen?"
      ]
    },
    {
      "input": "Arviointiin käytettiin pientä mutta monipuolista aineistoa, joka koostui 10 englanninkielisestä YouTube-videosta uutiskontekstissa. Valitut videot käsittelevät eri aiheita, kuten teknologiaa, ihmisoikeuksia, terrorismia ja politiikkaa, ja niiden pituus vaihtelee 2-10 minuutin välillä. ",
      "id": "task461-6d4f095d466946c5ade8eb9e9aca2a7b",
      "output": [
        "Millaisia Youtube-videoiden transkriptioita he käyttivät?"
      ]
    },
    {
      "input": "Suunnittelemme sanatason tarkentavan dekooderin, koska tämä prosessi on samankaltainen kuin yhteistyöelimen esiharjoitteluprosessissa oleva cloze-tehtävä, joten käyttämällä kontekstuaalisen kielimallin kykyä dekooderi voi tuottaa sujuvampia ja luonnollisempia sekvenssejä.",
      "id": "task461-6ed47bacfaac44b2a64019ed751ca208",
      "output": [
        "Miksi sanojen peittäminen dekooderissa on hyödyllistä?"
      ]
    },
    {
      "input": "Esimerkiksi WSC-kokoelman skeema 23 voidaan kääntää muotoon \"Tytöt kiusasivat poikia, joten [rankaisimme/pelastimme] heitä\" ja \"Pojat kiusasivat tyttöjä, joten [rankaisimme/pelastimme] heitä\", jolloin vältetään ennakko-oletukset siitä, kiusaavatko tytöt todennäköisemmin poikia vai päinvastoin.",
      "id": "task461-d7b462eaac53495da71ab3e4be532bae",
      "output": [
        "Mitä tietoja he tarkastelevat?"
      ]
    },
    {
      "input": "Minimimuutos muutti lauseen merkitystä huomattavasti, mutta silti muunnoksen upotus on hyvin lähellä alkuperäistä lausetta (keskimääräinen samankaltaisuus 0,930).",
      "id": "task461-c1c8bb3cce8f463795c81bda6f391a51",
      "output": [
        "Analysoidaanko niissä sitä, miten muutokset muuttivat alkuperäisiä lausekokonaisuuksia?"
      ]
    },
    {
      "input": "Ehdotamme edellä määriteltyä tehtävää varten kuullun ymmärtämisen mallia, Attention-based Multi-hop Recurrent Neural Network (AMRNN) -kehystä, ja osoitamme, että tämä malli pystyy suoriutumaan tehtävästä kohtuullisen hyvin. Ehdotetussa lähestymistavassa tarinoiden ääni transkriboidaan ensin tekstiksi ASR:n avulla, ja ehdotettu malli kehitetään käsittelemään transkriptioita oikean vastauksen valitsemiseksi kysymyksen antamista neljästä vaihtoehdosta. ",
      "id": "task461-6eebd8b1f0f643329300663787a2c0f0",
      "output": [
        "Millaista lähestymistapaa tässä työssä ehdotetaan uutta tehtävää varten?"
      ]
    },
    {
      "input": "Sovitamme siis valmiin palkitsemisoppimisalgoritmin BIBREF7 valvottuun ympäristöön automaattista tietojenkäsittelyä varten.",
      "id": "task461-7534bff919f744679c31d94ba3a3351f",
      "output": [
        "Mikä RL:n valmis palkkio-oppimisalgoritmi soveltuu tietojenkäsittelyn ja mallin harjoittelun yhteiseen oppimiseen?"
      ]
    },
    {
      "input": "CFQ sisältää 239 357 englanninkielistä kysymys-vastausparia, joihin voidaan vastata julkisten Freebase-tietojen avulla.",
      "id": "task461-d0ecfb8f57e44da994e512fa84b1a74f",
      "output": [
        "Kuinka suuri on uusi kysymysten vastaustietokanta?"
      ]
    },
    {
      "input": "Arviointitulokset ovat varsin myönteisiä molempien kohteiden osalta ja erityisen hyviä kohde-1:n osalta, kun otetaan huomioon, että ne ovat ensimmäisiä kokeita aineistolla.",
      "id": "task461-de8ec0462e59443e8658ed7a3d60119c",
      "output": [
        "Mikä SVM-menetelmä tuotti parhaan tuloksen?"
      ]
    },
    {
      "input": "Tarkastelemme jatkoanalyysia varten viittä tärkeintä profiilin ominaisuutta. Nämä attribuutit ovat käyttäjänimi, näyttönimi, profiilikuva, sijainti ja kuvaus.",
      "id": "task461-a1eeea9e5f6a433884c83587087b3986",
      "output": [
        "Mitä profiilin metatietoja käytetään tässä analyysissä?"
      ]
    },
    {
      "input": "Laskimme bag-of-words-pohjaisia vertailuarvoja seuraavilla menetelmillä:Luokittelu TF-IDF + Lineaarinen SVM (TF-IDF + SVM)Luokittelu Depeche++ Emotion-leksikoneilla BIBREF12 + Lineaarinen SVM (Depeche + SVM)Luokittelu NRC Emotion-leksikoneilla BIBREF13, BIBREF14 + Lineaarinen SVM (NRC + SVM)TF-IDF- ja NRC-Emotion-leksikoneiden yhdistelmä (TF-NRC + SVM)Vertailuarvot ::: Doc2Vec + SVMKäytimme myös yksinkertaisia luokittelumalleja, joissa oli opittuja upotuksia. Koulutimme Doc2Vec-mallin BIBREF15 käyttäen tietokokonaisuutta ja käytimme upotettuja asiakirjavektoreita lineaarisen SVM-luokittimen ominaisuuksina.Vertailukohteet ::: Tässä vertailuanalyysissä tarkasteltiin hierarkkista RNN:ää BIBREF16:n mukaisesti. Käytimme kahta BiLSTM:ää BIBREF17, joissa kummassakin on 256 yksikköä lauseiden ja asiakirjojen mallintamiseen. Lauseen merkkejä käsiteltiin muista lauseen merkkeistä riippumatta. Jokaisen token-tason BiLSTM:n suunnan viimeiset tuotokset yhdistettiin ja syötettiin lause-tason BiLSTM:ään syötteinä.BiLSTM:n tuotokset yhdistettiin kahteen tiheään kerrokseen, joissa oli 256 ReLU-yksikköä, ja Softmax-kerrokseen. Merkit alustettiin julkisesti saatavilla olevilla upotuksilla, jotka oli koulutettu GloVe BIBREF18 -ohjelmalla. Lauseiden rajat saatiin SpaCy:ltä. Koulutuksen aikana tiheisiin piilokerroksiin sovellettiin pudotusta: Bi-directional RNN and Self-Attention (BiRNN + Self-Attention)Yksi haaste RNN-pohjaisissa ratkaisuissa tekstiluokittelussa on löytää paras tapa yhdistää sanatason representaatiot korkeamman tason representaatioihin.Self-attention BIBREF19, BIBREF20, BIBREF21 on sovitettu tekstiluokitteluun, mikä on parantanut tulkittavuutta ja suorituskykyä. Käytimme BIBREF20:tä tämän vertailuanalyysin pohjana. vertailuanalyysissä käytettiin kerroksellista kaksisuuntaista RNN:ää (60 yksikköä), jossa oli GRU-soluja ja tiheä kerros. Molemmat itsetarkkailukerrokset olivat kooltaan 60 yksikköä, ja kustannusfunktiona käytettiin risti-entropiaa.Huomaa, että olemme jättäneet pois ortogonaalisen regularisaattoritermin, koska tämä tietokokonaisuus on suhteellisen pieni verrattuna perinteisiin tietokokonaisuuksiin, joita käytetään tällaisen mallin kouluttamiseen. Emme havainneet merkittävää suorituskyvyn paranemista, kun käytimme regularisaattoritermiä kokeissamme: ELMo embedding and Bi-directional RNN (ELMo + BiRNN)Deep Contextualized Word Representations (ELMo) BIBREF22 on viime aikoina osoittanut menestystä useissa NLP-tehtävissä. Kielen mallin valvomaton luonne antaa sille mahdollisuuden hyödyntää suurta määrää saatavilla olevaa merkitsemätöntä dataa oppiakseen parempia representaatioita sanoista.Käytimme tässä vertailuarvossa Tensorhubissa saatavilla olevaa esivalmennettua ELMo-mallia (v2). Syötimme ELMon sanojen upotukset syötteenä yksikerroksiseen kaksisuuntaiseen RNN-malliin (16 yksikköä), jossa on GRU-soluja (dropoutilla) ja tiheä kerros. Kustannusfunktiona käytettiin risti-entropiaa: Hienosäädetty BERTBidirectional Encoder Representations from Transformers (BERT) BIBREF11 on saavuttanut huipputuloksia useissa NLP-tehtävissä, kuten lauseiden luokittelussa.Käytimme alkuperäisessä työssä esitettyä hienosäätömenettelyä sovittaaksemme esivalmennetun koteloimattoman BERT$_\\textrm {{\\scriptsize LARGE}}$:n moniluokkaiseen tekstien luokittelutehtävään. Tällä tekniikalla saavutettiin vertailuarvoista paras tulos, ja keskimääräinen mikro-F1-pistemäärä oli 60,4 %.",
      "id": "task461-87e6a9165ae64e13bf7e6c676f499e37",
      "output": [
        "Mitkä ovat perustason vertailuarvot?"
      ]
    },
    {
      "input": "Tämä versio ylittää huomattavasti aikaisemman tekniikan tason, mutta siinä on silti vähemmän parametreja kuin aikaisemmissa töissä.",
      "id": "task461-7a7c650af7024a448eeed4714c35cbca",
      "output": [
        "Vertailevatko ne tuloksia uusimpiin kielimalleihin?"
      ]
    },
    {
      "input": "Oikeudellisesti järkevien vastausten löytämiseksi palkkaamme seitsemän juridisesti koulutettua asiantuntijaa laatimaan vastauksia Turkerin kysymyksiin. ",
      "id": "task461-40d4c38d98a44b86a932ebeff95e4ca3",
      "output": [
        "Keitä asiantuntijoita käytettiin kommentoinnissa?"
      ]
    },
    {
      "input": " Osoitamme, että twiittitekstin ulkopuolisen tiedon (URL-osoitteiden aloitussivuilta) ja käyttäjäominaisuuksien käyttö voi parantaa suorituskykyä merkittävästi. ",
      "id": "task461-4b8316c47f104256b84336ced7a5a459",
      "output": [
        "Mitä ulkoisia tietolähteitä käytetään?"
      ]
    },
    {
      "input": "Testaamme mgru:ta kahdella tunnetulla tietokannalla, Penn Treebankilla ja Text8:lla.",
      "id": "task461-8592e6b1c8804db1af69b32570764263",
      "output": [
        "Millä tietokokonaisuudella he kouluttavat mallinsa?"
      ]
    },
    {
      "input": " Tämän jälkeen koulutamme kappaleiden vektorimallin käyttämällä Document to Vector (Doc2Vec) -ohjelmistoa BIBREF7 koko esikäsitellyn tekstin (13 miljoonaa) joukolla, vaikka myös pienemmillä joukoilla (1 miljoona) harjoittelu tuottaa hyviä tuloksia.",
      "id": "task461-abbeed52d8a0400096760b5a93f8dcc4",
      "output": [
        "Mitä tekstin upottamismenetelmiä käytetään?"
      ]
    },
    {
      "input": "Havaitsimme prosessin aikana joitakin rajoituksia, joita kuvaamme tässä luvussa.Kun päätimme julkaisijan puolueellisuudesta, niiden henkilöiden määrä, joista laskimme pistemäärän, oli pieni. Esimerkiksi de Stentor tavoittaa arviolta 275 000 lukijaa päivittäin virallisella verkkosivustollaan. Yleisöön nojautumisen päättäminen 55 otoksen perusteella altistui otantavirheille. Sitä paitsi pisteet eroavat kustantajien välillä hyvin vähän. Yhdenkään kustantajan absoluuttinen pistemäärä ei ollut suurempi kuin 1, mikä tarkoittaa, että puolueellisin kustantaja oli vain vähän puolueellinen. Sen päättäminen, mitä kustantajia pidämme puolueellisina ja mitä ei, ei siis ole kovin luotettavaa. artikkelitason annotointitehtävä ei ollut yhtä tarkkaan määritelty kuin joukkoistamisalustalla. Sisällytimme kysymykset osaksi olemassa olevaa kyselyä emmekä halunneet aiheuttaa annotoijille suurta taakkaa. Siksi emme antaneet pitkää kuvailevaa tekstiä, jossa selitettiin, miten henkilön tulisi annotoida artikkeli. Näin ollen meillä on annotoijien puolueellisuuden riski. Tämä on yksi syy heikkoon arvioijien väliseen yhteisymmärrykseen.",
      "id": "task461-02a3a40a4c9c4c868daefbb1945060ea",
      "output": [
        "Mitä rajoituksia mainitaan?"
      ]
    },
    {
      "input": "Teemme kokeita useilla kielipareilla, kuten saksan ja englannin, ranskan ja englannin sekä japanin ja englannin välillä. ",
      "id": "task461-5e3ce47e42864601b35c4c3cdce2868e",
      "output": [
        "Mitä kieliä käytetään monikielisessä kuvatekstimallissa?"
      ]
    },
    {
      "input": "Sen sijaan, että lukisimme tokenisoidun syöttötekstin, mallimme lukee raakoja utf-8-tarkkoja tavuja. ASCII-alueen englanninkieliselle tekstille tämä vastaa merkkien käsittelyä yksittäisinä merkkeinä. Muut kuin ASCII-merkit (esim. aksenttimerkit tai muut kuin latinankieliset kirjoitusmerkit) ovat tyypillisesti kaksi tai kolme utf-8-tavua. Käytämme tavallista \"muuntajan dekooderia\" (pino muuntajakerroksia, joissa on kausaalinen huomiomaski) käsittelemään sekvenssiä $x_{0:i-1}$ ja ennustamaan seuraavan tavun $x_i$. Mallin ennuste on arvio todennäköisyysjakaumasta kaikkien mahdollisten 256 tavun arvojen yli. Syötteenä olevan tavun upotusmatriisimme ulottuvuus on 256.",
      "id": "task461-d7562ec144454143bb41a30ead8d839e",
      "output": [
        "Kuinka monta merkkiä hyväksytään kielimallin syötteeksi?"
      ]
    },
    {
      "input": "Työntekijöitä pyydetään arvioimaan, voidaanko lausuma johtaa artikkeleista kolmella tasolla, kun heille annetaan lausuma ja artikkelit: Totta, Todennäköistä (eli vastattavissa) tai Epävarmaa (eli vastaamattomia). Jos työntekijä valitsee vaihtoehdon Epävarma, pyydämme työntekijöitä kertomaan kahdesta vaihtoehdosta (\"Ei mainita artikkelissa\" tai \"Muu\"), miksi he ovat epävarmoja. Jos työntekijä valitsee arviointitehtävässä vaihtoehdon Totta tai Todennäköistä, kysymme ensin, mitkä annettujen artikkeleiden lauseet ovat perusteluja tietylle väitteelle, samoin kuin HotpotQA BIBREF2:ssa. \"Yhteenveto\"-tekstilaatikot (eli NLD:t) alustetaan sitten näillä valituilla lauseilla.",
      "id": "task461-9492e3672f494eebac47e3e694af25d9",
      "output": [
        "Miten tietokokonaisuutta kommentoitiin?"
      ]
    },
    {
      "input": "Kussakin kokeessa haettujen asiakirjojen tarkkuuden arvioimiseksi käytimme TREC_Eval-työkalua [3]. TREC_Eval on vakioväline IR-tehtävien arviointiin, ja sen nimi on lyhenne sanoista Text REtrieval Conference (TREC) Evaluation tool. TREC_Evalin raportoima keskimääräinen tarkkuus (Mean Average Precision, MAP) oli 27,99 prosenttia ilman kyselyn laajennusta ja 37,10 prosenttia kyselyn laajennuksen kanssa, mikä osoittaa yli 9 prosentin parannusta.",
      "id": "task461-f956a2589118422dadd53226fe540706",
      "output": [
        "Mitä arviointimittaria on mitattu?"
      ]
    },
    {
      "input": "Keskitymme tässä Europarl-alueeseen, josta meillä on runsaasti tietoja useilla kielillä, ja käytämme alan sisäisenä harjoitusaineistona Europarl-korpusta BIBREF5 kahta käännössuuntaa varten: Englannin INLINEFORM0 saksa ja englannin INLINEFORM1 ranska.",
      "id": "task461-1dfbd996ea004067ad40edf3f1d3fe18",
      "output": [
        "mitä kielipareja tutkitaan?"
      ]
    },
    {
      "input": "Arviointimittareina käytimme lebret2016neural-ohjelman mukaisesti BLEU-4-, NIST-4- ja ROUGE-4-mittareita.",
      "id": "task461-fe8db0859fba4913b992f625fc98e0d2",
      "output": [
        "Mitä mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Autokieli on abstraktia kieltä, joka liittyy auton fyysisiin ominaisuuksiin. Tässä tapauksessa fyysiset ominaisuudet, joihin termi \"nopea\" viittaa, voivat olla hevosvoimat, tai se voi olla auton muototekijä (miten auto näyttää). Emme kuitenkaan tiedä tarkalleen, mihin ominaisuuksiin termi \"nopea\" viittaa. Koulutamme sarjan luokittelijoita luokitellaksemme autopuheita. Koulutamme kolme luokittelijaa SECREF8-jaksossa laatimillamme arvosteluvektoreilla. Käyttämämme luokittelijat ovat K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM) ja Multi-layer Perceptron (MLP) BIBREF13.",
      "id": "task461-992bbe37b31141309adb9f6d98ef4d02",
      "output": [
        "Onko autokieli kokoelma abstrakteja piirteitä, joiden perusteella luokittelija koulutetaan myöhemmin?"
      ]
    },
    {
      "input": "Tiedonkeruuprosessi, jossa käytettiin jengiläisten käyttämiä sijaintineutraaleja avainsanoja ja laajennettua hakua heidän uudelleentwiittaus-, ystävä- ja seuraajaverkostoissaan, johti 400 aidon jengiläisen profiilin tunnistamiseen Twitterissä. Tutkimuksessamme havaittiin, että twiittien ja profiilikuvausten teksti, emojien käyttö, profiilikuvat ja musiikkiharrastukset, jotka ilmenevät linkkeinä YouTube-musiikkivideoihin, voivat auttaa luokittelijaa erottamaan toisistaan jengin jäsenten ja muiden kuin jengin jäsenten profiilit.",
      "id": "task461-a95b10081ce24fad80d8893b38424311",
      "output": [
        "Miten jengiin kuulumista koskeva perustotuus määritetään tässä aineistossa?"
      ]
    },
    {
      "input": "Tässä työssä analysoimme tietyn klassisen musiikin radiokanavaan, BBC Radio 3:een, liittyviä twiittejä ja pyrimme havaitsemaan kahdenlaisia musiikillisia nimettyjä entiteettejä, Contributor ja Musical Work.",
      "id": "task461-f10d3466182244e9a5f5dd5436cb62eb",
      "output": [
        "Millä kielellä Twitterin sisältö on?"
      ]
    },
    {
      "input": " Tässä käytetään pientä osaa englannin ja saksan välisestä suuresta rinnakkaisesta korpuksesta simulaationa skenaariota varten, jossa meillä ei ole paljon rinnakkaista tietoa: Englanninkielisten tekstien kääntäminen saksaksi. ",
      "id": "task461-e35901a2eb21400a82d70d04fe857499",
      "output": [
        "Millä kielillä he testaavat aliresursoitua skenaariota varten?"
      ]
    },
    {
      "input": "Kuvassa KUVIO15 esitetään saksan ja japanin testisarjan tarkkuus ilman resursseja suoritettujen vaiheiden määrän funktiona, kun käytössä on vastakohtainen koulutus ja kun sitä ei ole suoritettu. Kuvaajasta käy ilmi, että testitarkkuuden vaihtelu vähenee vastakohtaisen harjoittelun myötä, mikä viittaa siihen, että kieltenvälinen suorituskyky on johdonmukaisempi, kun vastakohtaista harjoittelua käytetään.",
      "id": "task461-cd60282757fa4813a83d2587631cac34",
      "output": [
        "Osoittaako mikään arvioinneista, että vastakkaisoppiminen parantaa suorituskykyä vähintään kahdessa eri kieliperheessä?"
      ]
    },
    {
      "input": "Tässä artikkelissa esitellään uusi toimintamalli, jonka avulla voidaan tuottaa useita toimintoja vuoroa kohti (ns. multi-toiminta), luoda sarja tupleja ja laajentaa agenttien ilmaisuvoimaa. Kukin tuple määritellään muotoon $(\\textit {continue}, \\textit {act}, \\textit {slots})$, jossa continue ilmaisee, jatketaanko vai lopetetaanko uusien tekojen tuottaminen, act on tekotyyppi (esim. inform tai request) ja slots on joukko nykyiseen tekotyyppiin liittyviä slotteja (nimiä). Vastaavasti ehdotetaan uudenlaista dekooderia (kuva KUVA 5) tällaisten sekvenssien tuottamiseksi. Kukin tupletti tuotetaan solulla nimeltä gated Continue Act Slots (gCAS, kuten kuvassa FIGREF7), joka koostuu kolmesta peräkkäin kytketystä gated-yksiköstä, jotka käsittelevät tupletin kolmea komponenttia. Tämä dekooderi voi tuottaa moniaktit kaksinkertaisella rekursiivisella tavalla BIBREF18. ",
      "id": "task461-708f60cb8c0c49a7a77311f558423c7c",
      "output": [
        "Mikä on erityistä gCAS-solulle?"
      ]
    },
    {
      "input": "Vertaamme malliamme kahteen perusjoukkoon: MemN2N BIBREF12 on päästä päähän koulutettava versio muistiverkoista BIBREF9 . Attentive and Impatient Readers BIBREF6 käyttää kaksisuuntaisia LSTM-verkkoja kysymyksen ja todisteiden koodaamiseen ja tekee luokittelun laajassa sanastossa näiden kahden koodauksen perusteella.",
      "id": "task461-f210a30a7925435d83a6a67dfd098b09",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Ensimmäisen kerroksen poistaminen käytöstä RTE-tehtävässä parantaa suorituskykyä merkittävästi, sillä absoluuttinen suorituskyky paranee 3,2 prosenttia. Tämän toimenpiteen vaikutukset vaihtelevat kuitenkin tehtävien välillä, ja QNLI- ja MNLI-tehtävissä se aiheuttaa jopa -0,2 prosentin suorituskyvyn laskun.",
      "id": "task461-7cf916ccf463407dbe57aea4893bebc0",
      "output": [
        "Kuinka paljon suorituskyky paranee, jos huomio poistetaan käytöstä tietyissä päissä?"
      ]
    },
    {
      "input": "Arvioimme ehdotetun kielimallin merkkitason muunnelmaa Penn Treebank (PTB) - ja Text8-tietokantojen esikäsitellyn version avulla. Valvomattomassa konstituution jäsentämistehtävässä verrataan mallin päättelemää puurakennetta ihmisasiantuntijoiden kommentoimiin rakenteisiin. Koe suoritetaan WSJ10-tietokannalla.",
      "id": "task461-bceca3fe8a1341f7970f532b6c8d8aff",
      "output": [
        "Millä tietokokonaisuudella he tekevät kokeita?"
      ]
    },
    {
      "input": "Tämä tietokokonaisuus kerättiin Mechanical Turkin kautta käyttäen 100 simuloitua ympäristöä ja vastaavaa topologista karttaa, ja tietojemme mukaan se on ensimmäinen laatuaan käyttäytymisnavigoinnin osalta.  Loimme uuden tietokokonaisuuden navigointiohjeiden seuraamista koskevaa ongelmaa varten BIBREFin5 käyttäytymiseen perustuvan navigointikehyksen mukaisesti. Tämä tietokokonaisuus luotiin käyttämällä Amazon Mechanical Turk -palvelua ja 100 karttaa simuloiduista sisäympäristöistä, joissa kussakin oli 6-65 huonetta. Tietojemme mukaan tämä on ensimmäinen vertailukohde käännösmallien vertailemiseksi käyttäytymiseen perustuvan robottinavigoinnin yhteydessä.Kuten taulukosta TABREF16 käy ilmi, tietokokonaisuus koostuu 8066 parista vapaamuotoisia luonnollisen kielen ohjeita ja navigointisuunnitelmia harjoittelua varten. Tämä harjoitusaineisto kerättiin 88 ainutlaatuisesta simuloidusta ympäristöstä, joissa on yhteensä 6064 erilaista navigointisuunnitelmaa (2002 suunnitelmassa on kussakin kaksi erilaista navigointiohjetta; lopuissa on yksi). Tietokokonaisuus sisältää kaksi testijoukkovaihtoehtoa: Vaikka tietokokonaisuus kerättiin simuloitujen ympäristöjen avulla, navigointiohjeille ei asetettu mitään rakennetta joukkoistamisen aikana. Näin ollen monet aineistossamme olevat ohjeet ovat moniselitteisiä. Lisäksi ohjeissa olevien käyttäytymismallien järjestys ei ole aina sama. Esimerkiksi eräs henkilö sanoi \"käänny oikealle ja etene\" kuvaamaan osaa reitistä, kun taas toinen henkilö sanoi samankaltaisessa tilanteessa \"mene suoraan oikealle kääntymisen jälkeen\". Koska aineistomme luonnollisen kielen kuvauksissa on suurta vaihtelua, ohjeiden purkaminen käyttäytymiseksi ei ole aivan yksinkertaista. Katso lisäaineiston liite A, jossa on lisätietoja tiedonkeruupyrkimyksistämme.",
      "id": "task461-a0cbc347a6b441b4b814b0f39bc0e37a",
      "output": [
        "Miten navigointiohjeet kerättiin?"
      ]
    },
    {
      "input": "Vain topologiset upotukset: ( INLINEFORM1 ) Topologian ja tekstin yhteinen upotus: Naivi yhdistelmä, TADW BIBREF5 , CENE BIBREF6 , CANE BIBREF9 , WANE BIBREF10 , DMTE BIBREF34 . ",
      "id": "task461-3fadfe499cc34325bfea2bae343d7ec5",
      "output": [
        "Mihin muihin sulautumiin niitä verrataan?"
      ]
    },
    {
      "input": "Muiden alojen tutkijat ovat mukauttaneet näitä NLP-yhteisön tehokkaita ideoita muihin kuin sanojen esittämiseen liittyviin tehtäviin, kuten relaatiokokonaisuuksiin BIBREF1 , BIBREF2 , yleisiin tekstipohjaisiin attribuutteihin BIBREF3 , kuvien kuvailevaan tekstiin BIBREF4 , verkkojen graafirakenteiden solmuihin BIBREF5 ja kyselyihin BIBREF6 , muutamia mainitakseni.",
      "id": "task461-50fffa5a22c9497b99d62c6d883f81d5",
      "output": [
        "Millaisilla aloilla on näin laajoja sanastoja?"
      ]
    },
    {
      "input": "Tutkimuksessamme katsomme, että twiitistä tuli virus, jos sitä uudelleentwiitattiin yli 1000 kertaa.",
      "id": "task461-e622cc2ed5dc40ea84d6b05cf56f75fb",
      "output": [
        "Mikä on heidän määritelmänsä siitä, että twiitit leviävät?",
        "Mikä on kynnys määrittää, että twiitti on muuttunut viraaliksi?"
      ]
    },
    {
      "input": "Vertailimme useita tiivistämismenetelmiä, jotka voidaan jakaa kolmeen ryhmään: valvomattomat, ei-neuraaliset valvotut ja neuraaliset valvotut menetelmät. Valvomattomien menetelmien osalta testasimme: SumBasic, joka käyttää sanojen frekvenssiä lauseiden sijoittamiseen ja valitsee parhaat lauseet yhteenvedoksi BIBREF13 , BIBREF14 . Lsa, joka käyttää latenttia semanttista analyysia (LSA) asiakirjan termi-lause-matriisin purkamiseen ja poimii lauseet tuloksen perusteella. Kokeilimme näitä kahta lähestymistapaa, joita ehdotettiin BIBREF15:ssä ja BIBREF16:ssä. LexRank, jossa asiakirjasta muodostetaan graafikuvaus, jossa solmut ovat lauseita ja särmät kahden lauseen välistä samankaltaisuutta, ja jossa suoritetaan PageRank-algoritmi kyseiselle graafille ja poimitaan lauseet tuloksena saatujen PageRank-arvojen perusteella BIBREF17 . TextRank, joka on hyvin samankaltainen kuin LexRank, mutta laskee lauseiden samankaltaisuuden yhteisten merkkien määrän perusteella BIBREF19 . Bayes, joka esittää jokaisen lauseen ominaisuusvektorina ja käyttää naiivia Bayes-menetelmää niiden luokitteluun BIBREF5 . Alkuperäisessä artikkelissa TF-IDF-pisteytys lasketaan monisanaisille tunnisteille, jotka tunnistetaan automaattisesti keskinäisen informaation avulla. Me emme tehneet tätä tunnistusta, joten TF-IDF-laskentamme perustuu sanamerkkeihin. Hmm, jossa käytetään piilotettua Markov-mallia, jonka tilat vastaavat sitä, pitäisikö lauseesta poimia BIBREF20 . Alkuperäisessä teoksessa käytetään QR-dekompositiota lauseiden valintaan, mutta meidän toteutuksessamme ei käytetä sitä. Me yksinkertaisesti järjestimme lauseet niiden pistemäärien mukaan ja valitsimme kolme parasta yhteenvedoksi. MaxEnt, joka edustaa kutakin lausetta ominaisuusvektorina ja käyttää maksimi-entropiamallia laskeakseen todennäköisyyden sille, että lause tulisi poimia BIBREF21 . Alkuperäisessä lähestymistavassa merkinnöille asetetaan ennakkojakauma, mutta me asetamme sen sijaan ennakkojakauman painoille. Toteutuksemme on silti alkuperäisen kanssa yhdenmukainen, koska käytimme bias-ominaisuutta, jonka pitäisi pystyä oppimaan etuliitejakauma. Neuraalisen valvotun menetelmän osalta arvioimme NeuralSum BIBREF11 -menetelmää käyttäen tekijöiden alkuperäistä toteutusta. Muutimme heidän toteutustaan hieman, jotta mallia voidaan arvioida ROUGE:n avulla. Huomaa, että kaikki menetelmät ovat ekstraktiivisia. Toteutuskoodimme kaikille edellä mainituille menetelmille on saatavilla verkossa. Käytimme perustasona Lead-N:ää, joka valitsee yhteenvedoksi INLINEFORM0:n johtavat lauseet. Kaikissa menetelmissä poimimme yhteenvedoksi 3 lausetta, koska se on tutkivan analyysin perusteella löytämiemme kultaisten yhteenvetojen lauseiden lukumäärän mediaani.",
      "id": "task461-517bf82c973b42f7aff789ee8448d282",
      "output": [
        "Mitä lähestymistapoja he käyttivät?"
      ]
    },
    {
      "input": "Jokainen twiitti on merkitty merkinnällä, jossa ei ole todisteita masennuksesta (esim. \"Kansalaiset pelkäävät taloudellista lamaa\") tai todisteita masennuksesta (esim. \"masentunut pettymyksestä\"). Jos twiitti on merkitty todisteeksi masennuksesta, se merkitään lisäksi yhdellä tai useammalla masennusoireella, esimerkiksi masentuneella mielialalla (esim. \"masentunut olo\"), unihäiriöillä (esim. \"taas yksi levoton yö\") tai väsymyksellä tai energian menetyksellä (esim. \"väsymys on sietämätöntä\") BIBREF10 .",
      "id": "task461-7eacdaabc12b416ea6f935a9a9b01879",
      "output": [
        "Miten tietokokonaisuus on kommentoitu?"
      ]
    },
    {
      "input": "Käytämme DSTC2 BIBREF20 -tietokokonaisuutta ja Maluuba BIBREF21 -tietokokonaisuutta ehdotetun mallin arvioimiseksi.",
      "id": "task461-3552697a524b467c9241a23e7dbc3fe1",
      "output": [
        "Mitä kahta vertailutietoaineistoa käytetään?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa käsitellään lyhyesti laadunvarmistusjärjestelmän vaiheita ja verrataan seitsemän koneoppimiseen perustuvan luokittelijan (Multi-Layer Perceptron (MLP), Naive Bayes Classifier (NBC), Support Vector Machine (SVM), Gradient Boosting Classifier (GBC), Stochastic Gradient Descent (SGD), K Nearest Neighbour (K-NN) ja Random Forest (RF)) suorituskykyä bengalinkielisten kysymysten luokittelussa luokkiin odotettujen vastausten perusteella.",
      "id": "task461-a579ccfc562b4b6f97195b6210f80b2f",
      "output": [
        "mitä ml-pohjaisia lähestymistapoja verrattiin?"
      ]
    },
    {
      "input": "Yksittäisen pään poistamisesta käytöstä saatava hyöty on erilainen eri tehtävissä, ja se vaihtelee STS-B:n pienimmästä absoluuttisesta hyödystä 0,1 %:sta MRPC:n suurimpaan 1,2 %:iin (ks. kuva: disableheadsall). Lisäksi koko kerroksen, eli kaikkien 12 pään poistaminen käytöstä tietyssä kerroksessa, parantaa myös tuloksia. Kuva:disablelayers osoittaa mallin suorituskyvyn GLUE-tavoitetehtävissä, kun eri kerrokset poistetaan käytöstä.",
      "id": "task461-e9ebba7b44e2428591d94854b4aa7496",
      "output": [
        "Missä tietyissä päissä tarkkaavaisuus oli kokeissa pois käytöstä?"
      ]
    },
    {
      "input": "Muihin kohdetehtäviin verrattuna kielioppiin liittyvä CoLA-tehtävä hyötyy huomattavasti ELMon esivalmennuksesta: Paras tulos ilman kielimallin esivalmennusta on alle puolet tuloksesta, joka saavutetaan tällaisen esivalmennuksen avulla. Sitä vastoin merkityssuuntautuneessa tekstin samankaltaisuuden vertailutehtävässä STS saadaan hyviä tuloksia useilla esivalmennuksilla, mutta ELMon käytöstä ei ole merkittävää hyötyä.",
      "id": "task461-b03cf38ca1ce4d8daaaf6154eee895c3",
      "output": [
        "Suoriutuvatko jotkin esivalmennuksen tavoitteet paremmin kuin toiset lausetason ymmärtämistehtävissä?"
      ]
    },
    {
      "input": "Yksinkertaisuuden vuoksi keskitymme analyysissämme New Yorkin Manhattanin Airbnb-ilmoituksiin ajanjaksolla 1. tammikuuta 2016-1. tammikuuta 2017. Meille toimitetut tiedot sisälsivät tietoja noin 40 000:sta Airbnb:ssä julkaistusta Manhattanin majoituspaikasta, jotka julkaistiin Airbnb:ssä tämän määritellyn ajanjakson aikana. Kunkin ilmoituksen osalta meille annettiin tiedot ilmoituksen mukavuuksista (kylpyhuoneiden lukumäärä, makuuhuoneiden lukumäärä ...), ilmoituksen postinumero, isännän kuvaus ilmoituksen sisällöstä, ilmoituksen hinta ja ilmoituksen käyttöaste. ",
      "id": "task461-7c14d80ff9194141aa7ea80ed7667cfc",
      "output": [
        "Mikä on Airbnb:n koko?"
      ]
    },
    {
      "input": "Aiemmissa töissä ei kuitenkaan ole tutkittu loukkaavan kielenkäytön kohdetta, mikä on tärkeää monissa tilanteissa, esimerkiksi tutkittaessa vihapuhetta tietyn kohteen osalta.",
      "id": "task461-2775f3d9607c4b809d739c372e16bca8",
      "output": [
        "Mitä eroja on tämän tietokokonaisuuden ja jo olemassa olevien tietokokonaisuuksien välillä?"
      ]
    },
    {
      "input": "Kokeelliset tulokset osoittavat, että yhteinen mallimme päihittää pelkän visuaalisen mallin kaikissa tapauksissa ja pelkän tekstin mallin Wikipediassa ja kahdessa arXivin osajoukossa.",
      "id": "task461-6ffdf94bb562403992a57f7d308ceb06",
      "output": [
        "Toimivatko menetelmät, jotka toimivat parhaiten akateemisissa artikkeleissa, parhaiten myös Wikipediassa?"
      ]
    },
    {
      "input": "Vertailun vuoksi koulutamme ja arvioimme näitä järjestelmiä VLSP-korpusten avulla. Erityisesti teemme kokeita Viet Treebankin korpuksella POS-tagaus- ja chunking-tehtäviä varten ja VLSP shared task 2016 -korpuksella NER-tehtävää varten. Kaikki nämä korpukset muunnetaan CoNLL-muotoon. POS-tagitehtävän korpus koostuu kahdesta sarakkeesta, nimittäin sanasta ja POS-tagista. Chunking-tehtävää varten korpuksessa on kolme saraketta, nimittäin sana, POS-tag ja chunk. NER-tehtävän korpus koostuu neljästä sarakkeesta. Näiden sarakkeiden järjestys on sana, POS-tunniste, klusteri ja nimetty entiteetti. NER-korpus on jaettu harjoitus- ja testausosiin, mutta POS-tagaus- ja chunking-tietoaineistoja ei ole aiemmin jaettu. Tästä syystä käytämme näistä aineistoista INLINEFORM0:aa koulutusjoukkona ja loput testausjoukkona. Koska järjestelmässämme käytetään varhaisen lopettamisen menetelmää, käytämme INLINEFORM1:tä näistä koulutusjoukon datajoukoista kehitysjoukkona, kun koulutamme NNVLP-järjestelmää. Taulukoissa TABREF24 ja TABREF25 esitetään kunkin korpuksen tilastot.",
      "id": "task461-36bfa5cae125448081fff8030c2c0104",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät tehtävissä?"
      ]
    },
    {
      "input": "Tässä asiakirjassa ehdotamme ensimmäistä laajamittaista tietokokonaisuutta sosiaalisen median tietojen laadunvarmistusta varten.   Taulukossa TABREF3 on esimerkki TweetQA-aineistosta. Tietokokonaisuus sisältää nyt 10 898 artikkelia, 17 794 twiittiä ja 13 757 joukkoresursoitua kysymys-vastaus -paria.",
      "id": "task461-29f78b72d73941d4afe54badfe254899",
      "output": [
        "Mikä on tämän tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Kuten kohdassa SECREF2 käsiteltiin, NLP-yhteisössä on saatavilla useita ominaisuuksia, jotka mittaavat tekstin sisältämän entiteetin tärkeyttä. Toteutimme uudelleen Dunietzin ja Gillickin BIBREF11 -julkaisussa esitetyt ominaisuudet. Tämä sisältää erilaisia piirteitä, esimerkiksi sijaintipiirteitä, esiintymistiheyttä sekä entiteetin ja sen sisältämän lauseen sisäistä POS-rakennetta. ",
      "id": "task461-a0a5b16d2e2145cd9fd20073bbc957ce",
      "output": [
        "Mitä ominaisuuksia käytetään kuvaamaan entiteettien tärkeyttä ja suhteellista arvovaltaa?"
      ]
    },
    {
      "input": "Esittelimme uuden lähestymistavan, jolla muunnetaan maskuliinisesti taivutettujen ja feminiinisesti taivutettujen substantiivilauseiden välillä morfologisesti rikkaissa kielissä. Tätä varten otimme käyttöön Markovin satunnaiskentän, jossa on valinnainen neuraalinen parametrisointi, joka päättelee, millä tavalla lauseen on muututtava, jotta morfosyntaktinen yhteisymmärrys säilyy, kun tiettyjen substantiivien kieliopillista sukupuolta muutetaan.",
      "id": "task461-3b5e313993e945a08b2aeae2ec0fb73c",
      "output": [
        "Minkä mallin avulla he vaihtavat maskuliinisesti taivutetut ja feminiinisesti taivutetut lauseet?"
      ]
    },
    {
      "input": "Toinen suuntaus on se, että käyttämällä alle 50 prosenttia käytettävissä olevista tiedoista malli pyrkii sovittamaan tiedot liian hyvin, kuten validointitappion johdonmukainen kasvu osoittaa noin 15 epookin jälkeen (katso katkoviivat kuvan FIGREF28 oikealla puolella).",
      "id": "task461-2ecb6a0c85d542a2be1f27859518513d",
      "output": [
        "Mitkä kokeelliset tulokset viittaavat siihen, että alle 50 prosentin käyttö käytettävissä olevista harjoitusesimerkeistä saattaa johtaa ylisovittamiseen?"
      ]
    },
    {
      "input": "Tässä vaiheessa lasketaan kaikkien sanojen esiintymät harjoitusjoukossa ja lajitellaan ne esiintymien vähenemisjärjestykseen. Kuten edellä mainittiin, sanavarastoksi katsotaan INLINEFORM0 useimmin esiintyvät sanat, jotka esiintyvät vähintään INLINEFORM1 kertaa. Se on toteutettu Sparkissa suoraviivaisena map-reduce-tehtävänä.",
      "id": "task461-084ff33e37bd4d5db439834b3ff60748",
      "output": [
        "Suorittavatko ne mitään morfologista tokenisointia?"
      ]
    },
    {
      "input": "Ensimmäisenä tietokokonaisuutena käytimme turkkilaisia elokuva-arvosteluja, jotka on kerätty suositulta verkkosivustolta. Tässä elokuvakorpuksessa on 20 244 elokuva-arvostelua, ja arvostelujen keskimääräinen sanamäärä on 39 sanaa. Jokaisella arvostelulla on tähtiarvosana, joka kertoo elokuvan tunnetilasta. Nämä polariteettipisteet ovat arvojen 0,5 ja 5 välillä 0,5:n välein. Katsomme, että arvostelu on negatiivinen, jos sen pistemäärä on 2,5 tai pienempi. Toisaalta, jos se on yhtä suuri tai suurempi kuin 4, sen oletetaan olevan positiivinen. Olemme valinneet satunnaisesti 7 020 negatiivista ja 7 020 positiivista arviota ja käsitelleet vain ne.",
      "id": "task461-95cca4fae917471587edb473b627c6da",
      "output": [
        "Mitä tietoja elokuvatietokannasta annetaan?"
      ]
    },
    {
      "input": "Malli koostuu koodaajasta (§SECREF5) ja dekooderista, jossa on huomiomekanismi (§SECREF7), jotka molemmat on toteutettu käyttämällä rekursiivisia neuroverkkoja (RNN); koodaaja muuntaa lähdesanat vektoreiden sekvenssiksi ja dekooderi tuottaa kohdekielen sanat yksi kerrallaan huomiomekanismin avulla yhtälössä DISPLAY_FORM2 ja DISPLAY_FORM3 esitetyn ehdollisen todennäköisyyden perusteella.",
      "id": "task461-640e2db9333e462d88cfcc28970b2ffc",
      "output": [
        "Mitä malliarkkitehtuuria he käyttävät mallin rakentamiseen?"
      ]
    },
    {
      "input": "Erityisesti NLG-tehtävässä yksittäinen mallimme päihitti kilpailevat mallit sekä Rouge-L:n että Bleu-1:n osalta.",
      "id": "task461-7eaf8036a2fb4553865d680eaed354fe",
      "output": [
        "Miten tiivistelmien laatua mitataan?"
      ]
    },
    {
      "input": "Käytämme BIBREF5:n katastrofitietoja. Se sisältää erilaisia tietokokonaisuuksia, mukaan lukien CrisiLexT6 -tietokokonaisuus, joka sisältää kuusi englanninkielisiin twiitteihin liittyvää kriisitapahtumaa vuosina 2012 ja 2013, jotka on merkitty kunkin kriisin aiheeseen liittyvyyden (on-topic ja off-topic) mukaan. Kukin kriisitapahtuman twiitti sisältää lähes 10 000 leimattua twiittiä, mutta keskitymme vain tulviin liittyviin twiitteihin, joten kokeilimme vain kahta tulvatapahtumaa eli Queenslandin tulvaa Queenslandissa, Australiassa ja Albertan tulvaa Albertassa, Kanadassa, ja leimasimme kaikki aiheeseen liittyvät twiitit aiheeseen liittyviksi ja aiheeseen liittymättömät twiitit aiheeseen liittymättömiksi, jotta ymmärrettäisiin implisiittiset luokkatunnisteet tässä tapauksessa.",
      "id": "task461-c09734afba924d199d73dea3f3641b8e",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": "Neuraalinen konekäännös koulutettiin Nematus-ohjelmalla. Sekä NMT- että PreMT-järjestelmässä käytettiin oletuskonfiguraatiota.",
      "id": "task461-3c9ac1c39a164ac1ae6938bd6f1e8766",
      "output": [
        "Mitä NMT-arkkitehtuuria ne käyttävät?"
      ]
    },
    {
      "input": "BioNLP 2009 Shared Task BIBREF195 perustui GENIA-korpukseen BIBREF196 , joka sisältää PubMed-artikkelien tiivistelmiä ihmisen verisoluissa esiintyvistä transkriptiotekijöistä.",
      "id": "task461-ed66698e37b24e3c84751510c983486e",
      "output": [
        "Mitä tietokokonaisuuksia tässä työssä käytetään?"
      ]
    },
    {
      "input": "Huomioon perustuva käännösmalli Käytämme BIBREF6 -järjestelmää, joka on konvolutiomalli sekvenssistä sekvenssiin.",
      "id": "task461-053fe219558e44f48cf2be709c9dadfa",
      "output": [
        "Mitä käännösjärjestelmää he käyttävät kääntääkseen englanniksi?"
      ]
    },
    {
      "input": "Tietokokonaisuuksien keräämisessä käytämme positiivisina näytteinä otsikoita, jotka on kerätty qin2018automatic, lin2019learning -ohjelmassa Tencent Newsilta, joka on yksi suosituimmista kiinalaisista uutissivustoista. Noudatamme samaa datan jakoa kuin alkuperäisessä artikkelissa. Koska osa linkeistä ei ole enää saatavilla, saamme 170 754 harjoitusnäytettä ja 4511 validointinäytettä. Negatiivisten harjoitusnäytteiden keräämistä varten valitsemme satunnaisesti luotuja otsikoita osoitingeneraattori BIBREF0-mallista, joka on koulutettu LCSTS:n tietokokonaisuudella BIBREF5, ja luomme tasapainoisen harjoituskorpuksen, joka sisältää 351 508 harjoitusnäytettä ja 9 022 validointinäytettä. Koulutetun luokittelijan arvioimiseksi muodostamme testijoukon ottamalla satunnaisesti 100 otsikkoa LCSTS-tietokannan testiosasta, ja merkinnät saadaan 11 ihmisen annotoijalta. Käytämme LCSTS BIBREF5 -tietokokonaisuutta tiivistelmämallin kouluttamiseen. Aineisto on kerätty kiinalaiselta mikroblogisivustolta Sina Weibo. Se sisältää yli 2 miljoonaa kiinankielistä lyhyttä tekstiä, joiden otsikot on antanut kunkin tekstin kirjoittaja. Tietokokonaisuus on jaettu 2 400 591 näytteeseen koulutusta varten, 10 666 näytteeseen validointia varten ja 725 näytteeseen testausta varten. Jokainen lause merkitään Jieba-ohjelmalla, ja sanaston koko on 50000.",
      "id": "task461-6f9718edd35d4695bc740e770021230d",
      "output": [
        "Käytettiinkö arvioinnissa toisen alan tietokokonaisuuksia?"
      ]
    },
    {
      "input": "Lisäksi QA:lla ja QG:llä on todennäköisyyskorrelaatio, koska molemmat tehtävät liittyvät $q$:n ja $a$:n yhteiseen todennäköisyyteen. Kun kysymys-vastaus -parin $\\kysymys q, a \\kysymys $ annetaan, yhteistodennäköisyys $P(q, a)$ voidaan laskea kahdella vastaavalla tavalla.$$P(q, a) = P(a) P(q|a) = P(q)P(a|q)$$ (Yht. 1)Ehdollinen jakauma $P(q|a)$ vastaa täsmälleen QG-mallia, ja ehdollinen jakauma $P(a|q)$ on läheisesti yhteydessä QA-malliin. Olemassa olevat tutkimukset oppivat tyypillisesti QA-mallin ja QG-mallin erikseen minimoimalla omia häviöfunktioitaan ja jättämällä huomiotta niiden välisen todennäköisyyskorrelaation.Näiden näkökohtien perusteella esittelemme koulutuskehyksen, joka hyödyntää QA:n ja QG:n kaksinaisuutta molempien tehtävien parantamiseksi. QA:n ja QG:n kaksinaisuutta voidaan hyödyntää eri tavoin. Tässä työssä hyödynnämme QA:n ja QG:n välistä todennäköisyyskorrelaatiota regularisointiterminä vaikuttaaksemme molempien tehtävien koulutusprosessiin. Tarkemmin sanottuna kehyksemme koulutustavoitteena on oppia yhdessä $\\theta _{qa}$:lla parametrisoitu QA-malli ja $\\theta _{qg}$:lla parametrisoitu QG-malli minimoimalla niiden häviöfunktiot seuraavan rajoituksen mukaisesti.$$P_a(a) P(q|a;\\theta _{qg}) = P_q(q)P(a|q;\\theta _{qa})$$ (Yhtälö 3)$P_a(a)$ ja $P_q(q)$ ovat vastauslauseiden ja kysymyslauseiden kielimallit. Kaiken kaikkiaan kehys sisältää kolme komponenttia, nimittäin QA-mallin, QG-mallin ja regularisointitermin, joka kuvastaa QA:n ja QG:n kaksinaisuutta. QA-kohtaisen tavoitteen tavoitteena on minimoida häviöfunktio $l_{qa}(f_{qa}(a,q;\\theta _{qa}), label)$ , jossa $label$ on 0 tai 1, joka ilmaisee, onko $a$ oikea vastaus kohtaan $q$ vai ei. Jokaisen oikean kysymys-vastausparin osalta QG-kohtainen tavoite on minimoida seuraava häviöfunktio,$$l_{qg}(q, a) = -log P_{qg}(q|a;\\theta _{qg})$$ (Yht. 6)$$, jossa $a$ on oikea vastaus kysymykseen $q$ . Kolmas tavoite on regularisointitermi, joka täyttää yhtälössä 3 esitetyt todennäköisyysduraliteettirajoitukset . Tarkemmin sanottuna, kun on annettu oikea $\\kulma q, a \\kulma $ pari, haluamme minimoida seuraavan häviöfunktion,$$ \\nonumber l_{dual}(a,q;\\theta _{qa}, \\theta _{qg}) &= [logP_a(a) + log P(q|a;\\theta _{qg}) \\\\\\ & - logP_q(q) - logP(a|q;\\theta _{qa})]^2$$ (Yht. 9)missä $P_a(a)$ ja $P_q(q)$ ovat marginaalijakaumia, jotka saadaan helposti kielimallin avulla.",
      "id": "task461-c75331d360244a328ae80ca107cffaf9",
      "output": [
        "Mitä tarkoittaa \"hyödyntää nimenomaisesti niiden todennäköisyyskorrelaatiota molempien mallien koulutusprosessin ohjaamiseksi\"?"
      ]
    },
    {
      "input": " Viittaamme lukijaa BIBREF10:een, jossa on lisätietoja propagandatekniikoista; alla on luettelo tekniikoista: Propagandatekniikat ::: 1. Kuormitettu kieli.Sanojen/lauseiden käyttäminen, joilla on voimakas emotionaalinen merkitys (positiivinen tai negatiivinen) yleisöön vaikuttamiseksi BIBREF11.Propagandatekniikat ::: 2. Nimittely tai leimaaminen.Propagandan kohteen leimaaminen joksikin, mitä kohdeyleisö pelkää, vihaa, pitää epätoivottavana tai muuten rakastaa tai ylistää BIBREF12.Propagandatekniikat ::: 3. Toistaminen.Saman viestin toistaminen yhä uudelleen ja uudelleen, jotta yleisö lopulta hyväksyisi sen BIBREF13, BIBREF12.Propagandatekniikat ::: 4. Liioittelu tai vähättely.Joko jonkin asian esittäminen liiallisella tavalla: asioiden tekeminen suuremmiksi, paremmiksi tai huonommiksi tai jonkin asian esittäminen vähemmän tärkeältä tai pienemmältä kuin se todellisuudessa on BIBREF14, esim. sanomalla, että loukkaus oli vain vitsi.Propagandatekniikat ::: 5. Epäilys.Jonkun tai jonkin asian uskottavuuden kyseenalaistaminen.Propagandatekniikat ::: 6. Pelkoon/ennakkoluuloihin vetoaminen.Pyritään saamaan tukea ajatukselle herättämällä väestössä ahdistusta ja/tai paniikkia vaihtoehtoa kohtaan, mahdollisesti ennakkokäsityksiin perustuen.Propagandatekniikat :::: 7. Lippujen heiluttaminen.Vahvoilla kansallisilla tunteilla (tai ryhmään, esim. rotuun, sukupuoleen tai poliittisiin mieltymyksiin liittyvillä tunteilla) leikittely toiminnan tai ajatuksen oikeuttamiseksi tai edistämiseksi BIBREF15.Propagandatekniikat :::: 8. Syy-seuraussuhteiden liiallinen yksinkertaistaminen.Oletetaan yksi syy, vaikka asian taustalla on useita syitä. Siihen kuuluu myös syntipukkius: syyllisyyden siirtäminen yhteen henkilöön tai ihmisryhmään tutkimatta asian monimutkaisuutta.Propagandatekniikat ::: 9. Iskulauseet: Lyhyt ja näyttävä lause, joka voi sisältää leimaamista ja stereotypisointia. Iskulauseilla on taipumus toimia emotionaalisina vetoomuksina BIBREF16.Propagandatekniikat ::: 10. Auktoriteettiin vetoaminen: Väite, jonka mukaan väite on totta vain siksi, että asiaa käsittelevä auktoriteetti/asiantuntija tukee sitä, ilman muita tukevia todisteita BIBREF17. Sisällytämme mukaan erikoistapauksen, jossa viittaus ei ole auktoriteetti/asiantuntija, vaikka kirjallisuudessa sitä kutsutaankin todistukseksi BIBREF14.Propagandatekniikat ::: 11. Mustavalkoinen harhaluulo, diktatuuri.Kahden vaihtoehtoisen vaihtoehdon esittäminen ainoina mahdollisuuksina, vaikka todellisuudessa vaihtoehtoja on useampia BIBREF13. Ääritapauksessa yleisölle kerrotaan täsmälleen, mihin toimiin sen tulisi ryhtyä, jolloin kaikki muut mahdolliset vaihtoehdot suljetaan pois (diktatuuri).Propagandatekniikat :::: 12. Ajatuksen katkaiseva klisee.Sanoja tai lauseita, jotka estävät kriittisen ajattelun ja mielekkään keskustelun tietystä aiheesta. Ne ovat tyypillisesti lyhyitä ja yleisiä lauseita, jotka tarjoavat näennäisen yksinkertaisia vastauksia monimutkaisiin kysymyksiin tai jotka vievät huomion pois muilta ajatuslinjoilta BIBREF18.Propagandatekniikat ::: 13. Whataboutism.Discredit an opponent's position by charging them with hypocrisy without directly disproving their argument BIBREF19.Propaganda Techniques ::: 14. Reductio ad Hitlerum.Yleisön suostuttelu paheksumaan jotakin toimintaa tai ajatusta vihjaamalla, että kyseinen ajatus on suosittu kohdeyleisön halveksimissa ryhmissä. Se voi viitata mihin tahansa henkilöön tai käsitteeseen, jolla on negatiivinen konnotaatio BIBREF20.Propagandatekniikat :::: 15. Punahilkka.Epäolennaisen materiaalin tuominen käsiteltävään asiaan, jotta kaikkien huomio harhautuu pois esitetyistä asioista BIBREF11. Punaisen harhaanjohtavan väitteen kohteeksi joutuneet johdatellaan pois keskustelun keskiössä olleesta asiasta ja kehotetaan seuraamaan havaintoa tai väitettä, joka saattaa liittyä alkuperäiseen väitteeseen, mutta joka ei ole kovinkaan olennainen kiistanalaisen asian kannalta BIBREF20.Propagandatekniikat ::: 16. Bandwagon.Yritetään saada kohdeyleisö liittymään mukaan ja ryhtymään toimintatapaan, koska \"kaikki muutkin ryhtyvät samaan toimintaan\" BIBREF15.Propagandatekniikat ::: 17. Hämärtäminen, tarkoituksellinen epämääräisyys, hämmennys.Käytetään tarkoituksellisesti epäselviä sanoja, jotta yleisö saisi oman tulkintansa BIBREF21, BIBREF11. Esimerkiksi silloin, kun argumentissa käytetään epäselvää lausetta, jolla on useita mahdollisia merkityksiä, eikä se näin ollen oikeastaan tue johtopäätöstä.Propagandatekniikat ::: 18. Straw man: Kun vastustajan väite korvataan samankaltaisella, joka sitten kumotaan alkuperäisen BIBREF22 sijasta.",
      "id": "task461-fb6c72cb245446d8b693a0ecd18fb3ed",
      "output": [
        "Mitkä ovat 18 propagandatekniikkaa?"
      ]
    },
    {
      "input": "Kokeemme tehdään todellisella uhanalaisella kielellä, Mboshi (Bantu C25), jota puhutaan Kongo-Brazzavillessa, käyttäen BIBREF17:n kaksikielistä ranska-mboshi 5K -korpusta.",
      "id": "task461-5329a3a7ea764ab2af233ddeb048ed83",
      "output": [
        "Mihin kieliperheeseen Mboshi kuuluu?"
      ]
    },
    {
      "input": "Corpus utilizados ::: Corpus 5KLEste corpus fue constituido con aproximadamente 5 000 documentos (en su mayor parte libros) en español. Los documentos originales, en formatos heterogéneos, fueron procesados para crear un único documento codificado en utf8. Las frases fueron segmentadas automáticamente, usando un programa en PERL 5.0 y expresiones regulares, para obtener una frase por línea.Las características del corpus 5KL se encuentran en la Tabla TABREF4. Este corpus es empleado para el entrenamiento de los modelos de aprendizaje profundo (Deep Learning, Sección SECREF4).El corpus literario 5KL posee la ventaja de ser muy extenso y adecuado para el aprendizaje automático. Tiene sin embargo, la desventaja de que no todas las frases son necesariamente \"frases literarias\". Muchas de ellas son frases de lengua general: estas frases a menudo otorgan una fluidez a la lectura y proporcionan los enlaces necesarios a las ideas expresadas en las frases literarias.Otra desventaja de este corpus es el ruido que contiene. El proceso de segmentación puede producir errors en la detección de fronteras de frases. También los números de página, capítulos, secciones o índices producen errores. No se realizó ningún proceso manual de verificación, por lo que a veces se introducen informaciones indeseables: copyrights, datos de la edición u otros. Estas son, sin embargo, las condiciones que presenta un corpus literario real.Corpus utilizados ::: Corpus 8KFUn corpus heterogéneo de casi 8 000 frases literarias fue constituido manualmente a partir de poemas, discursos, citas, cuentos y otras obras. Se evitaron cuidadosamente las frases de lengua general, y también aquellas demasiado cortas ($N \\le 3$ palabras) or demasiado largas ($N \\ge 30$ palabras). El vocabulario empleado es complejo y estético, además que el uso de ciertas figuras literarias como la rima, la anáfora, la metáfora y otras pueden ser observadas en estas frases.Las características del corpus 8KF se muestran en la Tabla TABREF6. Este corpus fue utilizado principalmente en los dos modelos generativos: modelo basado en cadenas de Markov (Sección SECREF13) y modelo basado en la generación de Texto enlatado (Canned Text, Sección SECREF15).",
      "id": "task461-6e548c16c2804a7ebf003461d4a5d32d",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Toinen lähestymistapa kyselyjen ja kuvien esitystapojen luomiseen on kuvien käsitteleminen mustana laatikkona. Kun otetaan huomioon tietokokonaisuutemme tilastot (3B kysely- ja kuvaparia, joissa on 220 miljoonaa yksilöllistä kyselyä ja 900 miljoonaa yksilöllistä kuvaa), tiedämme, että eri kyselyt esiintyvät samojen kuvien kanssa. Jos kysely $q_1$ esiintyy useiden samojen kuvien kanssa kuin kysely $q_2$ , niin $q_1$ ja $q_2$ ovat todennäköisesti semanttisesti samankaltaisia riippumatta yhteisten kuvien visuaalisesta sisällöstä. Näin ollen voimme käyttää menetelmää, joka käyttää vain esiintymistilastoja, ymmärtääkseen paremmin, kuinka hyvin pystymme kuvaamaan kyselyiden välisiä suhteita.",
      "id": "task461-61e7cec9830944aaacaa5ea2638eb29b",
      "output": [
        "Voisitko oppia tällaisen sulauttamisen pelkästään kuvamerkintöjen perusteella ja ilman visuaalista informaatiota?"
      ]
    },
    {
      "input": "Ensinnäkin se tarjoaa kommentointikäyttöliittymän, jonka avulla käyttäjät voivat määritellä sisältöelementtejä, ladata asiakirjoja ja kommentoida asiakirjoja. Alustamme pystyy ottamaan vastaan asiakirjoja eri muodoissa, kuten PDF- ja Microsoft Word -muodoissa, ja muuntaa nämä muodot tavalliseksi tekstiksi ennen niiden esittämistä kommentoijille.",
      "id": "task461-edce33c8f25d4ddb8461f50ca2195dc5",
      "output": [
        "Minkä tyyppisiä asiakirjoja annotaatioalusta tukee?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua malliamme Stanford Network Analysis Projectin (SNAP) Amazonin arvostelutietokannassa BIBREF8, joka sisältää arvostelujen ja arvosanojen lisäksi myös kultaisia tiivistelmiä. Vertailemme empiirisesti eri menetelmiä käyttämällä Amazon SNAP Review Dataset BIBREF20 -aineistoa, joka on osa Stanford Network Analysis Project -hanketta. Jotta voimme tehdä oikeudenmukaisen vertailun aiempiin töihin, otamme käyttöön samat osiot kuin aiemmissa töissä BIBREF6, BIBREF7, eli jokaisella alueella ensimmäiset 1000 näytettä otetaan kehitysjoukoksi, seuraavat 1000 näytettä testijoukoksi ja loput harjoitusjoukoksi.",
      "id": "task461-3e9a6ee4caad45a1a3cd6d372e04a571",
      "output": [
        "Mitä tarkistustietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Keskitymme ensisijaisesti pienempään 645 käsin merkityn artikkelin aineistoon, joka annettiin tehtävään osallistujille sekä harjoittelua että validointia varten.  Esikoulutimme BERT-basea 600 000:lla artikkelilla ilman merkintöjä käyttämällä samaa Cloze-tehtävää BIBREF5 , jota BERT oli alun perin käyttänyt esikoulutuksessa. ",
      "id": "task461-444505679a80499795205c33e707239f",
      "output": [
        "Kuinka pitkä tietokokonaisuus on?"
      ]
    },
    {
      "input": "Arvioimme menetelmäämme IWSLT16:n saksan ja englannin (DE-EN) välisessä käännöksessä molempiin suuntiin, WMT15:n englannin ja saksan (EN-DE) välisessä käännöksessä molempiin suuntiin ja NIST:n kiinan ja englannin (ZH$\\rightarrow $EN) välisessä käännöksessä.",
      "id": "task461-867f1d472944461aab2d208390d41e30",
      "output": [
        "Millä kielillä he tekevät kokeita?"
      ]
    },
    {
      "input": "Koska tässä tutkimuksessa keskitytään espanjankielisiin twiitteihin, kaikki englanninkielisten tietokokonaisuuksien twiitit käännettiin espanjaksi. ",
      "id": "task461-416b01259556481db06676a1cff046f7",
      "output": [
        "Miltä muilta kieliltä he käänsivät tiedot?"
      ]
    },
    {
      "input": "mcdonald:11 totesi, että kun kohdekielellä ei ole saatavilla puupankki-annotaatioita, harjoittelu useilla lähdekielillä päihittää harjoittelun yhdellä kielellä (eli usean lähteen mallinsiirto päihittää yhden lähteen mallinsiirron). Guo:16:n mukaisesti kunkin kohdekielen osalta jäsennin koulutetaan kuudella muulla kielellä Googlen universaalissa riippuvuuspankissa versiossa 2.0 (de, en, es, fr, it, pt, sv, lukuun ottamatta kohdekieltä) ja käytetään kultaisia karkean tason POS-tunnisteita.",
      "id": "task461-79603c600daf4cc1b7d4005c8c8ed19b",
      "output": [
        "Miten malli toimii, jos puupankkia ei ole saatavilla?"
      ]
    },
    {
      "input": "Testataksemme, voivatko opitut representaatiot erottaa äänneasukategoriat toisistaan, käytämme minimaalisen parin ABX-erottelutehtävää BIBREF19 , BIBREF20 . Puhujan sisäisessä tehtävässä kaikki puhelintripletit kuuluvat samalle puhujalle (esim. $x$3 ). Lopuksi jokaisen keskeisen puhujaparin pisteet keskiarvoistetaan ja vähennetään 1:stä, jotta saadaan raportoitu puhujan sisäinen ABX-virheprosentti. Puhujien välisessä tehtävässä $x$4 ja $x$5 kuuluvat samaan puhujaan ja $x$6 eri puhujaan (esim. $x$7 ). Tietyn minimiparin pisteet lasketaan ensin keskiarvona kaikista niistä puhujapareista, joille tämä kontrasti voidaan tehdä. Kuten edellä, tuloksena saadut pisteet keskiarvoistetaan kaikkien kontekstien ja kaikkien keskuspuhelinparien osalta ja muunnetaan virheprosentiksi.",
      "id": "task461-e9d437b6b0804c7ebfc3c16ad0abf906",
      "output": [
        "Mikä on se mittari, jota tässä asiakirjassa mitataan?"
      ]
    },
    {
      "input": "Tässä työssä käytämme perusluokittelijana MLP:tä (joka on muutettu käsittelemään tietojemme esitystapaa).",
      "id": "task461-94242bb39e23449b8ad5c32bc1e56f1c",
      "output": [
        "Mitä luokittelualgoritmia he käyttävät s2sL:ssä?"
      ]
    },
    {
      "input": "BERT-ADA BIBREF33 on APC-tehtävää varten ehdotettu toimialaan mukautettu yhteistyöhön perustuva yhteistyömalli, jossa BERT-BASE-mallia on hienosäädetty tehtävään liittyvällä korpuksella. Tämä malli saavutti huipputarkkuuden Laptops-tietokannassa. Rakennamme BERT-BASE-malliin perustuvan yhteisen mallin ATE:n ja APC:n monitehtävää varten. Kun malliparametrit oli optimoitu empiiristen tulosten perusteella, BERT-BASE-malliin perustuva yhteinen malli saavutti toivoa herättävän suorituskyvyn kaikissa kolmessa tietokokonaisuudessa ja jopa ylitti muut ehdotetut BERT-pohjaiset parannetut mallit joissakin tietokokonaisuuksissa, kuten BERT-PT, AEN-BERT, SDGCN-BERT jne.",
      "id": "task461-4e711a7f6f8c428d80ec2ce54827a08f",
      "output": [
        "Mikä oli SemEval-2014 task4 -tehtävän ravintola- ja kannettava tietokone -tietokannan nykytila?"
      ]
    },
    {
      "input": "Ensin vertaamme malleja BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2 CNN-malliinBIBREF0 ja Stanfordin CRF-malliinBIBREF21.",
      "id": "task461-1b051b0d48964d0bb2057ea22ee64b0c",
      "output": [
        "Mikä on lähtötaso?",
        "Mitä malleja käytetään Nepalin kielen NER:n ratkaisemiseen?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF39 käy ilmi, ehdotettu järjestelmä saa jatkuvasti parhaat tulokset kaikissa neljässä tietokokonaisuudessa. SemEval ABSA -kilpailun voittaneisiin järjestelmiin verrattuna kehyksemme saavuttaa 5,0 %, 1,6 %, 1,4 % ja 1,3 % absoluuttisen parannuksen INLINEFORM0-, INLINEFORM1-, INLINEFORM2- ja INLINEFORM3-tietokannoissa.Kehyksemme voi päihittää riippuvuuksien jäsennykseen perustuvan huippumallin RNCRF:n kaikissa tietokannoissa. Huomaamme myös, että RNCRF ei suoriudu hyvin INLINEFORM0- ja INLINEFORM1-tietokannoissa (3,7 % ja 3,9 % huonommin kuin meidän mallimme). Huomaamme, että INLINEFORM2 ja INLINEFORM3 sisältävät paljon epävirallisia arvosteluja, joten RNCRF:n suorituskyvyn heikkeneminen johtuu luultavasti riippuvuuksien jäsentäjän virheistä, kun se käsittelee tällaisia epävirallisia tekstejä.",
      "id": "task461-0ff67d58c22a4fef9157c743959f02ae",
      "output": [
        "Kuinka paljon ne ovat tehokkaampia kuin uusimmat menetelmät?"
      ]
    },
    {
      "input": "CIC on sopiva täydentävä mittari ROUGE:lle, koska se ottaa huomioon tärkeimmät tiedot kullakin dialogialueella. CIC:tä voidaan soveltaa mihin tahansa tiivistämistehtävään, jossa on ennalta määriteltyjä olennaisia kokonaisuuksia.",
      "id": "task461-cff75ba956b444dca11c41a280662320",
      "output": [
        "Onko uusi arviointimittari ROGUEn laajennus?"
      ]
    },
    {
      "input": "Käytimme Pasokh-tietokokonaisuutta BIBREF42 , joka sisältää 100 persialaista uutisasiakirjaa, joihin kuhunkin liittyy 5 tiivistelmää. Kukin tiivistelmä koostuu useista lauseista alkuperäisestä tekstistä, jotka on valinnut ihmisasiantuntija. Joitakin lauseita on hieman muutettu, eivätkä ne näin ollen ole täsmällinen kopio alkuperäisistä lauseista. Asiakirjat on luokiteltu kuuteen luokkaan, kuten poliittisiin, taloudellisiin ja muihin. Asiakirjojen pituus vaihtelee 4:stä 156:een virkkeeseen. Kaiken kaikkiaan siinä on noin 2 500 lausetta.",
      "id": "task461-0f859463ba0e41d6b63036ba488130b1",
      "output": [
        "Mitä tietokokonaisuutta käytetään tässä tehtävässä?"
      ]
    },
    {
      "input": "Otimme tehtävän käyttöön Amazon Mechanical Turkissa (AMT). Nähdäksemme, miten päättelytaidot vaihtelevat työntekijöiden välillä, palkkaamme 3 väkijoukkotyöntekijää yhtä instanssia kohden. Palkkaamme luotettavia työntekijöitä, joilla on $\\ge 5 000$ HIT-kokemusta ja hyväksyntäprosentti $\\ge $ 99.0 %, ja maksamme ¢20 palkkiota instanssia kohden.",
      "id": "task461-e382891e0ffa479a925ca67ff5217b42",
      "output": [
        "Käyttivätkö he jotain joukkoistamisalustaa?"
      ]
    },
    {
      "input": "Seuraavan kysymyksemme ratkaisemiseksi arvioimme putkistomme toimintaa, kun suhteita opitaan itsenäisesti (eli erikseen) verrattuna suhteiden yhteiseen oppimiseen RDN:ssä, mikä näkyy taulukossa TABREF22 .",
      "id": "task461-572ce66959484937b99cb1ee1099f478",
      "output": [
        "Mitä he oppivat yhdessä?"
      ]
    },
    {
      "input": "Syöttöominaisuudet ovat 40 mel-skaalattua log-suodatinpankki-egregaattia (FBanks), jotka lasketaan 10 ms:n välein 25 ms:n ikkunassa ja jotka on yhdistetty deltoihin ja delta-deltoihin (120 ominaisuutta vektorissa). Yritimme myös käyttää spektrogrammeja ja kokeilimme erilaisia normalisointitekniikoita.",
      "id": "task461-fdbb339ad67d415dbdc61a00222fa5f6",
      "output": [
        "Mitä ominaisuuksia he kokeilevat?"
      ]
    },
    {
      "input": "Nyt on selvää, että jotkin joissakin arkkitehtuureissa käytetyt konfiguraatiot (esim. ylimääräiset RNN-kerrokset) ovat itse asiassa merkityksettömiä ja ne voidaan poistaa kokonaan ilman, että tarkkuus kärsii.",
      "id": "task461-26d0e2959f504418b5f5805d253e5666",
      "output": [
        "Mitkä ovat vähiten tärkeät osatekijät, jotka on tunnistettu VQA-mallien koulutuksessa?"
      ]
    },
    {
      "input": "Kuvion 1 kaavioissa esitetään päällekkäisten ja ei-yllekkäisten kysymysten väliset etäisyydet eri sulautusjärjestelmillä. Large saavutti tässä tehtävässä F1-pistemäärän 0,71 ilman erityistä harjoittelua yksinkertaisesti valitsemalla kynnysarvon, jonka alapuolella kaikki lauseparit katsotaan kaksoiskappaleiksi. Testataksemme, voidaanko nämä tulokset yleistää meidän alallamme, suunnittelimme testin, jossa hyödynnettäisiin sitä vähäistä dataa, joka meillä oli arvioitavana.",
      "id": "task461-3bbe12a416ca4d7fbab4982a0e5b4591",
      "output": [
        "Miten järjestelmän tarkkuus mitataan?"
      ]
    },
    {
      "input": "Tässä kokeessa laskemme ehdotetun NED-mittarin korrelaation potilaan havaitsemien tunnesidearvioiden kanssa. Koska ehdotettu mittari on luonteeltaan epäsymmetrinen, laskemme mittarit sekä potilaan ja terapeutin väliselle että terapeutin ja potilaan väliselle sitoutumiselle. Ilmoitamme Pearsonin korrelaatiokertoimet ( INLINEFORM0 ) tätä koetta varten taulukossa TABREF26 yhdessä niiden INLINEFORM1 -arvojen kanssa. ",
      "id": "task461-2b9366723f7648b48eb87c4757ff0ae4",
      "output": [
        "Miten he korreloivat NED:n ja tunnesiteen tasojen välillä?"
      ]
    },
    {
      "input": "Vertaamme malliamme useisiin perusmalleihin, jotka kuvataan jäljempänä. Huomaamme, että kahden ensimmäisen tulokset on aiemmin raportoitu BIBREF2.Hasty Student BIBREF2 on heuristiikkapohjainen yksinkertainen malli, joka jättää reseptin huomiotta ja antaa vastauksen tarkastelemalla vain kysymystä ja vastausjoukkoa käyttäen etäisyyksiä visuaalisessa ominaisuusavaruudessa.Impatient Reader BIBREF19 on yksinkertainen neuraalinen malli, joka on saanut nimensä siitä, että se laskee toistuvasti huomion reseptin yli sen jälkeen, kun se on tarkastellut jokaista kyselyssä olevaa kuvaa. biDAF BIBREF14 on vahva luetun ymmärtämisen malli, joka käyttää kaksisuuntaista huomionvirtausmekanismia saadakseen kysymystietoisen representaation ja perustaa ennusteensa tähän representaatioon. Alun perin se on span-valintamalli syötekontekstista. BiDAF w/ static memory on laajennettu versio BiDAF-mallista, joka muistuttaa ehdottamaamme PRN-mallia siten, että se sisältää muistin yksikön olioille.",
      "id": "task461-ef3aa518dc2949028623e21a9da26ab3",
      "output": [
        "Mitä ovat aiemmin raportoidut mallit?"
      ]
    },
    {
      "input": "Tunnetunnistusta tekstistä varten transkriboimme manuaalisesti kaikki AMMER-tutkimuksen lausumat. Kehitämme siirto-oppimismenetelmän hyödyntääkseen olemassa olevia ja saatavilla olevia tietokokonaisuuksia, jotka ovat suurempia kuin AMMER-tietokokonaisuus. Käytämme neuroverkkoa, jossa on sulauttamiskerros (jäädytetyt painot, esivalmennettu Common Crawl ja Wikipedia BIBREF36), kaksisuuntainen LSTM BIBREF37 ja kaksi tiheää kerrosta, joita seuraa pehmeä maksimilähtökerros. Tämä asetelma on BIBREF38:n innoittama. Käytämme kaikissa kerroksissa 0,3:n pudotusprosenttia ja optimoimme Adam BIBREF39:llä oppimisnopeudella $10^{-5}$ (nämä parametrit ovat samat kaikissa myöhemmissä kokeissa). Rakennamme Keras-kirjaston päälle TensorFlow-backendillä. Pidämme tätä asetelmaa perusmallina.",
      "id": "task461-c244aa4a1bf44b9395c3f890e5ba1f58",
      "output": [
        "Mikä on tehtävän perusmenetelmä?"
      ]
    },
    {
      "input": "Jotta voimme suunnitella tulkittavissa olevan sanojen upotusmallin pienille korpuksille, tunnistamme uusia yhteyksiä sanojen upotusten ja aihepiirimallien välillä ja mukautamme aihepiirimallinnuksen edistysaskeleita. Jakaumahypoteesin BIBREF23 mukaisesti skip-grammin sanojen upotukset parametrisoivat diskreettejä todennäköisyysjakaumia sanoille INLINEFORM0, joilla on taipumus esiintyä yhdessä ja jotka ovat yleensä semanttisesti yhtenäisiä - ominaisuus, jota BIBREFin Gaussin LDA-malli hyödyntää21. Tulkitsemme siis skip-grammin uudelleen tietyn valvotun naivin Bayesin aihepiirimallin parametrisoinniksi (taulukko TABREF2 , ylhäällä oikealla). Kuten LDA:ssa, tätä mallia voidaan parantaa korvaamalla naiivi Bayes-oletus sekajäsenyysoletuksella. Soveltamalla mixed membership -esitystä tähän skip-grammin aihepiirimalliversioon saadaan taulukon TABREF2 oikeassa alakulmassa oleva malli. Kun tämä malli on jälleen kerran parametrisoitu sanojen upotusten avulla, saadaan lopullinen mallimme, mixed membership skip-gram (MMSG). ",
      "id": "task461-e1d1b7a3acb7410084b863468b33ef9a",
      "output": [
        "Mitä tekniikoita käytetään sanojen upotuksiin ja aihepiirimalleihin?"
      ]
    },
    {
      "input": "Havainnollistamme konseptia käsittelemällä joitakin hiljattain kokeilemiamme instansseja. Suunnitelmassa on myös selkeä \"relevanssipaikka\", jossa on mahdollisuus semanttiseen neuvotteluun, nimittäin ennen lopullisen päätöksen tekemistä. Tästä on esimerkki alla olevassa esimerkissä.   Kuten SECREF12 osoittaa, jopa tapauksissa, joissa päätös voidaan tehdä nopeasti, voi olla selkeä keskinäinen vahvistusvaihe ennen (hiljaisen) päätöksentekosignaalin lähettämistä. Kolmas tutkimamme asetelma BIBREF19 tuo käsitteellisen neuvottelun selvemmin etualalle. Kyseisessä pelissä pelaajille esitetään kuvia tiettyyn lajiin kuuluvista linnuista, ja heidän tehtävänään on keksiä kuvaus yhteisistä ominaisuuksista. Tässäkin tapauksessa molempien osallistujien on hyväksyttävä lopullinen vastaus. Kuten SECREF13 osoittaa, tämä voi johtaa käsitteellistä sisältöä koskevaan eksplisiittiseen neuvotteluun.",
      "id": "task461-6520acfda1c844c3bb181fca249d2992",
      "output": [
        "Suorittavatko kirjoittajat kokeita ehdottamallaan menetelmällä?"
      ]
    },
    {
      "input": "Stanford Sentiment Treebank Stanford Sentiment Treebank (SST) BIBREF14 . Kyseessä on elokuva-arvostelujen tunteen ennustaminen. Tästä korpuksesta on johdettu kaksi tietokokonaisuutta: (1) SST-1, joka sisältää viisi luokkaa: erittäin negatiivinen, negatiivinen, neutraali, positiivinen ja erittäin positiivinen. (2) SST-2, jossa on vain kaksi luokkaa: negatiivinen ja positiivinen. Molemmista poistetaan harjoitusjoukosta alle 4 pituiset lauseet. Subj BIBREF15 . Tässä pyritään luokittelemaan lauseet joko subjektiivisiksi tai objektiivisiksi. Kokonaisuuteen kuuluu 5000 kappaletta kumpaakin. TREC BIBREF16 . Kysymysten luokittelua koskeva tietokokonaisuus, joka sisältää kuusi luokkaa: lyhenne, entiteetti, kuvaus, ihminen, sijainti ja numeerinen. Harjoitustapauksia on 5500 ja testitapauksia 500. Ironia BIBREF17 . Tämä tietokokonaisuus sisältää 16 006 lausetta redditistä, jotka on merkitty ironisiksi (tai ei ironisiksi). Tietokanta on epätasapainoinen (suhteellisen harvat lauseet ovat ironisia). Ennen harjoittelua negatiiviset tapaukset otettiin liian pienestä näytteestä, jotta luokkien koot olisivat yhtä suuret. Huomaa, että tästä tietokokonaisuudesta raportoimme tarkkuuden sijasta AUC-arvon (Area Under Curve), koska se on epätasapainoinen.",
      "id": "task461-c524f158ed15446d82858548de303255",
      "output": [
        "Minkä tietokokonaisuuden/korpuksen perusteella tätä arvioidaan?"
      ]
    },
    {
      "input": "Toinen ongelma on se, että Googlen julkaisema BERT-malli on koulutettu vain arabian kielen Wikipediaan, joka on lähes yksinomaan modernia arabiaa (MSA). Jaetun tehtävän tietokokonaisuus sisältää 5 030 twiittiä, jotka liittyvät Lähi-idän eri poliittisiin kysymyksiin ja tapahtumiin vuosina 2011-2018. Twiitit sisältävät sekä MSA:ta että eriasteisia murteita, kuten egyptiläistä, Persianlahden murretta ja Levantin murretta.",
      "id": "task461-d08f9e9450714eb2b6b25a11bbe78e51",
      "output": [
        "Mitä murretta käytetään Googlen yhteistyömallissa ja mitä käytetään tehtävätiedoissa?"
      ]
    },
    {
      "input": "CodeInternational: Google Translate -työkalu, jolla voidaan kääntää koodia eri kielten välillä.",
      "id": "task461-75244c194be8494bbb7acf6919439258",
      "output": [
        "Perustuuko tämä automaattinen käännöstyökalu neuroverkkoihin?"
      ]
    },
    {
      "input": "Pyysimme lääkäreitä, joilla on kokemusta lääketieteellisiin kokonaisuuksiin liittyvän tiedon poimimisesta teksteistä, kommentoimaan edellä kuvattuja kokonaisuuksia. Aluksi pyysimme neljää annotoijaa testaamaan ohjeistustamme kahdella tekstillä. Tämän jälkeen havaituista ongelmista keskusteltiin ja ne ratkaistiin. Tämän pilottiannotointivaiheen jälkeen pyysimme kahta eri annotoijaa annotoimaan kaksi tapausraporttia ohjeidemme mukaisesti. Samat kommentoijat kommentoivat 53 tapausselostuksen kokoelman. Annotoinnissa käytettiin WebAnno BIBREF7 -nettityökalua, joka on web-pohjainen työkalu kielellistä annotointia varten. Annotaattorit saattoivat valita kunkin tekstin valmiiksi annotoidun version tai tyhjän version. Ennalta annotoidut versiot sisälsivät ehdotettuja entiteettikokonaisuuksia, jotka perustuivat ehtoluetteloiden ja löydösten synonyymiluetteloiden merkkijonotuloksiin.",
      "id": "task461-331c885d4d8b42f6bf5bebecbeffd0c5",
      "output": [
        "Miten merkinnät tehtiin?"
      ]
    },
    {
      "input": "Parannamme aiempaa huipputason BIBREF35 -menetelmää VQA-aineistossa noin 6 % BLEU-pisteissä ja 10 % METEOR-pisteissä. VQG-COCO-tietokannan osalta parannamme BIBREF5:tä 3,7 prosenttia ja BIBREF36:ta 3,5 prosenttia METEOR-pisteiden osalta.",
      "id": "task461-cb9d470ca90642f4bcb46b7a13e8d304",
      "output": [
        "Mitkä olivat aiemmat huipputason vertailuarvot?"
      ]
    },
    {
      "input": "Harvennamme tämän graafin minimitilannepuun ja k-naapurien (MST-kNN) graafin BIBREF14 yhdistelmäksi. Tämä geometrinen rakenne poistaa vähemmän tärkeät samankaltaisuudet, mutta säilyttää graafin ja siten myös tietokokonaisuuden globaalin liitettävyyden. Tämän jälkeen MST-kNN-graafia analysoidaan Markov Stability BIBREF15, BIBREF16, BIBREF17, BIBREF18 -menetelmällä, joka on moniresoluutioinen graafin jakomenetelmä, jolla tunnistetaan merkitykselliset aliraafit (eli asiakirjojen klusterit) eri rakeisuustasoilla.",
      "id": "task461-741378f6336b4f12b220ff72a24ef41b",
      "output": [
        "Mitä klusterin tunnistamismenetelmää käytetään tässä asiakirjassa?"
      ]
    },
    {
      "input": "Päädymme kahteen merkittävään rooliin, joita kutsutaan ankkuripuhujiksi ja täsmällisiksi puhujiksi: ankkuripuhujat (A) ovat yli 1 prosentin kynnyksen molemmissa kriteereissä, mikä tarkoittaa, että he puhuvat usein ja pitkään ja ovat siten tärkeässä asemassa vuorovaikutuksessa; täsmälliset puhujat (PS) sitä vastoin ovat alle 1 prosentin kynnyksen sekä vuorojen kokonaismäärän että kokonaispuheajan osalta.",
      "id": "task461-fd69a45a2fa0421196a3c4dd797eee15",
      "output": [
        "Kuinka monta luokkaa kirjoittajat määrittelevät puhujan roolille?"
      ]
    },
    {
      "input": "HASOC 2019 -tapahtuman tietokokonaisuudet annettiin kolmella kielellä: Hindi, englanti ja saksa. Hindi- ja englanninkielisessä datasetissä oli kummassakin kolme osatehtävää, kun taas saksankielisessä vain kaksi osatehtävää. Osallistuimme kaikkiin järjestäjien antamiin tehtäviin ja päätimme kehittää yhden ainoan mallin, joka olisi kieliagnostinen. Käytimme samaa malliarkkitehtuuria kaikilla kolmella kielellä. Hindi-tietokannan harjoitustietokanta oli tasapainoisempi kuin englannin- tai saksankielinen tietokanta. Näin ollen tulokset olivat noin 0,78. Koska saksan kielen tietokanta oli erittäin epätasapainoinen, tulokset putosivat 0,62:een.",
      "id": "task461-5b09fbf065924444adc9290fdb20cbf1",
      "output": [
        "Mitä kieliä käytetään mallin testaamiseen?"
      ]
    },
    {
      "input": "Kartoitamme jokaisen relaatiotyypin $R(x,y)$ vähintään yhdeksi parametrisoiduksi luonnollisen kielen kysymykseksi $q_x$ , jonka vastaus on $y$ .",
      "id": "task461-85879d5ab9574453805bb4afabf9965a",
      "output": [
        "Miten syötekolmio muunnetaan aukkotäytteiseksi tehtäväksi?"
      ]
    },
    {
      "input": "Kiillekirja on muinainen kirjoitusjärjestelmä, jonka sumerilaiset keksivät yli kolmen vuosituhannen ajan.",
      "id": "task461-7408961368554944ad6672d8aad95494",
      "output": [
        "Mikä on yksi maailman ensimmäisistä kirjoitusjärjestelmistä?"
      ]
    },
    {
      "input": "Kilpailu on jaettu viiteen osatehtävään, joihin kuuluvat standardiluokittelu, ordinaaliluokittelu ja jakauman estimointi. Yksityiskohtaisempi kuvaus löytyy osoitteesta BIBREF0 .",
      "id": "task461-a312f3dc59454f6dab4bf2a6ece285fb",
      "output": [
        "Mitkä olivat viisi englanninkielistä osatehtävää?"
      ]
    },
    {
      "input": "Tämän jälkeen LSTM-dekooderi tuottaa merkit sanamuodossa käyttäen kooderin tiloja ja huomiomekanismia.",
      "id": "task461-594f6f7cc9424a388c9ced62d9c5da8e",
      "output": [
        "Mikä on dekooderin arkkitehtuuri?",
        "Onko malli tarkkaavainen?"
      ]
    },
    {
      "input": "Tämän työn tulokset ovat:",
      "id": "task461-6a4bd561a1e14cc1897435c66e2393c0",
      "output": [
        "Etsivätkö he epäjohdonmukaisuuksia eri UD-pankkien välillä?"
      ]
    },
    {
      "input": "Arvioimme lähestymistapaamme kahdella hyvin vertaillulla sekvenssien merkintätehtävällä, CoNLL 2003 NER-tehtävällä BIBREF13 ja CoNLL 2000 Chunking-tehtävällä BIBREF14 . ",
      "id": "task461-ec7dde1673b6454b8cd98755c661dd90",
      "output": [
        "mitkä ovat arviointitietokannat?"
      ]
    },
    {
      "input": "Operationalisoimme kysymyksen lähettämällä valitut testidatat samalle toimittajapohjaiselle transkriptioputkelle, jota Microsoft käyttää tuotantodataa varten (mallien kouluttamista ja sisäistä arviointia varten), ja vertaamalla tuloksia ASR-järjestelmän tuloksiin NIST:n pisteytysprotokollan mukaisesti. ",
      "id": "task461-eb8397cff9264c1bae9f374a6f840825",
      "output": [
        "mitä standardoitua puheen transkriptioputkea käytettiin?"
      ]
    },
    {
      "input": "OLID-tietokannassa käytämme hierarkkista annotaatiomallia, joka on jaettu kolmeen tasoon, jotta voidaan erottaa toisistaan, onko kieli loukkaavaa vai ei (A), sekä loukkaavan kielen tyyppi (B) ja kohde (C). Kutakin tasoa kuvataan yksityiskohtaisemmin seuraavissa alaluvuissa, ja esimerkkejä esitetään taulukossa TABREF10 . Taso A: Loukkaavan kielen havaitseminenTasolla A erotetaan toisistaan loukkaavat (OFF) ja ei-loukkaavat (NOT) twiitit. Taso B: Loukkaavan kielen luokitteluTasolla B luokitellaan loukkauksen tyyppi, ja käytetään kahta merkintää: kohdistetut (TIN) ja kohdistamattomat (INT) loukkaukset ja uhkaukset. Taso C: Loukkaavan kielen kohteiden tunnistaminenTasolla C luokitellaan loukkausten ja uhkausten kohteet yksilöihin (IND), ryhmiin (GRP) ja muihin (OTH).",
      "id": "task461-2b430914b8c84283a2706fb0850810d2",
      "output": [
        "Mitkä ovat huomautusjärjestelmän kolme kerrosta?"
      ]
    },
    {
      "input": "LastStateRNN on klassinen RNN-malli, jossa viimeinen tila kulkee MLP:n läpi ja LR-kerros arvioi vastaavan todennäköisyyden. AvgRNN-mallissa sen sijaan tarkastellaan kaikkien soluista lähtevien tilojen keskimääräistä vektoria. AttentionRNN-malli on se, joka on esitetty BIBREF9:ssä.",
      "id": "task461-7ed9ddef7eb7420daa6f7ea17337e7ae",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Tammikuussa 2020 uusin CoVo-versio 2019-06-12 sisältää 29 kieltä. CoVoST perustuu tällä hetkellä kyseiseen julkaisuun ja kattaa seuraavat 11 kieltä: Ranska, saksa, hollanti, venäjä, espanja, italia, turkki, persia, ruotsi, mongoli ja kiina. Common Voice BIBREF10 on joukkoistettu puheentunnistuskorpus, jolla on avoin CC0-lisenssi. Osallistujat nauhoittavat äänileikkeitä lukemalla lahjoitettujen lauseiden pankista.",
      "id": "task461-076139f6f640456bb12ce84fb15da926",
      "output": [
        "Miten aineisto kerättiin?"
      ]
    },
    {
      "input": "Kaiken kaikkiaan tämä vahvistaa alkuperäistä intuitiotamme, jonka mukaan parhaiten toimivan suosioon perustuvan lähestymistavan ja parhaan samankaltaisuuteen perustuvan lähestymistavan yhdistämisen pitäisi johtaa korkeimpaan tarkkuuteen (eli INLINEFORM7 INLINEFORM8 -menetelmään).",
      "id": "task461-c1bd5744d6744fc7b687995642685587",
      "output": [
        "mikä algoritmi oli parhaiten menestynyt?"
      ]
    },
    {
      "input": "SnapCaptions-tietokanta koostuu 10 000 käyttäjän luoman kuvan (snap) ja tekstin kuvatekstipareista, joissa kuvatekstien nimetyt entiteetit on merkitty manuaalisesti asiantuntevilla ihmisannotoijilla (entiteettityypit: PER, LOC, ORG, MISC).",
      "id": "task461-173a62a957f649ff8e4c6bb8ae564705",
      "output": [
        "Minkä tyyppisiä nimettyjä entiteettejä ne tunnistavat?",
        "Kuinka suuri on heidän MNER SnapCaptions -tietokantansa?"
      ]
    },
    {
      "input": "Ainoa vaatimus on, että malli hyväksyy syötteenä (entiteettien ja relaatioiden) upotuskerroksen. Jos malli täyttää tämän vaatimuksen (ja monet tietämysgraafeihin perustuvat neuraaliset mallit täyttävät sen), voimme käyttää Doloresin upotuksia korvaavana vaihtoehtona. Aloitamme vain vastaavan upotuskerroksen Doloresin upotuksilla.",
      "id": "task461-afe91dd98e1c4fb99fc8ae8d23363424",
      "output": [
        "Tarvitaanko hienosäätöä, jotta nämä sulautukset voidaan sisällyttää nykyisiin malleihin?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvataan kokeellinen tutkimus. Sovitamme sefe-mallin kolmeen tietokokonaisuuteen ja vertaamme sitä efe BIBREF10 -malliin. Kvantitatiiviset tulokset osoittavat, että kontekstivektoreiden jakaminen tuottaa parempia tuloksia ja että amortisointi ja hierarkkinen rakenne parantavat tuloksia entisestään. Aineisto. Sovellamme sefe-mallia kolmeen tietokokonaisuuteen: ArXiv-papereihin, Yhdysvaltain senaatin puheisiin ja ostoksiin supermarketin päivittäistavarakaupan ostosdatassa. Kuvaamme nämä aineistot jäljempänä, ja taulukossa TABREF17 on yhteenveto aineistoista. ArXiv-paperit: Tämä tietokokonaisuus sisältää huhtikuun 2007 ja kesäkuun 2015 välisenä aikana ArXivissa 19 eri tunnisteella julkaistujen papereiden tiivistelmät. Käsittelemme kutakin tagia ryhmänä ja sovitamme sefejä tavoitteenamme paljastaa, millä sanoilla on voimakkain muutos käytössä. Jaamme tiivistelmät harjoittelu-, validointi- ja testijoukkoihin, joiden osuudet ovat vastaavasti INLINEFORM0 , INLINEFORM1 ja INLINEFORM2. Senaattipuheet: Tämä tietokokonaisuus sisältää Yhdysvaltain senaatin puheita vuodesta 1994 vuoden 2009 puoliväliin. Toisin kuin ArXiv-kokoelma, se on transkriptio puhutusta kielestä. Ryhmittelemme aineiston puhujan kotiosavaltion ja puoluekannatuksen mukaan. Ainoastaan republikaaniseen ja demokraattiseen puolueeseen kuuluminen otetaan huomioon. Tuloksena on 83 ryhmää (republikaanit Alabamasta, demokraatit Alabamasta, republikaanit Arkansasista jne.). Joitakin osavaltio/puolue-yhdistelmiä ei ole saatavilla tiedoissa, koska joissakin 50 osavaltiosta on ollut vain senaattoreita, joilla on sama puoluekanta. Jaoimme puheet harjoitteluun ( INLINEFORM0 ), validointiin ( INLINEFORM1 ) ja testaukseen ( INLINEFORM2 ). päivittäistavarakauppa-aineisto: Tämä aineisto sisältää INLINEFORM0-asiakkaiden ostokset. Aineisto kattaa 97 viikon ajanjakson. Kun matalataajuiset nimikkeet on poistettu, aineisto sisältää INLINEFORM1:n yksilöllisiä nimikkeitä 1.10upc-tasolla (Universal Product Code). Jaamme aineiston harjoitus-, testi- ja validointijoukkoihin, joiden osuudet ovat INLINEFORM2 , INLINEFORM3 ja INLINEFORM4 . Koulutusdata sisältää yhteensä INLINEFORM5 ostosmatkoja ja INLINEFORM6 ostoksia. Tekstikorpusten osalta kiinnitämme sanaston 15k yleisimpiin termeihin ja poistamme kaikki sanastoon kuulumattomat sanat. BIBREF2:n mukaisesti poistamme lisäksi jokaisen sanan, jonka todennäköisyys on INLINEFORM0 , jossa INLINEFORM1 on sanan taajuus. Tämä pienentää näytteitä erityisesti usein esiintyvistä sanoista ja nopeuttaa harjoittelua. (Taulukossa TABREF17 ilmoitetut koot ovat esikäsittelyn jälkeen jäljelle jäävien sanojen lukumäärä). Mallit. Tavoitteenamme on sovittaa sefe-malli näihin tietokokonaisuuksiin. Käytämme tekstidatassa Bernoulli-jakaumaa ehdollisena eksponenttiperheenä, kun taas ostosdatassa käytämme Poisson-jakaumaa, joka sopii paremmin laskentadataan. Kussakin tietokokonaisuudessa verrataan neljää sefe-malliin perustuvaa lähestymistapaa kahteen efe BIBREF10 -perusasetukseen. Kaikki on sovitettu sgd BIBREF34 -ohjelmalla. Vertaamme erityisesti seuraavia menetelmiä:",
      "id": "task461-b9e3712a3f474c81853dcedabab91851",
      "output": [
        "Mitä kokeita käytetään tämän lähestymistavan hyötyjen osoittamiseksi?"
      ]
    },
    {
      "input": " 29 794 Wikipedia-aineisto koostuu englanninkielisen Wikipedian artikkeleista, joille Wikipedia-yhteisö on antanut laatuluokkamerkinnät. Wikipedia-artikkelit on merkitty johonkin kuudesta laatuluokasta, jotka ovat laadun mukaan alenevassa järjestyksessä: Hyvä artikkeli (\"GA\"), B-luokan artikkeli (\"B\"), C-luokan artikkeli (\"C\"), aloitusartikkeli (\"Start\") ja tynkäartikkeli (\"Stub\"). Otimme satunnaisotannalla 5 000 artikkelia kustakin laatuluokasta ja poistimme kaikki uudelleenohjaussivut, jolloin saimme 29 794 artikkelin tietokokonaisuuden.",
      "id": "task461-79462b354fa1425c993d6c9a53060c0a",
      "output": [
        "Kuinka suuri on heidän aineistonsa?"
      ]
    },
    {
      "input": "Kuten yhtälöstä ( EQREF6 ) käy ilmi, äänensävyn ennustamisen aliverkko ( INLINEFORM0 ) ottaa videon ja pinyin-sekvenssin syötteenä ja ennustaa vastaavan äänensävysekvenssin. Videokontekstivektorit INLINEFORM0 ja pinyin-kontekstivektorit INLINEFORM1 fuusioidaan, kun äänimerkkiä ennustetaan kussakin dekooderivaiheessa. Videokooderi on sama kuin kohdassa SECREF7 ja pinyin-kooderi on: DISPLAYFORM0 Syötetty videosekvenssi syötetään ensin VGG-malliin BIBREF9 visuaalisten ominaisuuksien poimimiseksi. VGG:n conv5:n ulostuloon liitetään globaali keskiarvopoolaus BIBREF10, jotta saadaan 512-ulotteinen piirrevektori. Tämän jälkeen 512-dim-muotoinen ominaisvektori syötetään videokooderiin.",
      "id": "task461-82cdab0252c94ee3a515385a4ff7f16b",
      "output": [
        "Mikä visuaalinen informaatio luonnehtii sävyjä?"
      ]
    },
    {
      "input": "Käytämme leimattua dataa IEMOCAP-tietokannasta, jossa on leimatut aktivointi- ja valenssiarvot, jotka molemmat on mitattu viiden pisteen Likert-asteikolla kolmen eri kommentoijan toimesta.",
      "id": "task461-ab3079b282eb48d8afe6fdd1f89bc544",
      "output": [
        "Mitä monitehtäväannotoitua korpusta käytetään?"
      ]
    },
    {
      "input": "Perinteiset tekstistä puheeksi -järjestelmät (TTS) koostuvat monimutkaisista putkistoista BIBREF0 , joihin kuuluu usein akustisia etuosia, kestomalli, akustinen ennustemalli ja vokooderimalleja. Neuraaliset tekstistä puheeksi -järjestelmät ovat herättäneet suurta tutkimusintoa viimeisten kahden vuoden aikana. Ensimmäinen, joka tutki tätä tutkimusalaa perusteellisesti, oli Googlen tacotron BIBREF1 -järjestelmä. Mallimme arkkitehtuurissa käytetään RNN-pohjaista Seq2Seq-mallia mel-spektrogrammin tuottamiseen tekstistä. Arkkitehtuuri on samankaltainen kuin Tacotron 2:ssa BIBREF4 Alkuperäisessä Tacotron 2:ssa huomiomekanismina käytettiin sijaintiherkkää huomiota BIBREF12 yhdistettynä alkuperäiseen additiiviseen Seq2Seq BIBREF7 Bahdanau-huomioon. ehdotamme tämän huomion korvaamista yksinkertaisemmalla query-key-huomioinnilla muuntajamallista Edellä esitetyn logiikan mukaisesti käytämme BIBREF6:sta tuttua samankaltaista menetelmää, joka lisää kokonaistappiotavoitteeseen ylimääräisen ohjatun huomion häviön, joka toimii siten, että huomiomekanismista tulee mahdollisimman varhaisessa vaiheessa monotoinen. Kuten FIGREF24:stä nähdään, luodaan huomiohäviömaski, INLINEFORM0 , soveltaa häviötä, joka pakottaa huomiokohdistuksen, INLINEFORM1 , olemaan lähes diagonaalinen.",
      "id": "task461-c30c9cc34c3b4acd98254f9e1f2b6d44",
      "output": [
        "Mitä muutoksia ne tekevät vakiintuneisiin Seq2seq-arkkitehtuureihin?"
      ]
    },
    {
      "input": "Yleisesti ottaen vastakohtainen harjoittelu parantaa tarkkuutta kaikilla kielillä, ja parannus on toisinaan dramaattinen verrattuna BERT:n ei-vastakohtaiseen perustasoon. Kun BERT-yhteistyöhön yhdistetään adversaalinen oppiminen, kieltenväliset F1-pisteet paranevat saksan osalta verrattuna ei-adversaaliseen perustasoon, ja espanjan ja hollannin osalta tulokset pysyvät pitkälti samoina.",
      "id": "task461-81e0d8496d7e4c9c9a731ba83bc05133",
      "output": [
        "Onko adversio-oppimisella saavutettu vahvempi suorituskyky tekstiluokittelussa vai NER:ssä?"
      ]
    },
    {
      "input": "Arvioimme Bertramia BIBREF0:n WNLaMPro-tietokannassa.",
      "id": "task461-5efe834ae88742ee966003443e91eb31",
      "output": [
        "Mikä on sanojen kartoitustehtävän tietokanta?"
      ]
    },
    {
      "input": "Tässä jaksossa ehdotamme uusia yksinkertaisia disentanglementtimalleja, jotka toimivat aiempia menetelmiä paremmin, ja tarkastelemme uudelleen aiempaa työtä.",
      "id": "task461-25b1e7ea1db84dab84cd9dc639bdb803",
      "output": [
        "Kokeilivatko he korpusta?"
      ]
    },
    {
      "input": "Tässä jaksossa keskitytään äskettäin julkaistuihin tietokokonaisuuksiin ja LID-tutkimuksiin, joita voidaan soveltaa Etelä-Afrikan tilanteeseen. Syvällinen katsaus algoritmeihin, ominaisuuksiin, tietokokonaisuuksiin, jaettuihin tehtäviin ja arviointimenetelmiin on BIBREF0.DSL 2015 & DSL 2017 - jaettujen tehtävien tietokokonaisuuksia BIBREF1 käytetään usein LID-vertailumittauksissa, ja ne ovat saatavilla myös Kaggle-verkkopalvelussa. Hiljattain julkaistu rinnakkainen JW300-korpus BIBREF2 kattaa yli 300 kieltä, ja siinä on keskimäärin noin 100 tuhatta rinnakkaista lausetta kieliparia kohti. Yksikieliseen kirjoitetun luonnollisen kielen tunnistamiseen tarkoitettu WiLI-2018-vertailuaineisto BIBREF4 sisältää noin 1000 kappaletta 235 kielestä. NCHLT-tekstikorporaatio BIBREF7 on todennäköisesti hyvä lähtökohta eteläafrikkalaisten kielten BIBREF8 yhteiselle LID-tehtävätietokannalle.",
      "id": "task461-d4e79087e392459f89dc39a307d546a4",
      "output": [
        "Mitä tietokokonaisuuksia käytetään Etelä-Afrikan kielten LID-tutkimuksessa?"
      ]
    },
    {
      "input": "BIBREF0-, BIBREF1- ja BIBREF2-ohjelmissa Pasca et al. poimivat ensin mahdollisia luokka-attribuuttipareja käyttämällä kielellisesti motivoituja malleja strukturoimattomasta tekstistä, mukaan lukien kyselylokit ja kyselyistunnot, ja pisteyttävät sitten attribuutit Bayesin mallin avulla. Rahul Rai ehdotti julkaisussa BIBREF3 , että tuoteattribuutteja tunnistetaan asiakkaiden online-arvosteluista käyttämällä part-of-speech(POS)-merkintämalleja ja että niiden tärkeyttä arvioidaan useilla eri frekvenssimittareilla. BIBREF4 -julkaisussa Lee et al. kehittivät järjestelmän käsite-attribuuttiparien poimimiseksi useista tietolähteistä, kuten Probase-tietokannasta, yleisistä verkkodokumenteista, kyselylokeista ja ulkoisesta tietopohjasta, ja eri lähteistä saatujen painotusten yhdistämiseksi yhdeksi johdonmukaiseksi tyypillisyyspisteytykseksi käyttämällä Ranking SVM -mallia. BIBREF5 -julkaisussa Li et al. esittelivät OntoRank-algoritmin semanttisten web-objektien tärkeysjärjestykseen asettamista varten kolmella rakeisuustasolla: dokumentti, termit ja RDF-grafit. Algoritmi perustuu rational surfer -malliin, jota käytetään menestyksekkäästi Swoogle-semanttisessa web-hakukoneessa.",
      "id": "task461-34f5783215a54bd1954afd05a9cea534",
      "output": [
        "Mitkä ovat perinteiset menetelmät tärkeiden ominaisuuksien tunnistamiseksi?"
      ]
    },
    {
      "input": "Käytämme NIST:n DUC-05, DUC-06 ja DUC-07 jaettujen tehtävien BIBREF7, BIBREF19 ja BIBREF20 tietokokonaisuuksia. Kun kilpailijoille annettiin kysymys ja joukko uutisdokumentteja, heitä pyydettiin laatimaan 250 sanan tiivistelmä, joka vastaa kysymykseen. DUC-05 sisältää 1 600 tiivistelmää (50 kysymystä x 32 järjestelmää), DUC-06 sisältää 1 750 tiivistelmää (50 kysymystä x 35 järjestelmää) ja DUC-07 sisältää 1 440 tiivistelmää (45 kysymystä x 32 järjestelmää).",
      "id": "task461-37e1572baef64146bb6a7625d5ec22d8",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Sama BUTD-malli, joka saavutti 73,02 %:n tuloksen korjaamattomassa SNLI-VE-testijoukossa, saavuttaa 73,18 %:n tasapainotetun tarkkuuden, kun sitä testataan SNLI-VE-2.0:n korjatulla testijoukolla. Tämän mallin suorituskyvyssä ei siis ole merkittävää eroa. Tämä saattaa johtua satunnaisuudesta.",
      "id": "task461-383e4c7957e44fe48a383e03e3d1a54f",
      "output": [
        "Kuinka suuri on nykyisen mallin suorituskyvyn ero alkuperäisen ja korjatun korpuksen välillä?"
      ]
    },
    {
      "input": "Kaksoisoppimisen ydinajatus on hyödyntää primaaritehtävän (kartoitus alueesta $\\mathcal {X}$ alueeseen $\\mathcal {Y}$) ja kaksoistehtävän (kartoitus alueesta $\\mathcal {Y}$ alueeseen $\\mathcal {X}$ ) välistä kaksoistavoitetta molempien tehtävien suorituskyvyn parantamiseksi. MADL BIBREF0 laajentaa kaksoisoppimisen BIBREF1- ja BIBREF2-kehystä ottamalla käyttöön useita primaari- ja duaalimalleja.",
      "id": "task461-b2313616394a4913b8571eba58621095",
      "output": [
        "Miten moniagenttinen kaksoisoppiminen toimii?"
      ]
    },
    {
      "input": "Mallissamme otetaan käyttöön monikäänteinen päättelymekanismi, jolla käsitellään moninäkökulmaisia yhteensovitusominaisuuksia. ",
      "id": "task461-d9d324cbc5f741619857038049a1a5b0",
      "output": [
        "Mitä yhteensovitusominaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": " syötteiden fuusiokerros, joka mahdollistaa vuorovaikutuksen syötetietojen ja uudenlaisen huomioperusteisen GRU:n välillä, joka mahdollistaa loogisen päättelyn järjestettyjen syötteiden perusteella.",
      "id": "task461-e43d360332c8436ebb1962c0cb8481cc",
      "output": [
        "Miten malli kiertää tukevien faktojen puutteen koulutuksen aikana?"
      ]
    },
    {
      "input": "Supertaggauksen osalta havaitsemme, että perusmallin ristiinentropian avulla koulutettu malli parantaa ennusteitaan palkkihakupohjaisen dekoodauksen avulla 2 tarkkuuspistettä ahneeseen dekoodaukseen verrattuna, mikä viittaa siihen, että palkkihaku on jo hyödyllinen tässä tehtävässä, vaikka hakutietoista koulutusta ei tarvittaisikaan.",
      "id": "task461-9c93e9b281de453c9438f90b3fef0573",
      "output": [
        "Kuinka paljon ne ovat parempia kuin ahneen ja ristiinentrooppisen säteen perusdekoodaus?"
      ]
    },
    {
      "input": "Validoimme lähestymistapamme Wikipedian myrkyllisiä kommentteja koskevalla tietokokonaisuudella BIBREF18 .",
      "id": "task461-bd5e82b091ae409d80c431af5d8ce8ae",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": "Koulutusaineistona käytetään kahden monikielisen käännöskorpuksen sekoitusta: MultiUN BIBREF20 ja OpenSubtitles BIBREF21. MultiUN koostuu 463 406 virallisesta asiakirjasta kuudella kielellä ja sisältää noin 300 miljoonaa sanaa kullakin kielellä. OpenSubtitles on elokuvien ja television tekstityksistä koostuva korpus, joka sisältää 2,6 miljardia lausetta 60 kielellä. Valitsimme näistä kahdesta korpuksesta neljä yhteistä kieltä: englanti, espanja, venäjä ja kiina. Harjoituskorpuksen tilastot esitetään taulukossa TABREF14.",
      "id": "task461-cc4d48451731477ebd61bc96a63da7bb",
      "output": [
        "Mitä monikielistä rinnakkaista aineistoa käytetään ehdotetun mallin kouluttamiseen?"
      ]
    },
    {
      "input": "Lopuksi dekooderitehtävä, joka ennustaa kohdejonon todennäköisyyden ajankohtana INLINEFORM3 aikaisempien tulosteiden ja kontekstitietojen INLINEFORM4 perusteella, voidaan muotoilla seuraavasti: DISPLAYFORM0",
      "id": "task461-6f74545458494e93aa37b0007e9ccf70",
      "output": [
        "Miten heidän dekooderinsa tuottaa tekstiä?"
      ]
    },
    {
      "input": "Käyttämällä joukon semanttisesti suuntautuneita tehtäviä, jotka edellyttävät eksplisiittisiä semanttisia ristiinkielisiä representaatioita, osoitimme, että mBERT-kontekstin upotukset eivät representoi samankaltaisia semanttisia ilmiöitä samalla tavalla, eivätkä ne siksi ole suoraan käyttökelpoisia ristiinkielisiin nollakohtaisiin tehtäviin.",
      "id": "task461-908c12e55944490e86346d6bbf49df0f",
      "output": [
        "Millaisia haasteita tämä työ asettaa, jotka on ratkaistava, jotta voidaan rakentaa parempia kielineutraaleja esityksiä?"
      ]
    },
    {
      "input": "Kuvassa FIGREF32 havainnollistetaan jäsennysverkon arvioima syntaktinen etäisyys, kun luetaan kolmea eri sekvenssiä PTB-testisarjasta. Havaitaan, että syntaktinen etäisyys on yleensä suurempi sanan viimeisen merkin ja välilyönnin välillä, joka on järkevä taitekohta sanojen erottamiseksi toisistaan.  Malli havaitsi itsenäisesti välttämään sanojen välisen huomiokytkennän ja käyttämään välilyönnin (erotinmerkkien) piilotettuja tiloja tiivistämään aiempaa tietoa. Tämä on vahva todiste siitä, että malli pystyy ymmärtämään datan piilevän rakenteen.",
      "id": "task461-641a4148d83449cca2c069a71949f9cc",
      "output": [
        "Miten he osoittavat mallinsa paljastavan taustalla olevan syntaktisen rakenteen?"
      ]
    },
    {
      "input": "Luvussa \"Materiaalit ja menetelmät\" käsittelemme aineistomme ja menetelmämme, mukaan lukien tutkimamme aineisto, miten esikäsittelimme aineiston ja loimme \"kausaalisen\" korpuksen ja vastaavan \"kontrolli\"-korpuksen, sekä yksityiskohtaiset tiedot tilastollisista ja kielianalyysityökaluista, joilla tutkimme näitä korpuksia.",
      "id": "task461-4cfc84d2bc144fbd9127ec9c18283cfe",
      "output": [
        "Käytetäänkö korporaatioiden analysoinnissa asiantuntijoiden annotaatioita, joukkoistamista vai pelkästään automaattisia menetelmiä?"
      ]
    },
    {
      "input": "Tämä algoritmi löytää optimaalisen lukumäärän minimoimalla kustannusfunktion, joka perustuu sanojen samankaltaisuusmatriisin ominaisvektorirakenteeseen. Tarkemmat yksityiskohdat löytyvät asiaa koskevasta kirjallisuudesta.Tulokset ja keskustelu",
      "id": "task461-3c2cf90a4e5642a58004fe8970fca849",
      "output": [
        "Mitkä ovat kuusi kohdekieltä?"
      ]
    },
    {
      "input": "Lausuma ketjutetaan erityisellä symbolilla, joka merkitsee sekvenssin loppua. Alustamme sanojen upotukset käyttämällä 300-ulotteista GloVe BIBREF30 -sanastoa ja hienosäädämme niitä harjoittelun aikana.",
      "id": "task461-23f62c5f24034cea870e5c99ef8eb619",
      "output": [
        "Käyttävätkö ne esivalmisteltuja sanavektoreita dialogin kontekstin upottamiseen?"
      ]
    },
    {
      "input": "FastTextBIBREF4: Se käyttää tekstin luokittelussa ominaisuuksina sanapusseja ja n-grammipusseja, jotka keräävät tehokkaasti osittaista tietoa paikallisesta sanajärjestyksestä. BiLSTM: Toisin kuin feedforward-neuraaliverkot, BiLSTM:n kaltaiset rekursiiviset neuroverkot käyttävät historiatietoon perustuvaa muistia oppiakseen pitkän matkan piirteitä ja ennustaakseen sitten tuloksen. Käytämme kaksikerroksista BiLSTM-arkkitehtuuria, jossa on GloVe-sanojen upotukset, vahvana RNN-perustasona. BERT BIBREF5: Se on kontekstisidonnainen sanojen esitysmalli, joka käyttää kaksisuuntaisia muuntajia ja joka on esivalmennettu suurella 3,3 miljardin dollarin sanakorpuksella. Käytämme $BERT_{large}$-mallia, joka on hienosäädetty harjoitusaineistoon.",
      "id": "task461-4d6c5b35f8bd467991243fdbc7a7d5f8",
      "output": [
        "Mikä on kokeiden lähtötaso?"
      ]
    },
    {
      "input": "Yksi suosituimmista QG:n mittareista, BLEU BIBREF21 , tarjoaa joukon mittareita, joilla voidaan verrata automaattisesti luotuja tekstejä yhteen tai useampaan viitteeseen. Erityisesti BLEU-N perustuu ehdokkaan ja sitä vastaavan viitteen (vastaavien viitteiden) välisten päällekkäisten n-grammien lukumäärään. Sen vuoksi käytämme BIBREFissä33 alun perin ehdotettua Self-BLEU:ta luotujen tekstisekvenssien monimuotoisuuden mittarina.  Näin ollen, kun kysymyksen ja kontekstin pari annetaan QA-mallin syötteeksi, voidaan laskea kahdenlaisia mittareita: n-grammiin perustuva pistemäärä: mitataan haetun vastauksen ja perustotuuden keskimääräistä päällekkäisyyttä.todennäköisyyspistemäärä: QA-mallin luottamus haettuun vastaukseen; tämä vastaa todennäköisyyttä, jolla QA-malli antaa oikean vastauksen haetulle vastaukselle.",
      "id": "task461-734204c4d4774828a4c85027cd98d564",
      "output": [
        "Mitä automatisoituja mittareita kirjoittajat tutkivat?"
      ]
    },
    {
      "input": "On mielenkiintoista havaita, että perusmalli vahvistaa harjoitteluaineiston harhaa INLINEFORM0- ja INLINEFORM1-arvoilla mitattuna. Kuvattuja harhaisuusmittareita käyttävien mittausten perusteella menetelmämme lieventää tehokkaasti harhaisuutta kielen mallintamisessa ilman, että perpleksisyys lisääntyy merkittävästi.",
      "id": "task461-eb715f2db0004651bb34d89d06af94d0",
      "output": [
        "miten sukupuoleen perustuvien ennakkoluulojen lieventämistä arvioidaan?"
      ]
    },
    {
      "input": "Taulukossa TABREF9 on yhteenveto keskimääräisistä luokittelutarkkuustuloksista.",
      "id": "task461-8650aab42b5b48d88797157e5919b184",
      "output": [
        "Mitä arviointimittaria käytetään?"
      ]
    },
    {
      "input": " Analysoimme ensin koodien sekoittamissa sanaleikeissä esiintyviä rakennetyyppejä ja luokittelimme ne kahteen luokkaan, jotka ovat peräkkäiset ja sanansisäiset. ",
      "id": "task461-ebdd15b40e7443899ab9a888908e1cce",
      "output": [
        "Mihin luokkiin koodisekoitetut sanaleikit kuuluvat?"
      ]
    },
    {
      "input": "Taulukossa TABREF14 esitetään ehdotetun s2sL-lähestymistavan tulokset verrattuna MLP:n tuloksiin puhe/musiikki ja neutraali/sad-luokittelutehtävissä, kun otetaan huomioon eri osuudet harjoitusdatasta.",
      "id": "task461-0b6103858f9247f29cef0224371229bc",
      "output": [
        "Mihin malleihin/kehyksiin niitä verrataan?"
      ]
    },
    {
      "input": " Lisäksi ehdotamme tieliikennetutkimusta uudeksi mittariksi, jolla voidaan osoittaa mallin kestävyys altistumisharhoja vastaan.",
      "id": "task461-bf969ab5135d4651959cc7389f2f943d",
      "output": [
        "Mikä on tiekoemittari?"
      ]
    },
    {
      "input": "Haasteeseen vastataan seuraavasti: kun annetaan luonnollisen kielen syötesekvenssi, joka kuvaa kohtausta, kuten osa tarinasta, joka on peräisin transkriptiosta, tavoitteena on päätellä, mikä toiminto tapahtuu todennäköisimmin seuraavaksi.",
      "id": "task461-0750c9bca61b4f0aafa2af2e5a7d96d7",
      "output": [
        "Käsitelläänkö tätä kirjaimellisesti vain \"ennustaa seuraava tekstissä esiintyvä loitsu\"?"
      ]
    },
    {
      "input": "Toisaalta MHD:n tapauksessa huomiotason integroinnin sijasta jokaiselle päähän määritetään useita dekoodereita ja integroidaan niiden tuotokset lopullisen tuotoksen saamiseksi.",
      "id": "task461-863b90691cb149028d5ac16c1fd1cc84",
      "output": [
        "Laskeeko jokainen dekooderin tarkkaavaisuuspää saman ulostulon?"
      ]
    },
    {
      "input": "Huomaamme, että ketjuttaminen on jatkuvasti parempi kuin gated-attention-mekanismi sekä harjoittelu- että testausohjeiden osalta. Epäilemme, että gated-attention on hyödyllinen skenaarioissa, joissa objekteja kuvataan useiden attribuuttien avulla, mutta sillä ei ole haitallista vaikutusta, kun kyseessä ovat järjestysliittimet.",
      "id": "task461-878c9fd6a8474995ac80053ea0d12993",
      "output": [
        "Miksi he päättelevät, että Gated-Attentionin käyttö ei tarjoa kilpailuetua ketjuttamiseen verrattuna tässä tilanteessa?"
      ]
    },
    {
      "input": "Kuten näemme, kaikki CRU-mallimme variantit pystyvät antamaan huomattavia parannuksia perinteiseen GRU-malliin verrattuna, sillä kolmessa tietokokonaisuudessa voidaan havaita 2,7 %:n, 1,0 %:n ja 1,9 %:n enimmäishyöty.",
      "id": "task461-5b7c272a6f1e4a24bd988c5082fd9271",
      "output": [
        "Osoittavatko koetulokset uuden lähestymistavan johdonmukaisen merkittävän parannuksen perinteisiin CNN- ja RNN-malleihin verrattuna?"
      ]
    },
    {
      "input": "Tehtäviä on siis yhteensä 44 (22 INLINEFORM10 2). Lisäksi jokaisesta tehtävästä on 2 inhimillistä yhteenvetoa. Valitsimme kolme kilpailevaa järjestelmää (SumBasic, ILP ja ILP+MC), joten meillä on kolme järjestelmä-järjestelmä -paria (ILP+MC vs. ILP, ILP+MC vs. SumBasic ja ILP vs. SumBasic) kutakin tehtävää ja kutakin inhimillistä yhteenvetoa varten.",
      "id": "task461-9cca0e0c647b4c38bd21ef3749e47db7",
      "output": [
        "Rakentavatko he yhden mallin kutakin aihetta vai kaikkia aiheita varten?"
      ]
    },
    {
      "input": "Luomme kolme uutta harjoitustietokokonaisuutta lisäämällä alkuperäiseen Wikipedian korpukseen (jakso lm) lauseita, jotka sisältävät objektin RC-merkkejä. Tätä varten poimimme satunnaisesti 30 miljoonaa lausetta Wikipediasta (jotka eivät ole päällekkäisiä alkuperäisen korpuksen lauseiden kanssa), analysoimme ne samalla jäsentimellä ja suodatamme niistä 680 000 lausetta, jotka sisältävät objektin RC:n. Näin saamme 680 000 lausetta. ",
      "id": "task461-ca51d0c5dc374841957c05b10ff4df90",
      "output": [
        "Miten ne suorittavat tietojen lisäämisen?"
      ]
    },
    {
      "input": "Jos otamme CBT:llä koulutetun parhaan psr-kokoonpanon perustasoksi, malliarkkitehtuurin parantaminen BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , BIBREF11 -mallien mukaisesti ja alkuperäisen CBT-koulutusdatan käyttämistä jatkamalla johtaa INLINEFORM0- ja INLINEFORM1-luokkien absoluuttisiin parannuksiin nimettyjen entiteettien ja tavallisten substantiivien osalta. Sitä vastoin koulutustietokannan paisuttaminen paransi INLINEFORM2:n arvoa, kun käytettiin samaa mallia.",
      "id": "task461-819668e9fded4db68c07f73e3f66e013",
      "output": [
        "Kuinka suuria ovat Attention-Sum Reader -mallin parannukset, kun käytetään BookTest-tietokokonaisuutta?"
      ]
    },
    {
      "input": "Stanford - Twitter Sentiment Corpus (STS Corpus): STS-korpus sisältää 1 600 000 harjoitustwiittiä, jotka on kerätty BIBREF0-tietokannasta. BIBREF0 rakensi manuaalisesti testijoukon, jossa oli 177 negatiivista ja 182 positiivista twiittiä. Stanfordin testijoukko on pieni. Sitä on kuitenkin käytetty laajalti eri arviointitehtävissä BIBREF0 BIBREF5 BIBREF13 .Sanders - Twitter Sentiment Corpus: Tämä tietokokonaisuus koostuu käsin luokitelluista twiiteistä, jotka on kerätty hakusanojen avulla: INLINEFORM0 , #google, #microsoft ja #twitter. Rakennamme tietokokonaisuuden BIBREF14 binääriluokittelua varten.Terveydenhuollon uudistus (HCR): Tämä tietokokonaisuus rakennettiin indeksoimalla twiitit, jotka sisälsivät hashtagin #hcr BIBREF15 . Tehtävänä on ennustaa positiiviset/negatiiviset twiitit BIBREF14 .",
      "id": "task461-8ec3ec9cc06a40bcb2b07f0fdb68b8c5",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?",
        "Mitä kolmea Twitterin tunnetilaluokitusdataa käytetään kokeiluissa?"
      ]
    },
    {
      "input": "Toiseksi, twiittien poistaminen suoraan Twitterin verkkosivuilta. Toisen vaihtoehdon avulla ladattiin kiinnostavien osakkeiden päivittäiset twiitit vuodesta 2015 tammikuusta 2017 kesäkuuhun. Tästä syystä tutkitaan kahta saman toimialan yritystä, Teslaa ja Fordia, siitä, miten Twitter-tunnelmat voisivat vaikuttaa osakekurssiin. Kunkin twiitin kääntämiseksi sentimenttipisteytykseksi käytettiin Stanfordin coreNLP-ohjelmistoa.",
      "id": "task461-39964a06a3b34f35b062a2f5e054f44a",
      "output": [
        "Mitä twiittejä käytetään päivittäisen sentimenttisignaalin tuottamiseen?"
      ]
    },
    {
      "input": "Suuntaviivat uskollisuuden arvioimiseksi Ehdotamme seuraavia suuntaviivoja selitysten uskollisuuden arvioimiseksi. Näissä ohjeissa käsitellään kirjallisuudessa havaitsemiamme yleisiä sudenkuoppia ja epäoptimaalisia käytäntöjä.Guidelines for Evaluating Faithfulness ::: Ole selkeä sen suhteen, mitä arvioit.Uskottavuuden ja uskottavuuden sekoittaminen on haitallista. Sinun tulisi olla selvillä siitä, mitä niistä arvioit, ja käyttää sopivia menetelmiä kummallekin. Sama pätee tietysti myös tulkintatekniikoita suunniteltaessa - ole selvillä siitä, mitä ominaisuuksia priorisoidaan.Guidelines for Evaluating Faithfulness :::: Uskollisuuden arviointiin ei pitäisi sisältyä inhimillistä arviota tulkinnan laadusta. huomioimme, että: (1) ihmiset eivät voi arvioida, onko tulkinta uskollinen vai ei: jos he ymmärtäisivät mallin, tulkinta olisi tarpeetonta; (2) samankaltaisista syistä emme voi myöskään saada valvontaa tähän ongelmaan. Sen vuoksi ihmisen arvostelukykyä ei pitäisi ottaa mukaan uskollisuuden arviointiin, koska ihmisen arvostelukyky mittaa uskottavuutta. guidelines for Evaluating Faithfulness ::: Meidän pitäisi pystyä tulkitsemaan mallin virheellisiä ennusteita aivan samoin kuin oikeita ennusteita. Arviointimenetelmiin, jotka perustuvat kultaisiin merkintöihin, vaikuttavat ihmisen ennakko-odotukset siitä, mitä mallin pitäisi tehdä, ja ne taas työntävät arviointia uskottavuuden suuntaan.Guidelines for Evaluating Faithfulness ::: Älä luota \"luontaista tulkittavuutta\" koskeviin väitteisiin.Luontainen tulkittavuus on väite, kunnes toisin todistetaan. \"Luontaisesti tulkittavissa olevien\" mallien antamiin selityksiin on sovellettava samoja standardeja kuin post hoc -tulkintamenetelmiin, ja niiden uskottavuutta on arvioitava käyttämällä samoja arviointitekniikoita.Guidelines for Evaluating Faithfulness ::: Lopputehtävän käyttäjän suorituskyky HCI-ympäristöissä on vain osoitus uskottavuuden ja mallin suorituskyvyn välisestä korrelaatiosta, vaikka tämä korrelaatio olisi kuinka pieni tahansa. Vaikka se on tärkeää tulkintojen hyödyllisyyden arvioimiseksi joissakin käyttötapauksissa, se ei liity uskollisuuteen.",
      "id": "task461-7a348ec788c34ae79c4d219bddbae5f8",
      "output": [
        "Mitkä ovat keskeisiä kohtia uskollisuuden arviointia koskevissa suuntaviivoissa?"
      ]
    },
    {
      "input": "Klusterointi suoritettiin erikseen kunkin lääkärin erikoisalan osalta. Lisäksi tarkasteltiin lääkärien tunnusten jakautumista saatuihin klustereihin. Kävi ilmi, että jotkin klusterit kattoivat lähes täsmälleen yhden lääkärin kirjoittamat kuvaukset. Näin kävi erikoisaloilla, joilla klusterit erottuvat toisistaan suurilla marginaaleilla (esim. psykiatria, pediatria, kardiologia).",
      "id": "task461-e495c5fff0604fc898dc30ada3596139",
      "output": [
        "Tutkivatko he tekstien samankaltaisuutta eri lääkäreiden välillä?"
      ]
    },
    {
      "input": "Kokeet ::: Vertailua varten valitsemme useita julkisia malleja, mukaan lukien semanttisen jäsennyksen mallit: BiDAF BIBREF3, MRC-malli, joka käyttää kaksisuuntaista huomiovirtaverkkoa kysymyksen ja tekstin koodaamiseen; QANet BIBREF12, joka käyttää konvoluutioita ja itsehuomautuksia koodaajien rakennuspalikoina kysymyksen ja tekstin esittämiseen; BERT BIBREF23, valmiiksi harjoittelemamme kaksisuuntainen Transformer-pohjainen kielimalli, joka on viime aikoina saavuttanut huippusuorituskyvyn monissa julkisissa MRC-tietoaineistoissa; ja numeerisia MRC-malleja: NAQANet+, itse toteuttamamme parannettu versio NAQANetista, jossa otetaan lisäksi huomioon reaaliluku (esim. \"2,5\"), monipuolisempi aritmeettinen ilmaisu, datan lisääminen jne. Syn Dep BIBREF6, neuraalinen semanttinen jäsennysmalli (KDG) BIBREF22 Stanfordin riippuvuuksiin perustuvilla lause-esityksillä;OpenIE BIBREF6, KDG avoimeen tiedonlouhintaan perustuvilla lause-esityksillä;SRL BIBREF6, KDG semanttiseen roolimerkintään perustuvilla lause-esityksillä;ja perinteiset MRC-mallit:",
      "id": "task461-ffebd8ebd11f4113ba8a2a089affb5a6",
      "output": [
        "mihin nykyisiin malleihin niitä verrataan?"
      ]
    },
    {
      "input": "On myös huomattava, että käytännön ongelmien vuoksi tämän työn tavoitteena on luoda reseptiehdokkaita lääkemääräysmenettelyn helpottamiseksi sen sijaan, että korvattaisiin kokonaan ihmislääkärit.",
      "id": "task461-e05f9d5a815c4b5b98a79fc2b9026eed",
      "output": [
        "Miksi he pitivät tätä hyvänä ajatuksena?"
      ]
    },
    {
      "input": "BIBREF4 sisältää monenlaista uutisiin liittyvää tietoa, kuten kuvia, kuvatekstejä, maantieteellisiä sijaintitietoja ja kommentteja, joita voidaan käyttää artikkelin suosion mittarina. Tämän tietokokonaisuuden artikkelit kerättiin tammikuun ja joulukuun 2014 välisenä aikana. Vaikka yritimme hakea koko tietokokonaisuuden, pystyimme lataamaan vain 38 182 artikkelia, koska tietokokonaisuudessa julkaistiin kuolleita linkkejä. Haetut artikkelit julkaistiin tärkeimmissä uutiskanavissa, kuten Yahoo News, The Guardian tai The Washington Post. NowThisNews-tietokannan osalta normalisoimme tiedot ryhmittelemällä artikkelit kustantajakohtaisesti ja luokittelemalla ne suosituiksi, kun kommenttien määrä ylittää kyseisen kustantajan mediaaniarvon.",
      "id": "task461-70e63d1587a94c04b05d508a700b0695",
      "output": [
        "Mikä on uutisartikkelien lähde?"
      ]
    },
    {
      "input": " Käytämme hyperopt-kirjastoa hyperparametrien valitsemiseen seuraavilla arvoilla: LSTM-kerroksen koko (16, 32, 64), pudotusarvo ($0.0-0.9$), aktivointifunktio ($relu$, $selu$, $tanh$), optimoija ($sgd$, $adam$, $rmsprop$), oppimisnopeuden (1e-1,...,-5) ja erän koon (4, 8, 16) vaihtelulla.",
      "id": "task461-bc7af0e17ffa470c9963a02f92bd72c8",
      "output": [
        "Mitä aktivointifunktiota he käyttävät mallissaan?"
      ]
    },
    {
      "input": "Käytämme BIBREF6 aristo2016:combiningin tekstikorporaatiota (S) BIBREF6 aristo2016:combiningin tuple KB:n rakentamiseen.  Tarkemmin sanottuna käytämme jokaisen Q_\\mathit {tr}$:n monivalintakysymyksen $(q,A) \\ ja jokaisen A$:n vaihtoehdon $a \\ osalta kaikkia $q$:n ja $a$:n sisältämiä muita kuin pysähtymättömiä sanamerkkejä ElasticSearch-kyselynä S:lle. Otamme 200 parasta osumaa, suoritamme Open IE v4:n ja yhdistämme tuloksena saadut tuplat kaikkien $a \\in A$:n ja kaikkien Q_\\mathit {tr}$:n sisältämien kysymysten osalta luodaksemme tuple KB (T). Lause-korpus (S) koostuu 80 000 lauseesta ja 280 GB tavallisesta tekstistä, jotka on poimittu BIBREF6 aristo2016:combiningin käyttämiltä verkkosivuilta. ",
      "id": "task461-c7ee1c8b68844ae69df4c48a38341751",
      "output": [
        "Mistä korpuksesta OpenIE-uutteet on otettu?"
      ]
    },
    {
      "input": "Käytämme word2vec BIBREF0:ta sanojen upotusten kouluttamiseen.",
      "id": "task461-cb0f2d7e6014422f813a383d1a23aac3",
      "output": [
        "Millaisen mallin he rakentavat lyhenteiden laajentamiseksi?"
      ]
    },
    {
      "input": "Päästä päähän -menetelmämme lukee tekstiä ja kirjoittaa molempiin muistipaikkoihin ja niiden välisiin reunoihin. Intuitiivisesti muistipaikat vastaavat entiteettejä ja reunat entiteettien välisiä suhteita, jotka kukin esitetään vektorina.",
      "id": "task461-de6b7fdcf46e420e8b68359b402ca6dc",
      "output": [
        "Miten tieto palautuu muistiin?"
      ]
    },
    {
      "input": "Semanttinen haku: Käsittelimme neuraalista semanttista hakua sekä kappale- että lausetasolla binäärisenä luokitusongelmana, jossa mallien parametrit päivitetään minimoimalla binäärinen ristiinentropiahäviö. Tarkemmin sanottuna syötimme kyselyn ja kontekstin BERT:iin seuraavasti: Sovelsimme affiinikerrosta ja sigmoidiaktivaatiota viimeisen kerroksen ulostuloon [$\\mathit {CLS}$]-merkkiä, joka on skalaarinen arvo. Parametrit päivitettiin tavoitefunktiolla: jossa $\\hat{p}_i$ on mallin ulostulo, $\\mathbf {T}^{p/s}_{pos}$ on positiivinen joukko ja $\\mathbf {T}^{p/s}_{neg}$ on negatiivinen joukko. Kuten kuvasta FIGREF2 käy ilmi, lausetasolla positiivisina esimerkkeinä käytettiin perustotuuden lauseita, kun taas negatiivisina esimerkkeinä käytettiin muita lauseita, jotka oli haettu ylävirran joukosta. Vastaavasti kappaletasolla positiivisina esimerkkeinä käytettiin kappaleita, joissa oli jokin perustotuuslause, ja negatiivisina esimerkkeinä käytettiin muita kappaleita, jotka olivat peräisin termipohjaisista hakuprosesseista.",
      "id": "task461-1679c90cadb0418cb9499940eafc1896",
      "output": [
        "Miten he kouluttavat hakumoduulit?"
      ]
    },
    {
      "input": "Teemme myös hienojakoisen syntaktisen analyysin, joka osoittaa, miten menetelmämme avulla voidaan hallita ensimmäisen ja toisen persoonan pronominien sekä niihin liittyvien verbien ja adjektiivien morfologista toteutumista.",
      "id": "task461-5288739b8eda4c54954e59d8ae2e6551",
      "output": [
        "Mitä johtopäätöksiä syntaktisesta analyysistä tehdään?"
      ]
    },
    {
      "input": "Kehyksemme sisältää kolme keskeistä moduulia: Retrieve, Fast Rerank ja BiSET. Retrieve pyrkii palauttamaan jokaiselle lähdeartikkelille muutamia ehdokkaita malleiksi harjoituskorpuksesta. Tämän jälkeen Fast Rerank -moduuli tunnistaa nopeasti parhaan mallin ehdokkaiden joukosta. Lopuksi BiSET valitsee vastavuoroisesti tärkeät tiedot lähdeartikkelista ja mallista luodakseen parannetun artikkeliesityksen tiivistämistä varten. Tämä moduuli alkaa tavallisella tiedonhakukirjastolla, jolla haetaan pieni joukko ehdokkaita hienojakoista suodatusta varten cao2018retrievenä. Tätä varten kaikki muut kuin alfabeettiset merkit (esim. päivämäärät) poistetaan, jotta ne eivät vaikuttaisi artikkelien vastaavuuteen. Hakuprosessi aloitetaan tekemällä lähdeartikkelin avulla kysely harjoituskorpuksesta, jotta löydetään muutama (5-30) aiheeseen liittyvä artikkeli, joiden tiivistelmiä käsitellään ehdokasmalleina. Edellä kuvattu hakuprosessi perustuu lähinnä pinnalliseen sanojen yhteensovittamiseen, eikä sillä voida mitata kahden artikkelin välistä syvää semanttista suhdetta. Sen vuoksi kehitetään Fast Rerank -moduuli, joka tunnistaa ehdokkaista parhaan mallin sen perusteella, mikä on niiden syvällinen semanttinen yhteys lähdeartikkeliin. Mallina pidetään ehdokasta, jolla on suurin relevanssi. Kuten kuvassa FIGREF6 on esitetty, tämä moduuli koostuu konvoluutiokooderilohkosta, samankaltaisuusmatriisista ja poolointikerroksesta.",
      "id": "task461-13da1ff6e5334e269c3a0ef7a3ca77ed",
      "output": [
        "Miten mallit löydetään harjoitusdatasta?"
      ]
    },
    {
      "input": "Aloitimme vastaamalla aina KYLLÄ (erissä 2 ja 3) saadaksemme perustason suorituskyvyn. Erässä 4 käytimme päättelyä.",
      "id": "task461-6b6e1999992d48d9878585e8ad049211",
      "output": [
        "Mikä oli perusmalli?"
      ]
    },
    {
      "input": "Huomattakoon, että tässä tarkasteltavat kysymyksiin vastaamisen tehtävät ovat multimodaalisia, sillä vaikka konteksti on menettelytapatekstiä, kysymys ja monivalintatehtävät koostuvat kuvista.",
      "id": "task461-43c36d4b5dd14da4bfad6468de8dee3f",
      "output": [
        "Mitä multimodaalisuutta aineistossa on käytettävissä?"
      ]
    },
    {
      "input": " Tulevaisuudessa aiomme kiinnittää huomiota koodisekoitettujen tekstien yleistettyyn kielimalliin, jolla voidaan käsitellä myös hindi-koodisekoitettuja ja muita monikielisiä koodisekoitettuja tietokokonaisuuksia (eli pyrimme vähentämään riippuvuutta kielikohtaisista koodisekoitetuista resursseista). Järjestelmämme päihittää kaikki aiemmat aggressioiden tunnistamiseen käytetyt uusimmat lähestymistavat englanninkielisessä koodisekoitetussa TRAC-aineistossa, ja koska järjestelmä on koulutettu vain Facebook-kommenttien perusteella, se päihittää muut lähestymistavat myös Twitter-testijoukossa. Aggressiivisuuden/aggression tunnistamisen hienojakoinen määritelmä on TRAC-2018 BIBREF0, BIBREF2 -tapahtuman järjestäjien toimittama. He ovat luokitelleet aggressiivisuuden kolmeen merkintään (Overtly aggressive(OAG), Covertly aggressive(CAG), Non-aggressive(NAG)). Yksityiskohtainen kuvaus kustakin kolmesta leimasta on kuvattu seuraavasti: Overtly Aggressive(OAG) - Tämäntyyppinen aggressiivisuus osoittaa suoraa sanallista hyökkäystä, joka osoittaa tiettyyn yksilöön tai ryhmään. Esimerkiksi: \"Hyvin sanottu sonu..sinulla on rohkeutta vastustaa muslimien dadagiria\".Covertly Aggressive(CAG) - Tässä aggressiotyypissä hyökkäys ei ole suora vaan piilotettu, hienovarainen ja epäsuorempi, vaikka se useimmiten ilmaistaan kohteliaasti. Esimerkiksi: \"Rakas Intia, lakkaa leikkimästä kansasi tunteilla äänten saamiseksi.\" Non-Aggressive(NAG) - Yleensä tämäntyyppisissä teksteissä ei ole minkäänlaista aggressiota, vaan niitä käytetään pääasiassa tosiasioiden toteamiseen, tilaisuuksien toivomiseen, kohteliaisuuteen ja tukemiseen.",
      "id": "task461-f4316a13cf29470fadc199df6b7f112a",
      "output": [
        "Mihin TRAC-tietokannassa on sekoitettu englantia?"
      ]
    },
    {
      "input": "Tulevassa työssä aiomme myös lisätä tämäntyyppisiä tutkimuksia ERP-ennusteisiin.Keskustelu",
      "id": "task461-fea8f2db12c04918b7726843a70ed575",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?",
        "Mitkä kaksi kirjallisuudessa esiintyvää toiminnanohjausjärjestelmäparia hyötyvät yhteisestä harjoittelusta?"
      ]
    },
    {
      "input": "Julkaisimme Redditissä kyselyn, jossa pyysimme tanskankielisiä käyttäjiä ehdottamaan loukkaavia, seksistisiä ja rasistisia termejä sanastoa varten. Kieli ja käyttäjäkäyttäytyminen vaihtelevat eri alustoilla, joten tavoitteena on kerätä alustakohtaisia termejä. Näin saatiin 113 loukkaavaa ja vihamielistä termiä, joita käytettiin loukkaavien kommenttien löytämiseen. Loput korpuksen kommenteista sekoitettiin, ja osajoukkoa tästä korpuksesta käytettiin lopun lopullisen tietokokonaisuuden täyttämiseen. Tuloksena saatu tietokokonaisuus sisältää 3600 käyttäjien tuottamaa kommenttia, joista 800 Ekstra Bladetista Facebookissa, 1400 r/DANMAGista ja 1400 r/Denmarkista.",
      "id": "task461-6361835c9e654a938c56dea0d77c0a1d",
      "output": [
        "Kuinka suuri tanskalaisten kommenttien aineisto oli?"
      ]
    },
    {
      "input": "Korektorin jälkeen COSTRA 1.0 -tietokannan muodostavat 4262 yksilöllistä lausetta (mukaan lukien 150 siemenlausetta).",
      "id": "task461-885bed277c4c43dbb59cb637268d7c9e",
      "output": [
        "Kuinka monta lausemuunnosta on keskimäärin käytettävissä jokaista aineiston yksittäistä lausetta kohti?"
      ]
    },
    {
      "input": "Ensimmäinen haaste on hankkia erittäin suuri vietnaminkielinen korpus ja käyttää sitä luokittelijan rakentamiseen, mikä voisi parantaa tarkkuutta entisestään.  Toinen haaste on vietnamilaisten asiakirjojen suuren tietovaraston ja analyyttisen kehyksen suunnittelu ja kehittäminen, mikä vastaa Web 2.0 -sovelluksista, kuten Facebookista, Twitteristä ja niin edelleen, peräisin olevien artikkelien ja/tai asiakirjojen jättimäisen määrän nopeaa ja jatkuvaa kasvua. Viimeinen haaste liittyy sellaisen järjestelmän rakentamiseen, joka pystyy oppimaan asteittain uusia korporaatioita ja käsittelemään palautetta vuorovaikutteisesti.",
      "id": "task461-6a4cd3a9a70741e2bb8823fc8ea39360",
      "output": [
        "Miksi sanojen segmentointi vietnamin kielessä aiheuttaa haasteita?"
      ]
    },
    {
      "input": "Taulukon TABREF13 tuloksissa on kymmenen koetinta. ELMo-transformerin ja mSynC:n suorituskyky on jälleen samankaltainen, mutta mSynC suoriutuu hieman huonommin seitsemästä yhdeksästä tehtävästä.",
      "id": "task461-670d40b2183848a89d326fa678eff30b",
      "output": [
        "Kuinka monessa koetehtävässä matala-syntaksitietoinen kontekstisidonnainen sulautus toimii paremmin kuin ELMon sulautus?"
      ]
    },
    {
      "input": "Perusdekooderimme on vakiomuotoinen säteenhakupdekooderi BIBREF5 , johon on tehty useita suoraviivaisia suorituskykyoptimointeja.",
      "id": "task461-be7a4341cc004e5cafa6e48826297df5",
      "output": [
        "Mitä perusviivapurkulaitetta he käyttävät?"
      ]
    },
    {
      "input": "Aineistossamme on 3 209 arviota 553 eri autosta 49 eri autonvalmistajalta.",
      "id": "task461-60ae52ace30b42f99c38dc2fa5ce9104",
      "output": [
        "Kuinka suuri on autokielen kielitietokanta?"
      ]
    },
    {
      "input": "Sen jälkeen pyydämme erillistä turkkilaisryhmää arvioimaan tarinoiden yleistä laatua ja kolmea parannusaluetta. Kaikki arvosanat annetaan viisiportaisella asteikolla. Keräämme kaksi arviota kutakin juttua kohden ja hylkäämme arviot, jotka eroavat toisistaan yli kaksi pistettä. Kaikkiaan 11 prosenttia arvioinneista hylättiin, joten analysoitavaksi jäi neljä mittaria 241 jutun osalta.",
      "id": "task461-15ac6221717e4af6ae1d452240ae2c16",
      "output": [
        "Miten he arvioivat tuotettuja tarinoita?"
      ]
    },
    {
      "input": "Ensimmäinen luokittelumalli toimii suodattimena luokittelun toisessa vaiheessa. Käytämme sekä SVM:ää että NB:tä tulosten vertailuun ja valitsemme SVM:n myöhemmin ensimmäisen vaiheen luokittelumalliksi paremman F-tuloksen vuoksi. Koulutus suoritetaan tweeteillä, jotka on merkitty luokilla , ja jotka perustuvat unigrammeihin ominaisuuksina. Luomme twiitissä olevista merkkijonoista sanavektorit käyttämällä WEKA API BIBREF9 -ohjelmassa saatavilla olevaa suodatinta ja suoritamme ristiinvalidoinnin tavanomaisilla luokittelutekniikoilla.",
      "id": "task461-4471a79904fd4fecadaa76c681cd6bfe",
      "output": [
        "Mitä luokittelijaa käytetään hätätilanteiden havaitsemiseen?"
      ]
    },
    {
      "input": "Niissä tapauksissa, joissa mallin mielestä kaikkia historiallisia näytteitä olisi pidettävä yhtä tärkeinä peräkkäisessä analyysitehtävässä, meidän on etsittävä muualta laskennallisesti edullinen keino ymmärtää, mitä pysäytyskohdassa tapahtui.",
      "id": "task461-706c0aad9b55463f9641fc620eaf6627",
      "output": [
        "Voidaanko heidän tapaansa luoda informatiivisempaa visuaalista kuvaa soveltaa muihinkin tehtäviin kuin keskustelujen vuorotteluun?"
      ]
    },
    {
      "input": " Lisäksi niitä käsitellään niiden meluisan luonteen vuoksi käyttämällä joitakin Twitter-kohtaisia tekniikoita, kuten URL-osoitteiden, käyttäjien mainintojen, hashtagien ja hymiöiden korvaamista/poistamista, oikeinkirjoituksen korjaamista, pidennysten normalisointia, lyhenteiden etsimistä, välimerkkien poistamista, vahvistimien ja vähentäjien havaitsemista, negaatioiden tunnistamista jne. Kyseinen kieli osoittautui varsin haastavaksi luovan oikeinkirjoituksen ja välimerkkien käytön, kirjoitusvirheiden, slangin, uusien sanojen, URL-osoitteiden sekä genrekohtaisen terminologian ja lyhenteiden, esim. re-tweetin RT ja #hashtagien, käytön vuoksi. Genre-eron lisäksi myös pituusero: sosiaalisen median viestit ovat yleensä lyhyitä, usein pituudeltaan rajattuja, kuten Twitterissä, eli pikemminkin lause tai otsikko kuin kokonainen dokumentti.",
      "id": "task461-afbab404b45143cebb0d8d81a949faab",
      "output": [
        "Millaisia vaikeuksia Twitterin tunteiden analysoinnissa on verrattuna tunteiden analysointiin muilla aloilla?"
      ]
    },
    {
      "input": "jiant tarjoaa tukea huippuluokan lauseenkoodausmalleille, mukaan lukien tuki Huggingface Transformersille. Tuettuja malleja ovat mm: BERT BIBREF17, RoBERTa BIBREF27, XLNet BIBREF28, XLM BIBREF29, GPT BIBREF30, GPT-2 BIBREF31, ALBERT BIBREF32 ja ELMo BIBREF33. jiant tukee myös (kaksisuuntaisten) LSTM-mallien BIBREF34 ja syvien sanasäkkimallien BIBREF35 sekä syntaksitietoisten mallien, kuten PRPN BIBREF36 ja ON-LSTM BIBREF37, koulutusta alusta alkaen. jiant tukee myös sanojen upotuksia, kuten GloVe BIBREF38.",
      "id": "task461-7b98e07fda544aeb9dd75baa36026669",
      "output": [
        "Onko jiant yhteensopiva minkä tahansa ohjelmointikielen mallien kanssa?"
      ]
    },
    {
      "input": "Tässä jaksossa esittelemme kaksi kokeissamme käytettyä tietokokonaisuutta: Se sisältää 4090 viestiä ja niihin liittyviä videoita NowThisNews Facebook-sivulta, jotka on kerätty 07/2015 ja 07/2016 välisenä aikana. Kunkin viestin osalta keräsimme sen otsikon ja siihen liittyvän videon katselukertojen määrän, jota pidämme suosion mittarina. Melko pitkän tiedonkeruuprosessin vuoksi päätimme normalisoida aineistomme ryhmittelemällä ensin viestit niiden julkaisukuukauden mukaan ja merkitsemällä sitten viestit, joiden suosiometriikka ylittää kuukausittaisen mediaaniarvon, suosituiksi ja loput epäsuosituiksi.",
      "id": "task461-e71bd0d5b8204a7db2906fe62a45d5be",
      "output": [
        "Mistä he saavat uutisvideot?"
      ]
    },
    {
      "input": "Käytämme luokittelukokeissamme BIBREF4:n käyttöön ottamaa MH17 Twitter -tietokokonaisuutta, joka on kerätty tutkimaan MH17-lento-onnettomuutta koskevan (epä)tiedon kulkua Twitterissä. Se sisältää avainsanahaun perusteella kerättyjä twiittejä, jotka lähetettiin 17. heinäkuuta 2014 (lento-onnettomuuspäivä) ja 9. joulukuuta 2016 välisenä aikana.BIBREF4 tarjoaa annotaatioita osajoukolle tietokannan sisältämiä englanninkielisiä twiittejä.",
      "id": "task461-72d02bcf23f8470ca0cf18bb667a823e",
      "output": [
        "Mitkä kielet sisältyvät tietokantaan?"
      ]
    },
    {
      "input": "Käytämme Waseemin ja Hovyn BIBREF5-, Davidsonin ym. BIBREF9- ja Waseemin ym. BIBREF10-malleja perustasona ja vertailemme tuloksia eri hienosäätöstrategioillamme käyttäen esivalmistettua BERTbase-mallia. ",
      "id": "task461-0a1ad9ec8dc6472d8ff94209f87b31f9",
      "output": [
        "Mihin olemassa oleviin lähestymistapoihin niitä verrataan?",
        "Mitä perustasoa käytetään?"
      ]
    },
    {
      "input": "Luokkiin II ja III kuuluvia virheitä on vaikeampi välttää, ja niitä voitaisiin parantaa käyttämällä päättelyä BIBREF36 tai ironian havaitsemismenetelmiä BIBREF37.",
      "id": "task461-78b0d5d9781646e2999bd6e93dbc552e",
      "output": [
        "Mitä suosituksia annetaan suorituskyvyn parantamiseksi tulevaisuudessa?"
      ]
    },
    {
      "input": "Ihmisten merkitsemien harjoitusaineistojen luominen koneoppimista varten muistuttaa usein sisällönanalyysia, joka on vakiintunut menetelmä humanistisissa ja yhteiskuntatieteissä (erityisesti kirjallisuudessa, viestinnän tutkimuksessa ja kielitieteissä), mutta josta on myös versioita, joita käytetään biotieteissä, ekologiassa ja lääketieteessä. Sisällönanalyysi on saanut viime vuosisadan aikana monia muotoja, positivistisemmista menetelmistä, joissa vahvistetaan muodollisesti rakenteellisia tapoja arvioida sisältöä, tulkinnallisempiin menetelmiin, joissa hyväksytään monitulkintaisuus ja moninaiset tulkinnat, kuten grounded theory BIBREF16. Nykyään strukturoitua sisällönanalyysia (jota kutsutaan myös \"suljetuksi koodaukseksi\") käytetään kaikenlaisten laadullisten tai jäsentymättömien tietojen muuttamiseen strukturoiduiksi ja/tai määrällisiksi tiedoiksi, mukaan lukien mediatekstit, vapaamuotoiset kyselyvastaukset, haastattelupöytäkirjat ja videotallenteet. Hankkeisiin osallistuu yleensä koodaajien (joita kutsutaan myös annotaattoreiksi, merkitsijöiksi tai tarkastajiksi) ryhmiä, joissa tarvitaan ihmistyövoimaa koodaamaan, merkitsemään tai merkitsemään aineistokokonaisuuksia.",
      "id": "task461-d169b5ae54c449d6a504f8a386d2c2ab",
      "output": [
        "Missä mielessä tietojen annotointi muistuttaa strukturoitua sisällönanalyysia? "
      ]
    },
    {
      "input": "Testataksemme, onko horisontaalinen vai vertikaalinen johdonmukaisuus hyödyllisempi, harjoittelemme ja arvioimme M-Bertiä tietokokonaisuuden muunnoksella, jossa kaikki kysymykset ovat englanninkielisiä.",
      "id": "task461-169d2f9dd5414419a62f268d03f0c55a",
      "output": [
        "Suoritettiinko kieltenvälinen vs. yksikielinen arviointi?"
      ]
    },
    {
      "input": "Tietokannassamme tallennamme täydellisen twiittiobjektin, joka sisältää twiitin tunnisteen, käyttäjänimen, hashtagit ja twiitin maantieteellisen sijainnin. Loimme luettelon yleisimmistä COVID-19:ään liittyvistä arabian kielen avainsanoista. Twitterin streaming API:n avulla etsimme kaikki twiitit, jotka sisälsivät avainsanan (avainsanat) twiitin tekstissä. Taulukossa TABREF1 on luettelo käytetyistä avainsanoista sekä kunkin avainsanan seurannan alkamispäivä. Lisäksi taulukossa TABREF2 on luettelo seuraamistamme hashtageista sekä kustakin hashtagista kerättyjen twiittien määrä. ",
      "id": "task461-8eb58120efd3453386212d7ccbf1511d",
      "output": [
        "Mitä lisätietoa aineistosta löytyy?"
      ]
    },
    {
      "input": "Ominaisuudet. Väitämme, että erityyppiset ominaisuudet, kuten tekstin tunnetila, moraali ja muut tekstipohjaiset ominaisuudet, ovat kriittisiä tunnistettaessa Twitter-tilejä, jotka eivät ole tosiseikkoja, hyödyntämällä niiden esiintymistä uutisten raportoinnin aikana tilin aikajanalla. Käytämme runsaasti ominaisuuksia, jotka on lainattu aiemmista väärennettyjen uutisten, puolueellisuuden ja huhujen havaitsemiseen liittyvistä töistä BIBREF0, BIBREF1, BIBREF8, BIBREF9.[leftmargin=4mm]Tunne: Muodostamme tunnevektorin käyttämällä 15 tunnetyypin sanaesiintymiä kahdesta saatavilla olevasta tunnelexikoniasta. Käytämme NRC:n sanakirjaa BIBREF10, joka sisältää $\\sim $14K sanoja, jotka on merkitty käyttämällä Plutchikin kahdeksaa tunnetta BIBREF11. Toinen leksikko on SentiSense BIBREF12, joka on käsitepohjainen affektiivinen leksikko, joka liittää tunnemerkityksiä WordNet-tietokannan käsitteisiin. Siinä on $\\sim 5,5 dollaria sanoja, jotka on merkitty tunteilla 14 tunnekategorian joukosta Käytämme kategorioita, joita ei ole NRC-leksikossa.Sentiment: Poimimme twiittien sentimentin käyttämällä EffectWordNet BIBREF13, SenticNet BIBREF14, NRC BIBREF10 ja subj_lexicon BIBREF15, joissa kussakin on kaksi sentimenttiluokkaa, positiivinen ja negatiivinen: BIBREF16, jossa sanat merkitään johonkin seuraavista 10 luokasta (huolenpito, vahinko, oikeudenmukaisuus, huijaaminen, lojaalisuus, petos, auktoriteetti, kumouksellisuus, pyhyys ja alennustila).Style: Käytämme kanonisia tyylipiirteitä, kuten kysymysmerkkien, huutomerkkien, peräkkäisten merkkien ja kirjainten, linkkien, hashtagien ja käyttäjien mainintojen lukumäärää. Lisäksi poimimme isojen kirjainten osuuden ja twiitin pituuden.Words embeddings: Poimimme twiitin sanojen upotukset käyttämällä $Glove\\-840B-300d$ BIBREF17 -esivalmennettua mallia. Twiitin lopullinen esitys saadaan keskiarvoistamalla sen sanojen upotukset.",
      "id": "task461-10400ce6183848c383d59a6ecec1e7ad",
      "output": [
        "Mitä ominaisuuksia uutetaan?"
      ]
    },
    {
      "input": "Arviointitietokantana käytetään CoNLL-2012 shared task BIBREF21 -korpusta, joka on valittu Ontonotes 5.0 -tietokannasta.",
      "id": "task461-22c1652423394bc6a4383c96cb3b9dfe",
      "output": [
        "Millä tietokokonaisuudella he arvioivat malliaan?"
      ]
    },
    {
      "input": "Arvioidaksemme hypersphere-ominaisuutemme vaikutusta valmiisiin NER-järjestelmiin, suoritamme NE-tunnistuksen kahdella vakiomuotoisella NER-vertailuaineistolla, CoNLL2003 ja ONTONOTES 5.0.",
      "id": "task461-cbc99ec87df041bc8a61a12c15e430c8",
      "output": [
        "Arvioidaanko ne NER-tietoaineistoja?"
      ]
    },
    {
      "input": "Käytämme mandariinikiinan ja kantonin kielen tietoja. Kummankin kielen aineisto koostuu saman puhujan nauhoittamista puhutuista sanoista. Mandariinikiinan kielen aineisto on peräisin naispuoliselta puhujalta, ja sen on toimittanut Shtooka, ja kantonin kielen aineisto on peräisin miespuoliselta puhujalta, ja se on ladattu Forvo-verkkopalvelusta, joka on joukkorahoitteinen ääntämyssanakirja.",
      "id": "task461-7966490a75bb4a3b878a489a22b8d131",
      "output": [
        "Mitä tietokokonaisuutta käytetään harjoittelussa?"
      ]
    },
    {
      "input": "BERT: Toteutamme kaksi BERT-pohjaista peruslinjaa BIBREF51 todisteiden tunnistamista varten. Ensiksi koulutamme BERT:n jokaiselle kysely-käytäntö-lauseparille binäärisenä luokittelutehtävänä tunnistamaan, onko lause todiste kysymyksen kannalta vai ei (Bert). Kokeilemme myös kaksivaiheista luokittelua, jossa koulutamme mallin erikseen vain kysymyksille, jotta voimme ennustaa vastaamiskelpoisuuden. Jos päättelyhetkellä vastauskelpoinen luokittelija ennustaa, että kysymys on vastauskelpoinen, todisteiden tunnistamisen luokittelija tuottaa joukon ehdokaslauseita (Bert + vastauskelpoinen).",
      "id": "task461-3ca7f9e06bd54473a6575bf09e9e6151",
      "output": [
        "Minkä tyyppistä neuraalista mallia käytettiin?"
      ]
    },
    {
      "input": "jiant System Overview ::: jiant ComponentsTasks: Tehtävät: Tehtävissä on viittauksia tehtävätietoihin, menetelmiä tietojen käsittelyyn, viittauksia luokittelupäätteisiin sekä menetelmiä suorituskykymittareiden laskemiseen ja ennusteiden tekemiseen.",
      "id": "task461-0c16daa9cef04c90a8559532331c9af7",
      "output": [
        "Sisältyykö jiant-ohjelmaan tietokokonaisuuksia 50 NLU-tehtävää varten?"
      ]
    },
    {
      "input": "Swissmetro-tietokanta koostuu tutkimustiedoista, jotka kerättiin Sveitsin St. Gallenin ja Geneven välisissä junissa maaliskuussa 1998. ",
      "id": "task461-60ed3eaf531a400999465984afa032b1",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Harjoitusaineistomme koostuu 2,09 miljoonasta lauseparista, jotka on poimittu LDC-korpuksesta.",
      "id": "task461-7e976ca9181b44ab9b9a4a6bec6097f3",
      "output": [
        "Mistä sanasto tulee?"
      ]
    },
    {
      "input": "Tässä työssä arvioimamme aineisto on WMT English-French NewsTest2014, jossa on 380 miljoonaa sanaa rinnakkaista harjoitusdataa ja 3003 lauseen testijoukko. Validointiin käytetään NewsTest2013-joukkoa.",
      "id": "task461-31c5758b20794999848f8725962e60f6",
      "output": [
        "Testaavatko he vain yhdellä tietokokonaisuudella?"
      ]
    },
    {
      "input": "Kokosimme kolme kiinankielistä tekstikorpusta verkkoaineistosta kolmelle alalle, nimittäin \"hotelli\", \"matkapuhelin (mobiili)\" ja \"matkailu\". Kaikki tekstit koskevat käyttäjien arvosteluja. ",
      "id": "task461-dbf8813a3c964d86987681fb626e18af",
      "output": [
        "Mitkä ovat tietolähteet?"
      ]
    },
    {
      "input": "Optimaalisen kontekstin aktiivisesti valitsevien tarkkaavaisuusmallien parempi suorituskyky verrattuna malliin, jonka kontekstina on koko säie (hLSTM), osoittaa, että kontekstin päättely parantaa intervention ennustamista verrattuna oletusarvoisen täydellisen kontekstin käyttöön.",
      "id": "task461-6ca1a9ce8d264954a636954f79057c6e",
      "output": [
        "Mitkä keskustelun näkökohdat ovat huomiomekanismin mukaan merkityksellisiä ohjaajan intervention kannalta?"
      ]
    },
    {
      "input": "BIBREF16 on ottanut käyttöön BIBREF-tietokannan, jossa syötekysely on Wikipedia-artikkelin otsikon ja yhden sen jakson otsikon ketjutus. Relevantit kohdat ovat kyseisen osion sisältämiä kappaleita. Korpus koostuu kaikista englanninkielisen Wikipedian kappaleista lukuun ottamatta tiivistelmiä. Julkaistussa tietokokonaisuudessa on viisi ennalta määriteltyä taitosta, ja käytämme neljää ensimmäistä harjoitusjoukkona (noin 3 miljoonaa kyselyä) ja loput validointijoukkona (noin 700 000 kyselyä). Testijoukko on sama, jota käytettiin TREC-CAR 2017 -tapahtumaan lähetettyjen aineistojen arvioinnissa (noin 1800 kyselyä).",
      "id": "task461-8c2ddbf99b3845a485e78f07359f4238",
      "output": [
        "Mikä on TREC-CAR-tietokanta?"
      ]
    },
    {
      "input": "Sentimenttianalyysissä käytetty korpus on BIBREF11:n elokuva-arvosteluja sisältävä IMDb-tietokanta, kun taas NER-korpus on BIBREF12:n Groningenin merkityspankki (GMB), joka sisältää 47 959 lausenäytettä. ",
      "id": "task461-8f585b78f8654be995c690c8a8d01282",
      "output": [
        "Mitä Named Entity Recognition -tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Viime aikoina WMT 2018 APE -yhteistehtävässä on esitetty useita muuntajaarkkitehtuurin mukautuksia monilähteistä APE:tä varten. pal-EtAl:2018:WMT ehdotti APE-mallia, jossa käytetään kolmea itsetarkkailuun perustuvaa koodaajaa. He esittelevät ylimääräisen yhteisen koodaajan, joka kiinnittää huomiota kahden koodatun sekvenssin yhdistelmään $mt$:stä ja $src$:stä. tebbifakhr-EtAl:2018:WMT, WMT 2018:n NMT-alatehtävän voittaja ($wmt18^{nmt}_{best}$), käyttää sekvenssitason häviöfunktioita, jotta vältetään altistumisharhat harjoittelun aikana ja jotta se on johdonmukainen automaattisten arviointimetriikoiden kanssa. shin-lee:2018:WMT ehdottaa, että kullakin koodaajalla on oma itsehuomautus- ja feed-forward-kerroksensa jokaisen syötteen käsittelemiseksi erikseen. Dekooderin puolelle he lisäävät kaksi ylimääräistä monipäistä huomiokerrosta, yhden $src \\rightarrow mt$:lle ja toisen $src \\rightarrow pe$:lle. Tämän jälkeen toinen monipäähuomio näiden huomiokerrosten ulostulon välissä auttaa dekooderia ottamaan talteen $mt$:ssä olevat yhteiset sanat, joiden pitäisi pysyä $pe$:ssä. WMT 2018 -tapahtuman ($wmt18^{smt}_{best}$) APE PBSMT-osatehtävän voittaja BIBREF11 esitteli myös toisen muuntajapohjaisen monilähteisen APE:n, jossa käytetään kahta koodaajaa ja pinotaan ylimääräinen ristikkäistarkkailukomponentti $src \\rightarrow pe$:lle edellisen ristikkäistarkkailukomponentin päälle $mt \\rightarrow pe$:lle. Kun shin-lee:2018:WMT:n lähestymistapaa verrataan voittajajärjestelmään, arkkitehtuurissa on vain kaksi eroa: i) $src \\rightarrow mt$:n ja $src \\rightarrow pe$:n ristiinhuomaamisjärjestys dekooderissa ja ii) $wmt18^{smt}_{best}$ jakaa lisäksi parametreja kahden kooderin välillä. Äskettäin WMT 2018 APE shared -tehtävässä on esitetty useita muuntajaarkkitehtuurin mukautuksia monilähteistä APE:tä varten. pal-EtAl:2018:WMT ehdotti APE-mallia, jossa käytetään kolmea itsetarkkailuun perustuvaa kooderia. He esittelevät ylimääräisen yhteisen koodaajan, joka kiinnittää huomiota kahden koodatun sekvenssin yhdistelmään $mt$:stä ja $src$:stä. tebbifakhr-EtAl:2018:WMT, WMT 2018:n NMT-alatehtävän voittaja ($wmt18^{nmt}_{best}$), käyttää sekvenssitason häviöfunktioita, jotta vältetään altistumisharhat harjoittelun aikana ja jotta se on johdonmukainen automaattisten arviointimetriikoiden kanssa. shin-lee:2018:WMT ehdottaa, että kullakin koodaajalla on oma itsehuomautus- ja feed-forward-kerroksensa jokaisen syötteen käsittelemiseksi erikseen. Dekooderin puolelle he lisäävät kaksi ylimääräistä monipäistä huomiokerrosta, yhden $src \\rightarrow mt$:lle ja toisen $src \\rightarrow pe$:lle. Tämän jälkeen toinen monipäähuomio näiden huomiokerrosten ulostulon välissä auttaa dekooderia ottamaan talteen $mt$:ssä olevat yhteiset sanat, joiden pitäisi pysyä $pe$:ssä. WMT 2018 -tapahtuman ($wmt18^{smt}_{best}$) APE PBSMT-osatehtävän voittaja BIBREF11 esitteli myös toisen muuntajapohjaisen monilähteisen APE:n, jossa käytetään kahta koodaajaa ja pinotaan ylimääräinen ristikkäistarkkailukomponentti $src \\rightarrow pe$:lle edellisen ristikkäistarkkailukomponentin päälle $mt \\rightarrow pe$:lle. Kun shin-lee:2018:WMT:n lähestymistapaa verrataan voittajajärjestelmään, arkkitehtuurissa on vain kaksi eroa: i) $src \\rightarrow mt$:n ja $src \\rightarrow pe$:n ristiinhuomaamisjärjestys dekooderissa ja ii) $wmt18^{smt}_{best}$ jakaa lisäksi parametreja kahden kooderin välillä.",
      "id": "task461-6172fc9a4af443bbb590b328d11f854c",
      "output": [
        "Mikä oli automaattisen jälkikäsittelyn aiempi nykytilamalli?"
      ]
    },
    {
      "input": "Arvioimme sukupolvia ROUGE BIBREF29- ja METEOR BIBREF30 -mittareilla käyttäen kohteina todellisia lauseita.",
      "id": "task461-a0c78bc7a72746ffb999f99057db835a",
      "output": [
        "Mitä mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Käytämme useita standardimittareita, joita käytetään laajalti olemassa olevissa teoksissa mittaamaan vuoropuhelun luomismallien suorituskykyä, mukaan lukien BLEU BIBREF24, sulauttamiseen perustuvat mittarit (Average, Extrema, Greedy ja Coherence) BIBREF25, BIBREF26, entropiaan perustuvat mittarit (Ent-{1,2}) BIBREF0 ja erilliset mittarit (Dist-{1,2,3} ja Intra-{1,2,3}) BIBREF1, BIBREF6.",
      "id": "task461-3e577842b2734a66a60e28f5ab345988",
      "output": [
        "Mitä automaattisia arviointimittareita käytetään?"
      ]
    },
    {
      "input": "Siksi käytämme mallin signaalin voimakkuuden mittarina oikean suhteen softmax-todennäköisyyden vähenemistä. Kutsumme tätä metriikkaa ${\\Delta }_s$ (delta-softmax), joka voidaan kirjoittaa seuraavasti: missä $rel$ on EDU-parin oikea relaatio, $t_i$ edustaa merkkiä indeksillä $i$ $N$ merkistä ja $X_{mask=i}$ edustaa syötesekvenssiä, jossa on maskeerattu kohta $i$ (kun $i \\ in 1 \\ldots N$ ilman erottimia tai $\\phi $, tyhjä joukko).",
      "id": "task461-26436806b3b74a81908e325bf112865f",
      "output": [
        "Miten delta-softmax lasketaan?"
      ]
    },
    {
      "input": "MielialaluokitusKokeilemme ensin mielialaluokitusta monitehtäväkokeella.Käytämme 16 eri tietokokonaisuutta useista suosituista BIBREFissä20 käytetyistä arvostelukorpuksista. Nämä tietokokonaisuudet koostuvat 14 tuotearvostelutietokokonaisuudesta ja kahdesta elokuva-arvostelutietokokonaisuudesta.Kaikki kunkin tehtävän tietokokonaisuudet jaetaan satunnaisesti koulutusjoukkoon, kehitysjoukkoon ja testausjoukkoon, joiden osuudet ovat 70 %, 10 % ja 20 %. Jaetun lauseen edustuksen siirrettävyysHuomiointimekanismin avulla ehdotetuissa malleissamme oleva jaetun lauseen koodaaja voi tuottaa yleisempiä tehtävävariantteja edustuksia, joita voidaan pitää valmiiksi varastoituna tietämyksenä ja käyttää sitten uusissa tehtävissä, joita ei ole vielä nähty. Jaksojen merkitseminen aputehtävänäHyvän lauseen esityksen tulisi sisältää sen kielellistä tietoa. Siksi sisällytämme sekvenssien merkitsemistehtävän (kuten POS-taggaus ja pilkkominen) aputehtäväksi monitehtäväoppimisjärjestelmään, joka koulutetaan yhdessä ensisijaisten tehtävien kanssa (edellä mainitut 16 tunteiden luokittelutehtävää).",
      "id": "task461-6846585edc9b459c84ba563ca093bc2b",
      "output": [
        "Mitä tehtäviä he kokeilivat?"
      ]
    },
    {
      "input": "Tässä asiakirjassa korostetaan ensin televisio- ja radiolähetysten merkitystä sivutoimisen tunnistamisen tietolähteenä ja niiden mahdollisia vaikutuksia. Sen jälkeen tehdään tilastollinen analyysi sukupuolen edustuksesta aineistossa, joka koostuu neljästä uusimmasta ranskankielisen lähetyksen korpuksesta, joita käytetään laajasti puheyhteisössä. Lopuksi pohdimme ASR-järjestelmän näkökulmasta, miten tällainen edustus vaikuttaa tähän aineistoon perustuviin järjestelmiin.",
      "id": "task461-d641869daa6247fb94ee04e6c19eebf1",
      "output": [
        "Millaisia tehtäviä he käyttivät mies- ja naispuhujien suoritusten arvioinnissa?"
      ]
    },
    {
      "input": "Taulukossa TABREF21 esitetään korean INLINEFORM0-englannin tulokset käyttäen samoja kokoonpanoja (1, 2 ja 8) kuin saksanenglannin kohdalla. Tuloksemme vahvistavat, että soveltamamme tekniikat ovat menestyksekkäitä kaikissa tietokokonaisuuksissa, ja ne johtavat vahvempiin järjestelmiin kuin aiemmin on raportoitu tässä tietokokonaisuudessa, sillä ne saavuttavat 10,37 BLEU:ta verrattuna gu-EtAl:2018:EMNLP1:n raportoimaan 5,97 BLEU:hun.",
      "id": "task461-883246396165439fb4f35ac53aaba4cd",
      "output": [
        "Mihin menetelmiin niitä verrataan koreanenglantilaisessa tietokokonaisuudessa?",
        "Mitkä olivat heidän kokeelliset tuloksensa vähäisten resurssien aineistossa?"
      ]
    },
    {
      "input": "Tunteiden luokittelutehtävässä kokeilimme malliamme seuraavilla julkisilla tietokokonaisuuksilla. MR Elokuva-arvostelut, joissa kussakin on yksi lause. IMDB Elokuva-arvostelut IMDB-sivustolta, jossa jokainen elokuva-arvostelu on merkitty binääriluokilla, joko positiivinen tai negatiivinen BIBREF19. SUBJ$^1$ Elokuva-arvostelu, joka on merkitty subjektiivisella tai objektiivisella BIBREF20. Testasimme CRU-malliamme myös cloze-tyylisessä luetun ymmärtämistehtävässä. Suoritimme kokeita julkisilla tietokokonaisuuksilla: CBT NE/CN BIBREF25.",
      "id": "task461-736a6ba80673425ea748c1601065c286",
      "output": [
        "Mitä tietokokonaisuuksia käytetään tunnetilaluokituksen ja luetun ymmärtämisen testaamiseen?"
      ]
    },
    {
      "input": "Koulutimme ja arvioimme algoritmimme Microsoft COCO (MS-COCO) 2014 Captions -tietokannassa BIBREF21 . Raportoimme tulokset Karpathyn validointi- ja testijaoilla BIBREF8 , joita käytetään yleisesti muissa kuvatekstijulkaisuissa. Tietokokonaisuus sisältää 113 000 harjoituskuvaa, joihin kuhunkin kuvaan on liitetty 5 ihmisen kommentoimaa kuvatekstiä. Karpathyn testi- ja validointijoukot sisältävät kumpikin 5K kuvaa. Arvioimme mallejamme käyttämällä CIDEr-D BIBREF22 , SPICE BIBREF23 , BLEU BIBREF24 , METEOR BIBREF25 ja ROUGE-L BIBREF26 -mittareita. Vaikka kokeellisesti on osoitettu, että BLEU:lla ja ROUGE:lla on alhaisempi korrelaatio ihmisten tekemien arvioiden kanssa kuin muilla mittareilla BIBREF23 , BIBREF22 , yleinen käytäntö kuvatekstejä käsittelevässä kirjallisuudessa on ilmoittaa kaikki mainitut mittarit.",
      "id": "task461-f2b84ed390864597b1a97234651f83ad",
      "output": [
        "Mitkä ovat yleiset tekstitysmittarit?"
      ]
    },
    {
      "input": "Open IE BIBREF7 -tehtävästä tehtiin ulkoinen arviointi.",
      "id": "task461-75fd2f5d750f43a1900729feb72f7a01",
      "output": [
        "Käytetäänkö semanttista hierarkiaesitystä mihinkään tehtävään?"
      ]
    },
    {
      "input": "Arvioimme menetelmäämme kääntämällä englantia kolmelle morfologisesti rikkaalle kielelle, joilla kullakin on oma morfologinen typologiansa: Osoitamme, että mallimme pystyy saavuttamaan paremman käännöstarkkuuden ja yleistettävyyden kuin perinteiset avoimen sanaston NMT-menetelmät.",
      "id": "task461-6e64313266ba429bbc795060ffbddcfd",
      "output": [
        "Mitä kolmea kieltä tutkielmassa tarkastellaan?"
      ]
    },
    {
      "input": "Sosiaalisen median käyttö on viime vuosina kasvanut nopeasti. Ihmiset julkaisevat säännöllisesti päivittäisiä tapahtumia. BIBREF0 ehdottaa neljää tehtävää lääkkeiden nimien havaitsemiseksi, lääkkeiden käytön luokittelemiseksi, lääkkeiden haittavaikutusten luokittelemiseksi ja rokotuskäyttäytymisen havaitsemiseksi twiiteistä. Osallistuimme tehtäviin Task2 ja Task4.",
      "id": "task461-dfd1ce0123f449faa128e0271ed5b84b",
      "output": [
        "Arvioitiinko järjestelmä vain toisen jaetun tehtävän osalta?"
      ]
    },
    {
      "input": " Tässä luvussa kuvaamme lähestymistapaamme, jonka avulla luokittelemme käyttäjien reaktiot johonkin kahdeksasta diskurssityypistä: yhteisymmärrys, vastaus, arvostus, erimielisyys, tarkennus, huumori, kielteinen reaktio tai kysymys tai ei mikään annetuista merkinnöistä, jota kutsumme \"muuksi\", käyttämällä kielellisesti toimivia neuroverkkomalleja.",
      "id": "task461-b13e0be7456a4c789d677f4b8abbb591",
      "output": [
        "Mitkä ovat yhdeksän tyyppiä?"
      ]
    },
    {
      "input": " Käytimme CNN-verkkoa (Convolutional Neural Network), jonka rakenne on samankaltainen kuin BIBREF29:n ehdottama. ",
      "id": "task461-970e59feb79643b6a01ba4f3171b41a2",
      "output": [
        "Mitä neuraalisia arkkitehtuureja käytetään?"
      ]
    },
    {
      "input": "Käytämme asiantuntijoiden antamia merkintöjä abstraktia varten, jos ne ovat olemassa, muuten käytämme yleisön antamia merkintöjä. ",
      "id": "task461-b725d9c308224ea2bc17be10b6c0f973",
      "output": [
        "Miten he sovittavat kommentoijat ja instanssit yhteen?"
      ]
    },
    {
      "input": "Koulutamme MaLOPaa kaikkien seitsemän kielen harjoitusjaksojen rinnakkaistiedostojen avulla.",
      "id": "task461-74f9410377d24948885c6d90b53a72be",
      "output": [
        "Kuinka monella kielellä tätä jäsentäjää on kokeiltu?"
      ]
    },
    {
      "input": "Harjoittelussa käytettiin Kaldi Babel -reseptiä, jossa käytettiin 198 tuntia dataa kymmenellä kielellä (bulgaria, tšekki, ranska, saksa, korea, puola, portugali, venäjä, thai, vietnam) GlobalPhone-ohjelmasta.",
      "id": "task461-7b4ffa46c6a64843a98d434685362bdb",
      "output": [
        "Mitä kieliä otetaan huomioon?"
      ]
    },
    {
      "input": "TABREF5 näyttää sellaisten mallien tulostuskäyttäytymisen, joita vahingoitimme siten, että ne muistuttavat afasiaa aiheuttavaa vahinkoa. Koska kaikkien toimialueidemme tulostuskielet käyttävät monissa tapauksissa merkkejä merkitysten esittämiseen, on odotettavissa, että Wernicken alueen analogi on vastuussa korkean tarkkuuden ylläpitämisestä.",
      "id": "task461-143bce7954534254aef84cbfcfe5acf0",
      "output": [
        "Suorittavatko he kvantitatiivisen analyysin tietämyksen vääristymiä osoittavasta mallistaan?"
      ]
    },
    {
      "input": " Käytämme tunnetunnistukseen valmista työkalua (valmistajaa ei voida paljastaa lisenssirajoitusten vuoksi). Se antaa kehyskohtaiset pisteet ($\\in [0;100]$) erillisille tunnetiloille, joita ovat ilo, viha ja pelko. Poimimme äänisignaalin samasta jaksosta kuin kasvonilmeiden kohdalla ja käytämme valmiiksi saatavilla olevaa tunnetunnistustyökalua. Ohjelmisto tuottaa yksittäiset luokituspisteet 24 erillisen tunnetilan joukolle koko lausahduksen osalta.",
      "id": "task461-42b4288d59b74e1cada760c05dee553d",
      "output": [
        "Mitä tunteiden tunnistustyökaluja käytetään äänen ja kasvojen syöttämiseen?"
      ]
    },
    {
      "input": "Monitehtäväoppimisessa opitaan joukko toisiinsa liittyviä tehtäviä (esim. tunneaktivointi) sekä ensisijainen tehtävä (esim. tunnevalenssi); molemmat tehtävät jakavat osia verkon topologiasta ja siten ne koulutetaan yhdessä, kuten kuvassa KUVA4 on esitetty.",
      "id": "task461-43a0d7e21c3b497d9583338ebfe7eef2",
      "output": [
        "Mitkä ovat tehtävät monitehtäväoppimisasetelmassa?"
      ]
    },
    {
      "input": "Menetelmät ::: BIBREF11:n innoittamana käytämme pituuskoodausta antaaksemme verkolle tietoa jäljellä olevasta lauseen pituudesta dekoodauksen aikana. Ehdotamme kahdenlaista pituuden koodausta: absoluuttista ja suhteellista. Olkoon pos ja len merkin sijainti ja jakson loppu, jotka molemmat ilmaistaan numeromerkkeinä. Tällöin absoluuttinen lähestymistapa koodaa jäljellä olevan pituuden:missä $i=1,\\ldots ,d/2$.Vastaavasti suhteellinen ero koodaa suhteellisen sijainnin loppuun nähden. Tämä esitys saadaan yhdenmukaiseksi absoluuttisen koodauksen kanssa kvantisoimalla suhteellisten paikkojen avaruus äärelliseen $N$ kokonaislukujen joukkoon:missä $q_N: [0, 1] \\rightarrow \\lbrace 0, 1, ..., N\\rbrace $ määritellään yksinkertaisesti seuraavasti: $q_N(x) = \\lfloor {x \\times N}\\rfloor $. Koska olemme kiinnostuneita kohdesekvenssin merkin pituudesta, len ja pos annetaan merkkeinä, mutta esitämme sekvenssin BPE-segmentoitujen osasanojen sekvenssinä BIBREF17. Epäselvyyden ratkaisemiseksi len on merkkijonon pituus, kun taas pos on kaikkien edeltävien merkkien merkkimäärä.",
      "id": "task461-a50b7d5ce7fb458faec88adfa979ab67",
      "output": [
        "Miten ne rikastuttavat sijaintitietoa pituustiedolla?"
      ]
    },
    {
      "input": "Päätimme tutkia, miten CBT:tä voitaisiin vielä parantaa, testaamalla ihmisiä satunnaisella 50:llä nimetyn entiteetin ja 50:n yleisen substantiivin validointikysymyksen osajoukolla, joihin psr-kokoonpano ei pystynyt vastaamaan oikein.",
      "id": "task461-e32288ee05374c04b78f9eec4ccebe9c",
      "output": [
        "Miten ne osoittavat, että parannuksille on vielä tilaa?"
      ]
    },
    {
      "input": "Tämä menetelmä, josta käytämme nimitystä progressiiviset dynaamiset esteet (progressive dynamic hurdles, PDH), antaa jatkuvasti hyvin suoriutuville malleille mahdollisuuden harjoitella useampia vaiheita. Se alkaa tavallisena turnausvalinnan evoluutioarkkitehtuurihakuna, jossa on varhainen pysäytys, jolloin jokainen lapsimalli harjoittelee suhteellisen pienen $s_0$ määrän askelia ennen kuin sen soveltuvuus arvioidaan. Kun ennalta määrätty määrä lapsimalleja, $m$ , on kuitenkin arvioitu, luodaan este, $h_0$ , laskemalla nykyisen populaation keskimääräinen kunto. Seuraaville $m$ tuotetuille lapsimalleille, joiden kunto on suurempi kuin $h_0$ $s_0$ koulutusvaiheen jälkeen, annetaan $s_1$ lisäkoulutusvaihetta, minkä jälkeen ne arvioidaan uudelleen lopullisen kuntonsa määrittämiseksi. Kun toiset $m$ mallia on tarkasteltu tällä tavalla, muodostetaan toinen este, $h_1$ , laskemalla kaikkien niiden nykyisen populaation jäsenten keskimääräinen kunto, joita on koulutettu maksimimäärän askelia. Seuraavien $m$$ lapsimallien kohdalla koulutus ja arviointi jatkuu samalla tavalla, paitsi että malleille, joiden kunto on suurempi kuin $m$0 $m$1 koulutusaskeleen jälkeen, annetaan $m$2 lisää koulutusaskelia, ennen kuin niiden lopullinen kunto arvioidaan. Tätä prosessia toistetaan, kunnes saavutetaan tyydyttävä määrä maksimikoulutusaskeleita.",
      "id": "task461-951540a2ea234ede822c847461e79206",
      "output": [
        "Mikä on ehdotettu Progressive Dynamic Hurdles -menetelmä?"
      ]
    },
    {
      "input": "Lopuksi huomiomalli MDREA ylittää myös parhaat olemassa olevat tutkimustulokset (WAP 0,690-0,688) BIBREF19 .",
      "id": "task461-610a845715af47b18343d3f46b8e8920",
      "output": [
        "Kuinka paljon heidän mallinsa on parempi kuin uusimmat tulokset?"
      ]
    },
    {
      "input": "Neuroverkkomallimme koostuu pääasiassa kolmesta rinnakkaisesta LSTM BIBREF21 -kerroksesta.",
      "id": "task461-f54c00a54229461e9145d517cfaeed4b",
      "output": [
        "Millainen arkkitehtuuri neuroverkolla on?"
      ]
    },
    {
      "input": "Validoimme ehdotetun s2sL:n suorituskyvyn esittämällä alustavia tuloksia kahdesta eri tehtävästä, nimittäin puheen ja musiikin erottelusta ja tunteiden luokittelusta. Puhe- ja musiikkiluokittelutehtävää varten käytimme GTZAN Music-Speech -tietokokonaisuutta [17], joka koostuu 120 äänitiedostosta (60 puhetta ja 60 musiikkia). Kukin äänitiedosto (kestoltaan 2 sekuntia) esitetään 13-ulotteisella MFCC-vektorilla (mel-frequency cepstral coefficient), jossa kukin MFCC-vektori on kaikkien kehystason (kehyksen koko 30 sekuntia ja päällekkäisyys 10 sekuntia) MFCC-vektoreiden keskiarvo. On huomattava, että päätavoitteemme tässä tehtävässä ei ole parempi ominaisuuksien valinta vaan lähestymistapamme tehokkuuden osoittaminen erityisesti vähäisen datamäärän skenaarioissa. Tunteiden luokittelutehtävässä käytetään Berliinin puheen tunnetietokantaa (EMO-DB) [18], joka koostuu 535 lausumasta, jotka vastaavat seitsemää eri tunnetta. ",
      "id": "task461-8c4097f76f7e4e2ca578a870b3f88854",
      "output": [
        "Kuinka monella näytteellä he tekevät kokeita?"
      ]
    },
    {
      "input": "Käyttämämme arvostelut on poimittu TripAdvisorista, ja niitä on alun perin ehdotettu BIBREF10- ja BIBREF11 -julkaisuissa. ",
      "id": "task461-f50f0c5eaa064984a46290060a8e5b8d",
      "output": [
        "Mistä hotelliarvostelut ovat peräisin?"
      ]
    },
    {
      "input": "Tarkemmin sanottuna mallissamme käytämme sanan kontekstia ennustamaan sen merkinnän, ja näin mallimme oppii merkintätietoisen kontekstin jokaiselle lauseen sanalle. Parantaaksemme sanaesityksen ja sen kontekstin välistä vuorovaikutteisuutta lisäämme sanaesityksen ja sen kontekstin keskinäistä informaatiota.",
      "id": "task461-3e8aeb1f9eb94fd3b365ef5fd219ab89",
      "output": [
        "Miten heidän mallissaan hyödynnetään asiayhteystietoa kunkin teoksen osalta annetussa lauseessa monitehtävässä ympäristössä? ympäristössä?"
      ]
    },
    {
      "input": "Peruslinjat ovat: (a) koulutettu S-SQuAD:lla, (b) koulutettu T-SQuAD:lla ja sen jälkeen hienosäädetty S-SQuAD:lla ja (c) edellinen paras malli, joka on koulutettu S-SQuAD BIBREF5:llä käyttäen Dr.QA BIBREF20:tä. Ehdotettu lähestymistapa (rivi (f)) ylittää edellisen parhaan mallin (rivi (c)) 2 %:lla EM-tuloksella ja yli 1,5 %:lla F1-tuloksella.",
      "id": "task461-dd2c9b49f9cc43c2b35722f6d2d05af9",
      "output": [
        "Mikä oli edellinen paras malli?"
      ]
    },
    {
      "input": "Tunnistamisen poistotehtävissä kolme mittaria, joita käytämme arkkitehtuurimme suorituskyvyn arvioimiseen, ovat tarkkuus, palautus ja INLINEFORM0-pisteet, jotka määritellään jäljempänä.",
      "id": "task461-e6b1f5d954b642789ff5421b608e9109",
      "output": [
        "Mitä arviointimittareita ne käyttävät?"
      ]
    },
    {
      "input": "Ensiksi vertaamme sen suorituskykyä muihin BERT-malleihin ja uusimpiin tunneanalyysin järjestelmiin osoittaaksemme sen suorituskyvyn luokittelutehtävissä.  Toiseksi vertaamme sen suorituskykyä hiljattain toteutetussa hollannin kielen tehtävässä, nimittäin demonstratiivipronominien erottelussa, jolloin voimme lisäksi verrata meidän ja muiden BERT-mallien suorituskykyä nollapisteessä eli käyttämällä vain esivalmennettua mallia ilman mitään hienosäätöä.",
      "id": "task461-4325cc2801fe4e3db7ff22c72bc0e18d",
      "output": [
        "Mitä kielellisiä tehtäviä he kokeilivat?"
      ]
    },
    {
      "input": "Merkitsemme jokaisen arvosteluvektorin sillä autolla, jota se arvostelee. ",
      "id": "task461-36e569f4ee324f7fbde75772abf08ace",
      "output": [
        "Mitä ovat autojen puhekielitietokannan merkinnät?"
      ]
    },
    {
      "input": "Flickr30K-tietokanta BIBREF0 on kokoelma yli 30 000 kuvaa, joista jokaisessa on 5 joukkoistettua kuvausta. Sitä käytetään yleisesti kouluttamaan ja arvioimaan neuroverkkomalleja, jotka tuottavat kuvien kuvauksia (esim. BIBREF2 ). Tämän artikkelin tavoitteena on antaa yleiskatsaus kielellisistä ennakkoluuloista ja stereotypioista ja ennakkoluuloista johtuvista perusteettomista johtopäätöksistä. Rakennan aiempaan työhön, joka koskee kielellistä harhaa yleisesti BIBREF3 , annan esimerkkejä Flickr30K-aineistosta ja esittelen perusteettomien johtopäätösten taksonomian. Lopuksi käsittelen useita menetelmiä, joilla aineistoa voidaan analysoida ennakkoluulojen havaitsemiseksi.",
      "id": "task461-fd8b087079834874add1a53282945fa8",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Puitteena käytämme FLAIRin BIBREF46 lauseenluokittimen konfiguraatiota, jossa on biLSTM-kooderi/luokitinarkkitehtuuri, jota syötetään merkki- ja sanatason representaatioilla, jotka koostuvat kiinteistä 300-ulotteisista GloVe-editoinneista BIBREF47 , valmiiksi koulutetuista kontekstualisoiduista FLAIRin sanaeditoinneista ja valmiiksi koulutetuista kontekstualisoiduista merkkien etumerkkieditoinneista, jotka on saatu AllenNLP:stä BIBREF48 ja joissa on FLAIRin oletusarvoisilla hyperparametreilla.",
      "id": "task461-dff9cc77ab9740478d5357edff7322d6",
      "output": [
        "Onko joitakin malleja arvioitu tällä mittarilla, ja mitkä ovat tulokset?"
      ]
    },
    {
      "input": "Käytämme UltraSuitea: lasten puheterapiaistunnoista kerättyjen ultraääni- ja akustisten tietojen arkisto BIBREF15 . Käytimme kaikkia kolmea tietokokonaisuutta arkistosta: UXTD (tallennettu tyypillisesti kehittyvien lasten kanssa) sekä UXSSD ja UPX (tallennettu lasten kanssa, joilla on puheäänihäiriöitä). Kaikkiaan tietokokonaisuus sisältää 13 815 puhuttua lausetta 86 puhujalta, mikä vastaa 35,9 tuntia äänityksiä. Lausumat on luokiteltu sen mukaan, minkä tyyppinen tehtävä lapselle annettiin, ja ne on merkitty seuraavasti: Sanat (A), ei-sanat (B), lause (C), artikulaatio (D), ei-puhe (E) tai keskustelu (F). ",
      "id": "task461-30f5ea25d2ef4f89b4ad1f03da194ed0",
      "output": [
        "Annotoivatko he oman tietokokonaisuutensa vai käyttävätkö he olemassa olevaa tietokokonaisuutta?"
      ]
    },
    {
      "input": "Python-pakettia twitterscraper käytetään twiittien keräämiseen twitteristä. Ohjelmasta poimittiin 10 478 twiittiä kahdelta viime vuodelta aloilta kuten \"urheilu\", \"politiikka\" ja \"viihde\".",
      "id": "task461-ea4988eb9d4c4e5fb27ab8eece64a863",
      "output": [
        "Mistä korpuksen tekstit ovat peräisin?"
      ]
    },
    {
      "input": "Vaikka ehdokkaat antoivat suostumuksensa haastattelujensa käyttöön, aineistoa ei julkaista julkisesti tämän tutkimuksen ulkopuolella, koska videot ovat henkilötietoja, joihin sovelletaan tiukkoja yksityisyyden suojaa koskevia rajoituksia.",
      "id": "task461-35c6e9bfe6b24729a9dc8f4e13077673",
      "output": [
        "Ovatko ehdokkaat antaneet suostumuksensa siihen, että heidän videoitaan käytetään tutkimuksessa?"
      ]
    },
    {
      "input": "Lisäksi vertasimme mallejamme muihin olemassa oleviin teoksiin, kuten OpATT BIBREF6 ja Neural Content Planning with conditional copy (NCP+CC) BIBREF4.",
      "id": "task461-7507350ef8e74b998a5e28485681d61f",
      "output": [
        "Mikä on tehtävään soveltuva uusin malli?"
      ]
    },
    {
      "input": "Ihmisten arvioinnitSeuraamme BIBREF11 , BIBREF12 ja valtavaa määrää aiempaa semanttista samankaltaisuutta koskevaa työtä, ja pyydämme yhdeksää opiskelijaa arvioimaan 360 relaatioparin samankaltaisuutta Wikidata BIBREF8 -aineiston osajoukosta, jotka on valittu niin, että ne kattavat korkeasta matalaan samankaltaisuustasoon. Kokeessamme koehenkilöitä pyydettiin antamaan jokaiselle parille kokonaislukuinen samankaltaisuuspistemäärä 0:sta (ei yhtäläisyyttä) 4:ään (täysin samanlainen). ",
      "id": "task461-bb2ba3566d4e4951a0cca8531cad8e92",
      "output": [
        "Miten ne keräävät inhimillisiä arvioita suhteiden samankaltaisuudesta?"
      ]
    },
    {
      "input": "Esittelemme tässä askeleen tähän suuntaan: probabilistinen semanttinen jäsentäjä, joka käyttää suurta tietopohjaa (NELL) muodostaakseen ennakkotodennäköisyysjakauman jäsentämiensä lauseiden merkityksistä ja joka \"ymmärtää\" jokaisen lauseen joko tunnistamalla olemassa olevat uskomukset, jotka vastaavat lauseen merkitystä, tai luomalla uusia uskomuksia.",
      "id": "task461-1b4cfbcd698b4fa6a44fec783e641476",
      "output": [
        "Mitä tietopohjia ne käyttävät?"
      ]
    },
    {
      "input": "Sekä itse distributiohypoteesi että Tugendhatin tulkinta Fregen teoksesta ovat esimerkkejä holistisesta lähestymistavasta merkitykseen, jossa kokonaisuuden merkitys määrittää osien merkityksen.",
      "id": "task461-8114e0ba70114fac91b0329bc0a9a1dc",
      "output": [
        "Miten Fregen holistinen ja funktionaalinen lähestymistapa merkitykseen liittyy yleiseen distribuutiohypoteesiin?"
      ]
    },
    {
      "input": "Pinotut LSTM:t Solutietoiset pinotut LSTM:tJatketaan edellä määriteltyä pinotun LSTM:n muotoilua edellisessä alaluvussa mainitun ongelman ratkaisemiseksi. Lauseen koodaajatKokeissamme käyttämämme lauseen koodausverkko ottaa syötteenä INLINEFORM0-sanoja (joiden oletetaan olevan yhden pisteen vektoreita). Ylimmän kerroksen luokittelijat Luonnollisen kielen päättelykokeissa käytämme ominaisuuksien louhinnassa seuraavaa BIBREF36:n ehdottamaa heuristista funktiota: DISPLAYFORM0, jossa INLINEFORM0 tarkoittaa vektorien ketjuttamista ja INLINEFORM1 ja INLINEFORM2 sovelletaan elementtiviisaasti.",
      "id": "task461-7360d4b296d34033bd6e80d1424960c0",
      "output": [
        "Mitä malleja he kokeilivat?"
      ]
    },
    {
      "input": "Arkkitehtuuripohjaiset menetelmät pyrkivät joko luomaan tehtäväkohtaisen arkkitehtuurin esiharjoittelun aikana (tehtäväkohtaiset menetelmät) tai pyrkivät rakentamaan yleisen esiharjoitteluarkkitehtuurin, joka soveltuu kaikkiin myöhempiin tehtäviin (tehtäväkohtaiset menetelmät).",
      "id": "task461-0c478245ac3e49d18a5d64c1cddb041d",
      "output": [
        "Miten arkkitehtuuripohjainen menetelmä käsittelee NLG:n esteitä?"
      ]
    },
    {
      "input": "Käytämme videotekstien teksteihin VATEX-tietokokonaisuutta, joka sisältää yli 41 250 videota ja 825 000 englannin- ja kiinankielistä kuvatekstiä. Kuvatekstien joukossa on yli 206 000 englannin ja kiinan välistä rinnakkaiskäännösparia. Se kattaa 600 ihmisen toimintaa ja monenlaista videosisältöä. Jokaisen videon parina on 10 englanninkielistä ja 10 kiinankielistä erilaista kuvatekstiä. Noudatamme virallista jakoa, jossa on 25 991 videota harjoittelua varten, 3 000 videota validointia varten ja 6 000 julkista testivideota lopullista testausta varten.",
      "id": "task461-9816da3179874197a445c2d7368e4ab7",
      "output": [
        "Kuinka suuri on käytetty tietokokonaisuus?"
      ]
    },
    {
      "input": "Tavoitteenamme oli rakentaa yleistettävissä oleva tunneanalyysimalli, joten käytimme kolmea erilaista harjoitusjoukkoa, jotka on esitetty taulukossa TABREF5 . Yksi näistä kolmesta tietokokonaisuudesta (Amazonin arvostelut BIBREF23 , BIBREF24 ) on laajempi, ja siinä on tuotearvosteluja useista eri luokista, kuten kirja-arvosteluja, elektroniikkatuotteiden arvosteluja ja sovellusarvosteluja. Kahden muun tietokokonaisuuden tarkoituksena on tehdä mallista toimialueeseen erikoistuneempi. Tässä asiakirjassa keskitymme toimialueena ravintola-arvosteluihin ja käytämme Yelp-ravintola-arvostelujen tietokokonaisuutta, joka on poimittu Yelp Dataset Challenge BIBREF25 -kilpailusta, ja ravintola-arvostelujen tietokokonaisuutta, joka on osa Kaggle-kilpailua BIBREF26 .",
      "id": "task461-5c17b953feb9437187a374f8a924b2a6",
      "output": [
        "mitä tietokokonaisuutta käytettiin harjoittelussa?"
      ]
    },
    {
      "input": " Käytämme kolmea luovaa englanninkielistä tietokokonaisuutta, joilla on erilaiset kielelliset ominaisuudet: (1) 740 klassisen ja nykyaikaisen englanninkielisen runon korpus, (2) 14950 metaforalauseen korpus, joka on haettu metaforatietokannan verkkosivulta, ja (3) 1500 laulun sanoituksen korpus, joka koostuu eri genreistä. ",
      "id": "task461-6f8527ae1fee41b1a4228a77d2d5d70f",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Näihin jäsentymättömiin ominaisuuksiin kuuluvat: Nämä ovat: 1) kunkin riskitekijän osa-alueeseen liittyvien lauseiden suhteellinen määrä vastaanottotiedotteissa (vastaanottotiedotteessa olevien lauseiden kokonaismäärästä) ja 2) kliiniset sentimenttipisteet kullekin riskitekijäalueelle, eli sentimenttipisteet, jotka arvioivat potilaan psykososiaalisen toimintakyvyn tasoa (positiivinen, negatiivinen tai neutraali) suhteessa kuhunkin riskitekijäalueeseen.Nämä sentimenttipisteet saatiin automaattisesti aiemmassa työssämme BIBREF15 esitellyn aiheen poiminta- ja sentimenttianalyysiputken avulla, ja ne harjoitteltiin ennalta sisäisellä psykiatrisella EHR-tekstillä. Takaisinottoriskiluokittimen syötteeksi poimittiin 45 kliinisesti tulkittavissa olevaa piirrettä sisäänottoa kohti.",
      "id": "task461-7a322356cd0d4cecb694ca721bda934d",
      "output": [
        "Miten ne sisällyttävät tunneanalyysin?"
      ]
    },
    {
      "input": "Heidän tuloksensa paransivat BIBREFin8 antamaa perustasoa. Toinen vaikutusvaltainen työ oli BIBREF12 , jossa käytettiin Double Propagation -nimistä valvomatonta algoritmia, joka karkeasti ottaen koostuu siemenjoukon lisäämisestä asteittain riippuvuuksien jäsentämisen avulla. n tästä huolimatta taulukko TABREF20 osoittaa, että järjestelmämme on parempi kuin parhaat aiemmat lähestymistavat kaikilla viidellä kielellä. Joissakin tapauksissa, kuten turkki ja venäjä, parhaat aiemmat tulokset olivat ABSA:n järjestäjien antamia perustuloksia, mutta hollannin, ranskan ja espanjan kielissä järjestelmämme on huomattavasti parempi kuin nykyinen huipputekniikka. Huolimatta siitä, että käytämme samaa järjestelmää kaikilla kielillä, olemme paremmat kuin GTI:n toimittamassa ehdotuksessa, jossa käytettiin CRF-järjestelmää, jossa oli espanjankieliselle BIBREF-tietokannalle28 ominaisia kielellisiä piirteitä.",
      "id": "task461-a55815a9846a4aa18fa0380761e28b68",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "BIBREF12:n innoittamana integroimme tässä asiakirjassa rajojen kokoamisvaiheen uusimpaan LSTM-malliin kiinan sanojen segmentointia varten ja syötämme tuloksen CRF-malliin NER:ää varten. Tuloksena on 2 prosentin absoluuttinen parannus F1-kokonaispistemäärään verrattuna nykyisiin uusimpiin menetelmiin.",
      "id": "task461-714547aa09ae4f7e857b20f3be216713",
      "output": [
        "Mitä huipputason syvää neuroverkkoa käytetään?"
      ]
    },
    {
      "input": "Chowdhury BIBREF14 ja Thomas et al. BIBREF11 ehdottivat menetelmiä, joissa käytetään kielellisiä ilmiöitä ja kaksivaiheista SVM-menetelmää DDI:iden luokitteluun. FBK-irst BIBREF10 on jatkotyö, jossa kernel-menetelmää sovelletaan olemassa olevaan malliin ja se on parempi kuin se. Neuroverkkoihin perustuvia lähestymistapoja on ehdotettu useissa töissä. Liu et al. BIBREF9 käyttävät ensimmäistä kertaa CNN:ää DDI:iden louhintaan, mikä päihittää perinteiset koneoppimiseen perustuvat menetelmät.  Sahu et al. BIBREF12 ehdottivat LSTM:ään perustuvaa DDI:n louhintamenetelmää, joka on parempi kuin CNN:ään perustuva menetelmä, koska LSTM käsittelee lausetta sekvenssinä diaikkunoiden sijasta.",
      "id": "task461-524d0d4b85f74dababed4077c245432c",
      "output": [
        "Mitkä ovat asiakirjassa mainitut nykyiset menetelmät?"
      ]
    },
    {
      "input": "Lisäksi FSDM:ssä on uusi moduuli nimeltä vastauspaikkojen binääriluokittelija, joka lisää lisävalvontaa vastauksessa esiintyvien paikkojen tuottamiseksi tarkemmin ennen lopullisen tekstimuotoisen agenttivastauksen tuottamista (katso lisätietoja kohdasta \"Menetelmät\").",
      "id": "task461-9daa5e572e524ddda54e7a4f78836546",
      "output": [
        "Miten rakobinääriluokittelijat parantavat suorituskykyä?"
      ]
    },
    {
      "input": "Esittelemme ja arvioimme tätä varten kehittämämme mallin nimeltä QuaSP+Zero, joka muuttaa QuaSP+-parseria seuraavasti: Dekoodauksen aikana kohdissa, joissa jäsentäjä valitsee, mikä ominaisuus sisällytetään LF:ään (esim. kuva FIGREF31 ), se ei ota huomioon vain kysymysmerkkejä vaan myös näiden merkkien ja laadullisessa mallissa käytettyjen ominaisuuksien INLINEFORM0 välisen suhteen. Tämä lähestymistapa noudattaa BIBREF11 Krishnamurthy2017NeuralSP:n käyttämää entiteettien linkittämistä koskevaa lähestymistapaa, jossa kysymysmerkkien ja (entiteetteihin liittyvien) sanojen välinen samankaltaisuus - jota kutsutaan entiteettien linkittämispisteytykseksi - auttaa päättämään, mitkä entiteetit sisällytetään LF:ään jäsennyksen aikana.",
      "id": "task461-1c1e6a9e05b74b90973ae3d37155eaed",
      "output": [
        "Miten QuaSP+Zero-malli toimii?"
      ]
    },
    {
      "input": "Tein myös useita tapaustutkimuksia. Sain asiakirjojen upotukset samassa latentissa avaruudessa kuin aiheen upotukset laskemalla yhteen kunkin merkin jälkikeskiarvovektorit INLINEFORM0 ja visualisoin ne kaksiulotteisesti käyttämällä INLINEFORM1 -SNE BIBREF24 (kaikki vektorit normalisoitiin yksikköpituisiksi). Unionin tilaa koskevat puheet (kuva KUVIO FIGREF27 ) upotetaan lähes lineaarisesti vuosien mukaan, ja New Deal -aikakauden (1930-luku) ympärillä on suuri hyppäys, ja ne ovat hyvin erillään puolueittain millä tahansa aikajaksolla. ",
      "id": "task461-dcb39b2880ce41e9b37595ae031381ae",
      "output": [
        "Mikä on esimerkki laskennallisesta yhteiskuntatieteellisestä NLP-tehtävästä?"
      ]
    },
    {
      "input": "BIBREF25 ehdotti myös ajatusta käyttää sanojen upotusten keskiarvoa asiakirjan yleisen kontekstin esittämiseen. Heidän työstään poiketen me päätämme korruptoida alkuperäisen asiakirjan poistamalla satunnaisesti merkittävän osan sanoista ja esitämme asiakirjan käyttämällä vain jäljelle jääneiden sanojen upotuksia.",
      "id": "task461-a7e9bae2753a436686053699e5de98a1",
      "output": [
        "Onko heidän lähestymistapansa samanlainen kuin sanavektoreiden painotetun keskiarvosumman muodostaminen, jossa painot heijastavat sanojen frekvenssejä?"
      ]
    },
    {
      "input": "Koska yhtäkään aiempien töiden tietokokonaisuuksista ei ole julkaistu, päätämme rakentaa uuden tietokokonaisuuden. Keräämme satunnaisesti INLINEFORM0-tapauksia China Judgments Online -verkkopalvelusta, joista INLINEFORM1-tapaukset ovat harjoittelua varten ja INLINEFORM2-tapaukset validointia ja testausta varten.",
      "id": "task461-4cacb4b4863544dfb936d6ae6cbe8a5c",
      "output": [
        "mitä tietokokonaisuuksia kokeessa käytetään?"
      ]
    },
    {
      "input": "Alustan käyttäjät antavat vaikuttavuusääniä arvioidakseen, kuinka vaikuttava tietty väite on. Käyttäjät voivat valita yhden viidestä mahdollisesta väitteen vaikutusmerkinnästä: ei vaikutusta, vähäinen vaikutus, keskisuuri vaikutus, suuri vaikutus ja erittäin suuri vaikutus. Arvioidessaan väitteen vaikutusta käyttäjät voivat tutustua väitteen koko asiayhteyteen, joten he voivat arvioida, kuinka vaikuttava väite on väitteen tietyssä asiayhteydessä. Mielenkiintoinen havainto on, että tässä aineistossa sama väite voi saada eri vaikutusmerkinnät sen mukaan, missä yhteydessä se esitetään.",
      "id": "task461-9a046e625b1a4a35a4e8dd5f8e3f71da",
      "output": [
        "Miten pargmatiivinen ja diskurssikonteksti lisätään tietokokonaisuuteen?"
      ]
    },
    {
      "input": "Tämän vastapainoksi käytämme vasemmalta oikealle suuntautuvaa huomiomaskia, joka on samanlainen kuin alkuperäisessä Transformer-dekooderissa BIBREF1. Sovellamme $X$:n syötemerkkien osalta tällaista maskia kaikkiin $X$:n kanssa ketjutettuihin kohdemerkkeihin $Y$, jotta syötemerkit voivat kiinnittää huomiota vain muihin syötemerkkeihin. Vastaavasti kohdemerkkien $y_t$ kohdalla asetamme huomiomaskin kaikkiin merkkeihin $y_{>t}$, jolloin kohdemerkit $y_t$ voivat huomioida vain syötemerkit ja jo muodostetut kohdemerkit.",
      "id": "task461-0b61c2a07b1a4d4299403b10000d74d9",
      "output": [
        "Mitä eroa on BERT-genissä ja tavallisessa BERT:ssä?"
      ]
    },
    {
      "input": "CBOW-arkkitehtuurissa tehtävänä on ennustaa sana kontekstin perusteella ja SG-arkkitehtuurissa sanan perusteella. Rakensimme 16 mallia sanojen upotuksista käyttäen CBOW- ja Skip-gram-menetelmien toteutusta FastText-työkalussa BIBREF9 .",
      "id": "task461-7f2e0bd14f4a44709975806012bc5408",
      "output": [
        "Mitä erityistä on tietyissä upotuksissa?"
      ]
    },
    {
      "input": "Tutkimme seuraavia kuutta idiomiresurssia: Wiktionary, Oxford Dictionary of English Idioms (ODEI, BIBREF31), UsingEnglish.com (UE), Sporleder-korpus BIBREF10, VNC-tietokanta BIBREF9 ja SemEval-2013 Task 5 -tietokanta BIBREF15.",
      "id": "task461-5e8e9cdd0be442d298bf941933312d92",
      "output": [
        "Mitä sanakirjoja käytetään PIE:iden automaattiseen poimintaan?"
      ]
    },
    {
      "input": "Järjestelmämme, mukaan lukien ohjelmisto ja korpus, on saatavilla avoimen lähdekoodin projektina vapaaseen tutkimustarkoitukseen, ja uskomme, että se on hyvä lähtökohta tulevien vietnamilaisten SRL-järjestelmien kehittämiselle ja vertailulle. ",
      "id": "task461-a15fafca1070445897fbc6e9ace48d2a",
      "output": [
        "Ovatko niiden korpus ja ohjelmistot julkisia?"
      ]
    },
    {
      "input": "Mallimme BiLSTM+CNN(grafeemitaso) ja BiLSTM+CNN(G)+POS päihittää kaikki muut mallit, joita kokeiltiin OurNepali- ja ILPRL-tietokannoissa.",
      "id": "task461-3c9a0697c80a4e8682baa02959083c09",
      "output": [
        "Mikä on paras malli?"
      ]
    },
    {
      "input": "Kokeet ::: Tulokset ::: Natural Language Inference: (81.2 vs. 80.2 XLM:lle) ja käyttää alle puolet vähemmän parametreja (110M vs. 250M). Sen suorituskyky jää kuitenkin edelleen jälkeen alkuperäisellä englanninkielisellä harjoitusjoukolla koulutetuista malleista TRANSLATE-TEST-asetuksessa (81,2 vs. 82,91 RoBERTa). On huomattava, että CamemBERT käyttää paljon vähemmän parametreja kuin RoBERTa (110M vs. 355M parametria).",
      "id": "task461-cda288fdfc5b46a085eecef6324b55e2",
      "output": [
        "Missä tehtävissä CamemBERT ei parane?"
      ]
    },
    {
      "input": "Sitä vastoin tässä asiakirjassa ehdotetaan jaksotietojen hyödyntämiseksi sekä globaalin (koko asiakirja) että paikallisen kontekstin (esim. jakso/aihe) hajautettua esittämistä, kun päätetään, pitäisikö lause sisällyttää tiivistelmään.",
      "id": "task461-e70c41fe854541a4a7125cb906268d00",
      "output": [
        "Mitä he tarkoittavat globaalilla ja paikallisella kontekstilla?"
      ]
    },
    {
      "input": "Sanaintruusiotestiä on kallista soveltaa, koska se edellyttää ihmisen suorittamaa manuaalista arviointia erikseen kunkin upotusulottuvuuden osalta. Lisäksi sanaintruusiotesti ei määrittele sulautusulottuvuuksien tulkittavuuden tasoa, vaan se antaa binäärisen päätöksen siitä, onko ulottuvuus tulkittavissa vai ei. Jatkuvien arvojen käyttäminen on kuitenkin tarkoituksenmukaisempaa kuin binääriarviointien tekeminen, koska tulkittavuuden tasot voivat vaihdella asteittain eri ulottuvuuksien välillä.",
      "id": "task461-058d2f4670b64fff895635bfde7bc0fa",
      "output": [
        "Mitä etuja heidän ehdottamallaan tulkinnanvaraisuuden määrällisellä menetelmällä on verrattuna ihmislähtöiseen arviointiin, johon he vertaavat sitä?"
      ]
    },
    {
      "input": "Arvioimme QRNN-arkkitehtuuria suositussa dokumenttitason tunteiden luokittelun vertailukohteessa, IMDb:n elokuva-arvostelutietokannassa BIBREF17 . Tietokokonaisuus koostuu tasapainoisesta otoksesta, joka koostuu 25 000 positiivisesta ja 25 000 negatiivisesta arvostelusta, jotka on jaettu samankokoisiin train- ja testijoukkoihin ja joiden asiakirjojen keskimääräinen pituus on 231 sanaa BIBREF18 . Vertaamme vain muihin tuloksiin, joissa ei käytetä ylimääräistä merkitsemätöntä dataa (pois lukien esimerkiksi BIBREF19 ).",
      "id": "task461-47da5060ecf944be8828d407ee1c3cb8",
      "output": [
        "Mitä tunnetilaluokittelua koskevaa tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Kun validoinnin aikana on poistettu 135 kysymystä, lopullinen tietokokonaisuus sisältää 13 939 kysymystä, joista 3 827 edellyttää maalaisjärjen tietämystä (eli 27,4 %). ",
      "id": "task461-8d1ae850844c46a1a7a9a121fc3d1b8f",
      "output": [
        "Mikä on heidän aineistonsa koko?"
      ]
    },
    {
      "input": "Tässä esitellään arviointiasetelma ja analysoidaan artikkelin ja objektin (AEP) sijoittelutehtävän tuloksia. Raportoimme arviointimittarit vain \"merkityksellisten\" uutis-artikkeliparien osalta.  Perusasetukset. Tarkastelemme seuraavia perustasoja tätä tehtävää varten.B1. Ensimmäisessä perustasossa käytetään ainoastaan Dunietzin ja Gillickin BIBREF11 .B2. Toisessa perustasossa parille INLINEFORM0 annetaan arvo relevantti, jos ja vain jos INLINEFORM1 esiintyy INLINEFORM2:n otsikossa. Seuraavassa esitellään ASP-tehtävän arviointiasetelma ja keskustellaan tuloksista keskittyen kolmeen päänäkökohtaan: (i) kokonaissuorituskyky eri vuosina, (ii) entiteettiluokkakohtainen suorituskyky ja (iii) vaikutus entiteettiprofiilin laajentamiseen ehdottamalla puuttuvia osioita entiteeteille valmiiksi laskettujen mallien perusteella. Perustasot. Tietojemme mukaan emme ole tietoisia mistään vertailukelpoisesta lähestymistavasta tähän tehtävään. Sen vuoksi tarkastelemamme peruslinjat ovat seuraavat:S1: Valitaan malli INLINEFORM0:sta se jakso, jolla on suurin leksikaalinen samankaltaisuus INLINEFORM1:n kanssa : S1 INLINEFORM2S2: Sijoitetaan uutinen INLINEFORM0:n yleisimpään jaksoon.",
      "id": "task461-7adbc38ef5e44901ab6735dda8af9fd8",
      "output": [
        "Mitä perusmallia käytetään?"
      ]
    },
    {
      "input": "Tässä työssä ehdotamme, että kokonaislukuiseen lineaariseen ohjelmointiin (integer linear programming, ILP) perustuvaa yhteenvetokehystä täydennetään yhteisesiintymismatriisin matalan sijan approksimaatiolla, ja arvioimme lähestymistapaa laajalla joukolla tietokokonaisuuksia, joissa on suuri leksikaalinen monimuotoisuus.",
      "id": "task461-3254fa35325a4c7a9a5e602da6876f99",
      "output": [
        "Mitä ne rajoittavat käyttämällä kokonaislukuista lineaarista ohjelmointia?"
      ]
    },
    {
      "input": "Arvioimme CAHANin eri versioiden ja HAN-perustason avulla opittujen asiakirjojen upotusten laatua kolmella laajamittaisella asiakirjaluokitustietokannalla, jotka esiteltiin BIBREF14:ssä ja joita käytettiin alkuperäisessä HAN-julkaisussa BIBREF5. Ne jakautuvat kahteen luokkaan: aihepiiriluokittelu (Yahoo) ja hienojakoinen tunneanalyysi (Amazon, Yelp).",
      "id": "task461-c75d04ce606e492c93fdf415c58ee832",
      "output": [
        "Mitä tietokokonaisuuksia käytetään"
      ]
    },
    {
      "input": "Annotoijien joukko valitaan useiden lyhyiden harjoittelukierrosten jälkeen, joissa he saivat laajan henkilökohtaisen palautteen ja joissa oli enintään 15 predikaattia kierrosta kohden.",
      "id": "task461-321074f7db6c40cf94409db0a4d587af",
      "output": [
        "Miten työntekijät koulutetaan?"
      ]
    },
    {
      "input": "Ehdotetun BiLSTM-mallin arvioimiseksi huomion kanssa (BiLSTM+att) sitä verrataan kolmeen sen omaan vaihtoehtoon: BiLSTM ilman huomiota (BiLSTM) sekä yksi eteenpäin suuntautuva LSTM-kerros huomion kanssa (LSTM+att) ja ilman huomiota (LSTM). Muita perusmalleja ovat BIBREF32 , joka on jo ehdottanut LSTM-pohjaista arkkitehtuuria, joka käyttää vain muita kuin ajallisia piirteitä, sekä SVM-pohjainen estimointimalli, jota BIBREF24 on alun perin käyttänyt palkkion estimointiin.",
      "id": "task461-dc51af1276cf4e0c98212c64aa30c147",
      "output": [
        "Mitä mallia he käyttävät perustasona tyytyväisyyden arvioimiseksi?"
      ]
    },
    {
      "input": "Vaikka tällaista lähestymistapaa on käytetty eri tutkimuksissa ominaisuuksien suunnittelussa, sanavektoreiden valinta ja klusterien lukumäärä ovat edelleen kokeilu- ja virhemenettelyä. ",
      "id": "task461-5dc0f1ac2f9d47f1ab9ce0bd61a1519f",
      "output": [
        "Mitä muita hyperparametreja kuin klusterien lukumäärää arvioidaan tyypillisesti tämäntyyppisessä tutkimuksessa?"
      ]
    },
    {
      "input": "Huomasimme, että valvomaton morfologinen analysaattori, joka pystyy käyttämään ristikkoja, paransi foneemien tunnistuksen ja sanojen segmentoinnin tarkkuutta. Näin ollen tämä tulos viittaa siihen, että tämä sanojen segmentointimenetelmä ottaa huomioon puheentunnistuksen moninaiset hypoteesit kokonaisuutena ja vähentää epävarmuutta, kuten tunnistuksen vaihtelua, käyttämällä tavujen tunnistustuloksia ristikkomuodossa.",
      "id": "task461-9aea4baac31d45a1a50446c8d89c7942",
      "output": [
        "Miten he osoittavat, että paikkojen nimien hankkiminen auttaa itsensä paikallistamisessa?"
      ]
    },
    {
      "input": "He kommentoivat 7,8 000 verbiä ja raportoivat keskimäärin 2,4 QA-paria predikaattia kohti. Vaikka useamman annotaattorin osoitettiin tuottavan suuremman kattavuuden, heidän julkaisemansa tietokokonaisuus tuotettiin käyttämällä vain yhtä annotaattoria verbiä kohden.",
      "id": "task461-41026e4830cb41fc8620970382fbf2d4",
      "output": [
        "Miten kattavuutta mitattiin?"
      ]
    },
    {
      "input": "Seuraavaksi analysoimme kaikki loukkaaviksi merkityt twiitit, jotta ymmärtäisimme paremmin, miten arabian puhujat käyttävät loukkaavaa kieltä. Seuraavassa on käytön jakautuminen: Suora nimittely: Yleisin hyökkäys on kutsua henkilöä eläimellä, ja käytetyimmät eläinten nimet olivat كلب> (\"klb\" - \"koira\"), حمار> (\"HmAr\" - \"aasi\") ja بهيم> (\"bhym\" - \"peto\"). Toiseksi yleisintä oli henkisten kykyjen loukkaaminen käyttämällä sanoja kuten غبي> (\"gby\" - \"tyhmä\") ja عبيط> (\"EbyT\" - \"idiootti\"). Joitakin kulttuurikohtaisia eroja on otettava huomioon. Kaikkia eläinten nimiä ei käytetä loukkauksina. Esimerkiksi sellaisia eläinten nimiä kuin أسد> (\"Asd\" - \"leijona\"), صقر> (\"Sqr\" - \"haukka\") ja غزال> (\"gzAl\" - \"gaselli\") käytetään tyypillisesti ylistykseen. Muihin loukkauksiin ihmiset käyttävät: joitakin lintujen nimiä, kuten دجاجة> (\"djAjp\" - \"kana\"), بومة> (\"bwmp\" - \"pöllö\") ja غراب>. (\"grAb\" - \"varis\"); hyönteiset, kuten ذبابة> (\"*bAbp\" - \"kärpänen\"), صرصور> (\"SrSwr\" - \"torakka\") ja حشرة>. (\"H$rp\" - \"hyönteinen\"); mikro-organismit, kuten جرثومة> (\"jrvwmp\" - \"mikrobi\") ja طحالب> (\"THAlb\" - \"levä\"); elottomat esineet, kuten جزمة> (\"jzmp\" - \"kengät\") ja سطل> (\"sTl\" - \"ämpäri\") muiden käyttötapojen ohella.Vertaus ja metafora: Käyttäjät käyttävät vertausta ja metaforaa, jos he vertaisivat henkilöä johonkin: eläimeen, kuten زي الثور> (\"zy Alvwr\" - \"kuin härkä\"), سمعني نهيقك> (\"smEny nhyqk\" - \"anna minun kuulla karjuntaasi\") ja هز ديلك>. (\"hz dylk\" - \"heiluta häntääsi\"); henkilö, jolla on henkinen tai fyysinen vamma, kuten منغولي> (\"mngwly\" - \"mongolialainen (down-syndrooma)\"), معوق> (\"mEwq\" - \"vammainen\") ja قزم> (\"qzm\" - \"kääpiö\"); ja vastakkaiseen sukupuoleen kuten جيش نوال>. (\"jy$ nwAl\" - \"Nawalin armeija (Nawal on naispuolinen nimi)\") ja نادي زيزي> (\"nAdy zyzy\" - \"Zizin kerho (Zizi on naispuolinen lemmikkinimi)\").Epäsuora puhe: Tällaista loukkaavaa kieltä ovat mm: sarkasmia, kuten أذكى إخواتك> (\"A*kY AxwAtk\" - \"sisaruksistasi fiksuin\") ja فيلسوف الحمير> (\"fylswf AlHmyr\" - \"aasien filosofi\"); kysymykset, kuten ايه كل الغباء ده>. (\"Ayh kl AlgbA dh\" - \"mitä tämä kaikki typeryys on\"); ja epäsuora puhe, kuten النقاش مع البهايم غير مثمر> (\"AlnqA$ mE AlbhAym gyr mvmr\" - \"turha puhua karjalle\").Pahan toivominen: Tämä tarkoittaa kuoleman tai suuren vahingon toivomista jollekin, kuten ربنا ياخدك> (\"rbnA yAxdk\" - \"Jumala vieköön (tappakoon) sinut\"), الله يلعنك>. (\"Allh ylEnk\" - \"Jumala/ Allah kiroaisi sinut\"), ja روح في داهية> (\"rwH fy dAhyp\" - vastaa \"mene helvettiin\").Nimenmuutos: Yksi yleinen tapa loukata muita on muuttaa kirjain tai kaksi heidän nimissään, jotta saadaan uusia loukkaavia sanoja, jotka rimmaavat alkuperäisten nimien kanssa. Esimerkkejä tällaisesta ovat الجزيرة> (\"Aljzyrp\" - \"Aljazeera (kanava)\") muuttaminen الخنزيرة>:ksi. (\"Alxnzyrp\" - \"sika\") ja خلفان> (\"xlfAn\" - \"Khalfan (henkilön nimi)\") خرفان> (\"xrfAn\" - \"hullu\").Yhteiskunnallinen kerrostuneisuus: Jotkut loukkaukset liittyvät: tiettyihin ammatteihin, kuten بواب> (\"bwAb\" - \"ovimies\") tai خادم> (\"xAdm\" - \"palvelija\"); ja tiettyihin yhteiskunnan osiin, kuten بدوي> (\"bdwy\" - \"beduiini\") ja فلاح> (\"flAH\" - \"maanviljelijä\").Moraaliton käyttäytyminen: Nämä loukkaukset liittyvät negatiivisiin moraalisiin piirteisiin tai käyttäytymiseen, kuten حقير> (\"Hqyr\" - \"ilkeä\"), خاين> (\"xAyn\" - \"petturi\") ja منافق> (\"mnAfq\" - \"tekopyhä\").Sukupuoleen liittyvät: Niihin kuuluvat sellaiset ilmaukset kuin خول> (\"xwl\" - \"homo\"), وسخة> (\"wsxp\" - \"prostituoitu\") ja عرص> (\"ErS\" - \"parittaja\").",
      "id": "task461-d5947e95520247e995caeeada235db70",
      "output": [
        "Mitkä ovat arabian puhujien loukkaavan kielenkäytön erityispiirteet?"
      ]
    },
    {
      "input": "Ensimmäinen raportoimamme mittari on reaktiotyyppi. Toinen raportoimamme mittari on reaktionopeus. Jin et al. jin2013epidemiologisessa tutkimuksessa todettiin, että luotettavat uutistarinat leviävät nopeammin kuin väärät tiedot tai huhut; Zeng et al. zeng2016rumors havaitsivat, että huhut kiistävillä twiiteillä oli lyhyemmät viiveet kuin niitä tukevilla twiiteillä. Toinen tavoitteemme on selvittää, säilyvätkö nämä suuntaukset erityyppisten uutislähteiden osalta Twitterissä ja Redditissä. Tutkiaksemme, reagoivatko käyttäjät luotettavista lähteistä peräisin olevaan sisältöön eri tavalla kuin harhaanjohtavista lähteistä peräisin olevaan sisältöön, mittaamme reaktioviiveen, jonka määrittelemme linkin tai sisällön lähettämisen/twiittaamisen ja reaktiokommentin tai -twiittaamisen välillä kuluneeksi ajaksi. Raportoimme kumulatiiviset jakaumafunktiot (CDF) kullekin lähdetyypille ja käytämme Mann Whitney U (MWU) -testejä vertaillaksemme, reagoivatko käyttäjät tietyllä reaktiotyypillä merkittävästi erilaisilla viiveillä uutislähteisiin, joiden uskottavuus on erilainen.",
      "id": "task461-acb9f67c21844cc7965110742a04ed99",
      "output": [
        "Miten nopeus mitataan?"
      ]
    },
    {
      "input": "Opetussuunnitelman uskottavuus ::: Keskusteluominaisuudet ::: SpesifisyysNeuraalisen dialogin generointimallin tunnettu ongelma on, että malli on altis tuottamaan geneerisiä vastauksia. Opetussuunnitelman uskottavuus ::: Conversational Attributes :::: ToistuvuusToistuvia vastauksia on helppo tuottaa nykyisessä auto-regressiivisessä vastausten dekoodauksessa, jossa vastausten tuottaminen kiertää usein, kun taas monipuoliset ja informatiiviset vastaukset ovat paljon monimutkaisempia neuraalisessa dialogin tuottamisessa. Opetussuunnitelman uskottavuus ::: Keskusteluattribuutit :::: JatkuvuusYhteensopiva vastaus ei ainoastaan vastaa annettuun kyselyyn, vaan myös käynnistää seuraavan lausahduksen. Opetussuunnitelman uskottavuus ::: Conversational Attributes :::: Model ConfidenceHeuristisista keskusteluattribuuteista huolimatta otamme lisäksi käyttöön mallin luottamuksen attribuuttina, joka erottaa helposti opittavat näytteet heikosti opittavista näytteistä mallin oppimiskyvyn kannalta. Opetussuunnitelman uskottavuus ::: Keskusteluattribuutit ::: Query-relatednessKeskustelua pidetään johdonmukaisena, jos vastaus korreloi hyvin annetun kyselyn kanssa.",
      "id": "task461-8bab2fafbbcc407c8d2038dc3488ef64",
      "output": [
        "Mitä viittä vuoropuhelun ominaisuutta analysoitiin?"
      ]
    },
    {
      "input": "On osoitettu, että NER-järjestelmän sisältämää semanttista informaatiota voidaan lisätä merkittävästi, kun syväoppimismenetelmällä saadut entiteetit yhdistetään onnistuneesti tietopohjan BIBREF26 , BIBREF27 vastaaviin entiteetteihin. Uudelleenohjaus: Wikidata-linkityselementin osalta tunnistamme, että hakua rajoittaa kunkin entiteetin yleisin hakunimi. ",
      "id": "task461-dd91566d70c04439ae7a75e91c4fd4f0",
      "output": [
        "Miten he yhdistävät syväoppimismallin ja tietopohjan?"
      ]
    },
    {
      "input": "Tässä työssä tarkastelemme suunnattuja graafeja. Olkoon INLINEFORM0 graafi, joka koostuu joukosta kärkipisteitä INLINEFORM1 ja joukosta reunoja ( INLINEFORM2 ), jotka ovat järjestettyjä pareja. Lisäksi kullekin reunalle voidaan määrittää reaaliarvoinen paino. Olkoon INLINEFORM3 edustaa asiakirjaa, joka koostuu merkkeistä INLINEFORM4 . Tekstin merkkien esiintymisjärjestys tiedetään, joten INLINEFORM5 on täysin järjestetty joukko. Mahdollinen tapa rakentaa graafi asiakirjasta on yksinkertaisesti tarkkailla sanojen yhteisesiintymiä. Kun kaksi sanaa esiintyy yhdessä, niitä käytetään reunana. Tällaisissa lähestymistavoissa ei kuitenkaan oteta huomioon sanojen järjestysluonnetta, jolloin järjestys katoaa. Pyrimme ottamaan tämän näkökohdan huomioon seuraavasti. Annettu korpus käydään läpi, ja jokaiselle elementille INLINEFORM6 muodostetaan sen seuraaja INLINEFORM7 yhdessä tietyn elementin kanssa suunnattu reuna INLINEFORM8 . Lopuksi tällaisia reunoja painotetaan sen mukaan, kuinka monta kertaa ne esiintyvät tietyssä korpuksessa. Näin ollen graafi, joka on muodostettu tietyn korpuksen läpikäynnin jälkeen, koostuu kaikista paikallisista naapurustoista (järjestys yksi), jotka on yhdistetty yhdeksi yhteiseksi rakenteeksi. Globaalit kontekstuaaliset tiedot säilyvät mahdollisesti koskemattomina (painojen avulla), vaikka ne on havaittava verkkoanalyysin avulla, kuten seuraavassa ehdotetaan.",
      "id": "task461-03c2a107404145bf8e903d4707f66c9c",
      "output": [
        "Miten kuvaajat johdetaan tietystä tekstistä?"
      ]
    },
    {
      "input": "MIMIC-III on vapaasti saatavilla oleva, tunnistamaton tietokanta, joka sisältää Beth Israel Deaconess Medical Centerin teho-osastolle vuosina 2001-2012 otettujen potilaiden sähköiset terveystiedot.",
      "id": "task461-d9a7b53d124f41d6b638bc52ebbd54a3",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": " Tällä hetkellä puolustaja voi hyödyntää DNN:ien kestävyyden parantamisessa kuva-alalta tekstiin sovellettavia menetelmiä, kuten vastakohtaista koulutusta BIBREF107 , lisäkerroksen lisäämistä BIBREF113 , risti-entropiafunktion optimointia BIBREF114 , BIBREF115 tai vastakohtaisten esimerkkien siirrettävyyden heikentämistä.",
      "id": "task461-b92c6a3eb91d41d6b7da23ba7eaa2507",
      "output": [
        "Mitkä strategiat ovat lupaavimpia näiden hyökkäysten estämiseksi?"
      ]
    },
    {
      "input": "Keräämme lisää ihmisten kirjoittamia kohtauksia jokaiselle dev- ja testisarjan käsitejoukolle Amazon Mechanical Turk -alustan kautta. Jokaista syötettyä käsitejoukkoa kommentoi vähintään kolme eri ihmistä. Annotoijien edellytetään myös antavan perusteluina lauseita, jotka kannustavat heitä käyttämään tervettä järkeä kohtauksia luodessaan.",
      "id": "task461-7a10b0223cda40ebb48a2e0d86ac4801",
      "output": [
        "Ovatko perustelut syntyneet lauseiden kirjoittamisen jälkeen?"
      ]
    },
    {
      "input": "Tulevaisuuden työssä aiomme ratkaista kolmikoita, joissa toisena entiteettinä on useita entiteettejä, jotka eivät kuulu tämän asiakirjan ongelman piiriin. QA4IE:n syötteenä on dokumentti $D$ ja olemassa oleva tietopohja $K$, ja tuloksena on joukko relaatiokolmioita $R = \\lbrace e_i, r_{ij}, e_j\\rbrace $ $:ssa $D$, jossa $e_i$ ja $e_j$ ovat kaksi yksittäistä entiteettiä ja $r_{ij}$ on niiden välinen suhde.",
      "id": "task461-b71e60156ec94d3dabe2a13502436c7a",
      "output": [
        "Voidaanko tällä lähestymistavalla mallintaa n-alkuisia suhteita?"
      ]
    },
    {
      "input": "Bi-LSTM BIBREF11 on neuromallien perustaso. Bi-LSTM$_{+ att. + LEX + POS}$ BIBREF10 on monitehtäväinen oppimiskehys WSD:lle, POS-tunnisteille ja LEX:lle, jossa on itsehuomiointimekanismi, joka muuntaa WSD:n sekvenssioppimistehtäväksi. GAS$_{ext}$ BIBREF12 on GAS:n muunnos, joka on kiiltoa laajentava muistiverkon muunnos laajentamalla kiiltotietoa. CAN$^s$ ja HCAN BIBREF13 ovat lausetason ja hierarkkisen yhteishuomion neuroverkkomalleja, jotka hyödyntävät kiiltotietoa.",
      "id": "task461-5e751e28d8534a3196a0c380d8a0f717",
      "output": [
        "Miten neuroverkkoarkkitehtuuri mukautuu tuntemattomaan määrään aisteja sanaa kohti?"
      ]
    },
    {
      "input": "Kuten luvussa 2 mainittiin, CAEVO on nykyisin uusin järjestelmä ominaisuuksiin perustuvaan ajallisten tapahtumasuhteiden louhintaan BIBREF10 . Sitä käytetään laajalti perustasona TB-Dense-tietojen arvioinnissa. Otamme sen käyttöön CaTeRS- ja RED-tietokokonaisuuksien arvioinnin perustana.",
      "id": "task461-48f01db5f52f4efaa962c6844a37cf13",
      "output": [
        "Mitkä olivat perinteiset kielellisiin ominaisuuksiin perustuvat mallit?",
        "Minkälainen lähtötaso kahdelle tietokokonaisuudelle luodaan?"
      ]
    },
    {
      "input": "Se kerättiin joukkoistamalla BIBREF4. Tiedonkeruu tehtiin Android-sovelluksella.",
      "id": "task461-97eb1e9a88ff4db8ae4afb157ba3d913",
      "output": [
        "Mikä on tietojen lähde?"
      ]
    },
    {
      "input": "Mallissamme on viisi riippumatonta dekooderia, yksi kullekin sarjan kuvalle. Näin kukin dekooderi voi oppia tietyn kielimallin kuhunkin sekvenssin kohtaan.",
      "id": "task461-afe152134c0144dda7b286d0240c7969",
      "output": [
        "Onko kaikilla dekooderin LSTM-muisteilla samat painot?"
      ]
    },
    {
      "input": "Viimeksi GANeja käytettiin alkuperäisen maalauksen luomiseen ilman valvontaa BIBREF24. ",
      "id": "task461-297e51db342e4fe08ce9660ce3dbed4b",
      "output": [
        "Koulutetaanko teksti-kuvasynteesiä valvotulla vai valvomattomalla tavalla?"
      ]
    },
    {
      "input": "Tunnepisteiden jakauman mukaan Teslan tunnelmat ovat testausjakson aikana hieman vinoutuneet positiivisiksi.",
      "id": "task461-011ff5eab6ed4f8f8966dee2d46c6d4a",
      "output": [
        "Antavatko kirjoittajat esimerkkejä suurista tapahtumista, jotka herättävät yleisön huomion, ja niiden vaikutuksesta osakekurssiin?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF24 käy ilmi, MUSE päihittää kaikki aiemmat En-De- ja En-Fr-käännösmallit, mukaan lukien sekä uusimmat itsenäisen tarkkaavaisuuden mallit BIBREF0, BIBREF13 että konvoluutiomallit BIBREF11, BIBREF15 ja BIBREF10. Tämä tulos osoittaa, että pelkkä itsetarkkailu tai konvoluutio ei riitä sekvenssistä sekvenssiin oppimiseen. Ehdotettu rinnakkainen moniulotteinen huomio parantaa niitä sekä En-De- että En-Fr-käännöksessä.Verrattuna Evolved Transformer BIBREF19:ään, joka on rakennettu NAS:n avulla ja jossa sekoitetaan myös eri ytimen kokoisia konvoluutioita, MUSE saavuttaa 2,2 BLEU:n parannuksen En-Fr-käännöksessä.",
      "id": "task461-e5f92608ada4415ab162edc7217914dc",
      "output": [
        "Kuinka suuri on suorituskyvyn parannus Transformersiin verrattuna?"
      ]
    },
    {
      "input": "Kneser-Ney-sujutus Vertaamme erityisesti Kneser-Ney-sujutusta, joka on yleisesti hyväksytty tekniikan tasoksi ennen NLM:ää, nykyisiin parhaisiin NLM:iin.",
      "id": "task461-75260dcc6b1e43d2b70a28b3027ea6de",
      "output": [
        "mitä klassisia kielimalleja artikkelissa mainitaan?"
      ]
    },
    {
      "input": "Käytämme kokeissamme julkisesti saatavilla olevaa tietokokonaisuutta KVRET BIBREF5. Harjoittelua varten on 2425 dialogia, validointia varten 302 ja testausta varten 302 dialogia, kuten taulukon TABREF12 yläosasta käy ilmi.",
      "id": "task461-2d2f67bb07314b908c6a4039e9fb6b85",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Edellä mainittujen haasteiden ratkaisemiseksi ehdotamme paikallisesti lineaarista meta-kuvioinnin oppimismenetelmää, joka a) vaatii vain kunkin lähdekuvion sanaston sanat, eikä sen tarvitse ennustaa puuttuvien sanojen kuvioita, b) voi kuvioida eri ulottuvuuksisia lähdekuvioita ja c) on herkkä lähdekuvioiden naapurustojen monimuotoisuudelle.Ehdotetussa menetelmässä on kaksi vaihetta: naapuruston rekonstruointivaihe (kohta \"Lähimmän naapurin rekonstruointi\" ) ja projektiovaihe (kohta \"Projektio meta-sulautuma-avaruuteen\" ). Rekonstruktiovaiheessa sanan upotus esitetään lineaarisesti painotettuna yhdistelmänä sen lähimpien naapureiden upotuksista kussakin lähteen upotusavaruudessa.",
      "id": "task461-b57b537928bd412b93fadba370fe3081",
      "output": [
        "Mikä on tässä asiakirjassa esitelty meta-embedding-menetelmä?"
      ]
    },
    {
      "input": "Kokeelliset tutkimukset ::: Koska BERT on jo saavuttanut kysymysten vastaamisen huipputason suorituskyvyn, tässä jaksossa vertaamme ehdotettua malliamme uusimpiin kysymysten vastaamisen malleihin (eli QANet BIBREF39 ja BERT-Base BIBREF26). BERT-mallilla on kaksi versiota: BERT-Base ja BERT-Large, mutta laskentaresurssien puutteen vuoksi voimme verrata vain BERT-Base-mallia BERT-Large-mallin sijaan.",
      "id": "task461-391b1395f9b74c019a97eb9a0b499d01",
      "output": [
        "Mihin vertailukohtia ehdotettua mallia verrataan?"
      ]
    },
    {
      "input": "$D_a$ sisälsi kaikki twiitit, jotka kerättiin hyökkäyspäivänä kohdassa 4.2 mainituista viidestä hyökkäyksestä. Ja $D_b$ sisälsi kaikki ennen viittä hyökkäystä kerätyt twiitit. $D_a$:ssa on 1180 twiittiä ja $D_b$:ssa 7979 twiittiä. Hyökkäyspäivien twiitit ($D_a$) on kommentoitu manuaalisesti, ja vain 50 prosenttia näistä twiiteistä koskee todellisuudessa DDoS-hyökkäystä.",
      "id": "task461-6972ac0550c745d996131dc07781df0d",
      "output": [
        "Onko Twitter-käyttäjillä tapana twiitata DOS-hyökkäyksestä, kun se tapahtuu? Kuinka paljon tietoja tukee tätä oletusta?"
      ]
    },
    {
      "input": "Luomme kaksi mallia, jotka molemmat koostuvat kolmesta pääosasta: koodaaja, vuorovaikutus ja luokittelija, ja otamme syötteenä kaksi sekvenssiä. Kooderi on jaettu sekvenssien kesken ja käyttää yksinkertaisesti kahta pinottua GRU-kerrosta. Vuorovaikutusosa koostuu toisessa mallissa vain huomiosta, kun taas toisessa mallissa se koostuu huomion ja konfliktin yhdistelmästä, kuten (yhtälö 11) osoittaa. Luokittelijaosa on yksinkertaisesti pinottuja täysin kytkettyjä kerroksia. ",
      "id": "task461-54186fbd67b1411f9da4c2533b88077a",
      "output": [
        "Mitä neuraalista arkkitehtuuria ne käyttävät huomiokonfliktimekanismiensa perustana?"
      ]
    },
    {
      "input": "Tässä koesarjassa BERT-toteutusta verrataan useisiin MEDDOCAN-haasteeseen osallistuneisiin järjestelmiin: CRF-luokittelijaan BIBREF18, spaCy-entiteettitunnistimeen BIBREF18 ja NLNDE BIBREF12:een, joka voitti jaetun tehtävän ja on espanjankielisen kliinisen tekstin arkaluonteisen tiedon tunnistamisen ja luokittelun nykytekniikan taso.  Saatujen tulosten perusteella yhteistyöelin jää kuitenkin vain 0,3 F1-pistettä jälkeen ja olisi saavuttanut toisen sijan kaikkien MEDDOCANin jaetun tehtävän kilpailijoiden joukossa. Kun otetaan huomioon, että vain 3 prosenttia kultaisista merkinnöistä on edelleen virheellisesti merkitty, tehtävää voidaan pitää lähes ratkaistuna, eikä ole selvää, ovatko järjestelmien väliset erot todella merkittäviä vai johtuvatko ne vähäisistä vaihteluista alustuksessa tai vähäisten merkintäepävarmuuksien pitkästä sarjasta.",
      "id": "task461-4721f7d5e4ba4542ab141f7550ccbfef",
      "output": [
        "Saavuttaako yhteistyöhön perustuva yhteistyö parhaan suorituskyvyn kaikista vertailluista algoritmeista?"
      ]
    },
    {
      "input": "Lopuksi yhdistämme CNN- ja RNN-mallit äänestysprosessin avulla. Sovellamme kuhunkin testisarjan lauseeseen useita CNN- ja RNN-malleja, jotka on esitetty taulukoissa TABREF12 ja TABREF14, ja ennustamme eniten ääniä saaneen luokan. Jos äänet menevät tasan, valitsemme satunnaisesti yhden yleisimmistä luokista.",
      "id": "task461-3ece93571fcf459e8cb72ac735c5d5b3",
      "output": [
        "Miten heidän yksinkertainen äänestysjärjestelmänsä toimii?"
      ]
    },
    {
      "input": "Vertaamme parasta F1-pistemääräämme muihin uusimpiin lähestymistapoihin taulukossa TABREF39 , mikä osoittaa, että mallillamme on kilpailuetua lääkkeiden ja lääkkeiden välisestä vuorovaikutuksesta.",
      "id": "task461-194d2cbf4b7a4c158b5f8dac2ecffae7",
      "output": [
        "Mikä on heidän mallinsa suorituskyky?",
        "Kuinka paljon heidän mallinsa on parempi kuin nykyiset menetelmät?"
      ]
    },
    {
      "input": "Käytämme siis Krishnamurthyn ja Mitchellin esittelemää krishnamurthy-2015-semparse-open-vocabulary -tietokokonaisuutta, joka koostuu ClueWeb09-verkkokorpuksesta sekä Googlen FACC-entiteettilinkistä, joka yhdistää kyseisen korpuksen Freebase BIBREFiin9 .",
      "id": "task461-6dc030f6ffc144d5a14d5854e85ececd",
      "output": [
        "Mitä tietopohjaa he käyttävät?"
      ]
    },
    {
      "input": "Valitsimme SVMhmm BIBREF111-toteutuksen rakenteellisista tukivektorikoneista sekvenssien merkitsemistä varten. SVM-toteutus  ",
      "id": "task461-a7b1c87c13784367a29cef6494a5312d",
      "output": [
        "Mitä koneoppimismenetelmiä kokeissa käytetään?"
      ]
    },
    {
      "input": " Pysyäksemme johdonmukaisina LSTM:llä tehtyjen kokeiden kanssa käytämme morfessoria suomen kielen alasanojen tokenisointiin.",
      "id": "task461-c8adb87e5223410e89dc22397f984787",
      "output": [
        "Onko LSTM:n perustaso alasanamalli?"
      ]
    },
    {
      "input": "Testaamme malliamme ensin yhden toimialueen tietokokonaisuudella, WoZ2.0 BIBREF19 . Se koostuu 1 200 dialogista ravintolavarauksen alueelta, jossa on kolme ennalta määriteltyä kohtaa: ruoka, hintaluokka ja alue. Koska nimikenttä esiintyy aineistossa harvoin, sitä ei ole sisällytetty kokeiluihimme aikaisemman kirjallisuuden BIBREF3 , BIBREF20 mukaisesti. Malliamme testataan myös monialuetietoaineistolla MultiWoZ BIBREF9 . Siinä on monimutkaisempi ontologia, jossa on 7 toimialuetta ja 25 ennalta määriteltyä paikkaa. Koska uskomustilojen yhdistettyä slot-arvoparien esitystä on sovellettava malliin, jossa on $O(n)$ ITC, slottien kokonaismäärä on 35. ",
      "id": "task461-80af9eb9c7504b76a412985f876b0778",
      "output": [
        "Mitä tietokokonaisuuksia käytetään suorituskyvyn arvioinnissa?"
      ]
    },
    {
      "input": "Loimme kahdeksan erilaista luokittelijaa, joista kukin käytti jotakin seuraavista kahdeksasta ominaisuudesta, jotka ovat saatavilla Twitterin API:n virrasta haetusta twiitistä: Käyttäjän sijainti (uloc): Tämä on käyttäjän profiilissaan ilmoittama sijainti. Vaikka tämä ominaisuus saattaa vaikuttaa a priori hyödylliseltä, se on kuitenkin jossain määrin rajallinen, sillä kyseessä on vapaa tekstikenttä, jonka käyttäjät voivat jättää tyhjäksi, syöttää sijainnin nimen, joka on moniselitteinen tai jossa on kirjoitusvirheitä, tai merkkijonon, joka ei täsmää mihinkään tiettyyn sijaintiin (esim. \"kotona\"). Tarkasteltaessa käyttäjien itse ilmoittamia sijainteja Hecht et al. BIBREF49 havaitsivat, että 66 prosenttia ilmoitti tietoja, jotka voidaan kääntää, tarkasti tai epätarkasti, maantieteelliseksi sijainniksi, ja loput 34 prosenttia oli joko tyhjiä tai ei ollut maantieteellisesti paikannettavissa: Tämä on käyttäjän itse ilmoittama käyttöliittymän kieli. Käyttöliittymän kieli voi olla osoitus käyttäjän alkuperämaasta, mutta käyttäjä on voinut myös määrittää käyttöliittymän eri kielelle, kuten englanniksi, koska se oli oletuskieli, kun hän rekisteröityi tai koska hänen valitsemansa kieli ei ole käytettävissä.Aikavyöhyke (tz): Tämä ilmaisee aikavyöhykkeen, jonka käyttäjä on määritellyt asetuksissaan, esim. \"Pacific Time (US & Canada)\". Kun käyttäjä on määritellyt asetuksissaan tarkan aikavyöhykkeen, se voi olla osoitus hänen alkuperämaastaan; joidenkin käyttäjien asetuksissa voi kuitenkin olla oletusaikavyöhyke tai he voivat käyttää vastaavaa aikavyöhykettä, joka kuuluu eri paikkaan (esim. \"Eurooppa/Lontoo\" Portugalissa asuvalle käyttäjälle). Twitterin aikavyöhykeluettelo ei myöskään sisällä kaikkia maita.Tweet language (tlang): Twitter tunnistaa automaattisesti kielen, jolla twiitin uskotaan olevan kirjoitettu. Sen on todettu olevan tarkka tärkeimpien kielten osalta, mutta se jättää toivomisen varaa vähemmän käytettyjen kielten osalta. Twitterin kielitunnisteen on myös todettu olevan vaikeuksissa monikielisten twiittien kanssa, joissa twiitin osat on kirjoitettu eri kielillä BIBREF50 .Offset (offset): Tämä on käyttäjän asetuksissaan määrittelemä siirtymä UTC/GMT:hen nähden. Se on samanlainen kuin aikavyöhyke, vaikkakin rajoitetumpi, koska se on jaettu useiden maiden kanssa.käyttäjän nimi (name): Tämä on käyttäjän asetuksissaan määrittelemä nimi, joka voi olla hänen oikea nimensä tai hänen valitsemansa vaihtoehtoinen nimi. Käyttäjän nimi voi joissakin tapauksissa paljastaa hänen alkuperämaansa.Käyttäjän kuvaus (description): Tämä on vapaa teksti, jossa käyttäjä voi kuvailla itseään, kiinnostuksen kohteitaan jne: Teksti, joka muodostaa twiitin varsinaisen sisällön. Sisällön käyttöön liittyy useita varoituksia. Yksi niistä on se, että sisältö saattaa muuttua ajan myötä, ja näin ollen uudet twiitit saattavat käsitellä uusia aiheita, joita luokittelijat eivät ole nähneet aiemmin. Toinen varoitus on se, että twiitin sisältö ei välttämättä ole paikkakuntakohtaista; aiemmassa tutkimuksessa Rakesh et al. BIBREF51 havaitsivat, että 10 000 twiitistä vain 289:n sisältö oli paikkakuntakohtaista.",
      "id": "task461-7fc5c483169c4183b780f7ee9d1f4ff7",
      "output": [
        "Mitkä ovat kahdeksan mainittua ominaisuutta?"
      ]
    },
    {
      "input": "Suodatuksen jälkeen jätettiin 27 534 viestiä. Tätä aineistoa käytetään kokeiluissa.",
      "id": "task461-f26041111d424b6a9ee898fb1787be92",
      "output": [
        "Mikä on merkityn tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Plackett-Luce-mallin log-likelihood ei ole BLEU-pistemäärän tiukka yläraja, mutta se korreloi kuitenkin hyvin BLEU-pistemäärän kanssa, kun kyseessä ovat rikkaat ominaisuudet. Käsite \"rikas\" on itse asiassa kvalitatiivinen, ja sen määrittely on epäselvää eri sovelluksissa. Tarjoamme empiirisesti kaavan rikkauden mittaamiseksi konekääntämisen skenaariossa. Mitä suurempi, sitä rikkaampi. Käytännössä olemme havainneet, että r:n karkea kynnysarvo on 5 %.",
      "id": "task461-777ce516a7ed4bba8efed79ad5f8290f",
      "output": [
        "Miten he mittaavat kestävyyttä kokeissa?"
      ]
    },
    {
      "input": "Teimme kokeita CMU:n ARCTIC-tietokannalla BIBREF33, joka sisältää rinnakkaisia äänitteitä ammattimaisista yhdysvaltalaisista englannin puhujista 16 kHz:n taajuudella. Yksi naispuolinen puhuja (slt) valittiin kohdepuhujaksi ja yksi miespuolinen puhuja (bdl) ja yksi naispuolinen puhuja (clb) valittiin lähteiksi. Valitsimme kumpikin 100 lausumaa validointia ja arviointia varten, ja muita 932 lausumaa käytettiin harjoitusaineistona. TTS-korpusta valitsimme yhdysvaltalaisen naispuolisen englanninkielisen puhujan (judy bieber) M-AILABS-puhetietokannasta BIBREF34 yhden puhujan Transformer-TTS-mallin kouluttamista varten. Kun näytteenottotaajuus oli myös 16 kHz, harjoitusjoukko sisälsi 15 200 lausetta, jotka olivat noin 32 tuntia pitkiä.",
      "id": "task461-fb2b9915fa524f9e8160a26ff48489ec",
      "output": [
        "Mitä tietokokonaisuuksia kokeillaan?"
      ]
    },
    {
      "input": "Aiemmissa tutkimuksissa on sovellettu reduktionistista lähestymistapaa, jossa näitä kahta ongelmaa, \"mitä\" ja \"miten\", on tarkasteltu erikseen sisällön valinnan ja kysymysten rakentamisen avulla.  Neuraaliset mallit sen sijaan motivoivat kokonaisarkkitehtuuria. Syväoppimisen kehykset poikkeavat reduktionistisesta lähestymistavasta ja sallivat lähestymistavat, jotka yhdessä optimoivat sekä \"mitä\" että \"miten\" yhtenäisessä kehyksessä. ",
      "id": "task461-c6b3db235a2a47c1a4e9084a685c0356",
      "output": [
        "Mitä oppimisparadigmoja tässä tutkimuksessa käsitellään?"
      ]
    },
    {
      "input": "BIBREF17:ssä VAE:tä koskevassa työssä akustisten upotusten oppimiseksi tehtiin kokeita TIMIT-tietoaineistolla. BIBREF17:ssä tehtyjen VAE:hen perustuvien puhelinten luokittelukokeiden perustason suorituskyky raportoi 72,2 prosentin tarkkuuden. Työmme perustana oleva uudelleen toteutettu versio antoi 72,0 prosentin tarkkuuden, ja tämän tuloksen katsottiin tarjoavan uskottavan pohjan jatkotyölle.",
      "id": "task461-e06c1d155e4745bd94a9ca36749e34aa",
      "output": [
        "Mitä luokittelun perustasoja käytetään vertailussa?"
      ]
    },
    {
      "input": "Noudatamme samankaltaista arviointiprotokollaa kuin BIBREF6 , BIBREF8 , BIBREF9 -julkaisuissa, eli käytämme oppimiamme representaatioita ominaisuuksina matalan kompleksisuuden luokittimelle (tyypillisesti lineaariselle) uudessa valvotussa tehtävässä/alueella, jota ei ole nähty harjoittelun aikana, päivittämättä lauseen representaatiomallimme parametreja. Tarkastelemme myös tällaista siirto-oppimisen arviointia keinotekoisesti rakennetussa vähäresurssisessa ympäristössä. Lisäksi arvioimme myös oppimiemme yksittäisten sanarepresentaatioiden laatua käyttämällä vakiomuotoisia vertailukohtia BIBREF36 , BIBREF37 .",
      "id": "task461-f8a4295364f141e6b163592313677f27",
      "output": [
        "Miten he arvioivat lause-esityksiään?"
      ]
    },
    {
      "input": "Vaikka sekoitusstrategia korvaa suurimman osan Fr-De*:n ja Fr*-De:n välisestä erosta (3,01 $\\rightarrow $ 0,17) De $\\rightarrow $ Fr -tapauksessa, tuloksena saatu PSEUDOmix osoittaa edelleen alhaisempaa BLEU-arvoa kuin kohde-alkuperää oleva Fr-De*-korpus. Parannamme siis lähdeaineistosta peräisin olevan Fr*-De-korpuksen synteettisten esimerkkien laatua kouluttamalla edelleen sen käännösmallia (En $\\rightarrow $ Fr). Kuten kuvasta 2 käy ilmi, kun kohteena oleva Fr-De*-korpus on kiinteä, lähteenä olevalla Fr*-De-aineistolla ja PSEUDOmixilla koulutettujen mallien laatu kasvaa suhteessa Fr*-De-korpuksen emomallin laatuun. Lopulta PSEUDOmix osoittaa korkeinta BLEU-arvoa, ja se on parempi kuin sekä Fr*-De- että Fr-De*-aineisto.  Kuten taulukossa 6 esitetään, havaitaan, että hienosäätö, jossa käytetään perustotuuden rinnakkaisdataa, parantaa huomattavasti kaikkien NMT-mallien käännöslaatua. Kaikista hienosäädetyistä malleista PSEUDOmix osoittaa parasta suorituskykyä kaikissa kokeissa. Tämä on erityisen rohkaisevaa De $\\rightarrow $ Fr -mallissa, jossa PSEUDOmixin BLEU-arvo oli alhaisempi kuin Fr-De*-datan ennen hienosäätöä. Jopa siinä tapauksessa, että PSEUDOmix osoittaa vertailukelpoisia tuloksia muiden synteettisten korporaatioiden kanssa Pseudo Only -skenaariossa, se osoittaa suurempia parannuksia käännöksen laadussa, kun sitä hienosäädetään oikean rinnakkaisen datan kanssa. ",
      "id": "task461-184ede623ef54999b4c99561de629cfd",
      "output": [
        "Kuinka monta parannusta ranskan ja saksan käännösten vertailuarvoon?"
      ]
    },
    {
      "input": "Suoritamme sitten seuraavan analyysin.Puhujan sukupuolen vaikutukset: Etsimme yksikön ensimmäisen persoonan pronomineja, joilla on subjektin tapaus (ani, sukupuolen osalta merkitsemätön, vastaa englannin I:tä), ja otamme huomioon sitä hallitsevan verbin sukupuolen (tai adjektiivit kopulaarirakenteissa, kuten `I am nice'). Mahdolliset sukupuolet ovat `maskuliininen', `feminiininen' ja `kumpikin', joista jälkimmäinen tarkoittaa tapausta, jossa diakritisoimaton kirjoitusmuoto sallii sekä maskuliinisen että feminiinisen lukutavan. Odotamme, että sukupuoli vastaa etuliitteessä pyydettyä sukupuolta.Interlocutors' Gender and Number Effects: Etsimme toisen persoonan pronomineja ja tarkastelemme niiden sukupuolta ja lukumäärää. Subjektin asemassa olevien pronominien osalta otamme huomioon myös niitä hallitsevien verbien (tai adjektiivien kopulaarirakenteissa) sukupuolen ja lukumäärän. Kun kyseessä on yksikössä oleva yleisö, odotamme, että sukupuoli ja lukumäärä vastaavat pyydettyjä. Monikossa odotamme maskuliinisen ja monikollisen muodon vastaavuutta.",
      "id": "task461-202c90924836478f85df94c033c5699b",
      "output": [
        "Millainen syntaktinen analyysi suoritetaan?"
      ]
    },
    {
      "input": "Koska harjoitusaineisto koostuu vain lausuma-denotaatiopareista, ranker koulutetaan maksimoimaan oikean vastauksen $z$ log-likelihoodia käsittelemällä loogisia muotoja latenttina muuttujana. Rankerin tehtävänä on pisteyttää jäsentimen tuottamat loogiset muotokandidaatit; testiaikana korkeimman pistemäärän saanutta loogista muotoa käytetään suoritukseen. Ranker on diskriminoiva log-lineaarinen malli loogiselle muodolle $y$, kun kyseessä on lausuma $x$ : ",
      "id": "task461-fb66bcbcf9d94fcfa587695641510644",
      "output": [
        "Miten malli laskee todennäköisyyden suorittaa korjaus semanttiseen denotaatioon?"
      ]
    },
    {
      "input": "Vertailimme malliamme MLE-, RL- ja GAN-perusmalleihin. Koska COCO:lla ja EMNLP2017 WMT:llä ei ole syötettä, kun taas WeiboDial pitää viestejä syötteenä, valitsimme seuraavat perusmallit: MLE: RNN-malli, joka on koulutettu MLE-tavoitteella BIBREF4 . Sen laajennus, Seq2Seq, voi toimia dialogitietokannassa BIBREF2 .SeqGAN: Ensimmäinen teksti-GAN-malli, joka päivittää generaattoria politiikkagradientilla, joka perustuu erottelijan palkintoihin BIBREF7 .LeakGAN: SeqGANin muunnos, joka tarjoaa palkintoja erottelijan vuotaneen tiedon perusteella generaattorille BIBREF11 .MaliGAN: SeqGANin muunnos, joka optimoi generaattorin normalisoidulla maksimiluotettavuustavoitteella BIBREF8 .IRL: Tämä käänteinen vahvistusoppimismenetelmä korvaa diskriminaattorin palkitsemisapproksimaattorilla tiheiden palkkioiden tarjoamiseksi BIBREF12 .RAML: RL-lähestymistapa, jolla MLE-tavoite sisällytetään RL-koulutuskehykseen ja jossa BLEU:ta pidetään palkkiona BIBREF17 .DialogGAN: DialogGAN:n laajennus, joka on viritetty dialogin generointitehtävään ja jossa MLE-tavoite on lisätty vastakkaiseen tavoitteeseen BIBREF16 .DPGAN: DialogGAN:n muunnos, jossa käytetään kielimalliin perustuvaa diskriminaattoria ja jossa ristiinentropiaa pidetään palkkiona BIBREF13 .",
      "id": "task461-89adb24af2c34df18c3dd43ce8fa9ec4",
      "output": [
        "Mitä GAN-malleja käytettiin vertailukohtana?"
      ]
    },
    {
      "input": "Arkkitehtuurimme on suunniteltu osoittamaan, että käyttämällä mallia, joka tallentaa paremmin tietoa tekstin kontekstista ja peräkkäisestä luonteesta, voidaan päihittää kirjallisuudessa yleisesti käytetyt leksikonipohjaiset menetelmät.",
      "id": "task461-adc9691ec24f47df8939caf51c21523d",
      "output": [
        "Mitä merkityksellistä tietoa GRU-malli tallentaa, mitä perinteiset ML-mallit eivät?"
      ]
    },
    {
      "input": "Kuva-avusteisen mallin (W+C+V; ylempi rivi kuvassa FIGREF19 ) osalta vahvistamme, että modaliteettihuomio vaimentaa onnistuneesti epäolennaisia signaaleja (selfiet jne.) ja vahvistaa merkityksellisiä modaliteettipohjaisia konteksteja tietyn merkin ennustamisessa.",
      "id": "task461-d932505f22804a92bb07d3370c79f8d6",
      "output": [
        "Tarkastavatko he malliaan nähdäkseen, oppiiko heidän mallinsa yhdistämään kuvan osia kokonaisuuksiin liittyviin sanoihin?"
      ]
    },
    {
      "input": " Yhden puhujan vuoropuheluvuoro voi olla paitsi suora vastaus toisen puhujan kysymykseen, myös todennäköisesti jatkoa hänen omalle aiemmalle lausumalleen. Kun mallinnetaan dialogin vuoroa $k$, ehdotamme, että vuoron $k-2$ viimeinen RNN-tila liitetään suoraan vuoron $k$ alkutilaan sen sijaan, että sen annettaisiin levitä vuoron $k-1$ RNN:n kautta.",
      "id": "task461-d8d13232cf4e49ebb8723152c7d29580",
      "output": [
        "Kuinka pitkä dialogihistoria on tallennettu?"
      ]
    },
    {
      "input": "U.S. Newsin tilastoista poimitaan 200 korkeakoulua koskevat neljä tosiasioihin liittyvää ominaisuutta, jotka koostuvat seuraavista: Undergraduate Enrollment, Male/Female Ratio, Private/Public ja Region (Northeast, South, West ja Midwest). ",
      "id": "task461-cbb905e70dbc412aaa3d8d5291e25772",
      "output": [
        "Mitä suuria maantieteellisiä alueita tutkitaan?"
      ]
    },
    {
      "input": "Mallissamme käytetään hiljattain käyttöön otettua biaffiinista huomiota BIBREF14 parantamaan roolien pisteytystä. ",
      "id": "task461-ef842d40778a48159de2925f776f87dc",
      "output": [
        "Mikä on biaffinen maalintekijä?"
      ]
    },
    {
      "input": "Olemme käyttäneet kokeiluissamme 14 TD:n tietokokonaisuutta.",
      "id": "task461-54d505a4d26144b39069a26423c5b4d4",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": "Koska menetelmämme syötteenä on tekstimuotoinen tieto, noudatamme BIBREF15:n lähestymistapaa ja kuvaamme tekstin kiinteän kokoiseksi vektoriesitykseksi. Tätä varten käytämme sanojen upotuksia, joita on sovellettu menestyksekkäästi muilla aloilla. Noudatamme BIBREF5:tä ja käytämme valmiiksi koulutettuja GloVe-sanavektoreita BIBREF16 upotuskerroksen alustamiseen (tunnetaan myös nimellä look-up table). Jaksossa SECREF18 käsitellään upotuskerrosta yksityiskohtaisemmin.",
      "id": "task461-a7a4f7ca72714e0ea73e66228bff9a8f",
      "output": [
        "Mitä esivalmennettuja sanavektoreita he käyttivät?"
      ]
    },
    {
      "input": "Otamme käyttöön seuraavat kaksi tietokokonaisuutta: Quora BIBREF1: Quora Question Pairs -tietokanta sisältää kysymyspareja, jotka on merkitty merkinnöillä, jotka osoittavat, ovatko nämä kaksi kysymystä parafraaseja. Käytämme samaa tietokokonaisuuden osiota kuin BIBREF5:ssä, jossa on 384 348/10 000/10 000 paria harjoittelu-/kehitys- ja testijoukossa.MRPC BIBREF34: Microsoft Research Paraphrase Corpus koostuu lausepareista, jotka on kerätty online-uutisista. Jokainen pari on merkitty merkinnällä, joka osoittaa, ovatko kaksi lausetta semanttisesti samanarvoisia. Harjoitus-/testijoukossa on 4 076/1 725 paria.",
      "id": "task461-0d11ffbe0f8340a583ef8c4fc4634d50",
      "output": [
        "Mitkä ovat benhmark-tietoaineistot parafraasien tunnistamista varten?"
      ]
    },
    {
      "input": "Twiitit tunnukset 6, 8 ja 10 ovat joitakin näytteitä, jotka sisältävät loukkaavia sanoja ja solvauksia, jotka eivät kaikissa tapauksissa ole vihamielisiä tai loukkaavia ja joiden kirjoittajat käyttivät tällaista kieltä päivittäisessä viestinnässään. Kun otetaan huomioon nämä todisteet ja tarkastelemalla twiittien sisältöä, voimme nähdä twiittien ID:t 3, 4 ja 9 kohdalla, että BERT-pohjainen luokittimemme pystyy erottamaan twiitit, joissa ei ole vihamielistä eikä implisiittistä vihasisältöä.",
      "id": "task461-1ddc358894664ae68550f95296ed923d",
      "output": [
        "Mitä todisteita kirjoittajat esittävät siitä, että malli voi ottaa huomioon joitakin harhoja tietojen merkinnöissä ja keräämisessä?"
      ]
    },
    {
      "input": "Käytämme seuraavia kolmea arviointimittaria: Foneemivirheprosentti (PER) on ennustettujen foneemisekvenssien ja kultaisen standardin foneemisekvenssien välinen Levenshteinin etäisyys jaettuna kultaisen standardin foneemisekvenssien pituudella.Sanavirheprosentti (Word Error Rate, WER) on niiden sanojen prosenttiosuus, joissa ennustettu foneemisekvenssi ei täsmälleen vastaa kultaista standardia.Sanavirheprosentti 100 (Word Error Rate 100, WER 100) on niiden sanojen prosenttiosuus testijoukosta, joissa oikea arvaus ei ole järjestelmän sadan ensimmäisen arvausarvion joukossa.",
      "id": "task461-b857a1edda254f3aa41a466d79521487",
      "output": [
        "mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Päästä päähän -järjestelmässä (etuliite E2E) käytetään DNN-topologiaa, joka on kuvattu kuvassa KUVA8 . Esitämme tulokset kolmella eri kokokokoonpanolla (etuliitteet 700K, 318K ja 40K), joista kukin edustaa likimääräisten parametrien määrää, ja kahdella erityyppisellä harjoitusreseptillä (etuliitteet 1stage ja 2stage), jotka vastaavat vastaavasti end-to-end- ja encoder+decoder-järjestelmiä, kuten UID7:ssä on kuvattu.",
      "id": "task461-6dc5e548e77341f390b42ce44915f80e",
      "output": [
        "Kuinka monta parametria esitetyssä mallissa on?"
      ]
    },
    {
      "input": "KGR10, joka tunnetaan myös nimellä plWordNet Corpus 10.0 (PLWNC 10.0), on tulosta työstä, joka koskee verkkosivujen sisällön automaattiseen hankintaan ja uuttamiseen tarkoitettua työkaluketjua nimeltä CorpoGrabber BIBREF19 . Se on työkalupaketti, jonka avulla saadaan verkkosivuston olennaisin sisältö, mukaan lukien kaikki alasivustot (käyttäjän määrittelemään syvyyteen asti). Ehdotettua työkaluketjua voidaan käyttää suuren tekstidokumenttien web-korpuksen rakentamiseen. Se tarvitsee syötteenä luettelon juurisivustoista. CorpoGrabberin muodostavat työkalut on mukautettu puolankielelle, mutta useimmat osatehtävät ovat kielestä riippumattomia. Koko prosessi voidaan suorittaa rinnakkain yhdellä koneella, ja se sisältää seuraavat tehtävät: Kunkin syöttösivun URL-osoitteen HTML-alasivujen lataaminen HTTrackin avulla, pelkän tekstin poimiminen jokaiselta alasivulta poistamalla \"boilerplate\"-sisältö (kuten navigointilinkit, otsikot, alatunnisteet, mainokset HTML-sivuilta) BIBREF20 , pelkän tekstin deduplikointi BIBREF20 , huonolaatuisten asiakirjojen poistaminen käyttämällä Morphological Analysis Converter and Aggregatoria (MACA) BIBREF21 , asiakirjojen merkitseminen Wrocław CRF Taggerilla (WCRFT) BIBREF22 . Kaksi viimeistä vaihetta ovat käytettävissä vain puolan kielellä.",
      "id": "task461-e7030ad9a39b43aa9810dc5860d40155",
      "output": [
        "Miten KGR10-korpus luotiin?"
      ]
    },
    {
      "input": "BIBREF14 esittelee EMPATHETICDIALOGUES-tietokannan, joka on uusi tietokanta, joka sisältää 25 000 keskustelua ja sisältää emotionaalisia kontekstitietoja, jotka helpottavat tekstimuotoisen keskustelujärjestelmän harjoittelua ja arviointia. BIBREF2:n työ tuottaa tietokokonaisuuden, joka sisältää 1,5 miljoonaa Twitter-keskustelua, jotka on kerätty Twitter API:n avulla 62 tuotemerkin asiakaspalvelutililtä useilta eri toimialoilta. Tätä tietokokonaisuutta käytettiin sävytietoisen asiakaspalvelukeskustelurobotin rakentamiseen. Lopuksi BIBREF29 yritti parantaa SEMAINE-korpusta BIBREF30 käyttämällä crowdsourcing-skenaariota, jotta saataisiin inhimillistä arviota siitä, mikä vastaus herättää positiivisia tunteita. ",
      "id": "task461-dad4b694c9b44001b7df72f68ff67334",
      "output": [
        "Mitkä ovat tällä hetkellä saatavilla olevat EAC:n tietokokonaisuudet?"
      ]
    },
    {
      "input": "Ensin esivalmennamme generaattorimme Gutenbergin tietokokonaisuudella BIBREF24 20 epookin ajan ja sitten hienosäädämme BIBREF19 -tietokantoja kohdetietokantojamme varten kielen mallintamistavoitteella.",
      "id": "task461-f053090a895d41978d37fd19bb4da510",
      "output": [
        "Mitä tavoitefunktiota käytetään GAN:ssa?"
      ]
    },
    {
      "input": "Tässä työssä rakennamme uuden regressiomallin, joka perustuu kielellisiin, sisällöllisiin, käyttäytymiseen liittyviin ja aihepiirteisiin ja jonka avulla voimme havaita arabiankieliset Twitter-robotit ja ymmärtää niiden vaikutusta uskonnollisen vihan levittämiseen arabiankielisessä Twitter-avaruudessa. ",
      "id": "task461-bf81342858844ef991e4020b19133b82",
      "output": [
        "Ehdottavatko he uutta mallia, jolla voitaisiin havaita paremmin nimenomaan arabialaiset botit?"
      ]
    },
    {
      "input": "Tämän prosessin tuloksena saadaan yhteensä INLINEFORM0 10700 harjoitusesimerkkiä, joista noin 2000-3000 esimerkkiä luokkaa kohti, ja jokaisella puhujalla on keskimäärin 185 esimerkkiä.",
      "id": "task461-340c39ddbe5244e78cb28c548b3c10df",
      "output": [
        "Kuinka monta tapausta heidän tietokokonaisuudessaan on?"
      ]
    },
    {
      "input": "convertible.pl: DCG-sääntöjen toteuttaminen kolmivaiheisen muunnoksen 1. ja 3. vaihetta varten sekä muita sääntöjä, mukaan lukien sanasto.",
      "id": "task461-af8ade2ae8c441fc93d8c31e677219af",
      "output": [
        "Mitä DCG:tä käytetään?"
      ]
    },
    {
      "input": "Tuloksena syntynyt mallimme tuottaa huippuluokan tuloksia sekä VQA-tietokannassa että bAbI-10k-tekstikysymys-vastaus -tietokannassa, mikä osoittaa, että malli voidaan yleistää useilla eri aloilla.",
      "id": "task461-6c7ffa487eee473f9bcffe79d938ad01",
      "output": [
        "Toteutuuko DMN+-mallissa uusin tekniikka?"
      ]
    },
    {
      "input": "Järjestelmämme sijoittui kilpailussa toiseksi vain 0,3 BLEU-pistettä voittajatiimi UPC-TALP:n jälkeen. Kaikkien joukkueiden saamat suhteellisen alhaiset BLEU- ja korkeat TER-pisteet johtuvat kilpailussa annetuista toimialueen ulkopuolisista tiedoista, jotka tekivät tehtävästä yhtä haastavan kaikille osallistujille. Se, että järjestäjät tarjosivat toimialueen ulkopuolista dataa, johti haastavaan mutta mielenkiintoiseen skenaarioon kaikille osallistujille.",
      "id": "task461-6973c247bd23487a86a9e23794ca24f9",
      "output": [
        "Parantaako toimialueen ulkopuolisten tietojen käyttö menetelmän suorituskykyä?"
      ]
    },
    {
      "input": "Tässä artikkelissa esittelen tulkittavissa olevan sanojen upotusmallin ja siihen liittyvän aihepiirimallin, jotka on suunniteltu toimimaan hyvin, kun ne koulutetaan pienellä tai keskikokoisella kiinnostavalla korpuksella. Testasin representaatioiden suorituskykyä ominaisuuksina asiakirjojen luokittelu- ja regressiotehtävissä. Tulokset on esitetty taulukossa TABREF26 . Asiakirjojen luokittelussa käytin kolmea vakiomuotoista vertailuaineistoa: 20 uutisryhmää (19 997 uutisryhmän viestiä), Reuters-150-uutislehden artikkeleita (15 500 artikkelia ja 150 luokkaa) ja Ohsumed-tietokannan lääketieteellisiä tiivistelmiä 23 sydän- ja verisuonitaudista (20 000 artikkelia). I Analysoin myös regressiotehtävää, jossa ennustetaan unionin tilaa käsittelevän puheen vuosi sen tekstitietojen perusteella. ",
      "id": "task461-245ffde0f5c34a34b9f594e39dc4b956",
      "output": [
        "Millaisia valvottuja oppimistehtäviä näillä esityksillä yritetään suorittaa?"
      ]
    },
    {
      "input": "Arviointimittareina käytimme BLEU BIBREF8- ja RIBES BIBREF9 -mittareita käännöstarkkuuden mittaamiseen ja token-tason viivettä viiveen mittaamiseen. Japanin käännöstarkkuuden arvioinnissa käytimme Kytea BIBREF10 -menetelmää tokenize-menetelmänä.",
      "id": "task461-3fbf1edf5d684399a8645b3c8f85388c",
      "output": [
        "Mitä mittareita ne käyttävät simultaanikääntämisen arviointiin?"
      ]
    },
    {
      "input": "Vaikka lähestymistapamme on selvästi parempi kuin satunnaiset vertailut, suhteellisen alhaiset F1-pisteet osoittavat, että sen ennustaminen, mikä sana kaikui selityksissä, on hyvin haastava tehtävä. Tästä seuraa, että pystymme vain rajallisesti ymmärtämään, miten ihmiset valitsevat sanojen kaikuisuuden selityksissä. Se, missä määrin selitysten rakentaminen on pohjimmiltaan satunnaista BIBREF47 vai onko olemassa muita tunnistamattomia malleja, on tietenkin avoin kysymys. Toivomme, että tutkimuksemme ja julkaisemamme resurssit kannustavat jatkamaan työtä selitysten pragmatiikan ymmärtämiseksi.",
      "id": "task461-0bfb083985a741a68103d8b93f277638",
      "output": [
        "Antavatko kirjoittajat mitään selitystä kiehtoville sanojen kaikuille?"
      ]
    },
    {
      "input": "Yhdistetystä tulosjoukosta poimitaan yksilölliset käyttäjät ja twiitit, jolloin saadaan noin 60 000 yksilöllisen twiitin tietokokonaisuus, joka liittyy 51 104 yksilölliseen käyttäjään.",
      "id": "task461-6d041665cd58495fbbb207282aa8c406",
      "output": [
        "Kuinka monta seuraajaa he analysoivat?",
        "Kuinka monta twiittiä tässä paperissa tutkitaan?"
      ]
    },
    {
      "input": "Ehdotamme uutta valvomatonta mallia, Sent2Vec, universaalien lauseen upotusten oppimiseen. Muodollisesti opimme lähde- (tai konteksti-) upotuksen INLINEFORM0 ja kohde- upotuksen INLINEFORM1 jokaiselle sanaston sanalle INLINEFORM2, ja upotusulottuvuudet INLINEFORM3 ja INLINEFORM4 ovat samat kuin ( EQREF6 ). Lauseen upotus määritellään sen muodostavien sanojen lähdesanojen upotusten keskiarvona, kuten ( EQREF8 ). Täydennämme tätä mallia lisäksi oppimalla myös lähdesanojen upotukset kussakin lauseessa esiintyvien unigrammien lisäksi myös n-grammien osalta ja keskiarvoistamalla n-grammien upotukset yhdessä sanojen kanssa, eli lauseen INLINEFORM5:n upotus INLINEFORM6:lle mallinnetaan seuraavasti: DISPLAYFORM0",
      "id": "task461-749c226816004a26aafd58eb12024e9e",
      "output": [
        "Miten n-grammiominaisuuksissa otetaan huomioon kompositionaalisuus?"
      ]
    },
    {
      "input": "Siksi ehdotamme huomiomalleja, joiden avulla voidaan päätellä piilevä konteksti eli viestisarja, joka käynnistää intervention.",
      "id": "task461-c65d7f0f26b64c4dad6da4c77fe9d330",
      "output": [
        "Minkälaista latenttia kontekstia käytetään ohjaajan intervention ennustamiseen?"
      ]
    },
    {
      "input": "Arab-tweet. Iän ja sukupuolen mallintamiseen käytämme Arap-Tweet BIBREF19 , josta käytetään jatkossa nimitystä Arab-Tweet. UBC:n Twitterin sukupuolitietoaineisto. Kehitämme myös oman Twitter-tietokannan sukupuolta varten. Merkitsimme manuaalisesti 1 989 käyttäjää kustakin 21 arabimaasta. AraNetin murteiden tunnistamismalli perustuu MADARin jaetussa tehtävässä 2 BIBREF20 voittaneeseen järjestelmäämme, joka on kuvattu BIBREF12:ssa. Korpus on jaettu train-, dev- ja testikorpukseen, ja järjestäjät peittävät testisarjan merkinnät. Hyödynnämme kahta tietokokonaisuutta, BIBREF22:n LAMA-DINA-tietokokonaisuutta, Twitter-tietokokonaisuutta, jossa on yhdistelmä BIBREF23:n kultaisia merkintöjä ja etävalvonnan merkintöjä. Loput tietokokonaisuudesta on merkitty vain etänä valvottuna (LAMA-DIST) ($182 605$ twiittejä) . Lisätietoja tietokokonaisuudesta on BIBREF22:ssa.  Käytämme tietokokonaisuutta IDAT@FIRE2019 jaetun tehtävän BIBREF24 julkaisemien arabiankielisten twiittien ironian tunnistamiseen. Keräämme 15 arabian kielen sentimenttianalyysiin liittyvää tietokokonaisuutta, mukaan lukien MSA ja murteet BIBREF25, BIBREF26, BIBREF27, BIBREF1, BIBREF28, BIBREF29, BIBREF30, BIBREF31, BIBREF32, BIBREF33, BIBREF34. Taulukossa TABREF28 esitetään kaikki käyttämämme korporaatiot. ",
      "id": "task461-0296e959f7544a839cee4922a7cd5070",
      "output": [
        "Mitä tietokokonaisuuksia käytetään koulutuksessa?"
      ]
    },
    {
      "input": "Käytämme hienosäätöä varten esivalmennettua karsimatonta BERT$_\\mathrm {BASE}$-mallia, koska havaitsimme, että BERT$_\\mathrm {LARGE}$-malli suoriutuu tässä tehtävässä hieman huonommin kuin BERT$_\\mathrm {BASE}$. ",
      "id": "task461-bbe93b3f9ccd459f8e8cb548ae84690e",
      "output": [
        "Käytetäänkö suurta vai pientä BERT:iä?"
      ]
    },
    {
      "input": "DeepMine on julkisesti kaikkien saatavilla, ja eri käyttäjille on tarjolla erilaisia lisenssejä. Se kerättiin joukkoistamalla BIBREF4. Tiedonkeruu tehtiin Android-sovelluksella. Kukin vastaaja asensi sovelluksen henkilökohtaiseen laitteeseensa ja nauhoitti useita lauseita eri istunnoissa. ",
      "id": "task461-265e6a5ef09542b687ddfc5235505dc4",
      "output": [
        "miten puhe kerättiin?"
      ]
    },
    {
      "input": "TF-IDF: Tukivektorikone-luokittelija (SVM), logistinen regressioluokittelija (LR), Naive Bayes -luokittelija (NB) ja satunnaismetsä (RF); CNN: Käytimme TF-IDF-ominaisuuksia neljän luokittelijan syötteenä: LSTM: Sovelsimme LSTM-mallia BIBREF20 lauseiden luokitteluun valmiiksi koulutettujen sanojen upotusten avulla; LSTM-soft: Tämän jälkeen lisäsimme LSTM-mallin päälle pehmeän tarkkaavaisuuskerroksen BIBREF21 , jossa laskimme pehmeät kohdistamispisteet jokaiselle piilotetulle tilalle; LSTM-self: Sovelsimme LSTM-malliin BIBREF22-kerroksen. ",
      "id": "task461-11b25227a2294ea4b36d17736ea43536",
      "output": [
        "Mihin perusmalleihin ehdotettua mallia verrataan?"
      ]
    },
    {
      "input": "Davidson et al. BIBREF2 osoitti, että viidessä Twitterin vertailutietoaineistossa, jotka oli kommentoitu loukkaavan kielenkäytön havaitsemista varten, oli systemaattisia ja huomattavia rasistisia vääristymiä. Tarkastelemalla useampia näytteitä ja ottaen huomioon hiljattain tehdyt tutkimukset BIBREF2, BIBREF24 ja BIBREF19 on selvää, että monet virheet johtuvat tiedonkeruusta BIBREF19 ja annotaatiosäännöistä BIBREF24 johtuvista harhoista eivätkä itse luokittelijasta. ",
      "id": "task461-21a637bbd4734ba8bb85c0d28151abae",
      "output": [
        "Mitkä ovat olemassa olevat ennakkoluulot?"
      ]
    },
    {
      "input": "Käytämme ensin uusimpia PDTB-tunnisteiden merkitsimiä perustasoa BIBREF13 varten, BIBREF12:ta mallimme kausaalisuusennusteen arvioimiseksi (BIBREF12 vaatii syötteenä tekstistä poimittuja lauseita, joten käytimme jäsentäjäämme poimimaan lauseita viestistä).",
      "id": "task461-8d6b22c1aff849299e237a7635517151",
      "output": [
        "Mitä lähtökohtia he ottivat huomioon?"
      ]
    },
    {
      "input": "Havaitseminen: Hypernymian havaitsemisessa tehtävänä on luokitella, ovatko sanaparit hypernymiasuhteessa. Suunta: Suunnan ennustamisessa tehtävänä on tunnistaa, mikä termi on laajempi tietyssä sanaparissa. Graded Entailment: Graded entailment -toiminnossa tehtävänä on määrittää, missä määrin hypernyymisuhde on voimassa.",
      "id": "task461-380a617cf6fc4833aa3c0664092f799f",
      "output": [
        "Mitä hypernymian tehtäviä he tutkivat?"
      ]
    },
    {
      "input": "Näiden menetelmien mukaisesti arvioimme NCEL:ää seuraavilla viidellä tietokokonaisuudella: (1) CoNLL-YAGO BIBREF22 : CoNLL 2003:n jaettu tehtävä, joka sisältää 4791 mainintaa sisältävän testa-aineiston 216 asiakirjassa ja 4485 mainintaa sisältävän testb-aineiston 213 asiakirjassa. (2) TAC2010 BIBREF39 : muodostettu Text Analysis Conference -konferenssia varten ja sisältää 676 mainintaa 352 asiakirjassa testausta varten. (3) ACE2004 BIBREF23 : osajoukko ACE2004:n yhteisviiteasiakirjoja, joka sisältää 248 mainintaa 35 asiakirjassa ja joka on annotoitu Amazon Mechanical Turkilla. (4) AQUAINT BIBREF40 : 50 uutisartikkelia, joihin sisältyy 699 mainintaa kolmesta eri uutistoimistosta. (5) WW BIBREF19 : uusi vertailukohde, jossa mainintojen ennakkojakaumat ovat tasapainossa, mikä johtaa vaikeaan disambiguointitapaukseen. Siinä on 6374 mainintaa 310 asiakirjassa, jotka on poimittu automaattisesti Wikipediasta.",
      "id": "task461-f0442cb29f0b4582a220c643732f31b4",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": "Taulukon TABREF38 tulokset vahvistavat BIBREF13:n tulokset ja viittaavat siihen, että olemme onnistuneet toistamaan suuren osan niiden ominaisuuksista. Tulokset kaikille kolmelle ennusteasetukselle (yksi lähtevä reuna: INLINEFORM0 , tuki/hyökkäys: INLINEFORM1 ja tuki/hyökkäys/kumpikaan: INLINEFORM2 ) kaikkien tyyppimuuttujien ( INLINEFORM3 , INLINEFORM4 ja INLINEFORM5 ) osalta esitetään taulukossa TABREF39 . Kaikki mallit ylittävät merkittävästi enemmistön perusmallin makro F1:n osalta.",
      "id": "task461-6300b9b8baa348668d7a1c40935535b9",
      "output": [
        "Mitä perusviivoja ja luokittelujärjestelmiä kokeissa käytetään?"
      ]
    },
    {
      "input": "Tätä varten rakensimme uuden tietokokonaisuuden, jossa on 23 700 kyselyä, jotka ovat lyhyitä ja jäsentymättömiä ja jotka ovat samantyylisiä kuin tehtäväkeskeisten järjestelmien todellisten käyttäjien tekemät kyselyt. ",
      "id": "task461-11a490c52da9452e9683c23422ff67eb",
      "output": [
        "Mikä on tämän tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Näin ollen jatkuva relaksaatio top-k-argmax-operaatioon voidaan yksinkertaisesti toteuttaa käyttämällä iteratiivisesti max-operaatiota, joka on jatkuva ja mahdollistaa gradienttivirran takaisinkulkeutumisen aikana.",
      "id": "task461-8f6c80d863154543a808acef17aed8a0",
      "output": [
        "Mitä häviämismittareita he kokeilevat uudessa koulutusmenetelmässään, jota arvioidaan palkkihaun tuloksen perusteella?"
      ]
    },
    {
      "input": "Vaikka tässä korpuksessa on virheellisiä lauseita ja niiden tunnemerkintöjä, niistä puuttuvat vastaavat korjatut lauseet, joita tarvitaan mallimme harjoitteluun. Saadaksemme nämä puuttuvat tiedot, käytämme natiivien englanninkielisten puhujien apuna puolueetonta ja anonyymiä alustaa nimeltä Amazon Mechanical Turk (MTurk) BIBREF19, joka on maksullinen markkinapaikka ihmisälytehtäville (Human Intelligence Tasks, HIT). Käytämme tätä alustaa luodaksemme natiivien englanninkielisten puhujien tehtäviä alkuperäisten virheellisten twiittien muotoilemiseksi oikeiksi lauseiksi. Taulukossa TABREF12 on joitakin esimerkkejä. Mallien suorituskyvyn arvioinnissa käytetty tietokokonaisuus on Braun et al. BIBREF20 esittämä Chatbot Natural Language Unerstanding (NLU) Evaluation Corpus NLU-palvelujen testaamiseksi. Se on julkisesti saatavilla oleva vertailukohde, ja se koostuu lauseista, jotka on saatu saksalaisesta Telegram-keskustelurobotista, jota käytetään vastaamaan kysymyksiin julkisista liikenneyhteyksistä. Aineistossa on kaksi tarkoitusta, nimittäin lähtöaika ja yhteyden etsiminen, ja siinä on 100 harjoitus- ja 106 testinäytettä, jotka esitetään taulukossa TABREF18. Vaikka vertailukohteen pääkieli on englanti, tämä tietokokonaisuus sisältää muutamia saksankielisiä asemien ja katujen nimiä.",
      "id": "task461-ee4b48cb7aaa45f689f926fd445f3859",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "TOEFL-kuullunymmärtämiskoe on tarkoitettu englannin kielen oppijoille, joiden äidinkieli ei ole englanti. Tässä artikkelissa kerrotaan, miten nykypäivän kone pystyy suoriutumaan tällaisesta testistä.Tässä tarkasteltava kuullun ymmärtämistehtävä liittyy läheisesti Spoken Question Answering (SQA) BIBREF0 , BIBREF1 . ",
      "id": "task461-482a1231cf8348d493dc3a196fc401aa",
      "output": [
        "Mikä on tässä työssä ehdotettu uusi tehtävä?"
      ]
    },
    {
      "input": "Valitsimme lauseiden koodausmalleiksi yksinkertaisen yksikerroksisen kaksisuuntaisen LSTM:n, jossa on maksimipoolaus (BiLSTM-max) ja jonka piilokoko on 600D suuntaa kohti ja jota käytettiin esimerkiksi InferSent BIBREF17 ja HBMP BIBREF18 -malleissa. Muihin malleihin olemme valinneet ESIM BIBREF19 , joka sisältää lauseiden välisen huomion, ja KIM BIBREF2 , jossa on lauseiden välinen huomio ja jossa hyödynnetään ulkoista tietoa. Valitsimme myös kaksi mallia, joissa on mukana valmiiksi koulutettu kielimalli, nimittäin ESIM + ELMo BIBREF20 ja BERT BIBREF0 .",
      "id": "task461-6cc73bc628184096ad6127112a640fb4",
      "output": [
        "Mitä malleja vertailtiin?"
      ]
    },
    {
      "input": "Ennen kaikkea otamme käyttöön kaksi yhteistä peruslinjaa. Ensimmäisessä valitaan vain johtavat lauseet yhteenvedon muodostamiseksi. Sitä käytetään usein DUC:n virallisena perustasona, ja nimemme sen \"LEAD\". Toisen järjestelmän nimi on \"QUERY_SIM\", joka asettaa lauseet suoraan paremmuusjärjestykseen sen TF-IDF-kosiinimuunnoksen samankaltaisuuden mukaan. Ennen kaikkea esittelemme kaksi yleistä perusviivaa. Ensimmäisessä valitaan vain johtavat lauseet yhteenvedon muodostamiseksi. Sitä käytetään usein DUC:n virallisena perustasona, ja se on nimeltään \"LEAD\". Toisen järjestelmän nimi on \"QUERY_SIM\", joka asettaa lauseet suoraan paremmuusjärjestykseen sen mukaan, mikä on niiden TF-IDF-kosiinimuunnos samankaltaisuus kyselyn kanssa. Lisäksi toteutamme kaksi suosittua kyselyyn keskittyvää tiivistämismenetelmää, jotka ovat MultiMR BIBREF2 ja SVR BIBREF20 . Koska mallimme on täysin datalähtöinen, otamme käyttöön tuoreen tiivistämisjärjestelmän DocEmb BIBREF9 , joka myös käyttää vain syviä neuroverkko-ominaisuuksia lauseiden sijoittamiseen. Yhteisen mallin tehokkuuden todentamiseksi suunnittelemme ISOLATION-nimisen perustason, joka suorittaa erottelun ja merkityksellisyyden luokittelun erikseen.",
      "id": "task461-9326b749862e40f991d9525c3cebaacd",
      "output": [
        "Mihin malleihin niitä verrataan?"
      ]
    },
    {
      "input": "NMT-kokeessa käytimme Torch-toteutusta kouluttaaksemme 2-kerroksisen LSTM-mallin, jossa on 500 piilotettua yksikköä sekä koodaimessa että dekoodaimessa, 12 epookin aikana.",
      "id": "task461-94a6e2fb9d9e4736a9bf2000f38ab52e",
      "output": [
        "Mitä NMT-malleja he kokeilivat?"
      ]
    },
    {
      "input": "Käytämme tässä artikkelissa kahta eri upotusavaruutta. Ensimmäinen on laajalti käytetty esitys, joka perustuu GoogleNewsin BIBREF-tietokantaan8 . Toinen on otettu BIBREF2 -tietokannasta, ja se on koulutettu Reddit-tietokannalla BIBREF9 .",
      "id": "task461-fe6193dc84224719a651e6031e904805",
      "output": [
        "Missä sulautumissa ne havaitsevat vääristymiä?"
      ]
    },
    {
      "input": "LDA:n tuottamien aiheiden johdonmukaisuus on kuitenkin odotettua heikompi.Tämän johdonmukaisuuden puutteen korjaamiseksi käytimme ei-negatiivista matriisifaktorointia (NMF).",
      "id": "task461-895c403acd1544a58040fa3e3d862bb9",
      "output": [
        "Miten Dabiqissa ja Rumiyahissa tunnistetaan näkyvät aiheet?"
      ]
    },
    {
      "input": "Perustaso on hierarkkinen fraasipohjainen järjestelmä BIBREF29 , jossa on 4-grammainen kielimalli, jonka ominaisuuksien painotukset on viritetty MIRA BIBREF30 -ohjelmalla. Siksi sopiva ylimääräinen perustaso olisi merkitä käännössäännöt näillä indikaattorifunktioilla, mutta ilman pisteitä, mikä vastaa sellaisten sääntöjen tunnistamista, joissa on fraaseja (Baseline + SegOn).",
      "id": "task461-26a8720f4e5d41c4a1de4d91ce0dc3ad",
      "output": [
        "Mihin käännösjärjestelmiin niitä verrataan?"
      ]
    },
    {
      "input": "Järjestelmämme ovat huomiokooderi-dekooderiverkkoja BIBREF0 . Perustamme toteutuksemme dl4mt-oppaaseen, jota olemme parantaneet uusilla ominaisuuksilla, kuten ensemble-dekoodauksella ja läpäisevällä pudotuksella.",
      "id": "task461-74650e67c8a74efdbee14bbf2a18a70c",
      "output": [
        "Mitkä ovat perusjärjestelmät?"
      ]
    },
    {
      "input": "Käytämme BIBREF-tietokannassa46 esiteltyä valtavaa 45 000 masentuneesta käyttäjästä koostuvaa tietokantaa, jossa on 1500 masennukseen viittaavasta termistä koostuva masennusoireiden sanasto, joka luotiin psykologin avulla ja jota käytettiin masentuneiksi itsensä ilmoittaneiden henkilöiden profiilien keräämiseen. Kaksi ihmistuomaria tarkisti BIBREF46:ssa 8 770 käyttäjän (24 miljoonaa aikaleimattua twiittiä) osajoukon, joka sisälsi 3981 masentunutta ja 4789 vertailukäyttäjää (jotka eivät osoita masennusta).",
      "id": "task461-d5410dc68e3e4b24832beb77f39c4f64",
      "output": [
        "Miten tiedot on kommentoitu?"
      ]
    },
    {
      "input": "Arvioimme vastakohtaisesti koulutetut mallit, kuten taulukossa TABREF18 on esitetty.Vastakohtaisen koulutuksen jälkeen kaikkien kohdemallien suorituskyky paranee merkittävästi, kun taas alkuperäisten esimerkkien suorituskyky pysyy vertailukelpoisena.",
      "id": "task461-d852f1529be24f6591d6a0aaffbf03f3",
      "output": [
        "Kuinka paljon suorituskyky paranee kokeissa, kun mallit koulutetaan luotujen vastakkaisten esimerkkien avulla?"
      ]
    },
    {
      "input": "$Coherence@k$:n on osoitettu korreloivan hyvin eri aihepiirien mallinnusmenetelmillä opittujen aiheiden inhimillisen tulkinnanvaraisuuden kanssa BIBREF7 . Näin ollen voimme odottaa tulkinnanvaraisia upotuksia maksimoimalla sen. Tulkittavuuden arvioimiseksi käytämme $Coherence@k$ (yhtälö 6 ) , automatisoituja ja manuaalisia sanojen tunkeutumistestejä.",
      "id": "task461-f0cbc70b3d6a4aada7165279a716a6be",
      "output": [
        "Miten ne arvioivat tulkittavuutta?"
      ]
    },
    {
      "input": "Esimerkiksi viestiä voidaan pitää sellaisenaan harmittomana, mutta kun otetaan huomioon aiemmat viestiketjut, sitä voidaan pitää loukkaavana ja päinvastoin. Tämä tekee loukkaavan kielenkäytön havaitsemisesta erittäin työlästä jopa ihmisannotoijille, minkä vuoksi on vaikea rakentaa suurta ja luotettavaa tietokokonaisuutta BIBREF10 .",
      "id": "task461-21c32996d22e4650a69f45b00ad064da",
      "output": [
        "Millaisia esimerkkejä kirjoittajat antavat verkkoväkivallan kontekstiriippuvaisen luonteen aiheuttamista vaikeuksista?"
      ]
    },
    {
      "input": "Alan ehkä yllättävin tulos on kuitenkin Zipfin laki, jonka mukaan jos sanat asetetaan järjestykseen niiden esiintymistiheyden mukaan laajassa tekstissä, saadaan noin potenssilakiin perustuva jakauma kaikille kielille BIBREF0, BIBREF11. Toinen mielenkiintoinen tekstien luonnehdinta on Heaps-Herdanin laki, joka kuvaa sitä, miten sanavarasto eli erilaisten sanojen joukko kasvaa tekstin koon myötä, ja jonka määrän on empiirisesti havaittu kasvavan tekstin koon potenssina BIBREF18, BIBREF19. On syytä huomata, että on väitetty, että tämä laki on seurausta Zipfin laista. BIBREF20, BIBREF21",
      "id": "task461-db38b38c87cb4b86819df4aaeea58350",
      "output": [
        "Miten Zipfin ja Herdan-Heapin lait eroavat toisistaan?"
      ]
    },
    {
      "input": "Kuvaamme WikiSQL:ää koskevat sääntömme tässä. Sääntömme KBQA:ta varten on yksinkertainen ilman kuratoitua kartoitussanakirjaa. SequentialQA:n sääntöputki on samanlainen kuin WikiSQL:ssä.",
      "id": "task461-79b5eaf9c1eb44f5bf137f6c85583298",
      "output": [
        "Ovatko säännöt tietokokonaisuuskohtaisia?"
      ]
    },
    {
      "input": "Vertailua varten luomme kaksi perusjärjestelmää kumpaankin suuntaan: toisessa käytetään perinteistä fraasipohjaista tilastollista konekääntämistä (SMT) ja toisessa NMT-järjestelmää. ",
      "id": "task461-3262c06c9abc40db84d662b3404a8630",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Koulutustietokannassa on 1018 väärennettyä uutista, joissa on kaksoiskappale, kun taas koulutuksessa on 322 aitoa sisältöä sisältävää artikkelia, joissa on kaksoiskappale.",
      "id": "task461-55c199650fbb4e3d841e643085259ab2",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": " Kehittämisprosessissa kehitettiin annotaatio-ohjeita ja koulutettiin annotaattoreita, jotka eivät olleet tietoturva-asiantuntijoita. Darkoden ja Hack Forumsin kehitys- ja testisarjat kommentoitiin muiden tiimin jäsenten toimesta (viisi Darkoden ja yksi Hack Forumsin osalta), minkä jälkeen kaikista erimielisyyksistä keskusteltiin ja ne ratkaistiin lopullisen annotaation laatimiseksi. Kirjoittajat, jotka ovat joko NLP:n tai tietoturvan tutkijoita, tekivät kaikki annotaatiot.",
      "id": "task461-c8517033674e45779623c784bb86f574",
      "output": [
        "Kuka kommentoi tietoja?"
      ]
    },
    {
      "input": "Kuten kuviossa KUVIO 1 havainnollistetaan, keskeinen ajatuksemme on, että voimme hyödyntää diskurssisuhteita BIBREF4 levittääksemme polariteettia tehokkaasti siemenpredikaateista, jotka ilmoittavat suoraan henkilön tunteista (esim. \"olla iloinen\" on positiivinen). Oletetaan, että tapahtumat $x_1$ ja $x_2$ ovat diskurssirelaatiossa Cause (eli $x_1$ aiheuttaa $x_2$). Jos siemenleksikon mukaan $x_2$ on positiivinen, myös $x_1$ on todennäköisesti positiivinen, koska se laukaisee positiivisen tunteen. Se, että $x_2$:n tiedetään olevan negatiivinen, viittaa $x_1$:n negatiiviseen napaisuuteen. Vastaavasti, jos $x_1$ ja $x_2$ ovat myönnytysdiskurssisuhteessa (eli $x_2$ on $x_1$:sta huolimatta), $x_2$:n polariteetin käänteisyys voi levitä $x_1$:een. Vaikka $x_2$:n polariteettia ei tiedettäisikään etukäteen, voimme käyttää hyväksi sitä, että $x_1$ ja $x_2$ ovat joko samapolarisia (syy) tai käänteispolarisia (myönnytys), vaikka heuristiikka ei olekaan vapaa vastakohdista. Muunnamme tämän ajatuksen objektiivisiksi funktioiksi ja koulutamme neuroverkkomalleja, jotka ennustavat tietyn tapahtuman polariteetin.",
      "id": "task461-5a9562d5e16b4d3b81d747626a651511",
      "output": [
        "Miten suhteita käytetään polariteetin levittämiseen?"
      ]
    },
    {
      "input": "Ehdotettu multimodaalinen differentiaaliverkko (MDN) koostuu esitysmoduulista ja yhteisestä sekoitusmoduulista. Esitysmoduulissa käytetään triplettiverkkoa BIBREF41 , BIBREF42 . Triplettiverkko koostuu kolmesta osa-alueesta: kohde-, tuki- ja kontrastiverkko. Kaikilla kolmella verkolla on samat parametrit. Mixture-moduuli tuo kuvan ja kuvatekstin upotukset yhteiseen ominaisuuksien upotusavaruuteen.",
      "id": "task461-8818e20fe3b84a8aa0e74f8e811d826d",
      "output": [
        "Miten kirjoittajat määrittelevät differentiaalisen verkon?"
      ]
    },
    {
      "input": "Tietokanta (joka koostuu 2,6 gigatavusta raakatekstiä) sisältää 421\\ 829\\ 960$ sanaa, jotka on jaettu 17\\ 305\\ 401$ lauseeseen.",
      "id": "task461-7fc7e9a4d0d9454094b73bc9fab18e2d",
      "output": [
        "Kuinka suuri on aineisto, jota käytetään italian kielen Word2Vec-koulutukseen?"
      ]
    },
    {
      "input": "SVMRank on SVM:n muunnos, jossa jokaiselle datapisteelle annetaan pisteet ja tulokset voidaan asettaa paremmuusjärjestykseen ( BIBREF26 ). Käytämme SVMRankia seuraavissa kokeissa. ",
      "id": "task461-6d1b4d7a917b431bbcb47254a48bc4a0",
      "output": [
        "mikä on heidän kehittämänsä valvottu malli?"
      ]
    },
    {
      "input": "Rokotuksiin suhtautuminen luokiteltiin seuraavasti: \"kielteinen\", \"neutraali\", \"myönteinen\" ja \"ei selvä\".",
      "id": "task461-48a84e82335d4f088fcc327c741ac54e",
      "output": [
        "Sallivatko ne sen, että rokotuksiin liittyviä avainsanoja sisältävät viestit ovat neutraaleja?"
      ]
    },
    {
      "input": "Morfologisen analyysin tieto-ohjatut mallit rakennetaan käyttäen INLINEFORM0-koulutusdataa, joka koostuu INLINEFORM1-koulutusesimerkeistä. Vertailemamme perusmalli BIBREF5 pitää mallin lähtöavaruutta osajoukkona INLINEFORM2, jossa INLINEFORM3 on kaikkien tässä harjoitusaineistossa nähtyjen tunnistejoukkojen joukko. Tarkemmin sanottuna ne ratkaisevat tehtävän moniluokkaisena luokitusongelmana, jossa luokat ovat yksittäisiä tunnistejoukkoja. Vähäisten resurssien skenaarioissa tämä osoittaa, että INLINEFORM4 ja jopa niiden INLINEFORM5:ssä esiintyvien tagijoukkojen osalta olemme saattaneet nähdä hyvin vähän harjoitusesimerkkejä. Tunnistejoukkojen sekvenssin ehdollinen todennäköisyys lauseen perusteella muotoillaan 0. kertaluvun CRF:nä. DISPLAYFORM0",
      "id": "task461-f853d5467dc342049e0f46efa597a021",
      "output": [
        "Mihin muihin monikielisiin lähestymistapoihin mallia verrataan?"
      ]
    },
    {
      "input": "Kytean käytön jälkeen japaninkielisiin teksteihin sovelletaan LSW-algoritmia OOV-sanojen korvaamiseksi niiden synonyymeillä. ",
      "id": "task461-87e0219f23304c6cbc7d6a7b49aa9ccc",
      "output": [
        "Otetaanko japanilais-vietnamilaisessa tehtävässä huomioon synonyymiset suhteet?"
      ]
    },
    {
      "input": "Mallin syötteenä on sanan upotuksen ja toisen upotuksen yhdistelmä, joka osoittaa, onko tämä sana predikaatti: $ \\mathbf {x}_t = [\\mathbf {W}_{\\text{emb}}(w_t), \\mathbf {W}_{\\text{mask}}(w_t = v)]. $",
      "id": "task461-2f9f070f98f14c3799b968b98695be88",
      "output": [
        "Mikä on OpenIE-tuplien syöttöesitys malliin?"
      ]
    },
    {
      "input": "Tässä artikkelissa käsittelemme affektiivisen tapahtuman polariteetin tunnistamista, jota edustaa pistemäärä, joka vaihtelee arvosta $-1$ (negatiivinen) arvoon 1 (positiivinen).",
      "id": "task461-12f6aef80ef84f8c93731940ae7ae7cb",
      "output": [
        "Mitä merkintöjä on saatavilla tietokannassa valvontaa varten?"
      ]
    },
    {
      "input": " GlossBERT-ohjelmassa GlossBERT-ohjelmalla voidaan hyödyntää glossitietoa täysimääräisesti ja muodostaa konteksti-glossi-parit kaikista WordNetin mahdollisista kohdesanan merkityksistä, jolloin WSD-tehtävää voidaan käsitellä lauseparien luokittelun ongelmana.",
      "id": "task461-6f45b72ed6764c10acc33ff4d26660e9",
      "output": [
        "Sisällytetäänkö WordNet malliin?"
      ]
    },
    {
      "input": "Tällöin dekoodausfunktio on lineaarinen projektio, joka on $= f_{\\text{de}}()=+ $ , jossa $\\in ^{d_\\times d_}$ on koulutettava painomatriisi ja $\\in ^{d_\\times 1}$ on harhautustermi. NICE BIBREF -ohjelmassa17 suunniteltiin bijektiivisten muunnosten perhe, ja yksinkertaisin jatkuva bijektiivinen funktio $f:^D\\rightarrow ^D$ ja sen käänteisfunktio $f^{-1}$ määritellään seuraavasti:$$h: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2+m(_1) \\luku \\\\\\ h^{-1}: \\hpace{14.22636pt} _1 &= _1, & _2 &= _2-m(_1) \\nonumber $$ (Yht. 15)missä $_1$ on $d$ -ulotteinen osio syötteestä $\\in ^D$ ja $m:^d\\rightarrow ^{D-d}$ on mielivaltainen jatkuva funktio, joka voi olla koulutettava monikerroksinen feedforward-neuraaliverkko, jossa on epälineaarisia aktivointifunktioita. Sitä kutsutaan `additiiviseksi kytkentäkerrokseksi' BIBREF17 , jolla on yksikkö-Jacobin determinantti. Jotta oppimisjärjestelmä voisi tutkia tehokkaampia muunnoksia, noudatamme `affiinisen kytkentäkerroksen' BIBREF24 :$$h: \\hspace{5.69046pt} _1 &= _1, & _2 &= _2 \\odot \\text{exp}(s(_1)) + t(_1) \\nonumber \\\\\\ h^{-1}: \\hspace{5.69046pt} _1 &= _1, & _2 &= (_2-t(_1)) \\odot \\text{exp}(-s(_1)) \\nonumber $$ (Yht. 16)missä $s:^d\\rightarrow ^{D-d}$ ja $t:^d\\rightarrow ^{D-d}}$ ovat molemmat neuroverkkoja, joilla on lineaariset ulostuloyksiköt.Jatkuvan bijektiivisen muunnoksen vaatimuksena on, että syötteen $$ ja ulostulon $$ dimensioiden on täsmälleen vastattava toisiaan.",
      "id": "task461-450337e2534c4c5bb8712344e6d83f82",
      "output": [
        "Mitkä ovat nämä kaksi dekoodaustoimintoa?"
      ]
    },
    {
      "input": "Havaitsemme mielenkiintoisia piilokorrelaatioita tiedoissa. Kuvassa FIGREF24 on valittu aihe 2. Aihealue 2 sisältää neljä eniten esiintyvää avainsanaa: \"vegaani\", \"jooga\", \"työ\", \"every_woman\", joilla on suurin termifrekvenssi. Aiheesta voidaan päätellä erilaisia asioita, kuten \"naiset harrastavat yleensä joogaa enemmän kuin miehet\", \"naiset opettavat joogaa ja pitävät sitä työnä\", \"joogi noudattaa vegaanista ruokavaliota\". Sanoisimme, että tiedoissa on havaittavissa korrelaatioita, eli `jooga-veganismi', `naiset-jooga'. Naiset-jooga",
      "id": "task461-0aeb6dd670784a85b9a17a592f6fe210",
      "output": [
        "Mitä muita mielenkiintoisia korrelaatioita on havaittu?"
      ]
    },
    {
      "input": "Korpus sisältää 2000 lausetta. ",
      "id": "task461-b606fa5378a74dff92ee53c1f2818e89",
      "output": [
        "Kuinka pitkä tietokokonaisuus on?"
      ]
    },
    {
      "input": "Suorituskyvyn heikkenemisen syyn ymmärtämiseksi on ensin ymmärrettävä, miten yhteistyöelimen on käsiteltävä syötettyjä tekstitietoja. Yhteistyöelin käyttää WordPiece-tokenisaattoria tekstin tokenisointiin. WordPiece-tokenizer-lausekkeet perustuvat pisimmän etuliitteen vastaavuusalgoritmiin, jolla luodaan merkkejä . Näin saadut merkit syötetään BERT-mallin syötteeksi. WordPiece tokenizer käyttäytyy erittäin mielenkiintoisesti, kun kyseessä on meluisan datan merkitseminen. Kirjoitusvirheiden vuoksi näitä sanoja ei löydy suoraan BERTin sanakirjasta. Näin ollen WordPiece-tokenizer jakaa meluiset sanat alasanoiksi. Se päätyy kuitenkin hajottamaan ne osasanoiksi, joiden merkitys voi poiketa hyvin paljon alkuperäisen sanan merkityksestä. Usein tämä muuttaa lauseen merkityksen kokonaan, mikä johtaa huomattavaan suorituskyvyn heikkenemiseen.",
      "id": "task461-d857b12d87fb40038c0c108c05224b83",
      "output": [
        "Mikä on syy suorituskyvyn heikkenemiseen, kun käytetään BERT:iä joissakin suosituissa tehtävissä?"
      ]
    },
    {
      "input": "Samalla arkkitehtuurilla RCRN:n suorituskyky on parempi kuin ablatiivisten perusratkaisujen BiLSTM by INLINEFORM2 ja 3L-BiLSTM by INLINEFORM3 keskimäärin 16 tietokokonaisuudessa.",
      "id": "task461-ab31ab271f4f46b0a80849a41751ade0",
      "output": [
        "Kuinka paljon paremmat ne ovat kuin BiLSTM:t tunneanalyysissä?"
      ]
    },
    {
      "input": "Varmistaaksemme, että menetelmämme (eli monilinjainen huomio) korvaa Transformerissa monipäähuomion, suoritamme kaksi NLP-tehtävää, jotka ovat kielten mallintaminen (LM) ja neuraalinen konekääntäminen (NMT). Sen jälkeen testaamme eri mallikonfiguraatioita PTB BIBREF25 , WikiText-103 BIBREF26 ja One-Billion Word benchmark BIBREF27 -tietokannoissa ja raportoimme tulokset taulukoissa 1 ja 2. Tässä tehtävässä olemme kouluttaneet Transformer-mallin BIBREF2 WMT 2016 English-German datasetillä BIBREF36 .",
      "id": "task461-215aa5019a294c3dbe7b2f790cc9a327",
      "output": [
        "Millaisilla tietokokonaisuuksilla tai tehtävillä he tekevät kokeita?"
      ]
    },
    {
      "input": "Käytämme Dialogue State Tracking Competition 2 (DSTC2) -tietokokonaisuutta BIBREF27 , joka on laajimmin käytetty tietokokonaisuus tehtäväkeskeisten chatbottien tutkimuksessa.  Käytimme myös kahta muuta Google Research BIBREF28 -tietokokonaisuutta, jotka Google Research on hiljattain avannut. Nämä ovat M2M-sim-M (elokuva-alan tietokokonaisuus) ja M2M-sim-R (ravintola-alan tietokokonaisuus). ",
      "id": "task461-06d2a375e6334718bc47f9b2ba443876",
      "output": [
        "Mitä kolmea tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Ensimmäisessä skenaariossa dekooderi varustetaan ylimääräisellä morfologiataulukolla, joka sisältää kohdepuolen affiksit. Asetamme taulukon päälle huomiomoduulin, jota dekooderi ohjaa. Kun dekooderi ottaa näytteen merkistä, se etsii jokaisessa vaiheessa taulukosta olennaisimmat tiedot, jotka voivat rikastuttaa sen tilaa. Taulukosta lähetettyjä signaaleja voidaan tulkita lisärajoituksina. Toisessa skenaariossa dekooderi jaetaan kahden lähtökanavan kesken. Ensimmäinen ottaa näytteen kohdemerkistä ja toinen ennustaa merkin morfologisen merkinnän. Tämä monitehtäväinen lähestymistapa pakottaa dekooderin lähettämään morfologiatietoista tietoa viimeiselle kerrokselle, mikä johtaa parempiin ennusteisiin. Kolmannessa skenaariossa yhdistämme nämä kaksi mallia. ",
      "id": "task461-b2e8774b6f2c4ee1a82af2de4a1e16d7",
      "output": [
        "Miten morfologiataulukon apusignaalit sisällytetään dekooderiin?"
      ]
    },
    {
      "input": "Viimeisenä mutta ei vähäisimpänä eettisyys ja oikeudenmukaisuus ovat tärkeitä näkökohtia, joita on syytä tutkia. Tässä mielessä yksilöllisten ja yleisten vääristymien havaitseminen olisi asetettava etusijalle, jotta käytännön toimijoille voidaan antaa hyödyllistä palautetta. Lisäksi harkitsemme vastakkaisoppimisen käyttöä, kuten BIBREF:ssä33 , jotta voidaan varmistaa oikeudenmukaisuus koulutusprosessin aikana.",
      "id": "task461-fe94d260f0be489693bf6d993b44cf97",
      "output": [
        "Onko tutkimuksessa otettu huomioon eettisiä näkökohtia?",
        "Analysoidaanko he, onko heidän järjestelmässään minkäänlaista puolueellisuutta?"
      ]
    },
    {
      "input": "Mallien kouluttamiseen on käytetty kolmea eri tietokokonaisuutta: Toronton kirjakorpusta, Wikipedian lauseita ja twiittejä.  Sent2Vec-mallimme ovat myös keskimäärin parempia tai samantasoisia kuin C-PHRASE-malli, vaikka ne jäävätkin huomattavasti jälkeen STS 2014 WordNet- ja News-osatehtävissä. Tämä havainto johtuu siitä, että suuri osa C-PHRASE-mallin koulutettavasta datasta on peräisin englanninkielisestä Wikipediasta, mikä auttaa sitä suoriutumaan hyvin määritelmiä ja uutisia sisältävissä aineistoissa. ",
      "id": "task461-59e54b89812840868614935a7804b769",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Osoitimme BIBREF22:ssa, että Pearsonin korrelaatio soveltuu huonosti STS:ään. Sen sijaan laskemme Spearmanin korrelaation lauseiden upotusten ja kultaisten etikettien kosinus-similaarisuuden välillä.",
      "id": "task461-9845d136a32f4836a1d82ff359bd5456",
      "output": [
        "Mitä mittareita käytetään STS-tehtävissä?"
      ]
    },
    {
      "input": "Arvioimme hiljattain ehdottamiamme malleja ja niihin liittyviä perusmalleja useissa eri kielten vähäresurssiympäristöissä todellisilla, etäisesti valvotuilla aineistoilla, joissa ei ole synteettistä kohinaa. Meluisten merkintöjen edistynyt mallintaminen parantaa suorituskykyä huomattavasti, jopa 36 prosenttia verrattuna menetelmiin, joissa ei käsitellä kohinaa, ja jopa 9 prosenttia verrattuna kaikkiin muihin kohinan käsittelyä käyttäviin perusmenetelmiin.",
      "id": "task461-a7425cedbb95463aac0a57457f4e00d8",
      "output": [
        "Arvioivatko he lähtötasoa vasten?"
      ]
    },
    {
      "input": "Etusijalle asetetaan merkinnät, jotka ovat täydellisesti yhteensopivia kaikkien neuraalisten annotaattoreiden kanssa. Taulukosta TABREF11 nähdään, että molemmissa tietokokonaisuuksissa on noin 40 prosenttia täsmälleen yhteensopivia merkintöjä kaikissa malleissa (AM). Tämän jälkeen etusijalle asetetaan kontekstipohjaiset mallit, jotta voidaan tarkistaa, täsmäävätkö merkinnät täydellisesti kaikissa kontekstimalleissa. Jos kaksi kolmesta kontekstimallista on oikein, tarkistetaan, onko kyseinen etiketti tuotettu myös vähintään yhdellä kontekstittomalla mallilla. Sitten sallitaan, että etiketit luottavat näihin vähintään kahteen kontekstimalliin. Tämän tuloksena noin 47 prosenttia etiketeistä otetaan kontekstimallien (CM) perusteella. Kun huomaamme, että mikään kontekstimalli ei tuota samoja tuloksia, asetamme etiketit paremmuusjärjestykseen niiden luottamusarvojen avulla, jotka on tuotettu todennäköisyysjakaumana käyttäen $softmax$-funktiota. Merkinnät lajitellaan luottamusarvojen mukaan laskevaan järjestykseen. Tämän jälkeen tarkistetaan, että kolme ensimmäistä (kun yksi kontekstimalli ja molemmat muut kuin kontekstimallit tuottavat saman merkinnän) tai vähintään kaksi merkintää vastaavat toisiaan, ja valitaan kyseinen merkintä. IEMOCAP:ssa niitä on noin 3 % ja MELD:ssä (BM) 5 %. Jos mikään edellä mainituista ehdoista ei täyty, jätetään tuntemattoman kategorian sisältävä etiketti pois. Lopullisissa merkinnöissä tämä tuntematon kategoria merkitään merkinnällä `xx', ja niitä on noin 7 % IEMOCAPissa ja 11 % MELDissä (NM).",
      "id": "task461-aa047e8a03b548d8a0e53db012e4f226",
      "output": [
        "Miten ensemble-merkitsijä poimii lopullisen merkinnän?"
      ]
    },
    {
      "input": "Kaivannaisteollisuuden rakentaminen CNN/Daily Mail",
      "id": "task461-7c7fadbbedeb4079827bc1a79af5c574",
      "output": [
        "Mikä on nykyisten mittareiden ongelma, johon he yrittävät puuttua?"
      ]
    },
    {
      "input": "Viime aikoina SMT-järjestelmiin on sisällytetty sanojen ja lausekkeiden jatkuvatoimisia avaruusesityksiä neuroverkkojen avulla. Yksikielisten neuroverkkojen kielimallien BIBREF13 , BIBREF14 , neuroverkkojen yhteismallien (neural network joint models, NNJM) BIBREF4 ja neuroverkkojen globaalien leksikonimallien (neural network global lexicon models, NNGLM) BIBREF3 lisääminen on osoittautunut käyttökelpoiseksi SMT:ssä Kielioppivirheiden korjaus (GEC) on haastava tehtävä virheiden tyypin vaihtelevuuden ja virheiden syntaktisten ja semanttisten riippuvuuksien vuoksi. Useimmissa kielioppivirheiden korjausjärjestelmissä käytetään luokittelua ja sääntöpohjaisia lähestymistapoja tiettyjen virhetyyppien korjaamiseen. Nämä järjestelmät käyttävät kuitenkin useita kielellisiä vihjeitä ominaisuuksina. Tavanomaiset kielianalyysityökalut, kuten POS-taggerit (part-of-speech) ja jäsentimet, on usein koulutettu hyvin muodostetulle tekstille, ja ne toimivat huonosti epäkieliopillisessa tekstissä. Tämä aiheuttaa lisää virheitä ja rajoittaa sääntöpohjaisten ja luokitteluun perustuvien lähestymistapojen suorituskykyä GEC:ssä. Tämän seurauksena lausepohjainen tilastollinen konekääntäminen (SMT) on saavuttanut suosiota, koska se pystyy oppimaan tekstin muunnoksia virheellisestä tekstistä oikeaksi tekstiksi virheiden korjaamista rinnakkaisista korpuksista ilman kielellistä lisätietoa.  Teemme kokeita sisällyttämällä NNGLM:n ja NNJM:n sekä itsenäisesti että yhdessä perusjärjestelmään Edellä kuvatun perusjärjestelmän lisäksi sisällytämme ominaisuuksina kaksi neuroverkkokomponenttia, neuroverkon globaalin leksikonin mallin (NNGLM) ja neuroverkon yhteisen mallin (NNJM). Sekä NNGLM että NNJM koulutetaan käyttämällä perusjärjestelmämme käännösmallin kouluttamiseen käytettyä rinnakkaista dataa.",
      "id": "task461-90eabf28a3894ce1923c98e719ddca5e",
      "output": [
        "Miten ne yhdistävät kaksi ehdotettua neuroverkkomallia?"
      ]
    },
    {
      "input": "Havaitsemme, että yhteisöissä, joille on ominaista erikoistunut, jatkuvasti päivittyvä sisältö, on korkeampi käyttäjien pysyvyysaste, mutta niissä on myös suurempia kielellisiä eroja, jotka erottavat uudet tulokkaat vakiintuneista jäsenistä. Kun tarkastellaan tarkemmin tekijöitä, jotka voivat vaikuttaa tähän kielelliseen eroon, havaitaan, että erityisesti omaleimaisissa yhteisöissä vakiintuneilla käyttäjillä on suurempi taipumus sitoutua yhteisön erikoissisältöön kuin uusilla tulokkailla (SECREF5 ). ",
      "id": "task461-93f057e249a946e092f928c0131d99b5",
      "output": [
        "Millaisia malleja he havaitsevat siitä, miten käyttäjien sitoutuminen vaihtelee yhteisön ominaisuuksien mukaan?"
      ]
    },
    {
      "input": "Koulutamme kolme järjestelmää (S1, S2 ja S3) taulukossa TABREF5 esitetyillä korpuksilla. Kaksi ensimmäistä järjestelmää ovat muunnosmalleja, jotka on koulutettu erilaisilla tietomäärillä (6M vs. 18M rinnakkaista lausetta, kuten taulukosta näkyy). Kolmas järjestelmä sisältää muutoksen, jossa otetaan huomioon koko asiakirjan täydelliset ydinviittausketjut ja täydennetään käännettävää lausetta tällä tiedolla, ja se on koulutettu samalla määrällä lausepareja kuin S1.",
      "id": "task461-130e8e1c8e284519851a091fe1760e84",
      "output": [
        "Mitkä kolme neuraalista konekäännösjärjestelmää analysoidaan?"
      ]
    },
    {
      "input": "Jotkin kirjoittajat käyttävät esivalmisteltuja upotuksia (erityisesti silloin, kun heidän aineistokokonaisuutensa on liian pieni omien upotusten kouluttamiseen) tai yrittävät muuttaa näitä upotuksia ja mukauttaa ne omaan aineistokokonaisuuteensa. Näiden lähestymistapojen suurin haittapuoli on kuitenkin se, että upotusten kouluttamiseen käytettävä korpus ei välttämättä liity tiettyyn tehtävään, jossa upotuksia käytetään. Monet lääketieteelliset käsitteet eivät sisälly tunnettuihin sulautumispohjiin. Lisäksi sanojen samankaltaisuus voi vaihdella eri yhteyksissä. Tämän jälkeen lasketaan käsitteiden upotukset (GloVe-menetelmällä) erikseen haastattelukuvauksille ja tutkimuskuvauksille.",
      "id": "task461-bbd294e5f7ee42baadea25244154b906",
      "output": [
        "Hienosäätävätkö he lääketieteellisissä teksteissään käyttämiään sanojen upotuksia?"
      ]
    },
    {
      "input": "Meidän määritelmämme puolueellisuudesta on nyt: [Tulkintaharha episteemisessä ME-pelissä on todennäköisyysjakauma tyyppeihin, jonka keskustelijoiden tai pelaajien tai tuomariston uskomusfunktio antaa. Huomaa, että ME-pelissä on tyypillisesti useita tulkinnallisia ennakkoluuloja: jokaisella pelaajalla on oma ennakkoluulonsa, samoin kuin tuomaristolla.",
      "id": "task461-c5de128213bc41559c0e3d2df0dfb3c8",
      "output": [
        "Mitä tulkinnallisia ennakkoluuloja tässä asiakirjassa analysoidaan?"
      ]
    },
    {
      "input": "DDI-korpus sisältää tuhansia XML-tiedostoja, joista jokainen koostuu useista tietueista. Lauseessa, joka sisältää INLINEFORM0-lääkkeitä, on INLINEFORM1-lääkepareja.",
      "id": "task461-8d32a5ca0a7e4e09975dae76d705ecf1",
      "output": [
        "Kuinka suuri on arvioitava tietokokonaisuus?"
      ]
    },
    {
      "input": "Koska poimimme vain viittaukset muihin oikeuden päätöksiin, saimme 471 319 viittausta korkeimman oikeuden päätöksistä, 167 237 viittausta korkeimman hallinto-oikeuden päätöksistä ja 264 463 viittausta perustuslakituomioistuimen päätöksistä. Nämä ovat niiden tekstikatkelmien lukumäärät, jotka tunnistettiin viittauksiksi ennen SECREF3-jaksossa kuvattua jatkokäsittelyä.",
      "id": "task461-98d7be3190424b6fa93379b22133e379",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "Tulokset esitetään taulukossa TABREF11 . Tulokset osoittavat, että itsetarkkailumekanismin sisällyttäminen koodaajaan on hyödyllistä useimmissa tehtävissä. Alkuperäiset mallit olivat kuitenkin parempia joissakin tehtävissä (CR, MPQA, MRPC), mikä viittaa siihen, että itsetarkkailumekanismi voi joskus aiheuttaa kohinaa lauseiden ominaisuuksiin. Kaiken kaikkiaan itsehuomioivan lause-esityksen hyödyntäminen parantaa suorituskykyä viidessä tehtävässä kahdeksasta.",
      "id": "task461-5512851dea764ce2997e9d84f191cb96",
      "output": [
        "Kuinka paljon parempi suorituskyky ehdotetulla menetelmällä on verrattuna perusmenetelmiin?"
      ]
    },
    {
      "input": "Asiakirjojen esikäsittelyssä kokeillaan kolmea vaiheittaista tasoa: raakateksti, tekstin puhdistus asiakirjan loogisen rakenteen tunnistamisen avulla ja avainsanojen harvojen osien poistaminen asiakirjasta. Näin esitämme ensimmäisen johdonmukaisen vertailun eri avainsanojen poimintamalleista ja tutkimme niiden kestävyyttä kohinaisten tekstien käsittelyssä.",
      "id": "task461-9cd46422403a457d93361cc4ed232812",
      "output": [
        "mitä asiakirjojen esikäsittelyn tasoja tarkastellaan?"
      ]
    },
    {
      "input": "Tätä mittaria käytetään arvioitaessa vuoropuhelun uskomustenseurantajärjestelmän BIBREF1 tarkkuutta.APRA: APRA-mittarilla (Action Per-Response Accuracy) arvioidaan vuoropuhelupolitiikan laatijan tuottamien vuoropuhelutoimien tarkkuutta kierrosta kohden. Perusasetusten osalta APRA:lla arvioidaan dialogipolitiikan laatijan luokittelutarkkuutta. Mutta meidän mallimme tuottaa itse asiassa jokaisen yksittäisen toimintamerkin, ja pidämme ennustusta oikeana vain, jos mallin tuotoksen jokainen merkki vastaa vastaavaa merkkiä perustotuudessa.BLEU BIBREF19: Mittari arvioi luonnollisen kielen generaattorin tuottaman lopullisen vastauksen laatua. Mittaria käytetään yleensä tehtäväkeskeisen dialogijärjestelmän suorituskyvyn mittaamiseen.",
      "id": "task461-3979fcd5bfff432ea26308dbbf9f0c9f",
      "output": [
        "Mitä mittareita käytetään mallien suorituskyvyn mittaamiseen?"
      ]
    },
    {
      "input": "Kuvaamme ensin mallit yksitellen ja sitten käyttämämme yhdistämistekniikan. Seuraavassa MN tarkoittaa Memory Networks -verkkoja keskusteluhistorian koodaamiseksi, RCNN tarkoittaa R-CNN:ää kuvan objektitason esityksiä varten, Wt tarkoittaa lineaarista lisäkerrosta dekooderissa ja LF myöhäistä fuusiomekanismia, joka on määritelty BIBREF0.Models ::: LF-RCNN Myöhäinen fuusiokooderi BIBREF0, jossa on yhdistetty historia. Käytämme kaksikerroksisia LSTM-muisteja, joissa on 512 piilotettua yksikköä kysymysten ja historian upottamiseen. Objektitason piirteet punnitaan käyttämällä vain kysymysten upotuksia. Glove-vektoreista saadut sanojen upotukset jäädytetään, eikä niitä hienosäädetä. Kuvassa FIGREF6 on yleiskuva arkkitehtuurista: MN-RCNNMuistiverkkokooderi BIBREF0, jossa on kaksisuuntaiset GRU:t ja sanojen upotukset hienosäädetty. Objektitason piirteitä punnitaan kysymysten ja kuvatekstien upotuksilla. Muu osa järjestelmästä on sama kuin edellä. (Kuva FIGREF6)Mallit ::: MN-RCNN-WtSama kuin edellä, mutta ylimääräinen lineaarinen kerros, jota sovelletaan vastausehdokkaan ja koodaimen tuloksen pistetuotokseen, ja joka ohjataan tanh-funktion avulla. Vertaa kuvaa FIGREF6 kuvaan FIGREF6.",
      "id": "task461-5826121a2425423bbf9cc6269671feee",
      "output": [
        "Mitä kolmea erottelumallia he käyttivät?"
      ]
    },
    {
      "input": "Tätä haastetta silmällä pitäen esittelemme Torch-Structin, jolla on kolme erityistä panosta:Modulaarisuus: mallit esitetään jakaumina, joilla on syväoppimiskehykseen integroitu joustava standardikäyttöliittymä.Täydellisyys: laaja valikoima klassisia algoritmeja on toteutettu, ja uusia malleja voidaan helposti lisätä Pythonissa.Tehokkuus: toteutukset on suunnattu laskennalliseen/muistitehokkuuteen grafiikkasuorittimille, ja taustapohjaan sisältyy laajennuksia optimointia varten.",
      "id": "task461-65bbe129c9754361b6ff84f22d8e666e",
      "output": [
        "Onko tämä kirjasto toteutettu Torchiin vai onko se kehysriippumaton?"
      ]
    },
    {
      "input": "Teimme kaksi inhimillistä arviointia Mechanical Turk -palvelun avulla vertaillaksemme mallimme ja perustason suorituskykyä.",
      "id": "task461-e1ebdeb206504a55b0bf5ef3b4b723c4",
      "output": [
        "Liittyykö tämän perhetyön arviointiin mitään inhimillistä arviointia?"
      ]
    },
    {
      "input": "Kieliopin matemaattisen rakenteen tutkiminen on osoittanut, että lauseiden perustana eivät ole sanat vaan jotkin atomiset kieliopilliset tyypit, kuten substantiivi- ja lausetyyppi BIBREF23 , BIBREF24 , BIBREF25 . Transitiiviverbityyppi ei ole atomaattinen kieliopillinen tyyppi, vaan kahdesta substantiivityypistä ja yhdestä lausetyypistä koostuva komposiitti. Näin ollen erityisen mielenkiintoista tässä on se, että atomisella ei todellakaan tarkoiteta pienintä... Toisaalta, aivan kuten hiukkasfysiikassa, jossa meillä on hiukkasia ja antihiukkasia, atomisiin tyyppeihin kuuluu sekä tyyppejä että anti-tyyppejä. Mutta toisin kuin hiukkasfysiikassa, antityyppejä on kahdenlaisia, nimittäin vasemmanpuoleisia ja oikeanpuoleisia. Tämä tekee kielestä vieläkin ei-kommutatiivisemman kuin kvanttiteoria!",
      "id": "task461-980c64a3af5744ae9969025298bf25dc",
      "output": [
        "Jaetaanko sanojen merkitykset alkeishiukkasiksi kuten kvanttiteorian standardimallissa?"
      ]
    },
    {
      "input": "Toiseksi laskemme kolme metriikkaa poimitulle tiedolle: $\\bullet $ Relation Generation (RG) arvioi, kuinka hyvin järjestelmä pystyy tuottamaan tekstiä, joka sisältää faktatietoja (eli oikeita tietueita). Mittaamme niiden $\\hat{y}_{1:T}$:sta poimittujen ainutlaatuisten relaatioiden $r$ tarkkuutta ja absoluuttista lukumäärää (RG-P% ja RG-#), jotka esiintyvät myös $s$:s$:ssä.$\\bullet $ Sisällönvalinta (CS) mittaa, kuinka hyvin luotu dokumentti vastaa kultaista dokumenttia mainittujen tietueiden osalta. Mitataan niiden $\\hat{y}_{1:T}$:sta poimittujen ainutlaatuisten suhteiden $r$ tarkkuus ja palautus (merkitään vastaavasti CS-P% ja CS-R%), jotka on poimittu myös $y_{1:T}$:sta.$\\bullet $ Content Ordering (CO) analysoi, kuinka hyvin järjestelmä järjestää kuvauksessa käsitellyt tietueet. Mittaamme normalisoidun Damerau-Levenshteinin etäisyyden BIBREF36 niiden $\\hat{y}_{1:T}$:sta poimittujen tietueiden jaksojen välillä, jotka on poimittu myös $y_{1:T}$:sta.",
      "id": "task461-6a024f50abbe4481bed2715b140ca438",
      "output": [
        "Mitä laadullisia mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Ensimmäisenä perustasona käytämme Bag-of-Wordsia, joka on tunnettu ja vankka tekstin esitysmuoto, jota käytetään eri aloilla BIBREF21 , yhdistettynä tavalliseen matalaan luokittimeen eli lineaarisella ytimellä varustettuun tukivektorikoneeseen. Käytimme SVM:n LIBSVM-toteutusta.",
      "id": "task461-c9a09c781da24cdd902c93caeb8fa97b",
      "output": [
        "Mitä matalia lähestymistapoja he kokeilivat?"
      ]
    },
    {
      "input": "Vaikka luomme uusia malleja esimerkiksi tunneanalyysin ja sukupuolen tunnistamisen kaltaisiin tehtäviin osana AraNetiä, keskitymme enemmänkin itse työkalupaketin kokoamiseen ja vahvojen vertailukelpoisten perusmallien luomiseen. Vaikka tarjoammekin joitakin perusmalleja joihinkin tehtäviin, emme vertaile niitä nimenomaisesti aiempaan tutkimukseen, koska useimmissa nykyisissä töissä joko hyödynnetään pienempiä aineistoja (jolloin vertailu ei ole oikeudenmukaista) tai käytetään BERT:iä edeltäviä menetelmiä (jolloin meidän mallimme todennäköisesti päihittävät ne). Monille mallintamillemme tehtäville ei ole ollut vakiomuotoisia vertailuarvoja, joiden avulla malleja voitaisiin vertailla keskenään. Tämä vaikeuttaa edistymisen mittaamista ja sellaisten alojen tunnistamista, joille kannattaa kohdentaa ponnisteluja ja määrärahoja.",
      "id": "task461-9faf7fc1c19c46fd8df1b7412463e438",
      "output": [
        "Mihin malleihin niitä verrattiin?"
      ]
    },
    {
      "input": "Hyödynsimme olemassa olevaa, annotoitua Twitter-tietokokonaisuutta, joka on rakennettu masennukseen liittyvien oireiden hierarkkisen mallin BIBREF12 , BIBREF13 perusteella. Tietokanta sisältää 9 473 annotaatiota 9 300 twiitille.",
      "id": "task461-9fccabb754764dd0929ca9465f6d45c6",
      "output": [
        "Mitä tietokokonaisuutta tässä tutkimuksessa käytetään?"
      ]
    },
    {
      "input": "Koulutustietokanta sisältää 2 815 esimerkkiä, joista 1 940 (eli 69 %) on valeuutisia ja 1 968 (eli 70 %) klikkaushuijauksia; lisäksi meillä on 761 testausesimerkkiä.",
      "id": "task461-67d48091cc3d40ec8856fa1f6f252c37",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Teemme kokeita itse keräämillämme CAIS-tietokannoilla arvioidaksemme niiden yleistettävyyttä eri kielillä. Vertailussa käytetään kahta perusmallia, joista toinen on suosittu BiLSTM + CRF-arkkitehtuuri BIBREF36 sekvenssien merkintätehtävään ja toinen tehokkaampi sententce-state LSTM BIBREF21. Taulukossa TABREF50 luetellut tulokset osoittavat CM-verkkomme yleistettävyyden ja tehokkuuden eri alojen ja eri kielten käsittelyssä.",
      "id": "task461-fafeee69067349a2bcf60f718f9ff73c",
      "output": [
        "Mitkä olivat perusmallit?"
      ]
    },
    {
      "input": "Tutkimme lisäksi INLINEFORM0 -grammin pituuden vaikutusta malliimme (eli huomion jäsentämismoduulin käyttämien covolutional-kerrosten suodatinkokoa). Kuvassa FIGREF39 esitetään linkkien ennustamisen AUC-pisteet Cora-tietokannassa INLINEFORM1 -grammin pituuden vaihtelun suhteen. ",
      "id": "task461-4891382dd3aa413fafb79dbca0ccc4a9",
      "output": [
        "Mittaavatko ne erityisesti sitä, miten hyvin ne suoriutuvat pidemmistä jaksoista?"
      ]
    },
    {
      "input": "Lopuksi suoritimme hyperparametrin virityksen säätämällä yhteistarkkailulohkojen lukumäärää, eräkokoa ja koulutettujen epookkien lukumäärää ja yhdistimme kolme parasta verkkoamme.",
      "id": "task461-6811c6030151476c8814cd03f0d1301c",
      "output": [
        "Mitä hyperparametreja on viritetty?"
      ]
    },
    {
      "input": "Vertasimme mallejamme seuraaviin uusimpiin perusmalleihin: Sequence to Sequence (Seq2Seq): Hierarkkinen LSTM (HLSTM): Yksinkertainen koodaaja-dekooderimalli, joka yhdistää neljä lausetta pitkäksi lauseeksi huomiomekanismin avulla BIBREF31: Tarinan kontekstiä edustaa hierarkkinen LSTM: sanatason LSTM kullekin lauseelle ja lausetason LSTM, joka yhdistää neljä lausetta BIBREF29 . Sovelletaan hierarkkista huomiomekanismia, joka huolehtii vastaavasti kahden LSTM:n tiloista. HLSTM+Copy: Hierarkkisiin tiloihin sovelletaan kopiointimekanismia BIBREF32 , jolla kopioidaan tarinan kontekstissa olevat sanat generointia varten.HLSTM+Graph Attention(GA): Sovellamme monilähteistä HLSTM-huomiota, jossa commonsense-tieto koodataan graafihuomion avulla.HLSTM+Contextual Attention(CA): Sovelletaan kontekstuaalista huomiota commonsense-tiedon esittämiseen.",
      "id": "task461-1057e6bfaa264f55999dd0ab95da0441",
      "output": [
        "Vertasivatko ne Transformer-pohjaisiin suuriin kielimalleihin?",
        "Mitä perusviivoja he käyttävät?"
      ]
    },
    {
      "input": "Käytämme vakiomittareita ROUGE-1, ROUGE-2 ja ROUGE-L BIBREF29 kaikkien yhteenvetomallien arvioimiseen. BIBREF22:n ja BIBREF23:n mukaisesti käytämme F-mittausta ROUGE XSUM:n ja CNN/DailyMailin osalta ja rajoitetun pituuden recall-mittausta ROUGE:n osalta NYT:n ja DUC:n osalta.",
      "id": "task461-3c5d6e54730046d0938eedec96645fa6",
      "output": [
        "Mitä mittaria käytettiin arviointivaiheessa?"
      ]
    },
    {
      "input": "Epäilemme, että tämän epäjohdonmukaisuuden syynä on dekoodauksen puuttuminen maksimiluotettavuusestimoinnista, ja ehdotamme, että tulevaisuudessa vaihtoehtona tutkitaan sekvenssitason oppimista. Epäjohdonmukaisuus voi johtua dekoodauksen puuttumisesta tämän optimointiongelman ratkaisemisessa. Maximum likelihood -oppiminen sovittaa mallia $p_{\\theta }$ käyttäen datan jakaumaa, kun taas koulutetusta mallista dekoodattu sekvenssi noudattaa dekoodausalgoritmin aiheuttamaa jakaumaa $q_{\\mathcal {F}}$. Tämän ristiriidan perusteella esitämme vahvan olettamuksen: emme voi taata, että saamme hyvän johdonmukaisen sekvenssigeneraattorin käyttämällä maksimaalisen todennäköisyyden oppimista ja ahnetta dekoodausta.",
      "id": "task461-153b21a68ff44399b3a1500351607a84",
      "output": [
        "Onko äärettömän pituisten sekvenssien tuottaminen seurausta maksimaalisen todennäköisyyden harjoittelusta?"
      ]
    },
    {
      "input": "Lähestymistapamme koostuu muuntajaverkon syötteen jäsentämisestä muuntajien omatoimisen huomion käyttämiseksi ja ohjaamiseksi, jolloin se ehdollistuu kokonaisuuteen. Pääasiallinen tapamme koodata syötettä, eli entiteetti-ensimmäinen menetelmä, on esitetty kuvassa KUVA 4.  Meillä on myös entiteetti-viimeinen muunnos, jossa entiteetti havaitaan ensisijaisesti juuri ennen luokittelumerkkiä, jotta [CLS]-merkki ehdollistuu sen mukaisesti [CLS]-merkin itsehuomioon.  Lisävariaationa voimme joko ajaa muuntajan kerran asiakirjaa kohti useilla [CLS]-merkkeillä (asiakirjatason malli, kuten kuvassa KUVIO 4) tai erikoistaa ennusteen yhteen aikavaiheeseen (lausetason malli).",
      "id": "task461-2c38d1ff0ebc4470847cc97e6854ed38",
      "output": [
        "Millä tavoin syötteet on järjestetty uudelleen?"
      ]
    },
    {
      "input": "Ottaen huomioon etiikan ja moraalin monimutkaisuuden ja koskemattomuuden rajoitumme tämän rakenteen melko yksinkertaiseen toteutukseen deontologisen etiikan teorioiden mukaisesti. Niissä kysytään, mitkä valinnat ovat moraalisesti välttämättömiä, kiellettyjä tai sallittuja sen sijaan, että kysyttäisiin, millainen ihmisen tulisi olla tai mitä tekojemme seurauksia tulisi suosia. Siten normit ymmärretään universaaleiksi säännöiksi siitä, mitä tulee tehdä ja mitä ei tule tehdä. Siksi keskitymme sosiaalisen hyväksynnän arvostukseen yksittäisissä verbeissä ja yksittäisissä verbeissä, joihin liittyy ympäröivää kontekstitietoa - esim. luota ystävääni tai luota koneeseen - selvittääksemme, mitkä niistä edustavat tekemistä ja mitkä ovat yleensä tekemättä jättämistä. ",
      "id": "task461-637e78b9b4e944b5946e4f36d1601ade",
      "output": [
        "Miten kirjoittajat määrittelevät deontologisen eettisen ajattelun?"
      ]
    },
    {
      "input": "Fenerbahçe Olemme päättäneet pitää suosituista urheiluseuroista kertovia twiittejä verkkotunnistuksemme kohteena.  Näin ollen olemme määritelleet kohteiksemme Galatasarayn (eli Kohde-1) ja Fenerbahçen (eli Kohde-2), jotka ovat kaksi Turkin suosituinta jalkapalloseuraa.  Sitten olemme merkinneet näiden kohteiden twiittien kannanottotiedot joko kannattajiksi tai vastustajiksi. Tätä tutkimusta varten emme ole merkinneet twiittejä luokkaan Neither.",
      "id": "task461-53cd16916efe40ebb02c80fdbcc89fb9",
      "output": [
        "Miten twiitit kommentoitiin?"
      ]
    },
    {
      "input": "Kaikkien käsitteiden keskiarvon laskemisen jälkeen menetämme tiedon kunkin käsitteen leksikaalisesta vaihtelusta, mutta toisaalta voimme nyt tutkia, millä alueilla on samanlaista geolektistä vaihtelua, mikä johtaa hyvin määriteltyihin kielellisiin lajikkeisiin. Ne solut, joilla on samanlaiset värit joko kuviossa FIGREF16 tai kuviossa FIGREF17, voidaan olettaa kuuluvan samaan murrealueeseen. Näin ollen kartoissa voidaan erottaa kaksi pääaluetta tai klusteria. Violetti tausta peittää suurimman osan kartasta ja edustaa maaseutualueita, joilla on pieni, hajallaan oleva väestö. Analyysimme osoittaa, että tällä soluryhmällä on leksikossaan enemmän erityisiä sanoja. Vihreät ja keltaiset solut sen sijaan muodostavat toisen klusterin, joka on suurelta osin keskittynyt keskustaan ja rannikolle, jotka vastaavat suuria kaupunkeja ja teollisuusalueita. Näissä soluissa espanjan kielen vakiokielen käyttö on yleistä, mikä johtuu todennäköisesti kouluopetuksesta, tiedotusvälineistä, matkailijoista jne. Sen sanaston luonne on yhtenäisempi verrattuna violettiin ryhmään. Siinä missä violetti rypäs suosii tiettyjä lauseita, kaupunkiryhmän sanasto sisältää suurimman osan avainsanoista.",
      "id": "task461-61dc24c7f63e455eb07cf45024d0baab",
      "output": [
        "Mitkä ovat kaupungin murteen ominaispiirteet?"
      ]
    },
    {
      "input": "Kun otamme LM-sulautumat mukaan järjestelmäämme, kokonaissuorituskyky kasvaa 90,87 prosentista 91,93 prosenttiin INLINEFORM0 CoNLL 2003 NER -tehtävässä, mikä merkitsee yli 1 prosentin absoluuttista F1-parannusta ja huomattavaa parannusta aiempaan tekniikan tasoon verrattuna. Saavutamme myös uuden huipputuloksen (96,37 % INLINEFORM1 ) CoNLL 2000 Chunking -tehtävässä.",
      "id": "task461-441ddc274de0443d996e59a349a8e89b",
      "output": [
        "millaisia tuloksia niillä saavutetaan?"
      ]
    },
    {
      "input": "Tämän jakson tavoitteena on validoida teoreettisten tulostemme soveltuvuus - joiden mukaan itsetarkkaavaisuus voi suorittaa konvoluution - ja tutkia, oppivatko itsetarkkaavaisuuskerrokset käytännössä toimimaan konvoluutiokerrosten tavoin, kun niitä koulutetaan tavanomaisiin kuvanluokittelutehtäviin. Tutkimme erityisesti itsetarkkailun ja konvoluution välistä suhdetta kvadraattisten ja opittujen suhteellisten sijaintikoodausten kanssa. Huomaamme, että molemmissa tapauksissa opitut huomiotodennäköisyydet noudattavat yleensä lemman UNKREF15 ehtoja, mikä vahvistaa hypoteesimme. Varmistaaksemme, että mallimme oppii mielekkään luokittelijan, vertaamme sitä kuitenkin vakiomalliin ResNet18 BIBREF14 CIFAR-10-tietokannassa BIBREF15.",
      "id": "task461-dd629f71cc4444dd8aa0ddfe33b93001",
      "output": [
        "Mitä numeerisia kokeita he tekevät?"
      ]
    },
    {
      "input": "VQABQ-mallissa on kaksi päämoduulia, peruskysymysten luontimoduuli (moduuli 1) ja visuaalisten kysymysten yhteistarkkailuun perustuva vastausmoduuli (moduuli 2). ",
      "id": "task461-4f7d4f05e7994ebdb1dd9922dafa52a0",
      "output": [
        "Mistä kahdesta päämoduulista heidän lähestymistapansa koostuu?"
      ]
    },
    {
      "input": "Verrattuna kontekstin sisäiseen jäsennykseen perustuvaan järjestelmään, yhdistelmä, jossa käytetään tarkkaa merkkijonojen täsmäytystä, tuottaa yli 6 %:n parannuksen palautukseen, ja yhdistelmä, jossa käytetään taivutusmerkkijonojen täsmäytystä, tuottaa vieläkin suuremman, lähes 8 %:n parannuksen, kun taas tarkkuuden menetys on 0,6 % ja 0,8 %.",
      "id": "task461-9e7c016d098f41ccb2f3c252e120a5f4",
      "output": [
        "Millaisia täydentäviä PIE-uuttomenetelmiä käytetään luotettavuuden lisäämiseksi entisestään?"
      ]
    },
    {
      "input": "Käytämme 300-ulotteista Glove Common Crawl Embeddings (840B Token) BIBREF11 ja hienosäädämme ne tehtävään sopiviksi.",
      "id": "task461-88bffe587e144c66933393058e926d35",
      "output": [
        "Mitä sulautusalgoritmia ja ulottuvuuden kokoa käytetään?"
      ]
    },
    {
      "input": "Mallimme koostuu kahdesta neuroverkkomoduulista eli uuttimesta ja abstrahoijasta. Extractor koodaa lähdeasiakirjan ja valitsee asiakirjasta lauseita, minkä jälkeen abstractor parafrasioi tiivistelmäehdokkaat.  Uuttolaite perustuu koodaaja-dekooderi-kehykseen. Sovitamme BERT:n kooderia varten, jotta voimme hyödyntää kontekstisidonnaisia esitystapoja, jotka on saatu valmiiksi koulutetuista muunnoksista. Käytämme dekooderina LSTM-pointteriverkkoa BIBREF22 valitaksemme uutetut lauseet edellä mainittujen lause-esitysten perusteella.  Abstraktorimme on käytännössä identtinen BIBREF8:ssa ehdotetun abstraktorin kanssa.",
      "id": "task461-06adbcf29c8748cda7e244181cb07c59",
      "output": [
        "Mitä menetelmää tässä käytetään?"
      ]
    },
    {
      "input": "Arvioimme MPAD:n avulla opittujen asiakirjojen upotusten laatua 10 asiakirjaluokittelutietokannassa, jotka kattavat aiheen tunnistamisen, karkean ja hienojakoisen tunneanalyysin ja mielipiteiden louhinnan sekä subjektiivisuuden havaitsemisen. Seuraavaksi esittelemme lyhyesti tietokokonaisuudet. Niiden tilastotiedot esitetään taulukossa TABREF21.(1) Reuters. Tämä tietokokonaisuus sisältää uutistoimisto Reutersin vuonna 1987 keräämiä juttuja. Yleisen käytännön mukaisesti käytimme ModApte-jakoa ja otimme huomioon vain ne 10 luokkaa, joissa oli eniten positiivisia harjoitusesimerkkejä. Poistimme myös asiakirjat, jotka kuuluivat useampaan kuin yhteen luokkaan, ja sitten luokat, joihin ei jäänyt yhtään asiakirjaa (2 luokkaa). 2) BBCSport BIBREF30 sisältää BBC Sport -sivuston asiakirjoja, jotka vastaavat urheilu-uutisartikkeleita vuosilta 2004-2005. 3) Polarity BIBREF31 sisältää positiivisesti ja negatiivisesti leimattuja pätkiä Rotten Tomatoesista.(4) Subjektiivisuus BIBREF32 sisältää elokuva-arvostelukatkelmia Rotten Tomatoesista (subjektiiviset lauseet) ja Internet Movie Database -elokuvatietokannan juonitiivistelmiä (objektiiviset lauseet).(5) MPQA BIBREF33 koostuu positiivisista ja negatiivisista lauseista, jotka on annotoitu osana kesällä 2002 järjestettyä NRRC:n moninäkökulmaista kysymysten vastaamista käsittelevää työpajakokoelmaa (NRRC Workshop on Multi-Perspective Question Answering).(6) IMDB BIBREF34 on kokoelma IMDB:stä löytyviä vahvasti polarisoituja elokuva-arvosteluja (positiivisia ja negatiivisia). Kustakin elokuvasta on enintään 30 arvostelua.(7) TREC BIBREF35 koostuu kysymyksistä, jotka on luokiteltu kuuteen eri kategoriaan.(8) SST-1 BIBREF36 sisältää samoja pätkiä kuin Polarity. Kirjoittajat käyttivät Stanford Parser -ohjelmaa pätkien jäsentämiseen ja niiden jakamiseen useisiin lauseisiin. Sen jälkeen he käyttivät Amazon Mechanical Turk -palvelua annotoidakseen tuloksena saadut lauseet polariteetin mukaan (erittäin negatiivinen, negatiivinen, neutraali, positiivinen, erittäin positiivinen).(9) SST-2 BIBREF36 on sama kuin SST-1, mutta siitä on poistettu neutraalit arvostelut ja pätkät on luokiteltu positiivisiksi tai negatiivisiksi.(10) Yelp2013 BIBREF26 sisältää arvosteluja, jotka on saatu vuoden 2013 Yelp Dataset Challenge -kilpailusta.",
      "id": "task461-e82a33ce26f14a25a0befa67b82adda4",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Kaupallisista NLP-työkalupaketeista (esim. BIBREF14, BIBREF15, BIBREF16) valitsimme kokeiluihimme BIBREF17 ja BIBREF18, jotka ovat tietojemme mukaan ainoat julkisesti saatavilla olevat kaupalliset sovellusliittymät, jotka on tarkoitettu tekstialasta riippumattomaan entiteettitason tunneanalyysiin. Raportoimme myös TensiStrength BIBREF13:n, TwitterNLP BIBREF6:n, BIBREF19:n, CogComp-NLP BIBREF20:n ja Stanford NLP NER BIBREF21:n tulokset.",
      "id": "task461-4bfb5454b5ef43e6872246be0e0a9c83",
      "output": [
        "Mitä työkalupaketteja he käyttävät?"
      ]
    },
    {
      "input": "Taulukossa TABREF15 mitataan BLEU BIBREF19-, NIST BIBREF20-, METEOR BIBREF21-, ROUGE-L BIBREF22- ja CIDEr BIBREF23 -mittarit vuoden 2018 E2E NLG Challenge -testidatalla käyttäen järjestäjien toimittamaa arviointiskriptiä.  Käytämme kultaisen standardin valintaa tekstinmuodostusmallin harjoittelussa ja validoinnissa sekä automaattisessa arvioinnissa. Kun otamme tekstinmuodostusmallimme käyttöön manuaalista arviointia varten, käytämme CRF-mallia (Conditional Random Field, ehdollinen satunnaiskenttä) ennustamaan, mitkä tapahtumat mainitaan. Toisessa inhimillisessä arvioinnissa pyrittiin arvioimaan tuotoksen hyväksyttävyyttä uutistoimiston tuotantokäyttöön.  Minimimuokkausarvioinnissa, jonka suoritti uutiskorpuksen luonut kommentoija, korjataan vain asiavirheet ja kielioppivirheet, jolloin teksti voi jäädä kömpelöksi tai epäsuoraksi. Luodun tekstin sanavirheprosentti (WER) verrattuna sen korjattuun varianttiin on 5,6 prosenttia (6,2 prosenttia, jos välimerkkejä ei oteta huomioon).  Taulukossa TABREF23 on yhteenveto asiavirheistä ja niiden tyypeistä. Järjestelmän tuottamista 510 pelitapahtumasta 78:ssa oli asiavirhe, eli 84,7 prosenttia oli tuotettu ilman asiavirheitä. Suurin osa sujuvuusongelmista liittyy raportin yleiseen sujuvuuteen ja rakenteeseen. Näiden ongelmien ratkaiseminen edellyttäisi, että malli ottaisi huomioon useita pelitapahtumia ja yhdistelisi tietoja joustavammin toiston välttämiseksi.  Toisessa inhimillisessä arvioinnissa pyrittiin arvioimaan tuotoksen hyväksyttävyyttä uutistoimiston tuotantokäyttöön. Tuotosta arvioidaan sen käyttökelpoisuuden kannalta uutiskanavalla, joka on merkitty koneellisesti tuotetuksi, eli sen ei ole tarkoitus vastata ihmistoimittajan tasoa, joka on varustettu huomattavilla taustatiedoilla. Arvioinnin suoritti kaksi STT-toimiston toimittajaa, jotka jakoivat 59 peliä keskenään suunnilleen tasan.",
      "id": "task461-2f682db8ef7e4183a997dc4e2396cca0",
      "output": [
        "Mitä arviointikriteerejä ja -mittareita käytettiin tuotetun tekstin arvioinnissa?"
      ]
    },
    {
      "input": "Tutkitaan systemaattisesti merkkitason vastahyökkäysten vaikutusta tunnetilaluokitukseen kahdella arkkitehtuurilla ja neljällä eri syötemuodolla.  Tarkastelemme myös parafraasien havaitsemista.",
      "id": "task461-96f234e2d35142aab578b07bb3899dbe",
      "output": [
        "Minkä lopputehtävien perusteella ne arvioidaan?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF48 käy ilmi, kaksi malliamme osoittavat kilpailukykyisiä tuloksia verrattuna uusimpaan tekniikkaan Visual Dialog challenge 2018 -haasteessa (DL-61 oli Visual Dialog challenge 2018 -haasteen voittaja). ",
      "id": "task461-9b6a4c160a7d431c933a0997587b338d",
      "output": [
        "Mikä malli voitti Visual Dialog -haasteen 2018?"
      ]
    },
    {
      "input": "Vaikka LangID-High ei anna tarkempaa tulosta, se antaa kuitenkin kompaktimman tuloksen: LangID-High:n koko on 15,4 Mt, kun taas wFST:n yhdistetyt korkean resurssin mallit ovat 197,5 Mt.",
      "id": "task461-ed63bc35b24d4a18948536b5710acad0",
      "output": [
        "miten mallin tiiviyttä mitataan?"
      ]
    },
    {
      "input": "NUS:lla koulutettujen toimintatapojen keskimääräinen onnistumisprosentti (SR) oli 94,0 %, kun niitä testattiin ABUS:lla, ja 96,6 %, kun niitä testattiin NUS:lla.",
      "id": "task461-9cb1b945567b49bfbb473b2ab405e26d",
      "output": [
        "kuinka paljon nus päihitti abusin?"
      ]
    },
    {
      "input": "Poikkeamien havaitseminen. Outlier Detection -tehtävässä BIBREF0 määritetään, mikä sana INLINEFORM1-sanojen luettelossa INLINEFORM0 ei liity muihin INLINEFORM2-sanoihin, jotka valittiin liittyviksi. Kullekin INLINEFORM3 -sanalle voidaan laskea sen tiiviyspisteet INLINEFORM4 , joka on INLINEFORM5 -sanan tiiviys. Tunneanalyysi. Tarkastelemme myös BIBREF31 :ssä kuvattua sentimenttianalyysia.",
      "id": "task461-aecab0a8eb134b33b3e5c706e9c36caa",
      "output": [
        "Testaavatko he sanojen upotuksiaan myöhemmissä tehtävissä?"
      ]
    },
    {
      "input": "Tietokannat Englannin ja indin NMT-järjestelmien kouluttamiseen käytämme IITB:n englannin ja indin rinnakkaista korpusta BIBREF22 (INLINEFORM0-lauseet koulutusjoukosta) ja ILCI:n englannin ja indin rinnakkaista korpusta (INLINEFORM1-lauseet). ILCI:n (Indian Language Corpora Initiative) monikielinen rinnakkaiskorpus BIBREF23 kattaa useita intialaisia kieliä terveyden ja matkailun aloilta. Käytämme validointiin IITB:n rinnakkaiskorpuksen 520 lauseen dev-joukkoa. Kussakin lapsitehtävässä käytämme testijoukkona ILCI-korpuksen INLINEFORM2-lauseita.",
      "id": "task461-9fa5502efaf84cd58d0e18da021d4933",
      "output": [
        "Millä tietokokonaisuudella (tietokokonaisuuksilla) he tekevät kokeita?"
      ]
    },
    {
      "input": "Mittaamme, kuinka kontekstisidonnainen sanaesitys on, käyttämällä kolmea eri mittaria: itsesimilaarisuutta, lauseen sisäistä samankaltaisuutta ja suurinta selitettävissä olevaa varianssia.",
      "id": "task461-66c859ff7553408b8263a6491af7bb86",
      "output": [
        "Mitä kokeita ehdotetaan sen testaamiseksi, että ylemmät kerrokset tuottavat kontekstisidonnaisia sulautuksia?"
      ]
    },
    {
      "input": "Perusasetelman ja Oraakkelin lisäksi, joissa otetaan huomioon vain ASR:n 1 paras hypoteesi, suoritamme myös kokeita, joissa käytetään ASR:n $n$ parasta hypoteesia arvioinnissa.",
      "id": "task461-9558525660e84f5cb7657129360a9b17",
      "output": [
        "Mitä ovat yksinkertaisten mallien sarjat?"
      ]
    },
    {
      "input": "Runon tuottamiseen kuvista käytämme olemassa olevaa toimijakriittistä arkkitehtuuria BIBREF1. Shakespearen nykyaikaisten englanninkielisten tekstien luomiseksi kokeilimme erityyppisiä sekvenssistä sekvenssiin -malleja. Käytämme sekvenssistä sekvenssiin -mallia, joka koostuu yksikerroksisesta yksisuuntaisesta LSTM-koodaajasta ja yksikerroksisesta LSTM-dekoodaajasta sekä valmiiksi koulutetuista jälkikäteen sovitetuista sanojen upotuksista, jotka on jaettu lähde- ja kohdelauseiden välillä. Koska vastaavilla Shakespearen ja nykyenglannin lauseilla on merkittävä sanaston päällekkäisyys, laajennamme edellä mainittua sekvenssistä sekvenssiin -mallia käyttämällä osoitinverkkoja BIBREF11 , jotka tarjoavat sijaintiin perustuvan huomion ja joita on käytetty mahdollistamaan merkkien kopiointi suoraan syötteestä.",
      "id": "task461-ea788955bf2d46158bbff4bd86499268",
      "output": [
        "Mitä malleja käytetään maalauksen upottamiseen ja mitä kielityylin siirtämiseen?"
      ]
    },
    {
      "input": "Mukauttaminen elintarvikealan kuvateksteihin Näin ollen elintarvikealan tietokokonaisuudessa on 3 806 kuvaa harjoittelua varten ja 1 775 kuvaa validointia varten. Muihin kuin elintarvikkeisiin liittyvässä tietokokonaisuudessa on 78 976 kuvaa harjoittelua varten ja 38 749 validointia varten.",
      "id": "task461-c0192a961cf1487c83962bdefd37a0bf",
      "output": [
        "Kuinka monta esimerkkiä kohdealueella on?"
      ]
    },
    {
      "input": "Näyttää siis mahdolliselta, että käyttämällä samanlaista mallia voimme tuottaa tekstinäytteitä, joiden ehtona on joukko käyttäjän määrittämiä avainsanoja. Esimerkkinä sanotaan, että käyttäjä haluaa, että tuotettu tuloste sisältää avainsanat $\\lbrace subway, manhattan\\rbrace $ . ",
      "id": "task461-0c01d179fd6b426da26e99ece211c063",
      "output": [
        "Mitkä ovat käyttäjän määrittämät avainsanat?"
      ]
    },
    {
      "input": "Kuten aiemminkin, harjoittelu- ja testijoukkoihin sisältyy noin 30 000 ja 5 000 lauseparia.",
      "id": "task461-eb8c4a1163bd4c91b73079c299fd1ebc",
      "output": [
        "Kuinka monta näytettä he tuottivat keinotekoista kieltä varten?"
      ]
    },
    {
      "input": "Vaikka $\\beta $-VAE tarjoaa ELBO:n regularisoinnin lisäkertoimen $\\beta \\in {\\rm I\\!R}^+$ avulla, sen tavoitefunktion yksinkertainen laajennus BIBREF16 sisältää ylimääräisen hyperparametrin $C$ KL-termin suuruuden hallitsemiseksi,jossa $C\\!\\! \\ in \\!\\! {\\rm I\\!R}^+$ ja $| . |$ tarkoittaa absoluuttista arvoa.",
      "id": "task461-6c4ddcedb74b49f287ac45a2a48517c1",
      "output": [
        "Miltä näyttää kirjoittajien ehdottama KL-divergenssitermiä koskeva nimenomainen rajoitus?"
      ]
    },
    {
      "input": "Annotaatiojärjestelmämme tarjoaa koulutusyhteisölle mahdollisuuksia tehdä lisätutkimuksia opiskelijoiden puheen piirteiden, opiskelijoiden oppimisen ja keskustelun laadun välisestä suhteesta. Kun automatisoidut luokittelijat on kehitetty, tällaisia puheiden ja oppimisen välisiä suhteita voidaan tutkia laajamittaisesti. Lisäksi automaattinen merkintä standardikoodausjärjestelmän avulla voi tukea tulosten yleistämistä eri tutkimusten välillä ja mahdollisesti johtaa automaattisten työkalujen kehittämiseen opettajille ja opiskelijoille.  Erityisesti tätä ongelmaa varten suunnitellun merkintäjärjestelmän kehittäminen on ensimmäinen askel kohti sellaisten korpusten keräämistä ja merkitsemistä, joita NLP-yhteisö voi käyttää alan edistämiseksi tällä erityisalueella.",
      "id": "task461-251ea67c23824aad984f9e64198450dd",
      "output": [
        "mitä mahdollisuuksia korostetaan?"
      ]
    },
    {
      "input": "Sanojen upotukset ovat kasvattaneet suosiotaan NLP-sovelluksissa, koska erityisesti big data -ympäristöön suunnitellut mallit ovat menestyneet.  Huomattakoon, että \"suuria\" tietokokonaisuuksia ei aina ole saatavilla, erityisesti yhteiskuntatieteellisissä NLP-sovelluksissa, joissa kiinnostavia tietoja ei useinkaan saada laajamittaisista lähteistä, kuten internetistä ja sosiaalisesta mediasta, vaan lähteistä, kuten lehdistötiedotteista BIBREF11 , akateemisista aikakauslehdistä BIBREF10 , kirjoista BIBREF12 ja nauhoitettujen puheiden BIBREF13 , BIBREF14 , BIBREF15 , on ehdotettu mallipohjaista menetelmää tulkittavissa olevien korpuskohtaisten sanojen upotusten kouluttamiseksi laskennallisessa yhteiskuntatieteessä käyttäen sekamuotoisia jäsenyysrepresentaatioita, Metropolis-Hastings-Walker-näytteenottoa ja NCE:tä. Kokeelliset tulokset ennusteista, valvotusta oppimisesta ja tapaustutkimukset unionin tilaa koskevista puheista ja NIPS-artikkeleista osoittavat, että menetelmällä voidaan saada korkealaatuisia upotuksia ja aiheita. Tulokset korostavat sitä, että suuri data ei aina ole parasta, sillä aluespesifinen data voi olla hyvin arvokasta, vaikka se olisi pientä.",
      "id": "task461-3a4f472ed0874cbf99f4077065d47f94",
      "output": [
        "Miksi big data ei sovellu tähän tehtävään?"
      ]
    },
    {
      "input": "Klusteroimme upotukset INLINEFORM0 -Means-menetelmällä. ",
      "id": "task461-1a5e7aa1ad9748ad882f7cd17b200f5b",
      "output": [
        "Miten klusteri poimittiin? "
      ]
    },
    {
      "input": "Twitterissä näemme tuloksia, jotka ovat yhdenmukaisia RCV-tulosten kanssa vasemmistosta keskelle ulottuvan poliittisen kirjon osalta. Poikkeuksena, joka erottuu selvästi, ovat oikeistoryhmät ENL ja EFDD, jotka näyttävät olevan kaikkein yhtenäisimpiä. Tämä on täysin päinvastaista kuin mitä RCV:n tiedoissa havaittiin. Arvelemme, että tämä ilmiö johtuu siitä, että Euroopan oikeistoryhmät tukeutuvat sekä Euroopan että kansallisella tasolla suurelta osin sosiaaliseen mediaan levittääkseen Euroopan yhdentymistä kritisoivia kertomuksiaan.",
      "id": "task461-0e39f381586440ad9e3377924db25c7d",
      "output": [
        "Mainitsivatko kirjoittajat tutkimuksessaan mahdollisia sekaannuksia?"
      ]
    },
    {
      "input": "Psykolingvististen tutkimusten BIBREF5 , BIBREF4 , BIBREF7 innoittamana ehdotettiin puolimerkkeihin perustuvaa RNN:ää (ScRNN), joka käsittelee sanoja sisältävän lauseen, jossa on kirjoitusvirheitä, ja ennustaa oikeat sanat jokaisessa vaiheessa. Olkoon $s = \\lbrace w_1, w_2, \\dots , w_n\\rbrace $ syöttölause, joka on sarja sanoja $w_i$ . Kukin tulosana ( $w_i$ ) esitetään ketjuttamalla (i) ensimmäisen merkin yksi kuuma vektori ( $\\mathbf {w_{i1}}}$ ); (ii) viimeisen merkin yhden kuuman esityksen ( $\\mathbf {w_{il}}}$ , jossa $l$ on sanan $w_i$ pituus ); ja (iii) sisäisten merkkien merkkipussin esityksen ( $\\sum _{j=2}^{l-1}\\mathbf {w_{ij}})$ . ScRNN käsittelee ensimmäiset ja viimeiset merkit erikseen, ja se ei välitä sisäisten merkkien järjestyksestä. Kukin sana, joka esitetään vastaavasti, syötetään sitten BiLSTM-soluun. Jokaisessa sekvenssiaskeleessa koulutuskohteena on oikea vastaava sana (lähtöulottuvuus on sama kuin sanaston koko), ja malli optimoidaan risti-entropiahäviön avulla.",
      "id": "task461-ea524c02150e4a5097444fbe5bce4f9d",
      "output": [
        "Mikä on puolimerkkiarkkitehtuuri?"
      ]
    },
    {
      "input": "Validoimme lähestymistapamme Gigaword-korpuksella, joka koostuu 3,8 miljoonan artikkelin otsikoista (joita pidetään koko tekstinä) ja otsikoista (tiivistelminä) koostuvasta harjoitusjoukosta sekä 200 000 validointiparista, ja raportoimme testisuorituksen samalla 2 000 artikkelin joukolla, jota käytettiin BIBREF7:ssä. ",
      "id": "task461-bb7ff563703c49aaa6483a9d020ad9dc",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät arvioinnissa?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvaamme datan lisäämisen menetelmiä, joita käytämme koulutusdatan määrän lisäämiseksi, jotta NMT-järjestelmämme eivät kärsisi niin paljon japanin INLINEFORM0-vietnamin käännöstyön vähäisistä resursseista. TakaisinkääntäminenYksi lähestymistavoista yksikielisen datan hyödyntämiseksi on käyttää konekäännösjärjestelmää kääntämään nämä tiedot synteettisen rinnakkaisdatan luomiseksi. Tavallisesti kohdekielen yksikielinen aineisto käännetään, mistä menetelmän nimi johtuu: Back Translation BIBREF11 . Mix-Source ApproachToinen tiedon lisäämisen menetelmä, jota pidetään hyödyllisenä tässä vähäisten resurssien tilanteessa, on mix-source-menetelmä BIBREF12 .",
      "id": "task461-eabeb0404efa432fbfa49ac66b8ebb53",
      "output": [
        "mitä menetelmiä käytettiin tietojen harvinaisuuden vaikutusten vähentämiseksi?"
      ]
    },
    {
      "input": "AEM:n tehokkuuden validoimiseksi tapahtumien poimimisessa sosiaalisesta mediasta (esim. Twitter) ja uutismediasivustoista (esim. Google news) käytetään kolmea tietokokonaisuutta (FSD BIBREF12 , Twitter ja Google).",
      "id": "task461-503341bf23e248fa9e52950c47518510",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Logistinen regressio: Yhdistetään asiakirjan Bag-Of-Words-edustus ja kysymyksen Bag-Of-Words-edustus. LSTM: Aloitetaan asiakirjan indeksisarjan ja kysymyksen indeksisarjan ketjuttamisella. Syötämme LSTM-verkkoa tällä vektorilla ja käytämme lopputilaa syötteen esityksenä. Lopuksi sovellamme logistista regressiota tähän esitykseen lopullisen päätöksen tuottamiseksi. End-to-end-muistiverkot: Tämä arkkitehtuuri perustuu kahteen eri muistisoluun (tulo ja lähtö), jotka sisältävät asiakirjan esityksen. Syvä projektiivinen lukija: Tämä on itse suunnittelemamme malli, joka on pitkälti saanut vaikutteita tehokkaasta R-verkon lukijasta BIBREF12 .",
      "id": "task461-c3c6aa5742b9484d9686536823a3dad2",
      "output": [
        "Mitä perustasoja esitetään?"
      ]
    },
    {
      "input": "Suoritimme kokeita synteettisesti luoduilla tietokokonaisuuksilla, koska näin voimme paremmin hallita tietojen jakaumaa. Vertailimme erityisesti lähestymistapamme avulla saatuja hyötyjä suhteessa jakauman varianssiin. Loimme tietokokonaisuuden seuraavasta generatiivisesta prosessista. [H] Generatiivinen prosessi [1] Generoi dataPoimi k pistettä INLINEFORM0 toimialueen -1 keskiarvoiksi ja vastaava joukko k pistettä INLINEFORM1 toimialueen-2 keskiarvoiksi sekä kovarianssimatriisit INLINEFORM2iter INLINEFORM0 upto num INLINEFORM1 näytteet Näytteenottoluokka INLINEFORM2 Näyte INLINEFORM3 Näyte INLINEFORM4 Lisää q ja a niin näytteenottoluokka listaan q,a-parien joukkoon Generoimme tietokokonaisuuden edellä mainitulla näytteenottoprosessilla, jossa keskiarvot on valittu INLINEFORM5-kokoiselle 2-ulotteiselle ruudukolle, jossa varianssi on asetettu INLINEFORM6:ksi kussakin ulottuvuudessa.10000 otospistettä luotiin. Edellä mainitun algoritmin parametriksi INLINEFORM7 asetettiin 0,5 ja k:ksi 9 (koska pisteet voitiin tuottaa yhdestä yhdeksästä gaussista, joiden keskipisteet olivat INLINEFORM8 -ruudukossa).",
      "id": "task461-2d6261d28035445e9abc69c49293a899",
      "output": [
        "Miten synteettinen tietokokonaisuus luodaan?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvaamme ensin ilmiötä, joka liittyy poliittisten puolueiden nimien mainitsemiseen käyttäjien profiiliominaisuuksissa. Tämän jälkeen analysoidaan profiileja, joiden profiiliattribuuteissa mainitaan nimenomaisesti poliittisia kahvoja. Molemmat näistä ovat orgaaninen tapa osoittaa tukea puolueelle, eikä niihin liity puolueiden suoraa kampanjointia. Katsomme, että koko kampanja Chowkidarin lisäämisestä profiiliattribuutteihin osoittaa epäorgaanista käyttäytymistä, jossa poliittiset johtajat toimivat katalysaattoreina. Mielestämme profiiliattribuutin muuttaminen pääministerin kampanjan mukaisesti on esimerkki epäorgaanisen käyttäytymisen leviämisestä BIBREF6, BIBREF9.   Väitämme kuitenkin, että vaalikampanjaan liittyvien avainsanojen lisääminen profiiliin on eräänlaista epäorgaanista käyttäytymistä. ",
      "id": "task461-2fc5d71cc7384ef9a96dbbe59bcbd8eb",
      "output": [
        "Mitkä ovat orgaaniset ja epäorgaaniset tavat osoittaa poliittinen suuntautuminen profiilimuutoksilla?"
      ]
    },
    {
      "input": "Kun on annettu todistustila $= (_, _)$ , jossa $_$ ja $_$ merkitsevät korvausjoukkoa ja todistuspistemäärää, yhdistäminen lasketaan seuraavasti: Tuloksena saatu todistuspistemäärä $g$ on:$$ \\begin{aligned} \\max _{f \\in \\mathcal {K}} & \\; {unify}_(g, [f_{p}, f_{s}, f_{o}], (\\emptyset , ))) \\\\ & = \\max _{f \\in \\mathcal {K}} \\; \\min \\big \\lbrace , \\operatorname{k}(_{\\scriptsize {grandpaOf}:}, _{f_{p}:}),\\\\\\ &\\qquad \\qquad \\qquad \\qquad \\operatorname{k}(_{{abe}:}, _{f_{s}:}), \\operatorname{k}(_{{bart}:}, _{f_{o}:}) \\big \\rbrace , \\end{aligned}$$ (Eq. 3)missä $f \\triangleq [f_{p}, f_{s}, f_{o}]$ on fakta $\\mathcal {K}$:ssa, joka tarkoittaa $f_{s}$:n ja $f_{o}$:n välistä $f_{p}$-tyyppistä suhdetta $f_{s}$ ja $f_{o}$ välillä, $_{s:}$ on symbolin $s$ sulautusrepresentaatio, $$ tarkoittaa alkuperäistä todistuspistemäärää ja $\\operatorname{k}({}\\cdot {}, {}\\cdot {})$ tarkoittaa RBF-ydintä.",
      "id": "task461-9136092ef5f647c68782e103980d345a",
      "output": [
        "Miten todistuspisteet lasketaan?"
      ]
    },
    {
      "input": "Ensimmäinen tässä työssä arvioimamme luokittelijatyyppi on feedforward-neuraaliverkot (DNN), jotka koostuvat kolmesta piilokerroksesta, joissa kussakin on 512 rektifioitua lineaarista yksikköä (ReLU), joissa on softmax-aktivointifunktio.  Toisena arvioitavana luokittelijana käytämme konvoluutiohermoverkkoja (convolutional neural networks, CNN), joissa on 2 konvoluutio- ja max pooling-kerrosta, joita seuraa 2 täysin yhdistettyä ReLU-kerrosta, joissa on 512 solmua. ",
      "id": "task461-dd1ca51a244c42bf890350c722360d83",
      "output": [
        "Minkä mallin avulla he luokittelevat foneettisia segmenttejä? "
      ]
    },
    {
      "input": "Haluaisimme kiittää WASSA-2017 Shared Task on Emotion Intensity -tapahtuman järjestäjiä tietojen, ohjeiden ja oikea-aikaisen tuen tarjoamisesta.",
      "id": "task461-ed80ea0b358d44359a8750f7d623a10d",
      "output": [
        "mitä tietokokonaisuutta käytettiin?"
      ]
    },
    {
      "input": "UCL:n ryhmällä oli pääsy mikrokertomuksiin sekä kontekstikohtaisiin metatietoihin, kuten väestötietoihin ja hanketietoihin. Poliittisten päättäjien kansainvälistä vertailua varten tiimi käänsi monikieliset vastaukset englanniksi käyttämällä konekäännöstä, tässä tapauksessa Translate API:ta (Yandex Technologies). Esikäsittelyvaiheessa poistettiin sanat, joilla ei ollut toiminnallista merkitystä (esim. \"minä\"), harvinaiset sanat, jotka esiintyivät vain yhdessä kertomuksessa, numerot ja välimerkit. Jäljelle jääneistä sanoista poistettiin substantiivien monikkomuodot ja verbien taivutusmuodot.",
      "id": "task461-4706f583fa764fa0adc6f0480103d6aa",
      "output": [
        "Mitä luonnollisen kielen käsittelyn elementtejä ehdotetaan laadullisen tiedon analysoimiseksi?"
      ]
    },
    {
      "input": "Havaitsimme esimerkiksi, että talvisanat olivat yhdessä ja kaukana kesäsanoista. Viikonpäivät olivat myös ryhmiteltyinä ja kaukana viikonloppupäivistä.",
      "id": "task461-51c7a4f9682d4b0bb42ddf974ccd6f98",
      "output": [
        "Mitä geometrisia ominaisuuksia sulautumilla on?"
      ]
    },
    {
      "input": "LiLi:llä olisi oltava seuraavat ominaisuudet:",
      "id": "task461-7d5400e7627e4fb288df706ea45aaf54",
      "output": [
        "Mitkä ovat yleistiedon oppimismoottorin osat?"
      ]
    },
    {
      "input": "Kaikissa 26 tietokokonaisuudessa RCRN päihittää tavallisten BiLSTM:ien lisäksi myös 3L-BiLSTM:t, joiden parametrointi on suunnilleen sama.",
      "id": "task461-70105694bafb4b87af77c43815dbdefc",
      "output": [
        "Onko heidän mallissaan enemmän parametreja kuin muissa malleissa?"
      ]
    },
    {
      "input": "Loogisten johtopäätösten osalta monotoninen päättely BIBREF6 , BIBREF7 , joka on eräänlainen sanojen korvaamiseen perustuva päättelytapa, edellyttää kykyä kuvata leksikaalisten ja syntaktisten rakenteiden välistä vuorovaikutusta.",
      "id": "task461-805ed414210d435cbeddc1e401bb477b",
      "output": [
        "Mitä on monotoninen päättely?"
      ]
    },
    {
      "input": "W2V:n kouluttamiseen tarvittava tietokokonaisuus saatiin käyttämällä tietoja, jotka oli poimittu italialaisen Wikipedian dumppausdatasta (päivätty 2019.04.01), italialaisen Google Newsin pääluokista (MAAILMA, KANSAT, LIIKETOIMINTA, TEKNOLOGIA, VIIHDE, URHEILU, TIETO, TERVEYS) ja joistakin anonymisoiduista keskusteluista, jotka käytiin käyttäjien ja asiakaspalvelukeskustelurobotin (Laila) välillä. Tietokanta (joka koostuu 2,6 gigatavusta raakatekstiä) sisältää 421\\ 829\\ 960$ sanaa, jotka on jaettu 17\\ 305\\ 401$ lauseisiin. Kaikki sanat muutettiin pieniksi kirjaimiksi (kaksinkertaisen esiintymisen välttämiseksi), jolloin sanavarastoksi saatiin lopulta 618 \\ 224 \\ 224 \\ dollarin sanat.",
      "id": "task461-aa8daf254a2d4897af604d88a50cbee1",
      "output": [
        "Mitä tietokokonaisuutta käytetään Word2Vec-algoritmin syötteenä?"
      ]
    },
    {
      "input": "WordDec-mallimme (WDec) F1-pisteet ovat 3,9 \\%$ ja 4,1 \\%$ korkeammat kuin HRL:n tulokset NYT29- ja NYT24-tietokannoissa. Vastaavasti PtrNetDecoding (PNDec) -mallilla saavutetaan F1-pisteet, jotka ovat 3,0 \\%$ ja 1,3 \\%$ korkeammat kuin HRL:llä NYT29- ja NYT24-tietokannoissa.",
      "id": "task461-7a6acf6b2109403e885e012b1d69859a",
      "output": [
        "Kuinka korkeat F1-pisteet ovat aiempaan työhön verrattuna?",
        "Kumpi kahdesta ehdotetusta lähestymistavasta toimi kokeissa paremmin?"
      ]
    },
    {
      "input": "Vertailemme FlowSeqin suorituskykyä ensin vahvoihin perusmalleihin, kuten NAT w/ Fertility BIBREF6, NAT-IR BIBREF7, NAT-REG BIBREF25, LV NAR BIBREF26, CTC Loss BIBREF27 ja CMLM BIBREF8.",
      "id": "task461-ef4c2088907d4895bc1d8546dd834399",
      "output": [
        "Mitä ei-autoregressiivisiä NMT-malleja käytetään vertailussa?"
      ]
    },
    {
      "input": "Vuoropuheluaktit on luokiteltu moniin eri taksonomioihin: puheaktit BIBREF14 viittaavat lausahdukseen, ei ainoastaan tiedon esittämiseen, vaan myös suoritettavaan toimintaan. Myöhemmin puheaktit on muutettu viiteen luokkaan (Assertive, Directive, Commissive, Expressive, Declarative) BIBREF15. Keskustelutietojen merkitsemiseen on olemassa monia tällaisia vakiotaksonomioita ja -järjestelmiä, ja useimmat niistä noudattavat diskurssin kompositionaalisuutta. Nämä järjestelmät ovat osoittautuneet tärkeiksi diskurssi- tai keskustelunanalyysin kannalta BIBREF16. Vuoropuhelujärjestelmien ja diskurssianalyysin lisääntyneen kehityksen aikana viime vuosikymmeninä otettiin käyttöön vakiotaksonomia, jota kutsutaan nimellä Dialogue Act Markup in Several Layers (DAMSL) tag set. DAMSL:n mukaan jokaisella DA:lla on eteenpäin suuntautuva toiminto (kuten lausunto, infokysely, kiitos) ja taaksepäin suuntautuva toiminto (kuten hyväksyminen, hylkääminen, vastaus) BIBREF17.",
      "id": "task461-4d91b2a896654d6cb66a267297a6fe7e",
      "output": [
        "Miten vuoropuhelulakimerkinnät määriteltiin?"
      ]
    },
    {
      "input": " Yhteistyöelimen kokonaissuorituskyky oli huomattavasti parempi kuin muiden mallien, ja sen keskimääräinen tarkkuusero oli pienin, 22,5 pistettä.",
      "id": "task461-9024b660e4d74ff5a7a51452c458823e",
      "output": [
        "Mikä malli yleisti parhaiten?"
      ]
    },
    {
      "input": "Kutsumme näitä tekniikoita Recurrence over BERT (RoBERT) ja Transformer over BERT (ToBERT). Havaitsimme, että ToBERT päihittää RoBERT:n valmiiksi koulutetuilla BERT-ominaisuuksilla ja hienosäädetyillä BERT-ominaisuuksilla kaikissa tehtävissämme. ",
      "id": "task461-93d9ff77ed994a40845cc6b8337a10e9",
      "output": [
        "Toimiiko RNN-kerros BERTin päällä paremmin vai muuntajakerros?"
      ]
    },
    {
      "input": "Nimettyjen entiteettien tunnistaminen (NER) biolääketieteen alalla sisältää yleensä sellaisten entiteettien tunnistamisen kuin proteiinit, geenit, sairaudet, hoidot, lääkkeet jne. ",
      "id": "task461-e723fbbf42e34ef1a88f3a8da01cc74b",
      "output": [
        "Mikä on NER?"
      ]
    },
    {
      "input": "Järjestelmämme menestyi huomattavasti paremmin kuin perustason järjestelmä yhteisessä tehtävässä, sillä perustason järjestelmä sai huomattavasti huonommat pisteet sukupuolitehtävässä kuin lajitehtävässä.",
      "id": "task461-4ab60504a4b44ae8b6b14ae6c3aeefbe",
      "output": [
        "Missä tehtävässä malli toimii parhaiten?"
      ]
    },
    {
      "input": "Havaitseminen: Hypernymian havaitsemisessa tehtävänä on luokitella, ovatko sanaparit hypernymiasuhteessa. Tätä tehtävää varten arvioimme kaikkia malleja viidellä vertailutietoaineistolla: Ensinnäkin käytämme blessin substantiivi-substantiivi -osajoukkoa, joka sisältää hypernymia-merkintöjä 200 konkreettiselle, enimmäkseen yksiselitteiselle substantiiville. Toiseksi arvioimme leds BIBREF13 -mallilla, joka koostuu 2 770 substantiiviparista, jotka on tasapainotettu positiivisten hypernymiaesimerkkien ja satunnaisesti sekoitettujen negatiivisten esimerkkien välillä. Suunta: Suunnan ennustamisessa tehtävänä on tunnistaa, mikä termi on laajempi tietyssä sanaparissa. Tätä tehtävää varten arvioimme kaikkia malleja kolmella BIBREF16 -tietokannalla: On bless, tehtävänä on ennustaa suunta kaikille tietokannan 1337 positiiviselle parille. Parit lasketaan oikeiksi vain, jos hypernyymisuunta saa korkeammat pisteet kuin käänteissuunta, eli INLINEFORM0 . Varataan 10 % datasta validointia varten ja testataan loput 90 %. Wbless-tietokannassa noudatamme aiempaa työtä BIBREF17 , BIBREF18 ja suoritamme 1000 satunnaista iteraatiota, joissa 2 % datasta käytetään validointijoukkona luokittelukynnyksen oppimiseksi, ja testaamme lopuilla datan osilla. Raportoimme kaikkien iteraatioiden keskimääräisen tarkkuuden. Lopuksi arvioimme biblessin BIBREF16 , joka on wblessin muunnos, jossa hypernyymi- ja hyponyymiparit on nimenomaisesti merkitty niiden suunnan mukaan. Graded Entailment: Graded entailment -menetelmässä tehtävänä on kvantifioida se, missä määrin hypernymy-suhde pitää paikkansa. Tässä tehtävässä noudatamme aiempaa työtä BIBREF19 , BIBREF18 ja käytämme hyperlexin BIBREF20 substantiiviosaa, joka koostuu 2 163 substantiiviparista, jotka on kommentoitu INLINEFORM0 on-a INLINEFORM1 asteikolla INLINEFORM2 .",
      "id": "task461-619006cc3cce4e94aec07f0b012045a1",
      "output": [
        "Mitä vertailutietoaineistoja käytetään?"
      ]
    },
    {
      "input": "Arvioimme menetelmäämme kahdella laajasti tutkitulla tietokokonaisuudella, jotka ovat Waseem ja Hovey BIBREF5 sekä Davidson et al. BIBREF9.",
      "id": "task461-52b20e408ad74ce78666be34786c10cd",
      "output": [
        "Mitä julkisesti saatavilla olevia tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Verrattuna luetun ymmärtämiseen perustuvaan laadunvarmistukseen (RCQA), jossa vastaukset kysymykseen löytyvät yleensä annetusta pienestä kappaleesta, OpenBookQA-asetelmassa avoimen kirjan osa on paljon laajempi (kuin pieni kappale), eikä se ole täydellinen, koska siinä saatetaan tarvita lisää yleistä tietoa. ",
      "id": "task461-19d85d359b87452f903a182c29e678b4",
      "output": [
        "Miten OpenBookQA eroaa muusta luonnollisen kielen laadunvarmistuksesta?"
      ]
    },
    {
      "input": "CreateDebate-tietokokonaisuus kerättiin englanninkieliseltä verkkokeskustelufoorumilta, jossa keskusteltiin neljästä aiheesta: abortti (ABO), homojen oikeudet (GAY), Obama (OBA) ja marihuana (MAR). ",
      "id": "task461-bee1036b9f914e679615991c81fc7843",
      "output": [
        "Mitkä aiheet sisältyvät keskustelutietoihin?"
      ]
    },
    {
      "input": "Koulutusaineistona käytämme BIBREFin julkaisemia Daily Mail -uutisartikkeleita9 . ",
      "id": "task461-2a0aed8d12f6450fa91f60c3e246b6e6",
      "output": [
        "mitä tietokokonaisuutta käytettiin?"
      ]
    },
    {
      "input": "Tunnetietoisen chatbotin arviointi jakautuu kahteen eri osaan, laadulliseen ja määrälliseen arviointiin. Kvalitatiivisessa arvioinnissa keskitytään ohjelmiston toimivuuden arviointiin, kun taas kvantitatiivisessa keskitytään enemmän mittaamaan chatbottien suorituskykyä numerolla. Useiden aiempien tutkimusten perusteella havaitsimme, että useimmissa teoksissa käytettiin ISO 9241 -standardia chatbottien laadun arvioinnissa keskittymällä käytettävyysnäkökohtiin. Tämä näkökohta voidaan ryhmitellä kolmeen painopisteeseen, mukaan lukien tehokkuus, vaikuttavuus ja tyytyväisyys, jotka koskevat järjestelmien suorituskykyä määritettyjen tavoitteiden saavuttamisessa. Automaattisessa arvioinnissa joissakin tutkimuksissa keskitytään järjestelmän arviointiin tunnetasolla BIBREF15 , BIBREF28 . Siksi järjestelmän suorituskyvyn mittaamiseen käytetään joitakin yleisiä mittareita, kuten tarkkuutta, palautusta ja tarkkuutta, verrattuna kultaiseen merkkiin. Tämä arviointi on samanlainen kuin tunteiden luokittelutehtävät, kuten aiemmat SemEval 2018 BIBREF32 ja SemEval 2019 . Muissa tutkimuksissa on myös ehdotettu perpleksiteetin käyttöä mallin arvioimiseksi sisältötasolla (sen määrittämiseksi, onko sisältö merkityksellistä ja kieliopillista) BIBREF14 , BIBREF39 , BIBREF28 . Tätä arviointimittaria käytetään laajalti arvioitaessa dialogipohjaisia järjestelmiä, jotka perustuvat probabilistiseen lähestymistapaan BIBREF61 . Toisessa BIBREF14:n teoksessa käytettiin BLEU:ta koneellisen vastauksen arvioimiseksi ja sen vertaamiseksi kultaiseen vastaukseen (varsinaiseen vastaukseen), vaikka BIBREF62 ei suosittele BLEU:n käyttämistä keskustelunmuodostustehtävän mittaamiseen, koska se korreloi heikosti ihmisen arvioinnin kanssa. Tässä arvioinnissa chatbottien suorituskyvyn mittaamiseen käytetään ihmisen arviointia useiden kriteerien perusteella. BIBREF15 käytti kolmea kommentoijaa arvioimaan chatbottien vastauksia kahdella kriteerillä, jotka olivat sisältö (asteikko 0,1,2) ja tunteet (asteikko 0,1). Sisältö keskittyy sen mittaamiseen, onko vastaus luonnollisesti hyväksyttävä ja voisiko ihminen tuottaa sen uskottavasti. Tutkijat ovat jo ottaneet käyttöön ja suosittelevat tätä metriikkaa ja haastavia keskustelutehtäviä, kuten BIBREF-julkaisussa38 ehdotetaan. ",
      "id": "task461-2182a14d5a3f4f3db0d12caa1351aaf6",
      "output": [
        "Miten EAC arvioidaan?"
      ]
    },
    {
      "input": "Toinen turkkilainen tietokokonaisuus on Twitter-korpus, joka koostuu turkkilaisia matkaviestinoperaattoreita koskevista twiiteistä. Nämä twiitit ovat useimmiten paljon äänekkäämpiä ja lyhyempiä kuin elokuvakorpuksen arvostelut. Yhteensä twiittejä on 1 716 kappaletta. Niistä 973 on negatiivisia ja 743 positiivisia. Kaksi ihmistä on kommentoinut nämä twiitit manuaalisesti, ja merkinnät ovat joko positiivisia tai negatiivisia.",
      "id": "task461-a0e9c0b5aa54451b961ac09c7a1f638c",
      "output": [
        "Mitä tietoja Twitter-tietokannasta annetaan?"
      ]
    },
    {
      "input": "GPT-2 saa korkeimman pistemäärän ja $n$-grammi alhaisimman. Transformer-XL ja LSTM LM toimivat keskellä ja suunnilleen samalla tasolla keskenään. Taulukossa TABREF14 ilmoitetaan kaikkien mallien ja ihmisen suorittaman arvioinnin 12 kategorian tarkkuustulokset.",
      "id": "task461-34ff02329b764b0a83b7f829ec4ad1d5",
      "output": [
        "Mikä on mallien suorituskyky tehtävissä?"
      ]
    },
    {
      "input": "Vertailemme seuraamusluokittimen osalta Decomposable Attention BIBREF2 , BIBREF3 sellaisena kuin se on toteutettu virallisessa perusversiossa, ESIM BIBREF4 ja muunnosverkkoa, jossa on valmiiksi koulutetut painot BIBREF5 . ",
      "id": "task461-0df4f3d3e871420d9ac7caa113fc91d0",
      "output": [
        "Mitä valmiiksi koulutettua muuntajaa he käyttävät?"
      ]
    },
    {
      "input": "Edellä esitetyn analyysin mukaan Edellä esitetyn analyysin mukaan ehdotimme painotettua versiota DIRL:stä, jotta voimme ratkaista ongelman, joka aiheutuu $\\rm {P}(\\rm {Y})$:n siirtymisestä DIRL:ään. Tämän kehyksen keskeisenä ajatuksena on ensin yhdenmukaistaa $\\rm {P}(\\rm {Y})$ eri osa-alueiden välillä ennen osa-alue-invariantin oppimisen suorittamista ja ottaa sitten huomioon $\\rm {P}(\\rm {Y})$:n siirtymä etikettien ennustamismenettelyssä. Tarkemmin sanottuna siinä otetaan käyttöön luokkapaino $\\mathbf {w}$ lähdealueen esimerkkien painottamiseksi luokittain. Painotetun lähdealueen perusteella toimialueen siirto-ongelma ratkaistaan kahdessa vaiheessa.  Tämän käytännön motivaationa on säätää lähde- tai kohdealueen datajakaumaa, jotta $\\rm {P}(\\rm {Y})$:n siirtyminen eri alueiden välillä voidaan lieventää ennen DIRL:n soveltamista. Jos meillä on vain lähdealueen tietojen merkinnät, päätämme mukauttaa lähdealueen tietojen jakaumaa. Tätä tarkoitusta varten otamme käyttöön koulutettavan luokkapainon $\\mathbf {w}$, jolla lähdealueen esimerkkejä painotetaan uudelleen luokittain DIRL:ää suoritettaessa, kun $\\mathbf {w}_i > 0$. Tarkemmin sanottuna toivomme, että:ja merkitsemme $\\mathbf {w}^*$ $\\mathbf {w}$:n arvoa, joka saa tämän yhtälön pitämään paikkansa.  Näemme, että kun $\\mathbf {w}=\\mathbf {w}^*$, DIRL:n tehtävänä on sovittaa $\\rm {P}_S(G(\\rm {X})|\\rm {Y})$ yhteen $\\rm {P}_T(G(\\rm {X})|\\rm {Y})$:n kanssa ilman $\\rm {P}(\\rm {Y})$:n siirtoa. Analyysimme mukaan tiedämme, että $\\rm {P}(\\rm {Y})$:n siirtymisen vuoksi valvotun oppimisen $\\mathcal {L}_{sup}$ ja toimialuevariantin oppimisen $\\mathcal {L}_{inv}$ harjoituskohteiden välillä on ristiriita. Ristiriidan aste pienenee, kun $\\rm {P}_S(\\rm {Y})$ lähestyy $\\rm {P}_T(\\rm {Y})$. Siksi mallin harjoittelun aikana $\\mathbf {w}$ optimoidaan kohti $\\mathbf {w}^*$, koska se saa painotetun lähdealueen $\\rm {P}(\\rm {Y})$ lähelle $\\rm {P}_T(\\rm {Y})$:ta, jotta konflikti voidaan ratkaista.",
      "id": "task461-6857d4e86f09426680ab24c29e745ef3",
      "output": [
        "Miten eri aloja painotetaan WDIRL:ssä?"
      ]
    },
    {
      "input": "Molemmat päihittivät huomiotta jättämisen perustason huomattavasti. Huomion perustasoa varten käytämme tavallista parametrisoitua huomion BIBREF2 .",
      "id": "task461-68ff4b3babfc4969965dbff2d6378273",
      "output": [
        "Mitä perustason menetelmiä käytetään?"
      ]
    },
    {
      "input": "Arvioimme ehdotetun menetelmän suorituskykyä käyttämällä kahta kriteeriä: i) rank-korrelaatio BIBREF25 visuaalisen maadoituksen arvioimiseksi ja ii) tarkkuus kysymyksiin vastaamisen arvioimiseksi. Intuitiivisesti sijoituskorrelaatio mittaa ihmisen ja mallin huomiokarttojen samankaltaisuutta sijoitukseen perustuvalla mittarilla. Korkea sijoituskorrelaatio tarkoittaa, että malli \"katsoo\" kuva-alueita, jotka vastaavat ihmisen samaan kysymykseen vastaamiseen käyttämää visuaalista informaatiota. Ennustetun vastauksen tarkkuuden kannalta INLINEFORM0 arvioidaan seuraavasti: DISPLAYFORM0",
      "id": "task461-4bbcd1e4c47b424e98b1967863723912",
      "output": [
        "Miten he mittaavat manuaalisten ja mallin tuottamien pohjakosketusten välistä korrelaatiota?"
      ]
    },
    {
      "input": "Jäljelle jää vain kysymys siitä, mikä tekee kahdesta ympäristöstä tarpeeksi samanlaisia, jotta voidaan päätellä yhteisen luokan olemassaolo. Tästä kysymyksestä on olemassa laaja kirjallisuus (mukaan lukien edellä mainitut kielen mallintamista, valvomatonta jäsennystä ja yhdenmukaistamista koskevat työt), mutta tässä työssä käytämme hyvin yksinkertaista kriteeriä: fragmentit ovat keskenään vaihdettavissa, jos ne esiintyvät vähintään yhdessä täsmälleen samanlaisessa leksikaalisessa ympäristössä.",
      "id": "task461-70d5707d7f354088b24b754a09625a4b",
      "output": [
        "Miten ne määrittelevät samankaltaiset ympäristöt fragmentteja varten tietojen lisäysjärjestelmässä?"
      ]
    },
    {
      "input": "Koska englanti ei myöskään merkitse kieliopillista sukupuolta, englantia varten kehitettyjä lähestymistapoja ei voida siirtää morfologisesti rikkaisiin kieliin, joissa on sukupuolisopimusta BIBREF8 .",
      "id": "task461-4daba55695cc4a3bb454ee79be02a0c2",
      "output": [
        "Miksi englanninkielinen lähestymistapa ei toimi muilla kielillä?"
      ]
    },
    {
      "input": "GLUE-tehtävistä nämä huipputason järjestelmät saavuttavat suurimmat voitot hyväksyttävyystehtävässä, jossa käytetään kielellisen hyväksyttävyyden korpusta BIBREF0 . CoLA sisältää esimerkkilauseet kielitieteellisistä julkaisuista, jotka asiantuntijat ovat leimanneet kieliopillisen hyväksyttävyyden kannalta ja jotka on kirjoitettu niin, että niissä näkyy hienovaraisia kieliopillisia piirteitä. Koska minimaaliset syntaktiset erot voivat erottaa hyväksyttävät lauseet hyväksyttävistä lauseista, joita ei voida hyväksyä (Mistä Bo kirjoitti kirjan? / *Mitä kirjaa Bo kirjoitti?), ja hyväksyttävyysluokittelijat ovat luotettavampia, kun ne on koulutettu GPT:llä ja BERT:llä kuin rekursiivisilla malleilla, on loogista, että GPT:llä ja BERT:llä on parempi implisiittinen tietämys hyväksyttävyyden kannalta merkityksellisistä syntaktisista ominaisuuksista.",
      "id": "task461-17649000a6f94c31b83a699fb4f5dd69",
      "output": [
        "Miten CoLA on kieliopillisesti kommentoitu?"
      ]
    },
    {
      "input": "Oppimismalli hakua varten koulutetaan oraakkelilla, joka on rakennettu etävalvonnan avulla. Koulutusjoukon vastausmerkintöjen avulla voidaan löytää sopivia artikkeleita, jotka sisältävät kysymyksessä pyydetyt tiedot. Ensin kysymys ja artikkeli upotetaan vektorisarjoiksi käyttäen samaa menetelmää kuin ymmärtämismallissa. Emme käytä tässä anonymisointia yksinkertaisuuden säilyttämiseksi. Muussa tapauksessa anonymisointimenettely olisi toistettava useita kertoja mahdollisesti suuren asiakirjakokoelman osalta. Nämä vektorisekvenssit syötetään seuraavaksi Bi-GRU:lle, joka tuottaa tulosteet $v$ (kysymyksen osalta) ja $H_c$ (asiakirjan osalta) edellisen jakson tapaan.",
      "id": "task461-cc573bff34884b848de5719c751febc3",
      "output": [
        "Miten neuraalista mallia voidaan käyttää hakuun, jos syötteenä on koko Wikipedia?"
      ]
    },
    {
      "input": "Vertailemme luokittelu- ja regressiomenetelmiä ja osoitamme, että luokittelu tuottaa parempia tuloksia kuin regressio, mutta tulosten laatu riippuu siitä, miten tietojen merkinnät merkitään.",
      "id": "task461-6557468becce4c7790ae90e7f0c54398",
      "output": [
        "Suoriutuivatko luokittelumallit paremmin kuin aiemmat regressiomallit?"
      ]
    },
    {
      "input": "Esittelemme LOG-Cadin, neuroverkkopohjaisen kuvausgeneraattorin (kuva KUVA 1), jolla tämä tehtävä voidaan ratkaista suoraan. Kun annetaan sana ja sen konteksti, generaattorimme hyödyntää kohdesanan upotusta, joka on esivalmennettu massiivisesta tekstistä (globaalit kontekstit), samalla kun se koodaa myös annetun paikallisen kontekstin, ja yhdistää molemmat luodakseen luonnollisen kielellisen kuvauksen.",
      "id": "task461-fc7492295f064e84916b51ed2c9619df",
      "output": [
        "Käytetäänkö niissä esivalmisteltuja sanasulkeumia?"
      ]
    },
    {
      "input": "Yhdistetty mallimme, joka käyttää sekä latenttia että eksplisiittistä rakennetta, toimii parhaiten, sillä se parantaa ROUGE-L:n tuloksia huomattavasti, 1,08 pistettä perusosoitingeneraattorimalliin verrattuna ja 0,6 pistettä ROUGE-1:een verrattuna. ",
      "id": "task461-45ba1abfb5f644cd947d073334e51f42",
      "output": [
        "Kuinka paljon ne paranevat edelliseen huipputekniikkaan verrattuna?"
      ]
    },
    {
      "input": "Tämän tietokokonaisuuden vitsikorpus sisältää tuhansia ainutlaatuisia vitsejä eri kategorioista (scifi, urheilu jne.) ja tyypeistä (sanaleikit, limerikit jne.).",
      "id": "task461-0c5fbe3f88e74cb39ca491ba05c9b0db",
      "output": [
        "Mistä todelliset tuotantotiedot ovat peräisin?"
      ]
    },
    {
      "input": " Perustasomme on kolmikerroksinen LSTM-LM, jossa on 1 150 piilotettua yksikköä sisäisillä kerroksilla ja joka on koulutettu tavanomaisella ristiinentropiahäviöllä. ",
      "id": "task461-a0a6fb1a32584a8bb5c5ae48be795355",
      "output": [
        "Mitä neuraalisia kielimalleja tutkitaan?"
      ]
    },
    {
      "input": "Taulukosta TABREF20 käy ilmi, että WoZ- ja DSTC2-tietoaineistoissa SIM-mallilla on sama määrä parametreja, joka on vain 23 prosenttia ja 19 prosenttia GLAD-mallin parametreista.",
      "id": "task461-b30de0df797643399db0780b1d360017",
      "output": [
        "Miten he mittaavat mallin koon?"
      ]
    },
    {
      "input": "Koska tämä kommentoitujen potilasmuistiinpanojen korpus koostuu alkuperäisistä terveydenhuollon tiedoista, jotka sisältävät vuoden 1996 HIPAA-lain (Health Information Portability and Accountability Act of 1996) BIBREF16 mukaisia suojattuja terveystietoja ja jotka voidaan liittää MIMIC-III-tietokantaan, henkilöiden, jotka haluavat päästä käsiksi tietoihin, on täytettävä kaikki MIMIC-III-tietokantaan sisältyviin tietoihin pääsyä koskevat vaatimukset. Näiden edellytysten täyttämiseksi tietokantaan pääsyä haluavan henkilön on suoritettava \"Data or Specimens Management\" -kurssi sekä allekirjoitettava MIMIC-III-tietokannan verkkosivulla esitetty käyttäjäsopimus, jossa tämän tietokannan uusin versio sijaitsee nimellä \"Annotated Clinical Texts from MIMIC\" BIBREF17. Tähän korpukseen pääsee käsiksi myös GitHubissa, kun kaikki edellä mainitut vaatimukset on täytetty.",
      "id": "task461-2a9e69798d84420e97e53c0bfa76a983",
      "output": [
        "Onko tämä tietokokonaisuus julkisesti saatavilla kaupalliseen käyttöön?"
      ]
    },
    {
      "input": "Lisäksi Bertramin add- ja add-gated-muunnokset toimivat yllättävän hyvin useammin esiintyvien sanojen osalta: WNLaMPro-mediumin pisteet paranevat 50 % verrattuna BERT$_\\text{base}$:iin ja 31 % verrattuna Attentive Mimickingiin.",
      "id": "task461-3fd1d3cdc1d743ddb0d1fc3dc72ab9de",
      "output": [
        "Kuinka paljon harvinaisten ja keskitiheiden sanojen edustavuus on parantunut verrattuna erilliseen yhteistyöhön ja aiempaan työhön?"
      ]
    },
    {
      "input": "Osallistujat, joille näytettiin määritelmä, ehdottivat todennäköisemmin twiitin kieltämistä. Itse asiassa ryhmän yksi osallistujat antoivat hyvin harvoin eri vastauksia kysymyksiin yksi ja kaksi (18 tapausta 500:sta eli 3,6 %). Tämä viittaa siihen, että kyseisen ryhmän osallistujat yhdenmukaistivat oman mielipiteensä määritelmän kanssa.",
      "id": "task461-eb0da24535a64770bc6d9f015375c51a",
      "output": [
        "Miten kirjoittajat osoittivat, että vihapuheen määritelmän esittäminen sai kommentoijat osittain yhdenmukaistamaan oman mielipiteensä määritelmän kanssa?"
      ]
    },
    {
      "input": "Vaikka kilpailussa ehdotetaan kahta erilaista skenaariota, itse asiassa molempia ohjaa snomed ct -ontologia - osatehtävässä 1 entiteetit on tunnistettava offsettien avulla ja ne on yhdistettävä ennalta määriteltyihin neljään luokkaan (PROTEIINIT, NORMALIZABLES, NO_NORMALIZABLES ja UNCLEAR); osatehtävässä 2 on annettava luettelo kaikista tekstissä esiintyvistä entiteettien snomed ct -tunnisteista (sctid), jota yhteisen tehtävän järjestäjät kutsuvat käsiteindeksoinniksi.",
      "id": "task461-c3988b7adc0147d082f35bde1c808725",
      "output": [
        "Mitkä ovat PharmaCoNERin kaksi osatehtävää?"
      ]
    },
    {
      "input": "Pääsyy tähän on se, että tietokokonaisuudet sisältävät vain pienen osan moniulotteisista lauseista, joissa on erilaisia polariteetteja. Huomiohäiriö ei vaikuta kovinkaan paljon sentimentin ennustamiseen yksinäkökulmaisissa lauseissa tai moninäkökulmaisissa lauseissa, joissa on samat polariteetit.",
      "id": "task461-63333aef548c43c3a609ae6e1d6db9f0",
      "output": [
        "Arvioidaanko mallia perusmallia vastaan myös yhden aspektin lauseilla?"
      ]
    },
    {
      "input": "Logoscope hakee päivittäin sanomalehtiartikkeleita useista ranskankielisistä RSS-syötteistä.",
      "id": "task461-bf7cedbb25704eafb09bbd25e0b88c96",
      "output": [
        "Kuinka usein sanomalehtien verkkosivuja selataan päivittäin?"
      ]
    },
    {
      "input": "Kun kaikki sanat, joita vähintään kolme erillistä käyttäjää ei ole käyttänyt harjoitusjoukossa, on jätetty pois, muodostetaan AllWords-malli laskemalla kaikkien jäljelle jäävien sanojen frekvenssit ja harjoittelemalla multinomiaalinen Naive Bayes -luokitin. ",
      "id": "task461-6d903678ac4445eb96aefb1e260f3e4d",
      "output": [
        "Mitä mallia he käyttivät järjestelmässään?"
      ]
    },
    {
      "input": "Tästä syystä käytämme englanninkielisen aineiston perusalgoritmina BIBREF0-tietokannan tuloksia, ja venäjänkielisen aineiston osalta käytimme BIBREF8-tietokannassa kuvattua todennäköisyysperusteista kielimallia.",
      "id": "task461-25d0b61991d54a22a2afc2af3f3ac86a",
      "output": [
        "Mitä kieliä paperissa käytetään?",
        "Arvioidaanko RNN-mallia suhteessa johonkin perustasoon?"
      ]
    },
    {
      "input": "Ensimmäinen osa kuvataan tehtäväksi A, jonka tarkoituksena on tunnistaa aikatietojen rajat ja luokitella ne johonkin seuraavista luokista: päivämäärä, aika, kesto, joukko. Valitsimme kustakin sanojen upotusten ryhmästä (EE, EP, EC) kolme parasta tulosta taulukosta TABREF19, jossa esitetään kaikkien mallien F1-pisteet. Tämän jälkeen arvioimme näitä tuloksia käyttämällä yksityiskohtaisempia mittareita aikatekstien osalta, jotka on esitetty BIBREF:ssä27 .",
      "id": "task461-3e12881cacf8410284cabe5f67f7dd2f",
      "output": [
        "Mitä kokeita esitetään?"
      ]
    },
    {
      "input": "Kokeilussamme verrataan joitakin laajalti käytettyjä tekstin klusterointimenetelmiä lähestymistapaamme. K-means-, Skip-thought Vectors-, Recursive Neural Network- ja Paragraph Vector -pohjaisten klusterointimenetelmien lisäksi neljä perustason klusterointimenetelmää perustuu suoraan suosittuihin valvomattomiin dimensioiden pienentämismenetelmiin, jotka on kuvattu SECREF11 -jaksossa. ",
      "id": "task461-d6b1ec6a2e4e4ee7a2ac91c30585f3ed",
      "output": [
        "Mitä suosittuja klusterointimenetelmiä he kokeilivat?"
      ]
    },
    {
      "input": "BIBREF12 havaitsi kiinalaisessa korpuksessa, että sanamerkintä \"End\" toimii paremmin kuin \"Begin\". Tämä motivoi meitä suorittamaan taaksepäin suuntautuvan ahneen haun kunkin lauseen merkintäsekvenssistä sanojen rajojen tunnistamiseksi. Jos kaksi lauseessa segmentoitua sanaa tunnistetaan substantiiveiksi ja toinen sana on välittömästi ennen toista, yhdistämme niiden rajat ja luomme uuden sanaehdokkaan olion tunnistusta varten. Tämän strategian etuna on löytää nimettyjä entiteettejä, joiden sanan pituus on pitkä. Se myös vähentää eri segmentointikriteerien aiheuttamaa vaikutusta.",
      "id": "task461-47c3c33b81664b27a6aa6c3ff6791eb7",
      "output": [
        "Mitä rajakokoonpanomenetelmää käytetään?"
      ]
    },
    {
      "input": "Käytimme tehtävään kahta tietokokonaisuutta - AMR Bank BIBREF10 ja CNN-Dailymail ( BIBREF11 BIBREF12 ). ",
      "id": "task461-7aa26f5b7688407097055471694aed6b",
      "output": [
        "Mitä tietokokonaisuutta tässä asiakirjassa käytetään?"
      ]
    },
    {
      "input": "Tässä asiakirjassa esitetyt tiedot kerättiin ja validoitiin Mozillan Common Voice -aloitteen avulla. Käyttämällä joko Common Voice -sivustoa tai iPhone-sovellusta osallistujat nauhoittavat äänensä lukemalla näytöllä näkyviä lauseita (ks. kuva (KUVA 5)). Myöhemmin muut osallistujat vahvistavat äänitteet yksinkertaisen äänestysjärjestelmän avulla. Kuvassa (FIGREF6) esitetyssä validointirajapinnassa osallistujat merkitsevät $<$audio,transcript$>$-parit joko oikeiksi (ääni ylös) tai vääriksi (ääni alas).",
      "id": "task461-cd83c8efe52a4251848bb4ce998d0ea9",
      "output": [
        "Mitä joukkoistamisalustaa käytetään tietojen keräämiseen ja validointiin?"
      ]
    },
    {
      "input": "Harkitsemme seuraavia mittareita eri esitysten automaattista arviointia varten. Yhteisen tavoitteen tarkkuutta on käytetty ensisijaisena metriikkana esitysten sijoittamisessa paremmuusjärjestykseen.Active Intent Accuracy: Pyydettyjen aikojen F1: Pyydettyjen aikojen makrokeskiarvoinen F1-pistemäärä kaikista hyväksyttävistä aikojen aikomuksista. Käännöksiä, joissa ei ole pyydettyjä aikoja pohjatodellisuudessa ja ennusteissa, ei oteta huomioon.Average Goal Accuracy: Kullekin vuorolle ennustetaan yksi arvo jokaiselle dialogin tilassa olevalle aikavälille. Tämä on keskimääräinen tarkkuus, jolla slotin arvo ennustetaan oikein.Joint Goal Accuracy: Tämä on keskimääräinen tarkkuus, jolla ennustetaan oikein kaikki tietyn palvelun lähtöarvot vuorossa.",
      "id": "task461-e203ba422b414640b484f0090e29e5c7",
      "output": [
        "Miten malleja arvioidaan?"
      ]
    },
    {
      "input": "Käyntien vektorikuvausten välisen euklidisen etäisyyden perusteella sovellettiin ja verrattiin kahta klusterointialgoritmia: k-means ja hierarkkinen klusterointi Wardin menetelmällä klustereiden yhdistämiseksi BIBREF23 .",
      "id": "task461-147d1823fbbd4229aa31c0417acaf5f3",
      "output": [
        "Mitä klusterointitekniikkaa he käyttävät osanottajien vierailuteksteihin?"
      ]
    },
    {
      "input": "Panoksemme hyödyntää valmiiksi koulutettuja sanojen upotuksia (GloVe, koulutettu wikipedia+gigaword-korpuksen pohjalta), DepecheMood-vaikutteista leksikkoa ja konvoluutiohermoverkkoja.",
      "id": "task461-f61e1a1081a649c6b3485687b12d25a1",
      "output": [
        "Mitä sulautumia he käyttävät?",
        "Mikä on heidän sanastonsa lähde?"
      ]
    },
    {
      "input": "Työskentelemme neljän yksittäisen tietokokonaisuuden kanssa. Tietoaineistot sisältävät yhteen-, vähennys-, kerto- ja jakotehtäviä.AI2 BIBREF2. AI2 on kokoelma 395 yhteen- ja vähennyslaskuongelmaa, jotka sisältävät numeerisia arvoja, joista osa voi olla kysymyksen kannalta epäolennaisia.CC BIBREF19. Common Core -tietokokonaisuus sisältää 600 2-vaiheista kysymystä. Pennsylvanian yliopiston Cognitive Computation Group kokosi nämä kysymykset.IL BIBREF4. Illinoisin tietokokonaisuus sisältää 562 1-vaiheista algebran sanakysymystä. Cognitive Computation Group kokosi myös nämä kysymykset.MAWPS BIBREF20. MAWPS on suhteellisen laaja kokoelma, joka on peräisin pääasiassa muista MWP-tietokannoista. Käytämme 2 373:aa tämän joukon 3 915:stä MWP:stä.",
      "id": "task461-42fe98013e704af18e64ed01ce868cbc",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": "Tässä jaksossa raportoidaan kokeista, jotka on tehty edellä kuvatun järjestelmän ja tietojen avulla. Ensin esitellään englanninkieliset tulokset kolmesta ABSA-julkaisusta sekä vertailu aiempaan työhön. Sen jälkeen teemme saman viidelle muulle kielelle, jotka sisältyvät ABSA 2016 -painokseen: hollanti, ranska, venäjä, espanja ja turkki. Paikalliset ja klusterointiominaisuudet, jotka on kuvattu kohdassa SECREF11 , ovat samat jokaiselle kielelle ja arviointiasetelmalle. Ainoa muutos on eri kielissä käytettävät klusterointisanakirjat. Kuten kohdassa SECREF11 todetaan, paras klusteriyhdistelmä valitaan harjoitusaineistosta viisinkertaisella ristiinvalidoinnilla (CV). Ensin kokeillaan jokaista permutaatiota Clark- ja Word2vec-klustereilla. Kun paras yhdistelmä on saatu, kokeillaan Brownin klustereilla, jolloin saadaan lopullinen malli kullekin kielelle ja tietokokonaisuudelle.",
      "id": "task461-fc8e544f6b4f4fdfabd09d1fec934eff",
      "output": [
        "Mitä kuutta kieltä kokeillaan?"
      ]
    },
    {
      "input": "Lopuksi muutamme luokiteltavan tekstin skalaareiksi, jotka kuvaavat niiden etäisyyttä rakennetusta vihavektorista, ja käytämme näitä satunnaismetsäluokittimen syötteenä.",
      "id": "task461-832c26191b4c4e28a19f31b7a0b93c64",
      "output": [
        "Mitä luokittelulaitetta he käyttivät?"
      ]
    },
    {
      "input": "Vertaillaksemme neuromalliamme perinteisiin lähestymistapoihin, kokeilimme useita olemassa olevia malleja, kuten: Logistinen regressio (LR), erotteleva todennäköisyysmalli, ja Random Forest (RF), päätöspuiden yhdistelmämalli.",
      "id": "task461-6baa90ff418b426aa1f77fb7dee4612d",
      "output": [
        "Mikä oli heidän lähtötasonsa?"
      ]
    },
    {
      "input": "Useimmissa aiemmissa töissä keskitytään loukkaavan kielen eri osa-alueisiin, kuten loukkaavaan kieleen BIBREF0 , BIBREF1 , (verkko)aggressioon BIBREF2 , (verkko)kiusaamiseen BIBREF3 , BIBREF4 , myrkyllisiin kommentteihin INLINEFORM0 , vihapuheeseen BIBREF5 , BIBREF6 , BIBREF7 , BIBREF7 , BIBREF8 , BIBREF8 , BIBREF8 , BIBREF8 , BIBREF8 , BIBREF9 , BIPREF9 , BIBREF10 , ja hyökkäävään kielenkäyttöön BIPREF11 . Aiemmissa töissä on keskitytty näihin loukkaavan kielen näkökohtiin Twitterissä BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedian kommenteissa ja Facebook-postauksissa BIBREF2 .",
      "id": "task461-cbe36f4de04d4cda9ea48ce9800a8b6b",
      "output": [
        "Mikä on loukkaavan kielenkäytön määritelmä?"
      ]
    },
    {
      "input": "Huomattavaa on, että vaikka arkkitehtuurimme perustuu ja on integroitu BERT$_\\text{base}$-malliin, se jopa päihittää erillisen BERT$_\\text{large}$-mallin huomattavasti.",
      "id": "task461-82adbcb22fe54ccbb8531d036c9d974d",
      "output": [
        "Mihin muihin malleihin kuin erilliseen BERT-malliin uutta mallia verrataan?"
      ]
    },
    {
      "input": "Annotaatioprojektiomenetelmä, jota noudatamme tässä työssä, on yksi tapa ratkaista tämä ongelma. Se otettiin käyttöön POS-merkintää, substantiivilauseiden perussanojen sulkeistamista, NER-merkintää ja taivutusmorfologista analyysia varten BIBREF29 , mutta sitä on käytetty myös riippuvuusjäsennykseen BIBREF30 , roolimerkintään BIBREF31 , BIBREF32 ja semanttiseen jäsennykseen BIBREF26 .",
      "id": "task461-58c133d538d94760928dcb7f033165b1",
      "output": [
        "Testaavatko kirjoittajat annotaatioprojisointitekniikoitaan muissa tehtävissä kuin AMR:ssä?"
      ]
    },
    {
      "input": "Esimerkiksi BIBREF16 ja BIBREF17 osoittivat, että vain hypoteeseja sisältävä perustaso suoriutuu satunnaista paremmin leksikaaliseen valintaan ja lauseen pituuteen liittyvien vihjeiden ansiosta. Vastaavasti BIBREF18 osoitti, että NLI-malleilla on taipumus ennustaa entailment lausepareille, joissa on paljon leksikaalista päällekkäisyyttä.",
      "id": "task461-a3a1c63c833247b9957ad26542afc801",
      "output": [
        "Mitkä ovat esimerkkejä näistä esineistä?"
      ]
    },
    {
      "input": "CNN-C tarkoittaa CNN:ää, jossa on (kiinalaisten) merkkien upotus.CNN-W tarkoittaa CNN:ää, jossa on (kiinalaisten) sanojen upotus.CNN-Lex-C tarkoittaa algoritmia, jossa CNN:ään integroidaan myös polaariset sanat, ja jota ovat ehdottaneet Shin et al. BIBREF24 . CNN-Lex-W tarkoittaa algoritmia, joka integroi myös polaariset sanat CNN:ään, jota Shin et al. ovat ehdottaneet BIBREF24 . Bi-LSTM-C tarkoittaa BI-LSTM:ää, jossa on (kiinalaisten) merkkien upotus.Bi-LSTM-W tarkoittaa Bi-LSTM:ää, jossa on (kiinalaisten) sanojen upotus.Lex-rule tarkoittaa kuvassa 1 esitettyä sääntöpohjaista lähestymistapaa. BOW tarkoittaa perinteistä algoritmia, joka perustuu sanasäkkiominaisuuksiin.",
      "id": "task461-6617f51ce2184e949432795d3ea0cba0",
      "output": [
        "Mihin muihin malleihin niitä verrataan?"
      ]
    },
    {
      "input": "Muunnetun semanttisen avaruuden luotettavuuden todentamiseksi ehdotamme sanojen samankaltaisuustietokantoihin perustuvaa arviointivertailua. Kun otetaan huomioon rikastettu avaruus INLINEFORM0 ja samankaltaisuustietokanta INLINEFORM1 , lasketaan kunkin sanaparin INLINEFORM2 samankaltaisuus näiden kahden avaruuden vastaavien muunnettujen vektoreiden INLINEFORM3 ja INLINEFORM4 kosinuskohtaisena samankaltaisuutena, jossa INLINEFORM5 ja INLINEFORM6 LS:lle ja INLINEFORM7 ja INLINEFORM8 CCA:lle. Korkea suorituskyky tässä vertailuarvossa osoittaa, että kartoitus on onnistunut sijoittamaan semanttisesti samankaltaiset termit lähelle toisiaan, kun taas toisistaan poikkeavat termit ovat suhteellisen kaukana toisistaan avaruudessa. Toistamme laskennan kullekin parille päinvastaiseen suuntaan.",
      "id": "task461-6f7b925da2894da8944bbbdfe10559fb",
      "output": [
        "Miten suorituskykyä mitataan?"
      ]
    },
    {
      "input": "Sekä Yhdistyneen kuningaskunnan että Ranskan sulauttamismatriisien ensimmäiset analyysit osoittivat, että sanat ryhmiteltiin yleensä asiayhteyden tai sähkönkulutukseen kohdistuvan vaikutuksen mukaan. Havaitsimme esimerkiksi, että talvisanat olivat yhdessä ja kaukana kesäsanoista. ",
      "id": "task461-d9489adadcd242c387de55a091f8620e",
      "output": [
        "Onko olemassa esimerkkejä, joissa geometrinen ominaisuus näkyy sanojen samankaltaisuuden kontekstissa?"
      ]
    },
    {
      "input": "Konekäännöstä käytetään kemian tietotekniikassa \"kääntämisessä\" yhdeltä kieleltä (esim. reaktiot) toiselle (esim. tuotteet). Variational Auto-encoder (VAE) on toinen laajalti käytetty tekstinmuodostusarkkitehtuuri BIBREF101. Generative Adversarial Network (GAN) -mallit tuottavat uusia molekyylejä käyttämällä kahta komponenttia: generaattoriverkko tuottaa uusia molekyylejä, ja diskriminaattoriverkon tarkoituksena on erottaa generoidut molekyylit todellisista molekyyleistä BIBREF107.",
      "id": "task461-10ddb76c457843f8849a73804b7a9756",
      "output": [
        "Ovatko nämä mallit yleensä puolivalvottuja vai valvomattomia?"
      ]
    },
    {
      "input": "Otimme japanilaisia sanapareja Evaluation Dataset of Japanese Lexical Simplification kodaira -aineistosta. ",
      "id": "task461-5048958f5ccd4da08d6bc95bb150c0ab",
      "output": [
        "mistä tiedot ovat peräisin?"
      ]
    },
    {
      "input": "Kaikki tiedot ladattiin Twitteristä kahdessa erillisessä erässä käyttämällä \"twint\"-kaapimistyökalua BIBREF5 otokseen historiallisia twiittejä useilla eri hakusanoilla; kyselyihin sisältyi aina joko \"ilmastonmuutos\" tai \"ilmaston lämpeneminen\", ja lisäksi niihin sisältyi katastrofikohtaisia hakusanoja (esim. \"pommisykloni\", \"lumimyrsky\", \"lumimyrsky\" jne.). ",
      "id": "task461-c1ba105352a745bd9324122c6be3bafc",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Voimme nähdä, että 1.10älykkyyden käyttö vaihtelee eri aloilla: tietotekniikan alalla samankaltaisimpia sanoja ovat 1.10artificial ja 1.10ai; rahoituksen alalla samankaltaisia sanoja ovat 1.10abilities ja 1.10consciousness.",
      "id": "task461-b0a084510cea48f997f59e9668b67e57",
      "output": [
        "Mitä sanoja käytetään eri tavoin ArXivissa?"
      ]
    },
    {
      "input": "Osoitimme Katecheon käyttökelpoisuuden ottamalla järjestelmän käyttöön kysymyksiin vastaamiseen kahdessa aiheessa, lääketieteessä ja kristinuskossa.",
      "id": "task461-15478a45a1114a0a8162bb3f6bd9fbc8",
      "output": [
        "kuinka monta verkkotunnusta he kokeilivat?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa keskityimme suosittelujärjestelmien LDA-lähestymistapoihin, ja koska tutkimus on tärkeää, olemme tutkineet viimeaikaisia vaikuttavia artikkeleita tästä aiheesta ja esittäneet viimeaikaisen tutkimuksen LDA:han perustuvien suosittelujärjestelmien taksonomian. arvioimme ISWC- ja WWW-konferenssien artikkeleita DBLP-sivustolta ja käytimme Gibbs-näytteenottoalgoritmia arviointiparametrina. Onnistuimme löytämään LDA-aiheiden ja artikkelien ominaisuuksien välisen suhteen ja saimme myös tutkijoiden kiinnostuksen tutkimusalaa kohtaan. Likimääräisen päättelyn ja LDA:n oppimisen suorittamiseksi on olemassa monia päättelymenetelmiä LDA:n aihepiirimallia varten, kuten Gibbs-näytteenotto, romahtanut Variational Bayes, Expectation Maximization. Gibbs-näytteenotto on suosittu tekniikka sen yksinkertaisuuden ja alhaisen latenssin vuoksi. Suurten aiheiden lukumäärän tapauksessa Gibbs sampling voi kuitenkin muuttua hankalaksi. Tässä artikkelissa käytämme Gibbs Sampling -menetelmää kokeessamme luvussa 5.",
      "id": "task461-4fd731ccee8e423e9b31fcfe719cc223",
      "output": [
        "Miten he käyttävät LDA:ta ja Gibbs-näytteenottoa ISWC- ja WWW-julkaisujen arviointiin?"
      ]
    },
    {
      "input": "Näin ollen olemme määritelleet kohteiksemme Galatasarayn (eli Kohde-1) ja Fenerbahçen (eli Kohde-2), jotka ovat kaksi Turkin suosituinta jalkapalloseuraa.",
      "id": "task461-361e664f3a5d4d73a33820b305c66b3a",
      "output": [
        "Mitkä urheiluseurat ovat kohteita?"
      ]
    },
    {
      "input": "Odotamme, että selityksen suorituskyvyn pitäisi korreloida ennustuskyvyn kanssa. Koska mahdollista vastausta koskevaa tietoa tarvitaan ensisijaisesti päättämään, onko verkolla riittävästi tietoa vastata haastekysymykseen arvaamatta, ja relevanttia muuttujaa koskevaa tietoa tarvitaan, jotta verkko tietäisi, mitä kysyä, analysoimme verkon suorituskykyä kyselyssä ja vastaamisessa erikseen. Muistiverkolla on erityisiä vaikeuksia oppia kyselemään relevantteja muuttujia, sillä se saavuttaa vain noin 0,5 prosentin tarkkuuden kysyttäessä. Samaan aikaan se oppii vastaamaan erittäin hyvin, sillä se saavuttaa yli 0,9 prosentin tarkkuuden. Koska pyydämme sitä selittämään näitä vuorovaikutuksen kahta osaa kahdessa tilassa, havaitsemme, että selitysten laatu korreloi vahvasti verkon suorittaman algoritmin laadun kanssa.",
      "id": "task461-fc3b5b01e1c74468b733ce5273b9a772",
      "output": [
        "Miten he mittaavat korrelaatiota ennusteen ja selityksen laadun välillä?"
      ]
    },
    {
      "input": "Tässä artikkelissa tarkastellaan mahdollisuuksia ennustaa käyttäjän toimiala - tietyn alan yritysten kokonaisuus - tunnistamalla sosiaalisessa mediassa esiintyvää toimialakohtaista tekstiä. ",
      "id": "task461-138d35e4f30347e89365b08763b1c410",
      "output": [
        "Mitä he tarkoittavat henkilön toimialalla?"
      ]
    },
    {
      "input": "1. BERT-pohjainen hienosäätö: Ensimmäisessä lähestymistavassa, joka on esitetty kuvassa KUVA 8, BERT-pohjaan tehdään hyvin vähän muutoksia. Tässä arkkitehtuurissa käytetään ainoastaan yhteistyöelimen antamaa [CLS]-merkin ulostuloa. [CLS]-ulostulo, joka vastaa 12. muuntajakooderin [CLS]-merkkilähdettä, joka on 768-kokoinen vektori, annetaan syötteenä täysin kytketylle verkolle, jossa ei ole piilokerrosta. Piilokerrokseen sovelletaan luokittelua varten softmax-aktivointifunktiota. 2. Lisätään epälineaarisia kerroksia: Tässä päivitetään ensimmäistä arkkitehtuuria ja luodaan arkkitehtuuri, jossa on kestävämpi luokittelija ja jossa käytetään täysin kytkettyä verkkoa, jossa ei ole piilokerrosta, vaan täysin kytkettyä verkkoa, jossa on kaksi piilokerrosta, joiden koko on 768. Tässä käytetään täysin kytkettyä verkkoa, jossa on kaksi piilokerrosta, joiden koko on 768. Kahdessa ensimmäisessä kerroksessa käytetään Leaky Relu -aktivointifunktiota, jonka negatiivinen kaltevuus = 0,01, mutta viimeisessä kerroksessa käytetään ensimmäisen arkkitehtuurin tapaan softmax-aktivointifunktiota, kuten kuvassa KUVA 8.3 esitetään. Lisätään Bi-LSTM-kerros: Toisin kuin aiemmissa arkkitehtuureissa, joissa käytetään vain [CLS] luokittimen syötteenä, tässä arkkitehtuurissa viimeisimmän muuntajakooderin kaikkia ulostuloja käytetään siten, että ne annetaan syötteenä kaksisuuntaiselle rekursiiviselle neuroverkolle (Bi-LSTM), kuten kuvassa FIGREF8 on esitetty. Syötteen käsittelyn jälkeen verkko lähettää lopullisen piilotetun tilan täysin kytketylle verkolle, joka suorittaa luokittelun käyttäen softmax-aktivointifunktiota. 4. Lisää CNN-kerros: Tässä kuvassa FIGREF8 esitetyssä arkkitehtuurissa käytetään kaikkien muuntajakoodereiden ulostuloja sen sijaan, että käytettäisiin viimeisimmän muuntajakooderin ulostuloa. Kunkin muuntajakoodaajan ulostulovektorit yhdistetään ja tuotetaan matriisi. Konvoluutio-operaatio suoritetaan ikkunalla, jonka koko on (3, BERT:n piilokoko, joka on 768 BERTbase-mallissa), ja maksimiarvo tuotetaan kullekin muuntajakooderille soveltamalla max poolingia konvoluutiotulokseen. Yhdistämällä nämä arvot luodaan vektori, joka annetaan syötteenä täysin kytketylle verkolle. Soveltamalla softmaxia syötteeseen suoritetaan luokitteluoperaatio.",
      "id": "task461-190de633de724049820bb8ed35597782",
      "output": [
        "Mitä uusia hienosäätömenetelmiä esitellään?"
      ]
    },
    {
      "input": "ConvE:ssä vain $v_h$ ja $v_r$ muotoillaan uudelleen ja yhdistetään sitten tulomatriisiksi, joka syötetään konvoluutiokerrokseen.",
      "id": "task461-d3d9c97511f94d58b069cf72c59837ac",
      "output": [
        "Kokeilivatko kirjoittajat useiden konvoluutiokerrosten pinoamista?"
      ]
    },
    {
      "input": "Kokeissamme käytämme APDA:n yhteisten tehtävien järjestäjien julkaisemia tietoja. Tietokokonaisuus on jaettu järjestäjien mukaan train- ja testitietokokonaisuuksiin. Koulutusjoukkoon jaetaan merkinnät kolmea tehtävää varten: ikä, murre ja sukupuoli.",
      "id": "task461-c8c07cd3fc1b4692a4496e902b67229d",
      "output": [
        "Mitä kolmea tietokokonaisuutta käytetään tutkimuksessa?"
      ]
    },
    {
      "input": "Chatino on Meksikon Oaxacassa puhuttu kieliryhmä. Chatino-kielet muodostavat yhdessä zapotekkien kieliryhmän kanssa otomanguean kieliperheen zapotekkihaaran. ",
      "id": "task461-bbf281661a9b48458af06ff01efff82e",
      "output": [
        "Mihin kieliperheeseen chatino kuuluu?"
      ]
    },
    {
      "input": "Toiminnallinen eroavuuspistemäärä laskettiin käyttämällä CoNLL 2017 Universal Dependencies -tehtävän BIBREF20 testijoukon lauseita kyseisillä kielillä, joiden UPOS-sekvenssit on annettu. Laskimme lähimpien naapureiden kokeen kaikille kielille edellä mainittujen mallien harjoitusaineistossa.",
      "id": "task461-0019f5ddc52245c4a7d5a0a2337b1813",
      "output": [
        "Mitä arviointimittareita he käyttävät kielen mallintamisessa?"
      ]
    },
    {
      "input": "Toisessa algoritmissa käytetään viimeaikaisia ajatuksia tietojen valinnasta konekääntämisessä BIBREF7 . Kehitämme näiden ongelmien ratkaisemiseksi uudenlaisen uudelleenpainotusmenetelmän, jossa hyödynnetään ajatuksia, jotka ovat saaneet inspiraationsa konekääntämisen tiedonvalinnasta BIBREF26 , BIBREF7 .",
      "id": "task461-e8e27a79a4b2462fb7d44ae596c81da2",
      "output": [
        "Mikä on tietojen valinta paperi konekääntäminen"
      ]
    },
    {
      "input": "Tietojemme mukaan ainoa tieteellisen tiivistämisen vertailuarvo on TAC 2014:n tiivistämisraiteelta. Rouge-varianttien ja metriikkamme (Sera) tehokkuuden arvioimiseksi käytämme tätä vertailukohtaa, joka koostuu 20 aihealueesta, joista jokaisessa on biolääketieteellisen lehden artikkeli ja 4 ihmisen kirjoittamaa kultaista tiivistelmää. Tarkastellaan seuraavaa esimerkkiä: Endogeenisiä pieniä RNA:ita (miRNA) seulottiin geneettisesti ja tutkittiin niiden miRNA:iden löytämiseksi, jotka liittyvät kasvainten syntyyn.",
      "id": "task461-e26afa6982fc4e25acef8fd968b2ec12",
      "output": [
        "Raportoivatko kirjoittajat tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Vaikka on selvää, että sulautuksiamme voidaan käyttää uusien ennustemallien ominaisuuksina, on myös hyvin helppoa sisällyttää oppimamme Dolores-sulautumat olemassa oleviin tietämysgraafeihin perustuviin ennustemalleihin. Ainoa vaatimus on, että malli hyväksyy syötteenä upotuskerroksen (olioille ja suhteille). Jos malli täyttää tämän vaatimuksen (ja monet tietämysgraafeihin perustuvat neuraaliset mallit täyttävät tämän vaatimuksen), voimme käyttää Dolores-istutuksia korvaavana vaihtoehtona. Aloitamme vain vastaavan upotuskerroksen Doloresin upotuksilla. Jäljempänä esitettävässä arvioinnissa osoitamme, miten useita uusimpia malleja voidaan parantaa eri tehtävissä yksinkertaisesti ottamalla Dolores käyttöön alkuperäisen upotuskerroksen tilalle.",
      "id": "task461-d32c65a250634b40ac5a207ca56778fc",
      "output": [
        "Miten kuvaajan mielekkäät ketjut valitaan?"
      ]
    },
    {
      "input": "Luomme kuvaajan käyttäen kaikkia tietoja, ja harjoitussarjan twiiteillä on alkuperäinen kielitunnistejakauma. Naiivi lähestymistapa twiitti-twiitti-aligraafin rakentamiseen vaatii O( INLINEFORM0 ) vertailua, jossa mitataan kunkin twiitin samankaltaisuutta kaikkien muiden kanssa. Sen sijaan suoritimme INLINEFORM1 -lähimmän naapurin luokittelun kaikille twiiteille, jotka esitettiin unigrammien säkkinä, ja vertasimme kutakin twiittiä ja INLINEFORM2 -naapureita. Käytimme Junto (mad) BIBREF5 -järjestelmää etsiessämme merkintöjä merkityistä solmuista merkitsemättömiin solmuihin. Konvergenssin jälkeen normalisoimme uudelleen alun perin merkitsemättömien solmujen merkintäpisteet INLINEFORM4 -arvon löytämiseksi.",
      "id": "task461-9789ca33d9754a06883cec17fe93a491",
      "output": [
        "Miten merkinnät levitetään tätä lähestymistapaa käytettäessä?"
      ]
    },
    {
      "input": "Rakennamme kolme tietokokonaisuutta, jotka perustuvat IMDB- ja Yelp-arvosteluihin. IMDB-tietokanta binarisoidaan ja jaetaan harjoitus- ja testijoukkoon, joissa kummassakin on 25 000 arvostelua (2 000 arvostelua harjoitusjoukosta on varattu kehittämistä varten). Yelpin osalta binarisoimme arvostelut ja luomme kaksi tietokokonaisuutta, joissa säilytämme vain arvostelut, joissa on $\\le $ 50 -merkkejä (yelp50) ja $\\le $ 200 -merkkejä (yelp200).",
      "id": "task461-556a79942ff34a559cc520e130ef837f",
      "output": [
        "Mitä tietokokonaisuuksia ne käyttävät?"
      ]
    },
    {
      "input": "Esittelemämme QA-CTS-tehtävä yhtenäistää perinteisen CTS-tehtävän tulostusmuodon ja tekee harjoitustiedoista yhteiskäyttöisiä, mikä rikastuttaa harjoitustietoja. Kaikki kysymys-vastausparit ovat neljän kliinikon kommentoimia ja tarkistamia kolmenlaisilla kysymystyypeillä, nimittäin kasvaimen koolla, proksimaalisella resektiomarginaalilla ja distaalisella resektiomarginaalilla.  Kokeelliset tulokset reaalimaailman aineistolla osoittavat, että ehdotettu malli kilpailee vahvojen perusmallien kanssa kaikissa kolmessa erityistehtävässä.",
      "id": "task461-0e9b5a3b420b467b8ea528c9c28e45b1",
      "output": [
        "Mitkä ovat yhdistettävät erityistehtävät?"
      ]
    },
    {
      "input": "On myös huomattava, että signaalit voidaan tunnistaa, vaikka malli luokittelisi suhteet väärin, koska ${\\Delta }_s$ ei perustu oikeaan luokitteluun: se ainoastaan mittaa sanan osuutta kontekstissa oikean merkinnän pistemäärään. Jos tarkastelemme kunkin sanan vaikutusta oikean relaation pistemäärään, tämän vaikutuksen pitäisi edelleen korreloida ja korreloi ihmisen arvioiden kanssa, jotka perustuvat siihen, mitä järjestelmä saattaa merkitä toiseksi tai kolmanneksi parhaaksi luokaksi.",
      "id": "task461-6f20c0c1211e49ed853f050001b27645",
      "output": [
        "Missä ehdotettu metriikka on päällekkäinen juman-tuomion kanssa?"
      ]
    },
    {
      "input": "Koska INLINEFORM1:n merkinnät ovat tuntemattomia, EGL laskee gradienttinormin odotuksen kaikkien mahdollisten merkintöjen osalta. BIBREF3 tulkitsee EGL:n \"odotetuksi mallin muutokseksi\". Seuraavassa luvussa virallistetaan EGL:n intuitiota ja osoitetaan, että se seuraa luonnollisesti estimaattorin varianssin pienentämisestä. Yhtälö ( EQREF7 ) osoittaa, että INLINEFORM0:n pienentämiseksi testiaineistossa meidän on minimoitava odotettu varianssi INLINEFORM1 testijoukossa. Käytännön ongelmana on se, että emme tiedä INLINEFORM0:ta etukäteen. Voisimme sen sijaan korvata INLINEFORM1-estimaatin esivalmistellusta mallista, jossa on järkevää olettaa INLINEFORM2 olevan lähellä todellista INLINEFORM3 . Erävalinta toimii tällöin siten, että otetaan näytteet, joilla on suurimmat gradienttinormit, DISPLAYFORM0RNN:lle voidaan saada kunkin mahdollisen etiketin gradientit takaisinlevittämällä. Toinen käytännön ongelma on se, että EGL marginalisoi kaikki mahdolliset merkinnät, mutta puheentunnistuksessa merkintöjen määrä skaalautuu eksponentiaalisesti aika-askeleiden määrään. Siksi marginalisoimme vain INLINEFORM0 todennäköisimmät merkinnät. Ne saadaan palkkihakupurkujen dekoodauksella, kuten BIBREFissä7 . BIBREF3:n EGL-menetelmä on lähes sama kuin yhtälö ( EQREF8 ), paitsi että gradientin normi ei ole BIBREF3:ssa neliöllinen.",
      "id": "task461-40be583434e7482a9214ef91c9c144b5",
      "output": [
        "Miten he laskevat varianssin mallin tuloksista?"
      ]
    },
    {
      "input": "Tämän tutkimuksen tavoitteena on tarjota empiiristä näyttöä siitä, että saksankielisten tekstien avoimia tietolähteitä hyödyntämällä on mahdollista ennustaa poliittisia ennakkoluuloja automaattisesti ja todennäköistä tarkemmin.",
      "id": "task461-34c2924c3f1e47068c9549b19be4ff84",
      "output": [
        "Mistä maista ja kielistä poliittiset puheet ja manifestit ovat peräisin?"
      ]
    },
    {
      "input": "koneen ymmärtäminen Nelufar ",
      "id": "task461-2fec5ca47388431380b7b0754b2c10ba",
      "output": [
        "Mistä MC on lyhenne?"
      ]
    },
    {
      "input": "Twitter API BIBREF15 -rajapinnasta poimitaan yhteensä 2 50 000 Microsoftia koskevaa twiittiä 31. elokuuta 2015 - 25. elokuuta 2016 väliseltä ajalta. Mukaan otettiin myös Microsoftia koskevat Twitter-uutiset ja tuotejulkaisuja koskevat twiitit. Microsoftin osakkeen avaus- ja päätöskurssit 31. elokuuta 2015 ja 25. elokuuta 2016 väliseltä ajalta on saatu Yahoo! Finance BIBREF16 .",
      "id": "task461-4e9610d56ed14592a9df8d960027a037",
      "output": [
        "Mitä tietokokonaisuutta käytetään mallin kouluttamiseen?"
      ]
    },
    {
      "input": "Tarkastelemme kolmea vertailutietoaineistoa: ( INLINEFORM0 ) Cora, BIBREF44 -ohjelmalla luotu tekstitietoja sisältävä viittausverkko.  Hepth, Arxivista peräisin oleva korkean energian fysiikan teoriaa käsittelevä paperiviittausverkko, jossa paperien tiivistelmät ovat tekstitietoa. ( INLINEFORM2 ) Zhihu, BIBREF9:n rakentama Q&A-verkostotietokanta, jossa on 10 000 aktiivista käyttäjää tekstikuvauksineen ja heidän yhteistyölinkkeineen. ",
      "id": "task461-f4a6d23249a74251b3027bfab3cf5419",
      "output": [
        "Mitä tekstiaineistoa he käyttävät?"
      ]
    },
    {
      "input": "Käytämme yhtä julkista tietokokonaisuutta Social Honeypot -tietokokonaisuutta ja yhtä itse kerättyä tietokokonaisuutta Weibo-tietokokonaisuutta validoidaksemme ehdotettujen ominaisuuksien tehokkuuden. Ennen kuin suoritamme kokeet suoraan käytetyillä tietokokonaisuuksilla, poistamme ensin joitakin tilejä, joilla on vain vähän viestejä, koska twiittien määrä viittaa hyvin paljon roskapostittajiin. Englanninkielisestä Honeypot-tietokannasta poistetaan stopwords, välimerkit, muut kuin ASCII-sanat ja tehdään stemming. Kiinalaisen Weibo-tietokannan segmentointi suoritetaan kiinalaisen tekstin segmentointityökalun Jieban avulla. Esikäsittelyvaiheiden jälkeen Weibo-tietokanta sisältää 2197 laillista käyttäjää ja 802 roskapostittajaa, ja honeypot-tietokanta sisältää 2218 laillista käyttäjää ja 2947 roskapostittajaa.",
      "id": "task461-478f3c4bdaad4e0ebd44b295eb870475",
      "output": [
        "Mikä on vertailuaineisto ja onko sen laatu korkea?"
      ]
    },
    {
      "input": "Edellä esitetyn mukaisesti tehtävässä on havaittava semanttinen muutos kahden korpuksen välillä. Jaetussa tehtävässä käytetyt kaksi korpusta vastaavat BIBREF0:n diakronista korpusparia: DTA18 ja DTA19. Ne koostuvat DTA-korpuksen BIBREF11 osista, joka on vapaasti saatavilla oleva lemmatoitu, POS-tagitettu ja oikeinkirjoitusnormalisoitu saksan kielen diakroninen korpus, joka sisältää tekstejä 1500-luvulta 1900-luvulle. DTA18 sisältää 26 miljoonaa lausetta, jotka on julkaistu vuosina 1750-1799, ja DTA19 40 miljoonaa lausetta, jotka on julkaistu vuosina 1850-1899.",
      "id": "task461-2b61c11ddc6246f48b3c0b93eb6320c4",
      "output": [
        "Mitä korpusta käytetään tehtävässä?"
      ]
    },
    {
      "input": "Kaikista yksittäisistä malleista LFT toimii parhaiten, ja sen jälkeen tulee MinAvgOut. RL on myös vertailukelpoinen aiempien huippumallien VHRED (attn) ja Reranking-RL kanssa. Uskomme, että tämä johtuu siitä, että LFT ei käytä voimaa vetääkseen mallin ennusteita pois perustotuuden merkkien luota, vaan se vain tekee itsensä tietoiseksi siitä, kuinka tylsiä kukin vastaus on. Näin ollen sen vastaukset vaikuttavat merkityksellisemmiltä kuin kahden muun lähestymistavan vastaukset. Lisäksi hybridimalli (viimeinen rivi) päihittää kaikki muut mallit selvästi. ",
      "id": "task461-a16bd5c2943b431da59338cd83ace3ea",
      "output": [
        "Mikä neljästä ehdotetusta mallista toimi parhaiten?"
      ]
    },
    {
      "input": "Käytämme ensin ennusteita, jotka perustuvat kirjallisuudessa aiemmin ehdotettuihin sääntöihin: sanan pituus, foneemien määrä, tavujen määrä, aakkosjärjestys ja taajuus. ",
      "id": "task461-0670876178134b958a52cbb6650e097d",
      "output": [
        "Mitä aiemmin ehdotettuja sääntöjä käytetään kaksisuuntaisen järjestyksen ennustamiseen?"
      ]
    },
    {
      "input": "Verrattuna BERT-BASE-malliin BERT-SPC parantaa huomattavasti aspektin polariteetin luokittelun tarkkuutta ja F1-pistemäärää.",
      "id": "task461-7a46bc5a279747258d477d7c069bda45",
      "output": [
        "Kuinka paljon parempi on ehdotetun mallin suorituskyky verrattuna nykyiseen tekniikkaan näissä eri kokeissa?"
      ]
    },
    {
      "input": "Tämän seurauksena siirtokoulutus, jossa on vain 1000 tunnin tiedot, voi vastata 7300 tunnin tiedot sisältävän täyden koulutuksen suorituskykyä.",
      "id": "task461-51683d9948404fa8945634b0dd769aa0",
      "output": [
        "kuinka pienellä aineistolla he harjoittelivat?"
      ]
    },
    {
      "input": "Taulukossa TABREF16 esitetään kasvojen ja äänen tunnetunnistuksen sekoitusmatriisit koko AMMER-aineistolla, ja taulukossa TABREF17 esitetään kunkin menetelmän luokkakohtaiset tulokset, mukaan lukien kasvo- ja äänitiedot sekä mikro- ja makrokeskiarvot. Kasvojen ilmeiden luokittelu tuottaa makrokeskiarvona $\\text{F}_1$ 33 %:n tuloksen kolmelle tunteelle: ilo, epävarmuus ja ärsytys (P=0,31, R=0,35).",
      "id": "task461-317caba99e2545c29ab4f17e2ee4b11f",
      "output": [
        "Miten kasvojen ja äänitiedon analysointia arvioidaan?"
      ]
    },
    {
      "input": "Aloitimme indeksoinnin 100 kysymyksellä, jotka valittiin satunnaisesti eri aihealueilta, jotta eri kysymystyypit saataisiin katettua. Kysymysten indeksoinnissa noudatetaan BFS-mallia aiheeseen liittyvien kysymysten linkkien kautta. Saimme 822 040 yksilöllistä kysymystä 80 253 eri aihealueelta ja yhteensä 1 833 125 vastausta näihin kysymyksiin.",
      "id": "task461-70c419a711b74431a0cf1bb4681eb0f8",
      "output": [
        "Keskittyvätkö kokeet tiettyyn alaan?"
      ]
    },
    {
      "input": "Ensimmäinen vaihe on mallin esivalmennus yhdellä MCQA-aineistolla, jota kutsutaan lähdetehtäväksi ja joka sisältää yleensä runsaasti harjoitusdataa. Toisessa vaiheessa samaa mallia hienoviritetään toisella MCQA-aineistolla, jota kutsutaan kohdetehtäväksi ja josta me itse asiassa välitämme, mutta joka sisältää yleensä paljon vähemmän harjoitusdataa. ",
      "id": "task461-50d81840893c4333bb596b86f492402c",
      "output": [
        "Kuinka suuri on lähteen ja kohteen tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "NMT:hen käytimme KyotoNMT-järjestelmää BIBREF16 . NMT-koulutusasetukset ovat samat kuin WAT 2016 -tapahtumaan osallistuneiden parhaiden järjestelmien asetukset. Lähde- ja kohdesanastojen, lähde- ja kohdesivun upotusten, piilotettujen tilojen, huomiomekanismin piilotettujen tilojen ja syvän softmax-ulostulon, jossa on 2-maxout-kerros, koot olivat vastaavasti 32 000, 620, 1000, 1000 ja 500. Käytimme 2-kerroksisia LSTM:iä sekä lähde- että kohdepuolella. Oppimisalgoritmina käytettiin ADAMia, jossa kerrosten välisen pudotuksen pudotusprosentti oli 20 % ja L2-regularisointi, jossa painon hajoamiskerroin oli 1e-6. Minierän koko oli 64, ja yli 80 merkkiä pidemmät lauseet hylättiin.",
      "id": "task461-6e8179bced3346e1b86a8fb5a15f4307",
      "output": [
        "Millaisia neuroverkkoja he käyttivät tässä tutkimuksessa?"
      ]
    },
    {
      "input": "Kooderi on kaksisuuntainen Long-Short Term Memory (LSTM) solu BIBREF14 ja dekooderi yksittäinen LSTM-solu, jossa on huomiomekanismi. ",
      "id": "task461-0518234b4caa4108a4945375d85256f0",
      "output": [
        "Kuinka monta huomiokerrosta heidän mallissaan on?"
      ]
    },
    {
      "input": "Koska saman luokan tekstien sanat kuuluvat samaan kontekstiin, on mahdollista mallintaa kunkin luokan sanavektorit sanojen aliavaruuksina ja vertailla niitä tehokkaasti samankaltaisuuden suhteen käyttämällä sanojen aliavaruuksien välisiä kanonisia kulmia. ",
      "id": "task461-9bd80223ae214a469b9288725dec0dae",
      "output": [
        "Mitä sana aliavaruus voi edustaa?"
      ]
    },
    {
      "input": "Esittelemme tässä L-PCFG:n, jossa on kaksi latenttien tilojen kerrosta: toinen kerros on tarkoitettu tavanomaisen syntaktisen tiedon tallentamiseen, ja toisella kerroksella pyritään tallentamaan semanttista ja topikaalista tietoa käyttämällä suurta joukkoa tiloja, joilla on erityiset ominaisuusfunktiot.",
      "id": "task461-50a6d8f78bfe4ffab0f6825812def638",
      "output": [
        "Mitä latentteja muuttujia PCFG:ssä mallinnetaan?"
      ]
    },
    {
      "input": "WMT14 En-Fr- ja En-De-tietokannat WMT 2014 -mallin testaamiseen käytetään suurta englannin ja ranskan käännöstietokantaa, jossa on 36 miljoonaa dollaria lausepareja. Keskikokoisen tietokokonaisuuden osalta lainaamme BIBREF0:n asetusta ja otamme käyttöön WMT 2014 English-German translation dataset, joka koostuu 4,5 miljoonasta lauseparista, ja BPE-sanaston kooksi asetetaan 32 000 dollaria. IWSLT De-En- ja En-Vi-tietokannat Lisäksi teemme kokeita kahdella pienellä IWSLT-tietokannalla testataksemme MUSEn pientä versiota muiden vastaavien mallien kanssa. IWSLT 2014 German-English translation dataset koostuu 160 000 $$ lausepareista. Otamme käyttöön myös yhteisen lähde- ja kohdekielisen BPE-faktoroinnin, jonka sanaston koko on $32K$. IWSLT 2015 -englanti-vietnam -käännöstietokanta koostuu $133K$:n harjoituslausepareista.",
      "id": "task461-aeab9b6dfa3e458f9adeba30284a0028",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Tehtävien käsittely: tietojen etsintätehtävien muuntaminen algebrallisiksi operaatioiksi sulautusavaruudessa tehtäväkohtaisia muunnosmalleja noudattamalla. Joitakin tärkeitä tehtäviä ja niiden muunnosmalleja käsitellään jaksossa SECREF5. Kyselyjen käsittely: semanttisten kyselyjen suorittaminen sulautusavaruudessa ja tulosten palauttaminen. Huomaa, että sulautusvektoreiden algebralliset operaatiot ovat lineaarisia ja ne voidaan suorittaa rinnakkain. Siksi semanttinen kysely on tehokas.",
      "id": "task461-1f13987273714e119e2b24f5bcdeb2ca",
      "output": [
        "Millaista tietojen etsintää näiden semanttisten rakenteiden analyysi tukee?"
      ]
    },
    {
      "input": "Kokeet ::: doc2vec BIBREF37. Doc2vec (tai paragraph vector) on word2vecin laajennus, joka oppii vektoreita asiakirjoille täysin ilman valvontaa. Asiakirjojen upotukset syötetään sitten logistiselle regressioluokittelijalle.CNN BIBREF38. Tietokonenäköalalla tunnettua konvoluutiohermoverkkoarkkitehtuuria sovelletaan tekstiin. Paikkatietoulottuvuuksia on yksi, ja sanojen upotuksia käytetään kanavina (syvyysulottuvuuksina).DAN BIBREF39. Deep Averaging Network (Syvä keskiarvoverkko) siirtää syötesanojen upotusten painottamattoman keskiarvon useiden tiheiden kerrosten ja lopullisen softmaxin läpi.Tree-LSTM BIBREF40 on tavanomaisen LSTM-arkkitehtuurin yleistäminen konstituutio- ja riippuvuuslukupuille.DRNN BIBREF41. Rekursiiviset neuroverkot pinotaan ja niitä sovelletaan jäsennyspuihin.LSTMN BIBREF42 on LSTM-mallin laajennus, jossa muistisolu korvataan muistiverkolla, joka tallentaa sanojen representaatiot.C-LSTM BIBREF43 yhdistää konvoluutio- ja rekursiiviset neuroverkot. CNN:n tuottamat alueiden upotukset syötetään LSTM:ään.SPGK BIBREF44 mallintaa myös dokumentit sanojen yhteisesiintymisverkkoina. Se laskee graafin ytimen, joka vertaa lyhimpiä polkuja, jotka on poimittu sanojen yhteisesiintymisverkoista, ja käyttää sen jälkeen SVM:ää asiakirjojen luokitteluun.WMD BIBREF45 on sovellus tunnetusta Earth Mover's Distance -menetelmästä tekstiin. S-WMD BIBREF46 on valvottu laajennus Word Mover's Distance -menetelmään. Semantic-CNN BIBREF47. LSTM-GRNN BIBREF26 on hierarkkinen malli, jossa lauseiden upotukset saadaan CNN:llä ja GRU-RNN:lle syötetään lauseiden representaatiot asiakirjavektorin saamiseksi.HN-ATT BIBREF27 on toinen hierarkkinen malli, jossa samaa koodausarkkitehtuuria (kaksisuuntainen GRU-RNN) käytetään sekä lauseiden että asiakirjojen koodaamiseen eri parametreilla. RNN-merkintöihin kullakin tasolla sovelletaan itsehuomautusmekanismia.",
      "id": "task461-9f640ded736948f3a5ed2315f99e1bfb",
      "output": [
        "Mikä on nykyaikainen järjestelmä?"
      ]
    },
    {
      "input": "Arvioimme lähestymistapaamme kuudella kohdekielellä: ranska (fr), venäjä (ru), arabia (ar), kiina (zh), hindi (hi) ja vietnam (vi). ",
      "id": "task461-db7b906b9bbd46bb8d33a46beaa2747d",
      "output": [
        "Mille kielille malli siirretään?"
      ]
    },
    {
      "input": "Kutsumme mallia modifioiduksi Toulminin malliksi. Se sisältää viisi argumentin osatekijää, nimittäin väitteen, lähtökohdan, perustelun, vastaväitteen ja kumoamisen. Kun asiakirjaa merkitään, mikä tahansa merkkiväli voidaan merkitä argumenttikomponentilla; komponentit eivät ole päällekkäisiä. ",
      "id": "task461-f9a8ab70fcd84fe88785b787a3ddee1f",
      "output": [
        "Mitä argumenttikomponentteja ML-menetelmillä pyritään tunnistamaan?"
      ]
    },
    {
      "input": "Vertaamme lähestymistapaamme kahteen muuhun, joista ensimmäinen käyttää lähes samaa twiittidataa kuin me käytämme harjoitteluun, ja toinen on CrowdFlower-tietokanta, johon on merkitty tunteita.Ensimmäisessä Wang et al. BIBREF21 latasi yli 5 miljoonaa twiittiä, jotka sisälsivät yhden 131 emotionaalisesta hashtagista, jotka perustuvat Parrottin kolmiportaiseen tunteiden luokitteluun seitsemään kategoriaan: ilo, surullisuus, suuttumus, viha, rakkaus, pelko, kiitollisuus, yllätys.  Toisessa raportoidut tulokset ovat BIBREF33:n julkaisusta, jossa he käyttivät maksimieentropialuokittelijaa ja bag of words -mallia luokittelemaan erilaisia tunnetietoaineistoja. Tässä raportoidaan vain osa heidän CrowdFlower-tietokokonaisuutta koskevista tuloksistaan, jotka voidaan yhdistää johonkin seitsemästä tunnemerkinnästämme.",
      "id": "task461-492e0bd3228741beb04e8d0785ee4802",
      "output": [
        "Mitä perustasoa käytetään?"
      ]
    },
    {
      "input": "Tässä jaksossa vertaamme malliamme uusimpiin järjestelmiin, mukaan lukien järjestelmät, joissa on eriasteista valvontaa. Perusversioihin kuuluvat mm: (1) Procrustes BIBREF11, joka oppii lineaarisen kartoituksen Procrustes Analysis BIBREF36:n avulla. (2) GPA BIBREF37, joka on Procrustes-analyysin laajennus. (3) GeoMM BIBREF38, geometrinen lähestymistapa, jossa opitaan Mahalanobis-metriikka tarkentamaan samankaltaisuuden käsitettä. (4) GeoMM$_{semi}$, iteratiivinen GeoMM heikolla valvonnalla. (5) Adv-C-Procrustes BIBREF11, joka tarkentaa Adv-C:llä opittua kartoitusta iteratiivisella Procrustesilla, joka oppii uuden kartoitusmatriisin rakentamalla kaksikielisen sanaston iteratiivisesti. (6) Unsup-SL BIBREF13, jossa yhdistetään heikko valvomaton kartoitus ja kestävä itseoppiminen. (7) Sinkhorn-BT BIBREF28, jossa yhdistetään sinkhorn-etäisyys BIBREF29 ja takaisinkääntäminen.",
      "id": "task461-d7f66a3c05ae4cab8b39e4044c9da7c5",
      "output": [
        "Mitkä ovat nykyiset uusimmat menetelmät, joissa näitä kahta tehtävää tarkastellaan toisistaan riippumatta?"
      ]
    },
    {
      "input": "Yhteisviittauksen päätöslauselma: Joskus on tarpeen käyttää rinnakkaisviittausten ratkaisutekniikoita tehokkaan haun varmistamiseksi, jotta voidaan tukea monikierroksista vuorovaikutusta. Macaw-ohjelmassa tunnistetaan kaikki rinnakkaisviittaukset käyttäjän viimeisimmästä pyynnöstä keskusteluhistoriaan. Samoja rinnakkaisviittausten ratkaisun tuloksia voidaan käyttää eri kyselyjen muodostuskomponenteissa. Tämä voi olla yleinen tai toimintokohtainen komponentti: Tämä komponentti luo kyselyn käyttäjän ja järjestelmän aiempien vuorovaikutustilanteiden perusteella. Kyselyn luomisessa voidaan hyödyntää rinnakkaisviittausten ratkaisua kyselyn laajentamiseen tai uudelleenkirjoittamiseen: Tämä on keskeinen luokittelukomponentti, joka hakee asiakirjoja tai kohtia suuresta kokoelmasta. Macaw voi hakea asiakirjoja mielivaltaisesta asiakirjakokoelmasta käyttämällä Indri python-rajapintaa BIBREF9, BIBREF10. Tarjoamme myös tuen verkkohaulle Bing Web Search API:n avulla. Macaw mahdollistaa myös monivaiheisen asiakirjojen uudelleenjärjestyksen: Haetut asiakirjat voivat olla liian pitkiä esitettäväksi joidenkin käyttöliittymien avulla. Tulosten tuottaminen on periaatteessa jälkikäsittelyvaihe, joka suoritetaan haetulla tulosluettelolla. Kysymyksiin vastaamisessa voidaan käyttää vastausten valinta- tai tuottamistekniikoita, kuten koneellisia luetun ymmärtämisen malleja. Esimerkiksi Macaw käyttää DrQA-mallia BIBREF11 kysymyksiin vastaamiseen.",
      "id": "task461-d3d44d61d7934a6bb083461a34a6de81",
      "output": [
        "Mitä toimintoja Macaw tarjoaa?"
      ]
    },
    {
      "input": "Korpus on vapaasti saatavilla seuraavasta linkistä osoitteessa",
      "id": "task461-dc868a2e023c43989a3de75ebb3c8e57",
      "output": [
        "Onko tämä tietokokonaisuus julkisesti saatavilla?"
      ]
    },
    {
      "input": "Vertailua varten valitsimme parhaan tekstimallin kullekin esitykselle. Odotetusti suurin parannus ($22-26\\%$ E.R) saadaan, kun tekstipohjaiset valvomattomat mallit yhdistetään kuvamalleihin.",
      "id": "task461-24444d12feed409daa205dfe074f612a",
      "output": [
        "Kuinka paljon parempi on päättely, johon on lisätty kuvaesitys, verrattuna pelkkään tekstiesitykseen? "
      ]
    },
    {
      "input": "MP-kehys perustuu rekursiivisen naapuruusaggregoinnin ydinajatukseen. Toisin sanoen jokaisen vertexin esitys päivitetään jokaisessa iteraatiossa sen naapureilta saatujen viestien perusteella. Kaikkia spektraalisia GNN:iä voidaan kuvata MP-kehyksen avulla.GNN:iä on sovellettu menestyksekkäästi bioinformatiikan ja sosiaalisten verkostojen dataan solmujen luokitteluun, linkkien ennustamiseen ja graafien luokitteluun. Kuitenkin vain muutamissa tutkimuksissa on keskitytty MP-kehyksen soveltamiseen tekstin esittämisen oppimiseen. Tässä artikkelissa ehdotetaan yhtä tällaista sovellusta. Graafien yli tapahtuvan viestien välittämisen käsite on ollut käytössä jo useita vuosia BIBREF0, BIBREF1, samoin kuin graafeihin perustuvien neuroverkkojen käsite.",
      "id": "task461-4c19ab83c84249bf9c318b557d154ea1",
      "output": [
        "Mikä on viestinvälityskehys?"
      ]
    },
    {
      "input": "BIBREF21:n mukaisesti otamme REINFORCEa soveltaessamme jokaisesta kuvasta $K$:n otoksen kuvateksteistä: ${\\hat{c}}_1 \\ldots {\\hat{c}}_K$, ${\\hat{c}}}_k \\sim p_{\\theta }(c|I)$,Kunkin otoksen kuvatekstin perustasona käytetään loput otokset sisältävien otosten keskimääräistä palkkiota.",
      "id": "task461-b234e8f0f04d43f89f6902a79b228b16",
      "output": [
        "Mitä perustason funktiota käytetään REINFORCE-algoritmissa?"
      ]
    },
    {
      "input": "Arvioidaksemme kaikkien vertailtujen menetelmien tuottamia vastauksia, laskemme seuraavat automaattiset mittarit testijoukolle: BLEU: BLEU-n: BLEU-n mittaa keskimääräistä n-grammin tarkkuutta vertailuvastausten joukossa. Raportoimme BLEU-n:n, kun n=1,2,3,4.Distinct-1 & distinct-2 BIBREF5: Laskemme tuotetuissa vastauksissa olevien erillisten uni- ja bi-grammien lukumäärät ja jaamme lukumäärät testijoukon tuotettujen uni- ja bi-grammien kokonaismäärällä. Näitä mittareita voidaan pitää automaattisena mittarina vastausten monimuotoisuuden arvioimiseksi.",
      "id": "task461-37cd4302042041bfb545af729db8b64e",
      "output": [
        "Mitä automaattisia mittareita käytetään?"
      ]
    },
    {
      "input": "Luokittelijoiden harjoitteluun käytettiin osaa ILCI English-Hindi Tourism -rinnakkaiskorpuksesta (1500 lausetta). ",
      "id": "task461-1184f0dbce4a4599a31932f62adb4548",
      "output": [
        "Minkä kokoista rinnakkaista korpusta käytetään mallirajoitusten kouluttamiseen?"
      ]
    },
    {
      "input": "Doukhan2018openin työn jälkeen halusimme tutkia korporaatioita tarkastelemalla kunkin sukupuolikategorian puhujien määrää ja heidän puheensa kestoa, sillä molemmat muuttujat ovat hyviä ominaisuuksia, joiden avulla voidaan ottaa huomioon sukupuolen edustus. ",
      "id": "task461-1fcc9db9cbc14714859d4576170bb3d3",
      "output": [
        "Millaisia esityksiä tässä asiakirjassa esitetään?"
      ]
    },
    {
      "input": "Tämän asiakirjan pääkysymykset, joihin pyritään vastaamaan, ovat seuraavat: Haittaako yhteistyöelimen pakkaaminen sen kykyä siirtyä uusiin tehtäviin? Ja tekeekö hienosäätö yhteistyöelimestä enemmän vai vähemmän pakattavaa?Näiden kysymysten tutkimiseksi puristimme englanninkielisen yhteistyöelimen käyttäen suuruusluokan painojen karsintaa BIBREF8 ja havainnoimme tuloksia siirto-oppimisesta General Language Understanding Evaluation (GLUE) -vertailumittariin BIBREF9 , joka on monipuolinen joukko luonnollisen kielen ymmärtämistehtäviä, kuten tunneanalyysi, NLI ja tekstuaalisen samankaltaisuuden arviointi. Valitsimme suuruusluokan painojen karsinnan, joka pakkaa malleja poistamalla lähellä 0:a olevia painoja, koska se on yksi hienojakoisimmista ja tehokkaimmista pakkausmenetelmistä ja koska karsinnan tarkasteluun on monia mielenkiintoisia tapoja, joita tarkastelemme seuraavassa jaksossa. Havaintomme ovat seuraavat: Alhainen karsinta (30-40 %) ei lisää esiharjoittelun häviötä eikä vaikuta lainkaan siirtoon myöhempiin tehtäviin. Keskisuuret karsinnat lisäävät harjoittelua edeltävää häviötä ja estävät hyödyllisen harjoittelua edeltävän tiedon siirtymisen myöhempiin tehtäviin.",
      "id": "task461-df16cee7da9546b58990497effac2c95",
      "output": [
        "Miten he havaitsivat, että yhteistyöjärjestelmän hienosäätö tiettyä tehtävää varten ei paranna sen karsittavuutta?"
      ]
    },
    {
      "input": "Tämä kerros koostuu kahdesta alamoduulista: Multi-Head Attention (MHA) ja Point-wise Convolution Transformation (PCT).",
      "id": "task461-ea3233274e524a82b8fefe6e97f02e66",
      "output": [
        "Käytetäänkö niissä monihuomiopäitä?"
      ]
    },
    {
      "input": "Koulutusaineistona käytettiin 3 miljoonaa verkkosivua tästä korpuksesta, jotka käsiteltiin CCG-jäsennysohjelmalla loogisten muotojen BIBREF10 tuottamiseksi. Käytimme myös Krishnamurthyn ja Mitchellin luomaa testijoukkoa, joka sisältää 220 kyselyä, jotka on tuotettu samalla tavalla kuin harjoitusaineisto ClueWebin erillisestä osiosta. Koska he eivät kuitenkaan julkaisseet kehitysjoukkoa datansa kanssa, käytimme tätä joukkoa kehitysjoukkona. Tämä lopullinen testijoukko sisältää 307 kyselyä.",
      "id": "task461-e08350b7f7f948219d115b9cacae38cf",
      "output": [
        "Kuinka suuri on heidän tietokokonaisuutensa?"
      ]
    },
    {
      "input": "Negatiivisten arvojen käsittelemiseksi ehdotamme leikattua $\\mathit {PMI}$ -mallia, joka vastaa $\\mathit {PPMI}$ -mallia, kun $z = 0$. Käytännössä havaitsemme, että tämä toimii huonosti, jos se tehdään symmetrisesti, joten otamme käyttöön muunnoksen nimeltä $\\mathit {NNEGPMI}$, joka ainoastaan normalisoi $\\mathit {\\texttt {-}PMI}$:",
      "id": "task461-522bafb9293c4530b58b072518dc07b1",
      "output": [
        "Mitä uusia PMI-muunnoksia otetaan käyttöön?"
      ]
    },
    {
      "input": "Huomaa, että GANE-AP tuottaa parempia tuloksia kuin GANE-OT, mikä viittaa siihen, että huomion jäsentelymekanismi voi parantaa matalan tason keskinäisen huomion matriisia entisestään.",
      "id": "task461-7d952e2d40c64ca7b163f315353cb0f9",
      "output": [
        "Kumpi heidän ehdottamistaan huomiomenetelmistä toimii kokonaisuudessaan paremmin?"
      ]
    },
    {
      "input": "Määrittelemme metriikan nimeltä Semantic Text Exchange Score (STES), jolla arvioidaan mallin yleistä kykyä suorittaa STE, sekä säädettävän parametrin, jolla voidaan hallita semanttisen muutoksen määrää.",
      "id": "task461-c3590138c1574b6cbf916ea38d067534",
      "output": [
        "Onko STES:ää käytetty aiemmin kirjallisuudessa samankaltaisten tehtävien arviointiin?"
      ]
    },
    {
      "input": "Löytääksemme suuren määrän pakolaiskriisiä koskevaa vihapuhetta käytimme 10 hashtagia, joita voidaan käyttää loukkaavalla tai loukkaavalla tavalla.",
      "id": "task461-0cac8501268a4161b979cc53c33df095",
      "output": [
        "Miten mahdolliset vihamieliset viestit tunnistettiin?"
      ]
    },
    {
      "input": "Käytämme arviointimittarina mikrokeskiarvoista F1-pistemäärää kaikilla merkinnöillä.",
      "id": "task461-54212b4e7ce64b5eab2cffe6d7af7813",
      "output": [
        "Mitä mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Tässä käytetään vain sanakirjamääritelmiin liittyviä tietoja ja jätetään huomiotta polariteettipisteet. Kun kuitenkin hyödynnämme valvottua pistemäärää (+1 tai -1), vastakkaisia polariteetteja sisältävät sanat (esim. \"onnellinen\" ja \"onneton\") etääntyvät toisistaan, kun ne käännetään koordinaattialueiden välillä.",
      "id": "task461-abd38a5fcdf348b0b1ee96b66488693f",
      "output": [
        "Miten sanojen valvotut pisteet lasketaan?"
      ]
    },
    {
      "input": "Osatehtävässä C tavoitteena on luokitella loukkaavan kielenkäytön kohde. Tässä BIBREF17 -tehtävässä otetaan huomioon vain osatehtävässä B kohdennetuiksi loukkauksiksi (TIN) leimatut viestit. Näytteet merkitään yhdellä seuraavista: Yksilö (IND): Viestit, jotka kohdistuvat nimettyyn tai nimeämättömään henkilöön, joka on osa keskustelua. Englanniksi tämä voi olla esimerkiksi viesti: @USER Is a FRAUD Female @USER group paid for and organized by @USER. Tanskan kielessä tämä voisi olla esimerkiksi USER du er sku da syg i hoved. Nämä esimerkit osoittavat edelleen, että tämä luokka kattaa verkkokiusaamisen piirteet, sellaisina kuin ne on määritelty kohdassa \"Tausta\". ryhmä (GRP): Viestit, jotka kohdistuvat ihmisryhmään etnisen alkuperän, sukupuolen tai seksuaalisen suuntautumisen, poliittisen suuntautumisen, uskonnollisen vakaumuksen tai muiden ominaisuuksien perusteella. Englanniksi tämä voisi olla esimerkiksi viesti #Antifa are mentally unstable cowards, pretending to be relevant. Tanskan kielessä tämä voisi olla esimerkiksi Åh nej! Svensk lorteret!Muu (OTH): Loukkaavan kielenkäytön kohde ei täytä kummankaan edellisen kahden kategorian kriteerejä. BIBREF17 . Englanniksi tämä voisi olla esimerkiksi viesti And these entertainment agencies just gonna be an ass about it... Tanskan kielellä tämä voisi olla esimerkiksi viesti Netto er jo et tempel over lort.",
      "id": "task461-3a250ddfebd64cd18d96f079caf866fb",
      "output": [
        "Kuinka monta loukkaavan kielenkäytön luokkaa oli?"
      ]
    },
    {
      "input": "Käytetyt koneoppimistekniikat vaihtelivat maksimientropialuokittelijoista (BIBREF4) tukivektorikoneisiin (BIBREF5,BIBREF6,BIBREF7,BIBREF8), kun taas syväoppimismenetelmiin kuuluivat rekursiiviset neuroverkot (BIBREF9,BIBREF10), konvolutiiviset neuroverkot (BIBREF11) ja viimeisimpänä siirto-oppimiseen perustuvat arkkitehtuurit, kuten Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12). Kuvissa FIGREF1 ja FIGREF1 on yhteenveto spekulaation havaitsemista ja laajuuden selvittämistä käsittelevistä artikkeleista (BIBREF13, BIBREF5, BIBREF9, BIBREF3, BIBREF14, BIBREF15, BIBREF16, BIBREF17, BIBREF16, BIBREF6, BIBREF11, BIBREF18, BIBREF18, BIBREF10, BIBREF19, BIBREF7, BIBREF4 ja BIBREF8).",
      "id": "task461-4f9a757563cc4501a0b7c1d9e3ff2cbc",
      "output": [
        "Mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "BD-4SK-ASR-tietokanta ::: Loimme kielen transkriptioista. Malli luotiin käyttämällä CMUSphinxiä, jossa (kiinteä) diskonttomassa on 0,5, ja backoffit lasketaan suhdelukumenetelmällä. Malli sisältää 283 unigrammia, 5337 bigrammia ja 6935 trigrammia.",
      "id": "task461-bba90f3c2b8d459a8c863a48fe11e7fc",
      "output": [
        "Mitkä ovat kokeen tulokset?"
      ]
    },
    {
      "input": "Kuten edellä esiteltiin, \"One Million Post\" -korpus tarjoaa merkintöjä yli 11 000 käyttäjäkommentille. Vaikka jaetussa tehtävässä määriteltyä \"loukkaavaa kieltä\" kuvaavaa suoraan vertailukelpoista luokkaa ei olekaan, on olemassa kaksi läheisesti toisiinsa liittyvää luokkaa. Poistamme aineistosta kaikki ne kommentit, joiden kommentoijien enemmistö on sitä mieltä, että ne sisältävät joko \"sopimatonta\" tai \"syrjivää\" sisältöä tai ei mitään edellä mainituista. Käsittelemme kahta ensimmäistä tapausta esimerkkeinä `rikkomuksesta' ja jälkimmäistä tapausta esimerkkeinä `muut'.",
      "id": "task461-3bd3d23ec5544706bf337363e19fab04",
      "output": [
        "Mitkä ovat lähes loukkaavat kielikategoriat?"
      ]
    },
    {
      "input": "Kaikki perusmallit ovat Transformer-malleja niiden peruskonfiguraatiossa BIBREF11, jossa käytetään 6 kooderi- ja dekooderikerrosta, mallin ja piilotetun mallin dimensiot ovat 512 ja 2048 ja kaikkien huomiokerrosten 8 päätä. Alkuvaiheen monitehtäväkokeissa kaikki malliparametrit jaettiin BIBREF12:lla, mutta suorituskyky laski useita BLEU-pisteitä perusmalleihin verrattuna.",
      "id": "task461-87f737a56af04ed38ab8f680812893be",
      "output": [
        "Mitä mukautumattomia peruslinjoja käytetään?"
      ]
    },
    {
      "input": "Kirjallisuudessa kuvatuissa oikeinkirjoituksen korjaustesteissä on yleensä keskitytty yhteen lähestymistapaan, jota on sovellettu tiettyyn korpukseen. Esimerkkeinä voidaan mainita mammografiaraporttien ja twiittien oikeinkirjoituksen tarkistusta käsittelevät teokset BIBREF7 , BIBREF4 . Näissä töissä korostettiin, että on tärkeää räätälöidä korjausjärjestelmät niiden korpusten erityisongelmiin, joihin niitä sovelletaan. Esimerkiksi mammografiaraportit kärsivät huonosta kirjoitusasusta, joka tässä tapauksessa on suhteellisen kiireessä tehtyä toistotyötä. Twiitit taas sisältävät usein hymiöitä ja neologismeja, jotka voivat olla hankalia sääntöihin ja sanakirjoihin perustuville ratkaisuille, kuten LanguageToolille. Jälkimmäinen soveltuu sinänsä melko hyvin puolankielisiin teksteihin, koska monet laajennukset tämän sovelluksen rakenteeseen ovat saaneet innoituksensa puolan kielen morfologian ongelmista BIBREF3 .",
      "id": "task461-dcd829bcc77c4d58800106f83e49ee1b",
      "output": [
        "Mitä erityisiä virheenkorjausratkaisuja on aiemmin ehdotettu erikoistuneita korporaatioita varten?"
      ]
    },
    {
      "input": "Tässä artikkelissa olemme formalisoineet automaattisen tyhjiin täytettävien tietokilpailujen tuottamisen ongelman käyttämällä kahta hyvin määriteltyä oppimismenetelmää: sekvenssien luokittelua ja sekvenssien merkitsemistä.",
      "id": "task461-f052755e2ff645019c7d00e4d56f34d5",
      "output": [
        "Mitä kahta järjestelmää käytetään?"
      ]
    },
    {
      "input": "Arvioinnissa annotaattoreina toimi 50 natiivia henkilöä, jotka olivat hyvin perehtyneitä sekä englannin että tamilin kieliin. Vertailua varten otettiin noin 100 lauseen näytekokoelma testijoukon tuloksista. Tämä joukko sisälsi satunnaistetun valikoiman käännöstuloksia arvioinnin objektiivisuuden varmistamiseksi. RNNMorph-tulosten sujuvuus- ja riittävyystulokset on taulukoitu. Riittävyysluokitus laskettiin viisiportaisella asteikolla, jolla mitattiin, kuinka paljon merkitystä käännös välittää (kaikki, suurin osa, paljon, vähän, ei lainkaan). Sujuvuusluokitus laskettiin kieliopin oikeellisuuden perusteella viisiportaisella asteikolla (virheetön, hyvä, ei-äidinkielenomainen, epäselvä, käsittämätön). Vertailua varten RNNMorph- ja RNNSearch + Word2Vec -mallien lausetason käännökset asetettiin erikseen paremmuusjärjestykseen toistensa välillä, mikä mahdollisti kahden käännöksen tasapisteiden syntymisen paremmuusjärjestyksessä.",
      "id": "task461-5342242affbd42c99dea58c7fd571211",
      "output": [
        "Miten inhimilliset tuomiot koottiin?"
      ]
    },
    {
      "input": "Parantaaksemme suorituskykyä entisestään otamme käyttöön järjestelmän yhdistelmän dekoodausristikoiden tasolla. Yhdistämällä järjestelmiä voimme hyödyntää kunkin eri alueille optimoidun mallin vahvuuksia.  Paras tulos vlsp2018:ssa (4,85 % WER) saadaan yhdistelmällä painot 0,6:0,4, jossa 0,6 annetaan yleiskielimallille ja 0,4 keskustelumallille. Vlsp2019-joukossa suhdetta muutetaan hieman 0,7:0,3, jolloin paras tulos on 15,09 %.",
      "id": "task461-d3b9dad47fc74e1f9ddc6b9033988197",
      "output": [
        "Mitä kielimallien yhdistämistekniikkaa käytetään tutkimuksessa?"
      ]
    },
    {
      "input": "Olemme myös erityisen kiinnostuneita näkemään tämän mallin soveltamisen eri kieliin.",
      "id": "task461-276176fea1b34f6eb64afd71c7bd74d6",
      "output": [
        "Ovatko kirjoittajat kokeilleet tätä lähestymistapaa muilla kielillä?"
      ]
    },
    {
      "input": "ASR- ja ST-mallimme noudattavat berard2018endin arkkitehtuuria, mutta niissä on 3 dekooderikerrosta kuten pino2019harnessingissa.",
      "id": "task461-24100d0dd512467c980cd16f10e5c6b6",
      "output": [
        "Mikä on heidän mallinsa arkkitehtuuri?"
      ]
    },
    {
      "input": "Mallinnamme ASP-sijoitustehtävän AEP-tehtävän seuraajaksi. Tehtävänä on määrittää kaikille \"merkityksellisille\" uutisyksikköpareille oikea yksikköosio. Wikipedian oliosivun jokainen osio edustaa eri aihetta. Esimerkiksi Barack Obamalla on osiot `Early Life', `Presidency', `Family and Personal Life' jne. Artikkeli-osio Perustotuus. Aineisto koostuu kolmikosta INLINEFORM0 , jossa INLINEFORM1 , jossa oletetaan, että INLINEFORM2 on jo määritetty relevantiksi. Meillä on siis moniluokkainen luokitusongelma, jossa meidän on määritettävä INLINEFORM3:n jakso, jossa INLINEFORM4:ää siteerataan. ",
      "id": "task461-dbe837b7c04e401eb38906fa7953a0f8",
      "output": [
        "Miten he määrittävät tarkan osion, jossa käytetään syöttöartikkelia?"
      ]
    },
    {
      "input": "Käytämme ranskankielisen OSCAR-korpuksen käsittelemätöntä versiota, jossa on 138 gigatavua pakkaamatonta tekstiä ja 32,7 miljardia SentencePiece-merkkiä.",
      "id": "task461-c7da0295e7e64af8bb890b372a62ebbc",
      "output": [
        "Mihin CamemBERT on koulutettu?",
        "Mitä tietoja käytetään CamemBERT-koulutuksessa?"
      ]
    },
    {
      "input": "Näin ollen ehdotamme kahdenlaista suhdekohtaista metatietoa: suhdemetatietoa ja gradienttimetatietoa, jotka vastaavat edellä mainittuja kahta näkökulmaa. Ehdotetussa MetaR-kehyksessä relaation metatieto on korkeamman asteen esitys suhteesta, joka yhdistää pää- ja loppuoliot. Gradientti-meta on relaatio-metan häviögradientti, jota käytetään nopeaan päivitykseen ennen kuin relaatio-meta siirretään epätäydellisiin kolmioihin ennusteen aikana.",
      "id": "task461-a59e2547e8484e399ef02a028eb5b726",
      "output": [
        "Mitä metatietoja siirretään?"
      ]
    },
    {
      "input": "Kuten aiemmin mainittiin, tarpeisiimme ei ole saatavilla saksalaista vihapuhekorpusta, varsinkaan Euroopan pakolaiskriisiä koskevasta hyvin tuoreesta aiheesta. Siksi meidän oli koottava oma korpuksemme.",
      "id": "task461-e01fc34637e240fd909f02a032958078",
      "output": [
        "Mitkä kielet sisältyvät vihamielisen sisällön tietokantaan?"
      ]
    },
    {
      "input": "Kaksi suosittua segmentointimenetelmää ovat morfeemien segmentointi BIBREF4 ja tavuparikoodaus (BPE) BIBREF5. Sanojen segmentoinnin jälkeen lisäämme lisäksi jokaisen erotetun sanayksikön taakse erityisen symbolin, jonka tarkoituksena on auttaa NMT-mallia tunnistamaan morfeemien rajat ja vangitsemaan semanttinen informaatio tehokkaasti.  Hyödynnämme Zemberekiä morfologisen disambiguointityökalun kanssa turkkilaisten sanojen segmentoimiseksi morfeemiyksiköihin ja morfologian analysointityökalua BIBREF12 uiguurin sanojen segmentoimiseksi morfeemiyksiköihin. ",
      "id": "task461-63ef03812639465a82952c8aaafc0462",
      "output": [
        "Miten sanojen segmentointimenetelmä toimii?"
      ]
    },
    {
      "input": "Saimme noin 300 000 lauseen korpuksen, josta saatiin noin 1,5 miljoonaa yksittäistä kysymystä sisältävää harjoitusesimerkkiä. ",
      "id": "task461-c1279066df424727a27c7684af4ecd7e",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Niille, jotka haluavat Seshatin tiukemmin valvotun asennuksen järjestelmäänsä, annamme myös täydelliset tiedot manuaalisista asennusvaiheista verkkodokumentaatiossamme).",
      "id": "task461-459616ab408e477eaec02c694e2aa669",
      "output": [
        "Onko tämä ohjelmisto yleisön saatavilla?"
      ]
    },
    {
      "input": "Katecheon nykyisessä versiossa käytetään Bi-Directional Attention Flow (BiDAF) -mallia luetun ymmärtämiseen BIBREF6 . Katecheon tuleviin versioihin sisältyy mahdollisuus vaihtaa luetun ymmärtämisen malli uudempiin arkkitehtuureihin, jotka perustuvat esimerkiksi BERT BIBREF8 tai XLNet BIBREF9 -malleihin tai mukautettuihin koulutettuihin malleihin.Arkkitehtuuri ja konfigurointi",
      "id": "task461-861701949fe249e6b92b39a50bb1e314",
      "output": [
        "mitä esivalmennettuja malleja käytettiin?"
      ]
    },
    {
      "input": "Kokeellinen protokolla ::: Aineistot ::: TTS System dataset: Koulutimme TTS-järjestelmämme sekoituksella neutraalia ja uutisankkurityylistä puhetta. Yhteensä 24 tuntia harjoitusaineistoa, joka jakautui 20 tuntiin neutraalia puhetta (22000 lausumaa) ja 4 tuntiin uutisankkurin tyylistä puhetta (3000 lausumaa).(ii) Sulauttamisen valinta-aineisto: Koska arviointi suoritettiin vain uutisankkurin puhetyylillä, rajoitamme kielellisen hakuavaruuden uutisankkurin tyyliin liittyviin lausumiin: Kokeellinen protokolla :::: Aineistot ::: Järjestelmät arvioitiin kahdella tietokokonaisuudella:(i) Common Prosody Errors (CPE): Tietokokonaisuus, jossa Prostron-perusmalli ei pysty tuottamaan sopivaa prosodiaa. Tämä tietokokonaisuus koostuu monimutkaisista lausumista, kuten yhdyssanoista (22 %), \"tai\"-kysymyksistä (9 %) ja \"wh\"-kysymyksistä (18 %). Joukkoa on täydennetty hankkimalla monimutkaisia lauseita (51 %) BIBREF-tietokannasta24. ii) LFR: Kuten BIBREF-tietokannassa25 osoitettiin, lauseiden arviointi yksinään ei riitä, jos halutaan arvioida pitkän puheen laatua. Näin ollen LFR-arviointeja varten kuratoimme uutisnäytteiden tietokokonaisuuden. Uutistyyliset lauseet ketjutettiin kokonaisiksi uutisjutuiksi, jotta ne kuvaisivat suunnitellun käyttötapauksen kokonaiskokemusta.",
      "id": "task461-39b653b13f6f4439b23569c70e483b4d",
      "output": [
        "Mitä tietokokonaisuutta käytetään tämän menetelmän harjoittelussa/testauksessa?"
      ]
    },
    {
      "input": "Software Ontology (SWO) BIBREF5 on otettu mukaan, koska sen CQ-joukko on huomattavan suuri ja se oli osa Ren et al. analysoitujen CQ-joukkoa. Dem@Care BIBREF8:n ja OntoDT BIBREF9:n CQ-joukot otettiin mukaan, koska ne olivat saatavilla. Stuff BIBREF6- ja African Wildlife (AWO) BIBREF7 -ontologioiden CQ:t lisättiin joukkoon, koska yksi kirjoittajista on kehittänyt nämä ontologiat (mikä helpottaa tarvittaessa syvällistä analyysia), ne kattavat muita aiheita ja ovat eri tyyppisiä (opasontologia (AWO) ja ydinontologia (Stuff)), mikä osaltaan edistää lähteiden valinnan monimuotoisuutta.",
      "id": "task461-22354a0b6c26411aabe2df1dd854d717",
      "output": [
        "Kuinka monesta ontologian alueesta ne keräävät tietoja?"
      ]
    },
    {
      "input": "Menetelmää arvioidaan BERTbase-mallilla, jossa on 12 kerrosta, 12 itsetarkkailupäätä ja piilokoko 768. Koulutusnopeuden nopeuttamiseksi käytetään kaksivaiheista koulutusta BIBREF1. Ensimmäisessä vaiheessa käytetään 128 lauseen maksimipituutta ja toisessa vaiheessa 512 lauseen pituutta. Kahden vaiheen koulutusvaiheiden määrät ovat 50 000 ja 40 000 BERTBase-mallissa. Käytimme AdamW BIBREF13 -optimointilaitetta, jonka oppimisnopeus on 1e-4, $\\beta _1$ 0,9, $\\beta _2$ 0,999 ja L2-painon hajoamisnopeus $0,01$. Ensimmäiset 10 % kokonaisvaiheista käytetään oppimisnopeuden lämpenemiseen, minkä jälkeen käytetään lineaarista hajoamiskaaviota. Käytimme kaikilla kerroksilla 0,1:n pudotustodennäköisyyttä. Esiharjoittelussa käytetty data on sama kuin BERT:ssä, eli englanninkielinen Wikipedia (2500 miljoonaa sanaa) ja BookCorpus (800 miljoonaa sanaa) BIBREF14.",
      "id": "task461-545ef65cff0941e8bdc3391db09bf194",
      "output": [
        "Harjoittelevatko he mallia tarkistuspisteestä alkaen?"
      ]
    },
    {
      "input": "Koska BERT-kielimallin esivalmennus on kallista, otamme suoraan käyttöön Googlen esivalmennetut parametrit kiinalaisesta yleiskorpuksesta. Nimettyjen entiteettien tunnistusta sovelletaan sekä patologisten raporttien teksteihin että kyselyteksteihin.",
      "id": "task461-00e7934eddf44b47948da3058fb43378",
      "output": [
        "Millä aineistolla kielimalli on esivalmennettu?"
      ]
    },
    {
      "input": "Intuitiivisin tapa esittää syntaktista tietoa on käyttää suoraan yksittäisiä riippuvuussuhteita, kuten riippuvuuspäätettä ja riippuvuussuhteen merkintää, joita merkitään lyhyesti Dep ja Rel. Jotta riippuvuuspuiden rakenteellinen informaatio säilyisi mahdollisimman hyvin, otamme riippuvuuspuiden argumenttiehdokkaiden ja predikaattien välisen syntaktisen polun kielellisenä tietona. Viitaten BIBREF9:ään käytämme riippuvuuspolkuna (DepPath) puupohjaista sijaintiominaisuutta (TPF) ja lyhintä riippuvuuspolkua (SDP) relaatiopolkuna (RelPath).",
      "id": "task461-a943963c359f4f2d95a24ac4c3fc050b",
      "output": [
        "Mitä erilaisia lähestymistapoja syntaktisen tiedon koodaamiseen kirjoittajat esittävät?"
      ]
    },
    {
      "input": "Syöttötietojen simuloimiseksi kehitettiin rutiinit, jotka perustuvat kirjoittajien kokemukseen todellisista terveydenhuollon tiedoista. Tähän valintaan oli kaksi syytä: Ensinnäkin, terveydenhuollon tiedot voivat olla erittäin monimutkaisia ja vaatia kertaluonteista koodia epätavallisen syötteen käsittelemiseksi, mutta eivät välttämättä niin, että ne muuttaisivat merkittävästi tämän kaltaisen semanttisen rikastusmoottorin perustavanlaatuisia teknisiä valintoja. Toiseksi, terveydenhuollon tietoja säännellään tiukasti, ja terveydenhuollon tietojen saaminen tutkimuskäyttöön voi olla hankalaa ja aikaa vievää.Simuloinnissa käytettiin yksinkertaistettua syöttötietoaineistoa, joka oli eri muodoissa, joita esiintyy usein terveydenhuollossa.",
      "id": "task461-cbf5ded2463745f58ca1c2b98f139591",
      "output": [
        "Minkälaisia reaaliaikaisten syötteiden simulaatioita käytetään validoinnissa?"
      ]
    },
    {
      "input": "Osoittaaksemme lähestymistapamme tehokkuuden esitämme tuloksia SICK-tietokannassa BIBREF1, joka on yleinen vertailukohde logiikkapohjaiselle NLI:lle, ja havaitsemme, että MonaLog on kilpailukykyinen monimutkaisempien logiikkapohjaisten lähestymistapojen kanssa (monet niistä vaativat täydellistä semanttista jäsennystä ja monimutkaisempia loogisia koneistoja).",
      "id": "task461-ff065fcef76d4b459bd1d5f98a8ff75e",
      "output": [
        "Päihittävätkö ne SICKin nykyisen tekniikan tason?"
      ]
    },
    {
      "input": "Kahden puhujan päällekkäinen puhe tuotetaan keinotekoisesti sekoittamalla näitä aaltomuotoisia segmenttejä. Maksimoidaksemme puheen päällekkäisyyden kehitimme menettelyn, jolla samankokoisia segmenttejä sekoitetaan noin 0 dB:n tasolla. Ensin lajittelemme puhesegmentit pituuden mukaan. Sitten otamme segmentit pareittain ja nollaamme lyhyemmän segmentin niin, että molemmilla on sama pituus. Sitten nämä parit sekoitetaan yhteen päällekkäisen puheaineiston luomiseksi.",
      "id": "task461-b24237d8bd8743ceb5b4e0368355bb0a",
      "output": [
        "Miten nämä kaksi tietokokonaisuutta ovat keinotekoisesti päällekkäisiä?"
      ]
    },
    {
      "input": "Käytämme graafia sosiaalisen median kontekstin mallintamiseen, jossa twiitit liittyvät toisiinsa, kirjoittajat twiitteihin ja muihin kirjoittajiin. Kuvassa FIGREF7 esitetään graafi, joka koostuu kolmenlaisista solmuista: twiitit (T), käyttäjät (U) ja \"maailma\" (W). Solmujen välille luodaan särmiä, jotka painotetaan seuraavasti: T-T twiittien välinen unigram-kosiinimaisuus, T-U painotettu 100 twiitin ja sen kirjoittajan välillä, U-U painotettu 1 kahden käyttäjän välillä, joilla on \"seuraa\"-suhde, ja U-W painotettu 0,001, jotta varmistetaan, että graafi on yhdistetty hullua algoritmia varten.",
      "id": "task461-833c73cca57a41b19f4f9ab9a1b48349",
      "output": [
        "Mitä tietoa twiitin kirjoittajien sosiaalinen graafi sisältää?"
      ]
    },
    {
      "input": "Ranskaa, venäjää ja arabiaa voidaan pitää kielinä, joilla on paljon resursseja, kun taas hindistä on paljon vähemmän tietoja, ja sitä voidaan pitää kielinä, joilla on vähän resursseja.",
      "id": "task461-4f0f0163feca417098ca262466470fc7",
      "output": [
        "Onko järjestelmää testattu vähäisten resurssien kielillä?"
      ]
    },
    {
      "input": "Aloitimme näiden sanojen upotukset 300-ulotteisilla Glove- upotuksilla BIBREF31 . ",
      "id": "task461-05e7dfb6a71844e79b886d50340c7574",
      "output": [
        "Käytetäänkö niissä esivalmisteltuja upotuksia?"
      ]
    },
    {
      "input": "Perustason määrittämiseksi tarkastelemme satunnaista menetelmää, joka ennustaa positiivisen merkinnän 0,15 todennäköisyydellä (positiivisten tapausten perusprosentti). Yleinen suorituskyky (kuva FIGREF28). Vaikka sanatason tehtävämme on erittäin epätasapainoinen, kaikki mallimme ovat selvästi parempia kuin satunnainen perustaso. Odotetusti sisällön sanoja on paljon vaikeampi ennustaa kuin stop-sanoja, mutta paras F1-tulos sisällön sanojen osalta on yli kaksinkertainen satunnaiseen perusmalliin verrattuna (0,286 vs. 0,116). Huomattavaa on, että vaikka parannamme satunnaista perustasoa huomattavasti, parhaatkin F1-pisteet ovat suhteellisen alhaisia, ja tämä pätee käytetystä mallista riippumatta. Huolimatta siitä, että tehtäviin sisältyy enemmän merkkejä kuin tavanomaisiin merkintätehtäviin (esim. BIBREF41 ja BIBREF42), sen ennustaminen, tuleeko sana kaikuisaksi selityksissä, on edelleen haastava ongelma.",
      "id": "task461-93819ae5651a4a0b873cc148a4f20518",
      "output": [
        "Mitkä ovat tämän uuden tehtävän yleiset perustulokset?"
      ]
    },
    {
      "input": "Esittelemme luettelon kahdeksasta eri osaamisesta, jotka lukemisjärjestelmän tulisi hallita, jotta se voisi käsitellä arvosteluja ja tekstiasiakirjoja yleensä. Nämä kahdeksan tehtävää edellyttävät erilaista osaamista ja eritasoista asiakirjan ymmärtämistä, jotta niihin voidaan vastata hyvin. Esimerkiksi sen havaitseminen, mainitaanko arvostelussa jokin näkökohta, edellyttää vähemmän arvostelun ymmärtämistä kuin kyseisen näkökohdan arvosanan ennustaminen. Taulukossa TABREF10 esitellään kahdeksan tehtävää, jotka olemme ottaneet käyttöön tässä tietokokonaisuudessa, sekä esimerkki kutakin tehtävää vastaavasta kysymyksestä.",
      "id": "task461-0a450d7a23a741c8934258b563b04913",
      "output": [
        "Millaisia kysymyksiä aineistossa on?"
      ]
    },
    {
      "input": "Regressorina käytettiin tukivektoriregressiota (SVR) ja luokittelijana tukivektoriluokitusta (SVC). Taulukkoon sisältyy neuraalinen regressori (NNR) ja neuraalinen luokittelija (NNC). Neuraalinen luokittelija on koulutettu kahdessa asetelmassa: \"NNC top 5\" käyttää SECREF3-jaksossa kuvattuja luokittelutunnisteita ja \"NNC SU4 F1\" käyttää regressiotunnisteita eli kunkin lauseen ROUGE-SU4 F1 -pisteitä.",
      "id": "task461-9d6836bc40c54292828b7f25f650959e",
      "output": [
        "Millaisia luokittelumenetelmiä kokeiltiin tätä tehtävää varten?"
      ]
    },
    {
      "input": "Asiantuntijoiden määrä vaihteli mallien välillä käyttämällä tavallisia MoE-kerroksia, joissa oli 4, 32 ja 256 asiantuntijaa, ja hierarkkisia MoE-kerroksia, joissa oli 256, 1024 ja 4096 asiantuntijaa.",
      "id": "task461-f8c5232542d44ca580af00ecd5f7c2e9",
      "output": [
        "Miten päätetään käytettävien asiantuntijoiden oikea määrä?"
      ]
    },
    {
      "input": "Keräämme Food.com-sivustolta uudenlaisen tietokokonaisuuden, joka sisältää yli 230 000 reseptitekstiä ja yli 1 miljoonaa käyttäjän vuorovaikutusta (arvostelua) 18 vuoden ajalta (2000-2018).",
      "id": "task461-d6a30deacd6b4a3bbe29cb7a0a2225b6",
      "output": [
        "Mistä he saavat reseptit?",
        "Miten he saivat vuorovaikutussuhteet?"
      ]
    },
    {
      "input": "Teimme kokeen selvittääksemme, voimmeko säilyttää tai parantaa luokittelijan suorituskykyä soveltamalla seuraavaa kolmiportaista ominaisuuksien eliminointimenetelmää: Vähentäminen Vähensimme kutakin luokkaa varten koodattua tietokokonaisuutta poistamalla ominaisuudet, jotka esiintyvät koko tietokokonaisuudessa vähemmän kuin kaksi kertaa.Valinta Sovelsimme pienennettyyn tietokokonaisuuteen iteratiivisesti khiin neliö -ominaisuuden valintaa valitsemalla korkeimmalle sijoittuneiden ominaisuuksien ylimmän prosenttiosuuden 5 prosentin askelin tukivektorimallin harjoittelua ja testausta varten käyttäen lineaarista ydintä ja 5-kertaista ositettua ristiinvalidointia.Sijoitus Kuvasimme kumulatiivisesti kunkin korkeimmalle sijoittuneiden ominaisuuksien prosenttiosuuden keskimääräisen F1-pistemäärän suoritukset. Ilmoitamme prosenttiosuuden ja niiden ominaisuuksien lukumäärän, jotka johtavat korkeimman keskimääräisen F1-pistemäärän ensimmäiseen esiintymiseen kussakin luokassa.",
      "id": "task461-796f574e139f437085b40bd08fb7e838",
      "output": [
        "Mitkä ovat kolme vaihetta ominaisuuksien poistamiseksi?"
      ]
    },
    {
      "input": "Vertailukohtamme, Honk( UID9 ), DeepSpeech-finetune( UID10 ), olivat verrattain alhaisemmat sekä recall että precision.",
      "id": "task461-9a8658bb3ed34ab58d835164c7074071",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Järjestelmän tulosta, jossa kohdesanat ovat ennustetussa järjestyksessä, verrataan DURel-tietoaineiston kultaiseen sijoitukseen. Mittarina käytettiin Spearmanin $\\rho $:n mittaria sen arvioimiseksi, kuinka hyvin mallin tuotos vastaa kultaista järjestystä. Mitä korkeampi Spearmanin järjestyskorrelaatio on, sitä parempi on järjestelmän suorituskyky.",
      "id": "task461-1d618b3f6e654c2c8c2295289949c7fc",
      "output": [
        "Miten arviointi suoritetaan?"
      ]
    },
    {
      "input": "Tuloksena saatu tietokokonaisuus koostuu 22 880 käyttäjästä, 41 094 blogista ja 561 003 viestistä. Taulukossa TABREF2 esitetään aineistomme muita tilastoja.",
      "id": "task461-1e36fa8bcb9346ad8c008da4e5d64d65",
      "output": [
        "Kuinka monta käyttäjää he katsovat?"
      ]
    },
    {
      "input": "Tästä huolimatta havaitsimme, että upotusten harjoittelu ei ollut merkittävästi hitaampaa kuin SGNS:n kaltaisten 2. järjestyksen vastaavien järjestelmien harjoittelu. Selkeästi sanottuna GPU koulutti CBOW-vektorit (käyttäen jäljempänä esitettyjä kokeellisia asetuksia) 3568 sekunnissa, kun taas CP-S:n ja JCP-S:n koulutukseen kului 6786 ja 8686 sekuntia.",
      "id": "task461-f6f5e4f5bd994ab689498d6ce01078fd",
      "output": [
        "Mittaavatko ne faktorisointiensa laskenta-aikaa verrattuna muihin sanojen upotuksiin?"
      ]
    },
    {
      "input": "Vertailimme useita tiivistämismenetelmiä, jotka voidaan jakaa kolmeen ryhmään: valvomattomat, ei-neuraaliset valvotut ja neuraaliset valvotut menetelmät.  Perustasona käytimme Lead-N-menetelmää, joka valitsee yhteenvedoksi INLINEFORM0-johtavat lauseet. Kaikkien menetelmien osalta poimimme tiivistelmäksi 3 lausetta, koska se on tutkimuksellisessa analyysissämme löytämiemme kultaisten tiivistelmien lauseiden mediaanimäärä. Lead-3-peruslinja suoriutuu todella hyvin ja päihittää lähes kaikki muut mallit, mikä ei ole yllättävää ja jopa yhdenmukaista muiden töiden kanssa, joiden mukaan uutisten tiivistämisessä Lead-N-peruslinja on yllättävän vaikeasti lyötävissä.",
      "id": "task461-de790c771e124b268e9afa345c9ae51b",
      "output": [
        "Mikä oli parhaiten toimiva perustaso?"
      ]
    },
    {
      "input": " Lopulliset kyselytutkimukseen perustuvat luokittelutulokset osoittivat 96 prosentin tarkkuuden PTSD:n havaitsemisessa ja 1,2 prosentin keskimääräisen neliövirheen sen voimakkuuden arvioinnissa, kun otetaan huomioon, että meillä on neljä voimakkuutta: ei PTSD:tä, matalan riskin PTSD:tä, kohtalaisen riskin PTSD:tä ja korkean riskin PTSD:tä pistemäärillä 0, 1, 2 ja 3. ",
      "id": "task461-c2b4cee1c6394c3d896b16fb269d95d5",
      "output": [
        "Miten PTSD:n voimakkuus määritetään?"
      ]
    },
    {
      "input": "Kahdessa yksittäisen lauseen tehtävässä - syntaksiin suuntautuneessa CoLA-tehtävässä ja SST-tunnetehtävässä - suorituskyky heikkeni jonkin verran.",
      "id": "task461-f9d7763fcc744cbb81b7b783268451c9",
      "output": [
        "Haittaako valvottuja tehtäviä koskeva lisäkoulutus suorituskykyä joissakin tehtävissä?"
      ]
    },
    {
      "input": "Nämä tietokokonaisuudet ovat osa SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28 . Taulukossa TABREF7 esitetään kunkin testikorpuksen havaintojen määrä.",
      "id": "task461-68751ce251ce4f14bdcb6d5434a9e622",
      "output": [
        "mitä tietokokonaisuuksia arvioinnissa käytettiin?"
      ]
    },
    {
      "input": "Työssämme käyttämämme Twitterin tietokokonaisuus koostuu koulutussarjasta, validointisarjasta ja testisarjasta. Se julkaistiin \"First workshop on categorizing different types of online harassment languages in social media\" -tapahtumaa varten. Koko tietokokonaisuus on jaettu kahteen luokkaan, jotka ovat häirintäviestit ja ei-häirintäviestit. Lisäksi häirinnän tyyppi huomioon ottaen twiitit on jaettu kolmeen alaluokkaan, jotka ovat epäsuora häirintä, seksuaalinen ja fyysinen häirintä.",
      "id": "task461-1b525676b70642668939bd71a4457233",
      "output": [
        "Millaista verkkohäirintää tutkitaan?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme on kommentoitu Ruijinin sairaalan ruoansulatuskanavan kirurgian osaston toimittamien kiinalaisten patologisten raporttien perusteella. Se sisältää 17 833 lausetta, 826 987 merkkiä ja 2 714 kysymys-vastausparia. Neljä kliinikkoa on kommentoinut ja tarkistanut kaikki kysymys-vastausparit kolmen kysymystyypin avulla: kasvaimen koko, proksimaalinen resektiomarginaali ja distaalinen resektiomarginaali. ",
      "id": "task461-49b1a9a492cb49cba9db97edf39ccc88",
      "output": [
        "Onko kaikki tämän aineiston teksti kysymystä, vai onko kysymysten välissä irrallisia lauseita?"
      ]
    },
    {
      "input": "Käytämme BIBREF73 -painotettua termien sanastoa, jossa käytetään 75 394 Facebook-käyttäjän tietokokonaisuutta, jossa käyttäjät ovat ilmoittaneet statuksensa, ikänsä ja sukupuolensa. Näiden kahden painotetun sanaston avulla ennustamme INLINEFORM0:n demografiset tiedot (ikä tai sukupuoli) (merkitään INLINEFORM1 ) seuraavan yhtälön avulla: INLINEFORM2 jossa INLINEFORM0 on termin sanakirjapaino ja INLINEFORM1 edustaa termin esiintymistiheyttä käyttäjän tuottamassa INLINEFORM2 -lomakkeessa ja INLINEFORM3 mittaa sanojen kokonaismäärää INLINEFORM4 -lomakkeessa.",
      "id": "task461-c3208cc2583b4fea8fd9a0f0a246853c",
      "output": [
        "Miten nämä puitteet helpottavat demografisia päätelmiä sosiaalisesta mediasta?"
      ]
    },
    {
      "input": "Vertailemme tavallisen Transformer Base -mallin ja puoliparametrisen NMT-lähestymistapamme suorituskykyä englannin ja ranskan välisessä käännöstehtävässä.",
      "id": "task461-6f73357e332a4dcc828314724dd0898f",
      "output": [
        "Mihin järjestelmiin he vertaavat tuloksiaan?"
      ]
    },
    {
      "input": "Ehdotamme myös tehokasta mallia, jolla kliiniset nimetyt entiteettitiedot voidaan integroida valmiiksi koulutettuun kielimalliin. Tässä jaksossa esitellään tehokas malli kysymyksiin vastaamiseen perustuvaa kliinisen tekstin jäsentämistä varten (QA-CTS). Kuten kuvassa FIGREF8 on esitetty, kappaleen teksti $X$ siirretään ensin kliinisen nimettyjen entiteettien tunnistuksen (CNER) malliin BIBREF12 nimettyjen entiteettien tietojen keräämiseksi ja yhden kuuman CNER-tulosteen merkintäsekvenssin saamiseksi kyselytekstille $I_{nq}$ ja kappaleen tekstille $I_{nt}$ BIEOS (Begin, Inside, End, Outside, Single) -merkintäjärjestelmällä. $I_{nq}$ ja $I_{nt}$ integroidaan sen jälkeen yhteen $I_n$:ksi. Samaan aikaan kappaleen teksti $X$ ja kyselyteksti $Q$ järjestetään ja siirretään kontekstualisoidulle esitysmallille, joka on tässä esivalmennettu kielimalli BERT BIBREF26, jotta saadaan kontekstualisoitu esitysvektori $V_s$ sekä tekstille että kyselylle. Tämän jälkeen $V_s$ ja $I_n$ integroidaan yhteen ja syötetään eteenpäin syöttävään verkkoon vastaukseen liittyvän tekstin alku- ja loppuindeksin laskemiseksi.",
      "id": "task461-36f2c4747b9d483bae44959051ab6d85",
      "output": [
        "Miten he tuovat toimialakohtaisia piirteitä valmiiksi koulutettuun kielimalliin?"
      ]
    },
    {
      "input": "Myöhemmin BIBREF8 esitteli RNN:n, jossa on ulkoinen pino-muisti, jolla opitaan yksinkertaisia kontekstittomia kieliä, kuten $a^n b^m$ , $a^nb^ncb^ma^m$ ja $a^{n+m} b^n c^m$ . Samankaltaisissa tutkimuksissa BIBREF15 , BIBREF16 , BIBREF17 , BIBREF10 , BIBREF11 on tutkittu, onko yksinkertaisissa RNN:issä olemassa stabiileja laskentamekanismeja, jotka mahdollistaisivat erilaisten kontekstivapaiden ja kontekstiherkkien kielten oppimisen BIBREF9 , puolestaan ehdotti LSTM-verkkojen (Long Short-Term Memory) muunnelmaa kahden kontekstittoman kielen, $a^n b^n$ , $a^n b^m B^m A^n$ , ja yhden tiukasti kontekstisidonnaisen kielen, $a^n b^n c^n$ , oppimiseen.",
      "id": "task461-5b63ef35e8584db5a3d7212c2d585f64",
      "output": [
        "Miten he saavat viralliset kielet?"
      ]
    },
    {
      "input": " Plackett-Luce Model for SMT RerankingKaksoistamisen jälkeen N-parhaan listan keskimääräinen koko on noin 300 ja siinä on 7491 ominaisuutta. Tämä kokeilu osoittaa, että suurten piirteiden osalta Plackett-Luce-malli korreloi hyvin BLEU-pisteiden kanssa ja lieventää jossain määrin ylisovittamista.",
      "id": "task461-7baf4301fe2644eb8d68357d54c631c3",
      "output": [
        "Mitä kokeita tehdään laajamittaisilla ominaisuuksilla?"
      ]
    },
    {
      "input": "Arvioimme LinkNBediä ja perusratkaisuja kahdella todellisella tietograafilla: D-IMDB (johdettu suuren mittakaavan IMDB-tietotilannekuvasta) ja D-FB (johdettu suuren mittakaavan Freebase-tietotilannekuvasta).",
      "id": "task461-ef382a852bf94fe9b84e583b6d760328",
      "output": [
        "Millä tiedoilla mallia arvioidaan?"
      ]
    },
    {
      "input": "Englannin kielen WSD:tä varten koulutamme WSD-mallimme SemCor BIBREF24:llä ja testaamme sitä Senseval-2:lla (SE2), Senseval-3:lla (SE3), SemEval 2013 task 12:lla (SE13) ja SemEval 2015 task 13:lla (SE15). Käytämme OntoNotes Release 5.0 -versiota, joka sisältää useita annotaatioita, mukaan lukien kiinan kielen sanojen aistimukset.",
      "id": "task461-3906794b7bf14f84a68d80e432dcc6b2",
      "output": [
        "Mitä tietokokonaisuuksia käytetään testauksessa?"
      ]
    },
    {
      "input": "Menetelmät ::: Kontekstitieto on informatiivista siinä mielessä, että yleensä samankaltaisilla sanoilla on taipumus esiintyä samoissa yhteyksissä.  Korpuspohjaisessa lähestymistavassa otetaan huomioon nämä kaksi ominaisuutta ja luodaan alalle ominaisia sanojen upotuksia. Menetelmä ::: Sanakirjapohjainen lähestymistapaTurkin kielessä ei ole vakiintuneita tunnesanastoja kuten englannissa. Tässä lähestymistavassa käytimme TDK-sanakirjan (Türk Dil Kurumu - \"Turkish Language Institution\") sanapolariteetteja.",
      "id": "task461-0aac4e7c37574a53b8fd6a5ebc280980",
      "output": [
        "Mitä sanapohjaisia ja sanakirjapohjaisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "BIBREF8-julkaisussa esitellään tarkennettu kokoelma Twitteristä kerättyjä twiittejä. Heidän tietokokonaisuutensa, joka on merkitty nimettyjen entiteettien tunnistustehtävää varten, sisältää 8 257 twiittiä. Tässä tietokokonaisuudessa on yhteensä 12 784 entiteettiä. Taulukossa TABREF19 esitetään kuhunkin nimettyyn entiteettiin liittyviä tilastoja koulutus-, kehitys- ja testijoukoissa.",
      "id": "task461-f0c5a9ccf4414f6a83dd4f192062d25a",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?",
        "Mitä sosiaalisen median alustaa tutkitaan?"
      ]
    },
    {
      "input": "Vertaamme mallimme tuloksia yang2016multi-arkkitehtuurin innoittamaan perustason monitehtäväarkkitehtuuriin. Perusmallissamme ei ole eksplisiittisiä yhteyksiä tehtävien välillä - ainoat jaetut parametrit ovat piilokerroksessa.",
      "id": "task461-d1eaa6fce6c942888fc04235ca767f2e",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Tämän mahdollistamiseksi käytämme bifokaalista huomiomekanismia, joka laskee huomion makrotason kenttiin ja mikrotason arvoihin. Tämän jälkeen yhdistämme nämä huomiopainot siten, että kentän huomiopaino vaikuttaa myös sen sisällä olevien arvojen huomioon. Fuusioitu bifokaalinen tarkkaavaisuusmekanismiIntuitiivisesti, kun ihminen kirjoittaa kuvauksen taulukosta, hän pitää kirjaa tiedosta kahdella tasolla. Makrotasolla on tärkeää päättää, mikä on sopiva kenttä, johon kiinnittää seuraavaksi huomiota, ja mikrotasolla (eli kentän sisällä) on tärkeää tietää, mihin arvoihin kiinnittää seuraavaksi huomiota. Tämän käyttäytymisen kuvaamiseksi käytämme bifokaalista huomiomekanismia, joka on kuvattu jäljempänä. Yhdistetty huomio: Intuitiivisesti kentälle annettujen huomiopainojen pitäisi vaikuttaa kaikkiin kyseiseen kenttään kuuluviin arvoihin. Tämän varmistamiseksi punnitsemme mikrotason huomiopainot uudelleen vastaavien makrotason huomiopainojen perusteella. Toisin sanoen yhdistämme kahden tason huomiopainot seuraavasti: DISPLAYFORM0jossa INLINEFORM0 on kenttä, joka vastaa INLINEFORM1 -osaa, INLINEFORM2 on makrotason kontekstivektori.",
      "id": "task461-c149474b54a54aa4a661e9efff454c35",
      "output": [
        "Mikä on bifokaalinen huomiomekanismi?"
      ]
    },
    {
      "input": "Koulutamme molemmat järjestelmät WMT15:n saksan ja englannin välisellä harjoitusaineistolla, ks. taulukko TABREF18, jossa on joitakin tilastoja. Tätä tarkoitusta varten käytämme RWTH:n saksan ja englannin datasetin manuaalisia linjauksia kovina linjauksina.",
      "id": "task461-a0b8eeeff9ba4bdd9e138326b21869d2",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Arvioimme lausekekompositionaalisuusmalleja Mitchell2010:n laatimilla adjektiivi-substantiivi ja substantiivi-substantiivi -lauseiden samankaltaisuustehtävillä käyttäen samaa arviointijärjestelmää kuin alkuperäisessä työssä. Arviointimittarina käytettiin Spearmanin INLINEFORM0 -lukua koostumustehtävistämme johdettujen fraasien samankaltaisuuksien ja ihmisannotoijien välillä (laskettuna erikseen annotoijittain ja sitten keskiarvona kaikkien annotoijien kesken).",
      "id": "task461-cabc759167d5490d85e5cd1a52c4aa4f",
      "output": [
        "Miten he pisteyttävät fraseaalisen kompositionaalisuuden?"
      ]
    },
    {
      "input": "Tarkemmin sanottuna tutkimme kolmea regularisointitermiä ongelman ratkaisemiseksi: (1) neutraaleihin piirteisiin liittyvä regularisointitermi, (2) luokkajakauman maksimieentropian regularisointitermi ja (3) KL-divergenssi referenssi- ja ennustetun luokkajakauman välillä.",
      "id": "task461-ceb38d420e434cf7986b22f394dac380",
      "output": [
        "Mitkä ovat kolme regularisointitermiä?"
      ]
    },
    {
      "input": "Käytämme kahta perusominaisuutta: POS-tunnisteet (Parts of Speech): Käytämme NLTK:n POS-taggeria twiittitekstien merkitsemiseen BIBREF0 . Käytämme POS-ominaisuuksina substantiivi-, adjektiivi-, adverbi- ja verbisanojen lukumäärää twiitissä: Käytämme polariteettisanakirjaa BIBREF3 saadaksemme sanojen aikaisemman polariteetin. Sanakirja sisältää positiiviset, negatiiviset ja neutraalit sanat sekä niiden polariteetin voimakkuuden (heikko tai vahva). Sanan polariteetti riippuu sen POS-tunnisteesta. Esimerkiksi sana `excuse' on negatiivinen, kun sitä käytetään `substantiivina' tai `adjektiivina', mutta sillä on positiivinen merkitys, kun sitä käytetään `verbinä'. Käytämme NLTK postaggerin tuottamia tunnisteita, kun valitsemme sanan etukäteispolariteetin sanakirjasta. Käytämme myös stemming-toimintoa (NLTK:n Porter Stemmer -toteutusta), kun teemme sanakirjahakua, jotta voimme lisätä osumien määrää. Käytämme ominaisuuksina heikosti positiivisten sanojen, heikosti negatiivisten sanojen, vahvasti positiivisten sanojen ja vahvasti negatiivisten sanojen lukumäärää twiitissä.Olemme myös tutkineet joitakin kehittyneitä ominaisuuksia, jotka auttavat parantamaan twiittien tunnetilan havaitsemista. hymiöt: Käytämme BIBREF:n2 emoticon-sanakirjaa ja laskemme positiiviset ja negatiiviset emoticonit jokaisesta twiitistä.[1] Urlin sentimentti: Koska lähes kaikki artikkelit on kirjoitettu hyvin muotoillulla englannilla, analysoimme artikkelin ensimmäisen kappaleen sentimenttiä Standfordin sentimenttianalyysityökalulla BIBREF4 . Se ennustaa sentimentin jokaiselle artikkelin sisältämälle lauseelle. Laskemme negatiivisten, positiivisten ja neutraalien lauseiden osuuden ja käytämme näitä kolmea arvoa ominaisuuksina. hashtag: Laskemme hashtagien määrän kussakin twiitissä.Suuraakkoset: Oletamme, että twiittien isolla alkukirjaimella on jonkinlainen yhteys sentimenttiasteeseen. Laskemme twiiteissä olevien isolla alkukirjaimella kirjoitettujen sanojen määrän.Retweet: Tämä on boolean-ominaisuus, joka ilmaisee, onko twiitti uudelleentwiittaus vai ei.User Mention: Boolean-ominaisuus, joka osoittaa, sisältääkö twiitti käyttäjän maininnan.Negation: Sanoja, kuten \"ei\", \"ei\", \"ei\", \"ei\" kutsutaan negaatiosanoiksi, koska ne kumoavat sitä seuraavan sanan merkityksen. Esimerkiksi `hyvä' muuttuu `ei hyvä'. Tunnistamme kaikki negaatiosanat twiiteistä. Jos negaatiosanaa seuraa polariteettisana, kumoamme kyseisen sanan polariteetin. Jos esimerkiksi sanaa \"hyvä\" edeltää sana \"ei\", muutamme polariteetin sanasta \"heikko positiivinen\" sanaksi \"heikko negatiivinen\": Käytämme tf-idf-pohjaisia tekstiominaisuuksia ennustamaan twiitin sentimenttiä. Teemme tf-idf-pohjaisen pisteytyksen twiitissä oleville sanoille ja twiitissä esiintyville hashtageille. Käytämme tf-idf-vektoreita luokittelijan kouluttamiseen ja sentimentin ennustamiseen. Tätä käytetään sitten pinottuna ennusteominaisuutena lopullisessa luokittimessa.",
      "id": "task461-fe9da1c6b00845ea9a78b506edcde65b",
      "output": [
        "Mitä kielellisiä piirteitä käytetään?"
      ]
    },
    {
      "input": "Yksinkertainen valinta ei-harvinaiselle porttifunktiolle BIBREF17 on kertoa tulo koulutettavalla painomatriisilla INLINEFORM0 ja soveltaa sitten INLINEFORM1-funktiota. DISPLAYFORM0Lisäämme Softmax-verkkoon kaksi komponenttia: harvuus ja kohina. Ennen Softmax-funktion ottamista lisäämme viritettävää Gaussin kohinaa, sitten säilytämme vain ylimmät k arvot ja asetamme loput INLINEFORM0:een (mikä saa vastaavat porttiarvot olemaan 0). Harvinaisuuden tarkoituksena on säästää laskentaa, kuten edellä on kuvattu. Vaikka tämä harvinaisuuden muoto luo teoreettisesti pelottavia epäjatkuvuuskohtia porttifunktion ulostuloon, emme ole vielä havainneet tämän olevan ongelma käytännössä. Kohinatermi auttaa kuorman tasapainottamisessa, kuten lisäyksessä SECREF51 käsitellään. Kohinan määrää komponenttia kohden ohjataan toisella koulutettavalla painomatriisilla INLINEFORM1 . DISPLAYFORM0 DISPLAYFORM1 Yksinkertainen valinta ei-harvaksi porttifunktioksi BIBREF17 on kertoa tulo koulutettavalla painomatriisilla INLINEFORM0 ja soveltaa sitten INLINEFORM1-funktiota. DISPLAYFORM0Lisäämme Softmax-verkkoon kaksi komponenttia: harva ja kohina. Ennen Softmax-funktion ottamista lisäämme viritettävää Gaussin kohinaa, sitten säilytämme vain ylimmät k arvot ja asetamme loput INLINEFORM0:een (mikä saa vastaavat porttiarvot olemaan 0). Harvinaisuuden tarkoituksena on säästää laskentaa, kuten edellä on kuvattu. Vaikka tämä harvinaisuuden muoto luo teoreettisesti pelottavia epäjatkuvuuskohtia porttifunktion ulostuloon, emme ole vielä havainneet tämän olevan ongelma käytännössä. Kohinatermi auttaa kuorman tasapainottamisessa, kuten lisäyksessä SECREF51 käsitellään. Kohinan määrää komponenttia kohden ohjataan toisella koulutettavalla painomatriisilla INLINEFORM1 . DISPLAYFORM0 DISPLAYFORM1",
      "id": "task461-e32d2d0696fe43d88464e50b5df59b38",
      "output": [
        "Mitä yhtälöitä käytetään koulutettavassa porttiverkossa?"
      ]
    },
    {
      "input": "Vertaamme personoituja mallejamme kahteen perusmalliin. Ensimmäinen on nimipohjainen lähin naapuri -malli (Nearest-Neighbor, NN). Sovelsimme aluksi BIBREF0:n neuraalista tarkistuslistamallia perustasoksi; käytämme kuitenkin lopulta yksinkertaista Encoder-Decoder-perustasoa, jossa on ainesosahuomio (Enc-Dec), joka tarjoaa vertailukelpoisen suorituskyvyn ja pienemmän monimutkaisuuden.",
      "id": "task461-1e30d3bf674c4fe28d5118301617465f",
      "output": [
        "Mitkä ovat perusmallit?"
      ]
    },
    {
      "input": "Ensinnäkin ehdotamme NLP-tehtäviä varten luokkaa rekursiivisia neuroverkkoja, jotka täyttävät differentiaaliyhtälön DISPLAYFORM0 jossa DISPLAYFORM0ja jossa INLINEFORM0 ja INLINEFORM1 ovat opittuja funktioita. INLINEFORM2 vastaa perinteisiä RNN-verkkoja, joiden INLINEFORM3 . INLINEFORM4:n osalta tämä tapahtuu RNN-solujen muodossa, joilla on joko sisäkkäisiä sisäisiä muistoja tai riippuvuuksia, jotka ulottuvat ajallisesti välittömästi edellisen piilotetun tilan ulkopuolelle. ",
      "id": "task461-35e80869c2634cb4901003ef8866ec7d",
      "output": [
        "Mitä uutta luokkaa rekursiivisten verkkojen kaltaisia verkkoja ehdotetaan?"
      ]
    },
    {
      "input": "Käytämme WMT 2017 English-Chinese test set BIBREF18 -testisarjan kiinalaisten lähdetekstien englanninkielisiä käännöksiä kaikissa tässä artikkelissa esitetyissä kokeissa:",
      "id": "task461-99afbacd76094760b3495943251cda37",
      "output": [
        "Mitä kieliä ne tutkivat konekääntämistä varten?"
      ]
    },
    {
      "input": "Tässä luvussa kuvaamme useita kokeita, joiden tarkoituksena on vertailla suosittujen nimettyjen entiteettien tunnistusalgoritmien suorituskykyä aineistossamme. Koulutimme ja arvioimme Stanfordin NER:ää, spaCy 2.0:aa ja rekursiivista mallia, joka on samanlainen kuin BIBREF13 , BIBREF14 , joka käyttää kaksisuuntaisia LSTM-soluja merkkipohjaiseen ominaisuuksien poimintaan ja CRF:ää, joka on kuvattu Guillaume Genthialin blogikirjoituksessa Sequence Tagging with Tensorflow BIBREF15 . Stanford NER on CRF-luokittelija (Conditional Random Fields), joka perustuu leksikaalisiin ja kontekstuaalisiin piirteisiin, kuten nykyiseen sanaan, merkkitason n-grammeihin, joiden pituus on enintään 6 sen alussa ja lopussa, edellisiin ja seuraaviin sanoihin, sanan muotoon ja sekvenssipiirteisiin BIBREF16 . spaCy 2.0 käyttää CNN-pohjaista siirtymävaihetta nimettyjen entiteettien tunnistamiseen. Pääasiallinen malli, johon keskityimme, oli rekurrenssimalli, jossa on CRF-yläkerros, ja edellä mainitut menetelmät toimivat enimmäkseen vertailukohtina. ",
      "id": "task461-cf6b64ddcaad4afc9a07f54e476f5925",
      "output": [
        "mitä ner-malleja arvioitiin?"
      ]
    },
    {
      "input": "Tavoitteenamme on verrata ehdotetun lähestymistavan tehokkuutta BIBREF-julkaisussa13 kuvattuun perusjärjestelmään. Arvioimme väärän hylkäämisen (FR) ja väärän hyväksymisen (FA) kompromissia useissa eri kokoisissa ja laskennallisesti monimutkaisissa päästä päähän -malleissa. Kuten kuvassa FIGREF14 esitetyistä Receiver Operating Characteristic (ROC) -käyristä voidaan nähdä, kaksi suurinta päästä päähän -mallia, joissa on kaksivaiheinen koulutus, ovat huomattavasti parempia kuin paljon suuremman ja monimutkaisemman Baseline_1850K-järjestelmän tunnistuksen laatu. Tarkemmin sanottuna E2E_318K_2stage ja E2E_700K_2stage osoittavat jopa 60 prosentin suhteellista FR-asteen alenemista Baseline_1850K:hon verrattuna useimmissa testiolosuhteissa. ",
      "id": "task461-8c91c87d2c3448938c03ec541a224872",
      "output": [
        "Miten he mittaavat havaitsemisen laatua?"
      ]
    },
    {
      "input": "Käyttämällä luokan yksittäisten sanojen jakaumaa voimme laatia koko luokan jakaumat ja siten luoda karttoja näille sanaluokille. ",
      "id": "task461-c2085ff741114445afe4185daad31e53",
      "output": [
        "Rakentavatko he mallin, jolla voidaan automaattisesti havaita ihmisten demografiset, lingvistiset tai psykologiset ulottuvuudet?"
      ]
    },
    {
      "input": "Vertailun vuoksi raportoimme myös Rei2016:n virheentunnistusjärjestelmän suorituskyvyn, joka on koulutettu käyttäen samaa FCE-tietokokonaisuutta.",
      "id": "task461-e348c2263b2143128c760a8ac25ffa18",
      "output": [
        "Mitä perustasoa käytettiin?"
      ]
    },
    {
      "input": " Ongelma-avaruuden tutkimiseksi keskitymme erityisesti viiteen binääriseen luokitusongelmaan, joita on käsitelty BIBREF-tietokannoissa17 , BIBREF-tietokannassa18 ja jotka ovat konsonanttien läsnäolo/poissaolo, foneemiset nasaalit, bilabiaalit, korkeat etuvokaalit ja korkeat takavokaalit.",
      "id": "task461-e96d3ddcd9db45fea98de9ec5c653fe5",
      "output": [
        "Mitkä ovat viisi erilaista binääriluokittelutehtävää?"
      ]
    },
    {
      "input": "Tällä tavoin huomiovektorisekvenssi segmentoidaan useisiin osajaksoihin, ja kukin osajakso edustaa yhden sanan huomiota. Tämän jälkeen kehitämme sopivan aggregointimoduulin, joka yhdistää sanan sisäisen merkkihuomion, koska psykolingvistinen havainto, jonka mukaan lukijat kiinnittävät todennäköisesti likimääräistä huomiota kuhunkin merkkiin yhdessä kiinalaisessa sanassa, motivoi meitä.",
      "id": "task461-029ac89e825443d78a9b04267106dae7",
      "output": [
        "Miten fuusiomenetelmä toimii?"
      ]
    },
    {
      "input": "Arvioidaksemme ehdotetun kehyksen tehokkuutta ATE-tehtävässä suoritamme kokeita neljällä SemEval ABSA -haasteeseen kuuluvalla vertailutietoaineistolla BIBREF1 , BIBREF18 , BIBREF12 . Taulukossa TABREF24 esitetään niiden tilastot. INLINEFORM0 (SemEval 2014) sisältää arvosteluja kannettavien tietokoneiden alalta ja INLINEFORM1 (SemEval 2014), INLINEFORM2 (SemEval 2015) ja INLINEFORM3 (SemEval 2016) ravintola-alalta. Näissä tietokokonaisuuksissa aspektitermit on leimannut tehtävän järjestäjä.",
      "id": "task461-22dc5b09f01d44dd90cad941f2c949ba",
      "output": [
        "Mitä tietokokonaisuutta (tietokokonaisuuksia) he käyttävät mallin kouluttamiseen?"
      ]
    },
    {
      "input": "Erityisesti ei ole selvää, onko yhteistyöelimen avulla voitu ratkaista sellaisia tehtäviä kuin Pronoun Disambiguation Problem (PDP) ja Winograd Schema Challenge (WSC). Pronominien erittelyä koskevassa tietokokonaisuudessa PDP-60 menetelmämme saavuttaa 68,3 prosentin tarkkuuden, mikä on parempi kuin uusimman tekniikan tason 66,7 prosentin tarkkuus. WSC-tietokannassa, WSC-273, menetelmämme saavuttaa 60,3 %:n tuloksen. ",
      "id": "task461-aaf62d59a175432797f5367224e773dd",
      "output": [
        "Millaisia tietokokonaisuuksia ne arvioivat?"
      ]
    },
    {
      "input": "Ensemble, joka valitsee lauseen käyttäen 100 agenttia, jotka on koulutettu klusteroitujen dialogien perusteella kohdassa SECREF4 kuvatulla tavalla - keskittyvä agentti valitaan käyttämällä regressoria dialogipalkkion ennustajana INLINEFORM0 käyttäen samanlaista neuroverkkoa kuin ChatDQN-agentit, paitsi että viimeisessä kerroksessa on yksi solmu ja piilokerrosten välissä käytetään BIBREF44 -eränormalisointia piilokerrosten välillä, kuten BIBREF36:ssa;",
      "id": "task461-f919be072810470ab2332d666436f4e7",
      "output": [
        "Kuinka monta agenttia he kokoavat yhteen?"
      ]
    },
    {
      "input": "Käytämme monialueen polariteettiluokituskokeissa monialueen aistimustietoaineiston (Multi-Domain Sentiment Dataset BIBREF0) toista versiota. Aineisto sisältää Amazonin tuotearvosteluja neljältä eri toimialueelta: Kirjat (B), DVD:t (D), elektroniikka (E) ja keittiökoneet (K). ",
      "id": "task461-be7ff21059444923b68321b99e4a0761",
      "output": [
        "Mitä osa-alueita polariteettiluokittelua koskeva tietokokonaisuus sisältää?"
      ]
    },
    {
      "input": "Koska tavoitteenamme on vertailla merkkipohjaisia ja sanapohjaisia lähestymistapoja, olemme myös toteuttaneet yksinkertaisen sanatason koodaajan twiittejä varten. Syötetty twiitti jaetaan ensin merkkeihin valkoisia välejä pitkin. Voidaan käyttää kehittyneempää tokenizeria, mutta tasapuolisen vertailun vuoksi halusimme pitää kielikohtaisen esikäsittelyn mahdollisimman vähäisenä. Kooderi on periaatteessa sama kuin tweet2vec, mutta syötteenä on merkkien sijasta sanoja. Hakutaulukkoon tallennetaan sanavektorit $V$ (tässä 20K) yleisimmille sanoille, ja loput ryhmitellään yhteen `UNK'-merkin alle.",
      "id": "task461-91f5b335e7eb44b2a72cf66519306da0",
      "output": [
        "Mikä on sanatason lähtötaso, johon niitä verrataan?",
        "Mikä on sanatason perustaso?"
      ]
    },
    {
      "input": "Työskentelemme tietokokonaisuuden kanssa, joka koostuu 3 206 uutisartikkelista, joista jokainen on merkitty joko oikeaksi tai väärennetyksi, ja 1 603 oikeaa ja väärennettyä artikkelia on jaettu täydellisesti 50/50. Väärennetyt artikkelit hankittiin verkkosivuilta, jotka voittoa tavoittelematon riippumaton tiedotusvälineiden faktantarkastusjärjestö Verafiles ja Filippiinien kansallinen journalistiliitto NUJP (National Union of Journalists in the Philippines) olivat merkinneet väärennetyiksi uutissivustoiksi. Oikeat artikkelit saatiin Filippiinien valtavirta-uutissivustoilta, kuten Pilipino Star Ngayon, Abante ja Bandera.",
      "id": "task461-e49064ca03f0456b86280ba5a4fb6dc5",
      "output": [
        "Mikä on tietokokonaisuuden lähde?"
      ]
    },
    {
      "input": "MADAMIRA BIBREF6 -järjestelmää on äskettäin arvioitu sokealla testisarjalla (25 000 sanaa modernia arabian standardia (MSA) varten, jotka on valittu Penn Arabic Tree Bankista (PATB)), ja raportoitu tarkkuus oli 96,2 % niiden sanojen prosenttiosuutena, joissa valittu analyysi (SAMA-morfologisen analysaattorin BIBREF7 tarjoama) sisältää oikean lemman. Koska MSA kirjoitetaan yleensä ilman diakriittisiä merkkejä ja IR-järjestelmät poistavat yleensä kaikki diakriittiset merkit hakukyselyistä ja indeksoidusta datasta esikäsittelyn perusvaiheena, lisätään toinen sarake diakriittisille lemoille, ja sitä käytetään lemmatisaattorimme arvioimiseen ja vertailuun uusimman lemmatisointijärjestelmän MADAMIRA:n kanssa.",
      "id": "task461-dd51fd4046324566b9ffdb02adb4fe01",
      "output": [
        "Mikä on tekniikan nykytila?"
      ]
    },
    {
      "input": "Niinpä tässä työssä hyödynnämme hybridi-koodiverkkoja (HCN) BIBREF4 , koska HCN:n avulla saavutetaan huippuluokan suorituskyky datatehokkaalla tavalla tehtäväkeskeisissä vuoropuheluissa, ja ehdotamme AE-HCN:iä, jotka laajentavat HCN:ää automaattisella koodaajalla (kuva FIGREF8 ).  AE-HCN(-CNN) päihittää HCN:n Test-OOD-testissä suurella marginaalilla, keskimäärin noin 17(20) pisteellä, säilyttäen samalla suorituskyvyn mahdollisimman pienen kompromissin Testiin verrattuna. ",
      "id": "task461-14eff9ca0df14cdb9ca2d4bbaf953159",
      "output": [
        "Kuinka paljon heidän menetelmänsä on parempi kuin uusin OOD-tunnistusmenetelmä?"
      ]
    },
    {
      "input": "Tutkimme manuaalisesti virheitä, joita keinotekoiset neuroverkot tekevät kohdekielen morfologisen taivutuksen osalta sen jälkeen, kun ne on esiharjoitettu eri lähdekielillä. Laadullisessa analyysissämme käytämme validointijoukkoa. Siksi näytämme validointisarjan tarkkuudet taulukossa TABREF19 vertailun vuoksi. Annotoimme manuaalisesti kunkin lähde-kohdekieliyhdistelmän 75 ensimmäisen kehitysesimerkin tuotokset. Kaikki löydetyt virheet luokitellaan johonkin seuraavista luokista.",
      "id": "task461-0f2fd461030149fc96c7d96b5c6ef869",
      "output": [
        "Miten tehtävässä suoriutumista arvioidaan?"
      ]
    },
    {
      "input": "Wav2vec BIBREF22 ehdotti monikerroksista konvoluutiohermoverkkoa, joka optimoitiin melukontrastisen binääriluokittelun avulla, ja sitä sovellettiin WSJ ASR-tehtäviin. Kokeemme koostuivat kolmesta eri asetelmasta: 1) täysin valvottu järjestelmä, jossa käytettiin kaikkea merkittyä dataa; 2) SSL-järjestelmä, jossa käytettiin wav2vec-ominaisuuksia; 3) SSL-järjestelmä, jossa käytettiin ehdottamiamme DeCoAR-ominaisuuksia. Kaikki käytetyt mallit perustuivat syviin BLSTM-malleihin, joissa käytettiin CTC-häviökriteeriä.",
      "id": "task461-2d3402cb53904876a25bcd886544feb6",
      "output": [
        "Mitkä ovat WSJ eval92:n ja LibriSpeech test-cleanin perusmallit?"
      ]
    },
    {
      "input": "Vertaamme malliamme seuraaviin uusimpiin yhteisiin entiteettien ja relaatioiden louhintamalleihin:(1) SPTree BIBREF4: Tämä on kokonaisvaltainen neuraalinen entiteettien ja relaatioiden louhintamalli, jossa käytetään sekvenssi-LSTM:ää ja puu-LSTM:ää. (2) Tagging BIBREF5: Tämä on neuraalinen sekvenssimerkintämalli, joka poimii entiteetit ja relaatiot yhdessä käyttäen LSTM-kooderia ja LSTM-dekooderia. (3) CopyR BIBREF6: Tässä mallissa käytetään enkooderi-dekooderi-lähestymistapaa entiteettien ja relaatioiden yhteiseen uuttamiseen. (4) HRL BIBREF11: Tässä mallissa käytetään vahvistusoppimisalgoritmia (RL), jossa on kaksi hierarkiatasoa tuplien louhintaan. (5) GraphR BIBREF14: Tämä malli pitää jokaista lauseen merkkiä graafin solmuna ja solmuja yhdistäviä reunoja niiden välisinä suhteina. (6) N-gram Attention BIBREF9: Tässä mallissa käytetään koodaaja-dekooderi-lähestymistapaa, jossa on N-gram attention -mekanismi tietämyspohjan täydentämiseen käyttäen etäisesti valvottuja tietoja.",
      "id": "task461-1075d56bceee4ab28e281861349a961a",
      "output": [
        "Mihin aiempaan työhön kirjoittajat viittaavat?"
      ]
    },
    {
      "input": "Tutkimme erityisesti huomion kiinnittämistä substantiiveihin, verbeihin, pronomineihin, subjekteihin, objekteihin ja negaatiosanoihin sekä erityisiin BERT-merkkeihin eri tehtävissä.",
      "id": "task461-65d0bba786644babac4ac9e61ab96960",
      "output": [
        "Mitä käsityöläisominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Vaikka valinnainen lemmatointivaihe käytettäisiinkin, voidaan silti pyrkiä vähentämään graafin monimutkaisuutta edelleen yhdistämällä samankaltaisia kärkipisteitä. Tätä vaihetta kutsutaan metapisteiden rakentamiseksi. Metahuipun rakentamisvaihe toimii seuraavasti. Olkoon INLINEFORM0 edellä määritetty kärkipisteiden joukko. Metapiste INLINEFORM1 koostuu joukosta huippuja, jotka ovat INLINEFORM2:n eli INLINEFORM3:n elementtejä. Olkoon INLINEFORM4 INLINEFORM5 -niminen metapiste. Rakennetaan tietty INLINEFORM6 siten, että jokaisen INLINEFORM7 :n osalta INLINEFORM8 :n alkuperäiset särmät (ennen sen yhdistämistä metapisteeksi) kytketään uudelleen juuri lisättyyn INLINEFORM9 :ään. Huomaa, että tällaiset särmät yhdistyvät huippuihin, jotka eivät ole osa INLINEFORM10 -järjestelmää. Näin ollen sekä kärkipisteiden että reunojen määrä vähenee huomattavasti. Tämä ominaisuus toteutetaan seuraavalla menettelyllä: Meta-vertex-ehdokkaiden tunnistaminen. Muokkausetäisyyttä ja sanojen pituusetäisyyttä käytetään sen määrittämiseksi, pitäisikö kaksi sanaa yhdistää metapisteeksi (vain jos pituusetäisyyden kynnysarvo täyttyy, lasketaan kalliimpi muokkausetäisyys). Metatekstin luominen. Yhteisinä tunnisteina käytetään alkuperäisten verteksien kantakielisiä versioita, ja jos kantakielisiä versioita on useampi kuin yksi, valitaan tunnistetuista ehdokkaista se verteksi, jolla on korkein centraliteettiarvo graafissa, ja sen kantakielinen versio otetaan käyttöön uutena verteksinä (meta verteksinä).",
      "id": "task461-68a8b7e170bd4f0997d9a395a1b6244e",
      "output": [
        "Miten metapisteet lasketaan?"
      ]
    },
    {
      "input": "Toinen tietoerä koostuu tapahtumiin liittyvistä twiiteistä, jotka koskevat viittä Yhdysvalloissa vuonna 2018 tapahtunutta luonnonkatastrofia. Nämä ovat: itärannikon pommisykloni (2.-6.1.), Mendocinon, Kalifornian maastopalot (27.7.-18.9.), Florence-hurrikaani (31.8.-19.9.), Michael-hurrikaani (7.10.-16.10.) ja Kalifornian leiripalot (8.11.-25.11.). ",
      "id": "task461-da1cca3fadb747958b7e80e73b226569",
      "output": [
        "Mitä viittä luonnonkatastrofia tutkittiin?"
      ]
    },
    {
      "input": "Vertaileva arvioija koulutetaan maksimiluotettavuusarvioinnin (MLE) tavoitteella, kuten on kuvattu eq DISPLAY_FORM6:ssa, jossa $\\mathcal {X}$ on edellä kuvatulla tavalla muodostettu pareittaisten harjoitusesimerkkien joukko, $Q(x_1, x_2) \\ in \\lbrace >,<,\\approx \\rbrace $ on parin ($x_1$, $x_2$) todellinen etiketti, $D_\\phi ^q(x_1, x_2)$ on todennäköisyys sille, että vertailevan erottelijan ennuste on $q$ ($q \\in \\lbrace >,<,\\approx \\rbrace $) parille ($x_1$, $x_2$).",
      "id": "task461-51cf8519cfce487e8ce4ff670c0f9a94",
      "output": [
        "Miten he lisäävät ihmisen ennakko-odotuksia koskevan merkinnän hienosäätöprosessiin?"
      ]
    },
    {
      "input": "Maksimientropiateoriaa sovelletaan vietnaminkielisten sanojen segmentoinnin ratkaisemiseen BIBREF15 , BIBREF22 , BIBREF23 . Vietnamin kielen sanojen segmentointitehtävästä on tehty useita tutkimuksia viime vuosikymmenen aikana. Dinh et al. aloittivat tämän tehtävän WFST-lähestymistavan (Weighted Finite State Transducer) ja neuroverkkomenetelmän avulla BIBREF9 . Lisäksi koneoppimisen lähestymistapoja on tutkittu ja sovellettu laajalti luonnollisen kielen käsittelyyn ja sanojen segmentointiin. Itse asiassa useissa tutkimuksissa on käytetty tukivektorikoneita (SVM) ja ehdollisia satunnaiskenttiä (CRF) sanojen segmentointitehtävään BIBREF7 , BIBREF8 .",
      "id": "task461-6ca22b4bdeac49d4a3594c6a437e784b",
      "output": [
        "Mitä lähestymistapoja on sovellettu sanojen segmentoinnin ratkaisemiseen vietnamiksi?"
      ]
    },
    {
      "input": "Tulevaisuudessa pyrimme käyttämään korpusta annotaatiohankkeissa, kuten puheen osien merkitsemisessä ja nimettyjen entiteettien tunnistamisessa. Lisäksi tuotettuja sanasulkeumia hyödynnetään Sindhi WordNetin automaattisessa rakentamisessa.",
      "id": "task461-3b54a18403e64d57a762605d7edb41dc",
      "output": [
        "Käytetäänkö koulutettuja sanasulkeumia muihin NLP-tehtäviin?"
      ]
    },
    {
      "input": "Valitsimme vertailuarvoja varten viisi järjestelmää. Valitsimme ensin langid.py-kirjaston, jota käytetään kirjallisuudessa usein järjestelmien vertailuun. Koska työmme koskee neuroverkko-LID-järjestelmää, valitsimme kirjallisuudesta kaksi neuroverkkojärjestelmää, nimittäin BIBREF6:n koodaaja-dekooderi EquiLID-järjestelmän ja BIBREF10:n GRU-neuroverkko LanideNN-järjestelmän. Lopuksi otimme mukaan CLD2:n ja CLD3:n, kaksi toteutusta Naïve Bayes LID -ohjelmistosta, jota Google käyttää Chrome-selaimessaan BIBREF4, BIBREF0, BIBREF8 ja jota käytetään joskus vertailukohtana LID-kirjallisuudessa BIBREF7, BIBREF6, BIBREF8, BIBREF2, BIBREF10.",
      "id": "task461-9af1f859159c4f8d8b5f2572001f2667",
      "output": [
        "Mitä nykyisiä kielten tunnistusjärjestelmiä testataan?"
      ]
    },
    {
      "input": "Koska konservatiivien ja liberaalien on raportoitu käyttäytyvän eri tavoin sosiaalisilla verkkoalustoilla BIBREF19BIBREF20BIBREF21 , annoimme lisäksi poliittisen puolueellisuusmerkinnän eri yhdysvaltalaisille tiedotusvälineille (ja näin ollen myös uutisartikkeleille) BIBREF2:ssa kuvatun menettelyn mukaisesti. Menetelmämme kestävyyden arvioimiseksi teimme luokittelukokeita harjoittelemalla vain vasemmistolaisuuteen (tai oikeistolaisuuteen) suuntautuneita sekä disinformaatio- että valtavirta-alan tiedotusvälineitä ja testaamalla koko lähdejoukkoa sekä jättämällä pois tietyt lähteet, jotka olivat näytteiden määrässä muita suurempia, jotta vältyttäisiin liialliselta sovittamiselta.",
      "id": "task461-551ad34be2374027a7269ccca9467f15",
      "output": [
        "Miten eri lähteiden poliittinen puolueellisuus otetaan huomioon mallissa?"
      ]
    },
    {
      "input": "Keräämme HLA-dataa TV Tropes BIBREF3:sta, joka on pop-kulttuurille omistettu tietopohjainen verkkosivusto, joka sisältää tietoa lukuisista hahmoista eri lähteistä. Wikipedian tapaan sen sisältöä tarjoaa ja muokkaa yhteistyössä valtava käyttäjäkunta. Ominaisuudet määräytyvät ihmiskatsojien ja heidän hahmoista saamiensa vaikutelmien perusteella, ja ne korreloivat ihmisen kaltaisten ominaisuuksien kanssa. Uskomme, että TV Tropes soveltuu tarkoitukseemme fiktiivisten hahmojen mallintamiseen paremmin kuin tietolähteet, joita käytetään esimerkiksi BIBREF25 shuster2019engaging -teoksissa, koska TV Tropesin sisällöntuottajat palkitaan sisällön oikeanlaisesta tarjoamisesta yhteisön tunnustuksen kautta.",
      "id": "task461-01287f4f3d1c41bcb699d341818497e2",
      "output": [
        "Miten dataset mallintaa hahmojen profiileja?"
      ]
    },
    {
      "input": "Suoritimme inhimillisen arvioinnin Amazon Mechanical Turk -palvelun avulla subjektiivisen laadun arvioimiseksi. Rekrytoimme master-tason työntekijöitä (joilla on hyvät ennakkohyväksyntäprosentit) suorittamaan inhimillisen vertailun kahden järjestelmän tuottamien vastausten välillä (jotka on poimittu satunnaisesti vertailujärjestelmistä). Työntekijöiden on arvioitava jokainen lausahdus asteikolla 1 (huono) - 3 (hyvä) informatiivisuuden ja luonnollisuuden suhteen. Informatiivisuus ilmaisee, missä määrin tuotettu lausuma sisältää kaikki vuoropuhelussa määritellyt tiedot. Luonnollisuus kertoo, onko lausuma yhtä luonnollinen kuin ihmisen lausuma. Arviointiharhojen vähentämiseksi jaamme kunkin kysymyksen kolmelle eri työntekijälle. Lopulta keräsimme yhteensä 5800 tuomaria.",
      "id": "task461-66f5347fb8064d9caca21f0088e1c7f7",
      "output": [
        "Mitkä olivat ihmisten arviointiperusteet?"
      ]
    },
    {
      "input": " Lopuksi, kun tutkitaan eurooppalaisten ja ei-eurooppalaisten kielten välistä sukulaisuutta (vrt. (En/Fr)$\\rightarrow $Ar), saadaan samankaltaisia tuloksia kuin yksikielisessä kokeessa (makro F-tulos 62,4 vs. 68,0), ja parhaat tulokset saavutetaan Ar $\\rightarrow $(En/Fr) -kielellä. Tämä osoittaa, että molemmilla puolilla on yhteisiä pragmaattisia välineitä ja samalla tavalla ironisten twiittien kerrontatavassa samankaltaisia tekstipohjaisia kuvioita.",
      "id": "task461-6c64a4cebbd143339998c7eb5aa7cb05",
      "output": [
        "Tunnistavatko kirjoittajat kulttuurieroja ironian käytössä?"
      ]
    },
    {
      "input": "Vastakohtaisten muutosten jälkeen alkuperäisten kohdemallien (ilman \"-adv\"-loppusanaa) suorituskyky putoaa dramaattisesti (esimerkiksi BERT:n kokonaistarkkuus Quorassa putoaa 94,6 prosentista 24,1 prosenttiin), mikä paljastaa, että kohdemallit ovat haavoittuvia vastakohtaisille esimerkeillemme.",
      "id": "task461-bde697737b2d49bc8a3149d4f862b5a7",
      "output": [
        "Kuinka paljon dramaattisesti tulokset laskevat malleissa, jotka käyttävät luotuja vastakkaisia esimerkkejä?"
      ]
    },
    {
      "input": "Koska loukkaavan kielenkäytön havaitsemista koskeva tutkimus on suurelta osin keskittynyt englannin kieleen, lähdimme tutkimaan sellaisten mallien suunnittelua, joita voidaan menestyksekkäästi käyttää sekä englannin että tanskan kielessä.",
      "id": "task461-fa63cd71f4294f1b85063046ff746b6a",
      "output": [
        "Mikä on haaste muille kielille kuin englannille"
      ]
    },
    {
      "input": "Aloitimme arvioimalla tavanomaisia MT-paradigmoja eli PBSMT BIBREF3 ja NMT BIBREF1 . PBSMT:n osalta tarkastelimme myös kahta kehittynyttä menetelmää: apukieleen perustuvaa pivot-pohjaista käännöstä BIBREF10 ja fraasitaulukoiden induktiota yksikielisestä datasta BIBREF14 . NMT:n osalta vertasimme kahta erilaista koodaaja-dekooderi-arkkitehtuuria: tarkkaavaisuuteen perustuvaa RNN-pohjaista mallia (RNMT) BIBREF2 ja Transformer-mallia BIBREF18 . Normaalin yksisuuntaisen mallintamisen lisäksi tutkimme vähäisten resurssien ongelman ratkaisemiseksi kahta monisuuntaista mallia: kaksisuuntaista mallia BIBREF11 ja monista moniin (M2M) -mallia BIBREF8 . Parhaan mallin tunnistamisen jälkeen tutkimme myös takaisinkääntämiseen perustuvan tiedonlisäysmenetelmän hyödyllisyyttä BIBREF17 .",
      "id": "task461-8f9c5ecfd86549fa85bda67cec743231",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Toisella kierroksella keräsimme 293 annotaatiota 12 annotoijalta. Korektorin jälkeen COSTRA 1.0 -tietokannan muodostavat 4262 yksilöllistä lausetta (mukaan lukien 150 siemenlausetta).",
      "id": "task461-6647a35d3bba4ee3aa6e42cc58cef325",
      "output": [
        "Miten mahdolliset lauseiden muunnokset esitetään tietokannassa uusina lauseina?"
      ]
    },
    {
      "input": "Suoritamme kokeilumme käyttäen SemEval 2010 Task 14: Word Sense Induction & Disambiguation BIBREF5 -arviointimenetelmää. ",
      "id": "task461-9a60ef442cfc45fb926516aaf7f4f8e5",
      "output": [
        "Millainen arviointi suoritetaan?"
      ]
    },
    {
      "input": "Vuoden 2019 Workshop on Neural Generation of Text (WNGT) Efficiency -tapahtuman jaettua tehtävää BIBREF0 varten Notre Dame Natural Language Processing (NDNLP) -ryhmä tutki menetelmää, jolla parametreihin saadaan aikaan harvennusta, jota kutsutaan automaattiseksi koonmääritykseksi, jotta voidaan vähentää parametrien lukumäärää muuntajassa suhteellisen vähäisellä suorituskyvyn laskulla.",
      "id": "task461-54185039c05d41fca0ad13b40ce64b7d",
      "output": [
        "Mikä on WNGT 2019:n yhteinen tehtävä?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme on kommentoitu Ruijinin sairaalan ruoansulatuskanavan kirurgian osaston toimittamien kiinalaisten patologisten raporttien perusteella. Se sisältää 17 833 lausetta, 826 987 merkkiä ja 2 714 kysymys-vastausparia. ",
      "id": "task461-1db48e3d900b499aad1f08e47aad70b7",
      "output": [
        "Kuinka suuri QA-CTS-tehtävätietokanta on?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvaamme näitä kolmea osatekijää koskevaa tiedonkeruuta. Aluksi kuvaamme pilottitutkimuksia, jotka teimme kerätessämme tervejärkisiä päättelykysymyksiä (SECREF4 ). Jaksossa SECREF5 käsitellään kysymysten, tekstien ja vastausten keräämistä Amazon Mechanical Turk -palvelun (jäljempänä MTurk) avulla. Jaksossa SECREF17 annetaan tietoa eräistä tarvittavista jälkikäsittelyvaiheista ja tietokokonaisuuden validoinnista. ",
      "id": "task461-a978aaeebd0c4b9cbab9889ff4e1fd7f",
      "output": [
        "miten tiedot kerättiin?"
      ]
    },
    {
      "input": "Määrittelemme vihapuheen kieleksi, joka nimenomaisesti tai epäsuorasti uhkaa tai halventaa henkilöä tai ryhmää heidän identiteettinsä, kuten sukupuolen, etnisen alkuperän tai seksuaalisen suuntautumisen, perusteella.",
      "id": "task461-27a0ef8742d341d9a454663ec2f2e64c",
      "output": [
        "Mikä on heidän vihapuheen määritelmänsä?"
      ]
    },
    {
      "input": "Keräsimme tietokokonaisuuden, jossa oli 1900 vuoropuhelua ja 8533 kierrosta. ",
      "id": "task461-f6fa711ef2f94a03bf14648981145314",
      "output": [
        "Mikä on dialogin keskimääräinen pituus?"
      ]
    },
    {
      "input": "Joukkotyöntekijöitä pyydettiin merkitsemään, oliko kolmikko oikein, eli kuvastiko kolmikko lauseen seurausta.",
      "id": "task461-c36f7f0ed79b47089aed8a54370df562",
      "output": [
        "Mikä on joukkoistamisen rooli?"
      ]
    },
    {
      "input": "Taulukossa TABREF18 esitetään GM$\\_$KL-mallin Spearmanin korrelaatioarvot, jotka on arvioitu sanojen samankaltaisuuden vertailuaineistoissa: SL BIBREF20, WS, WS-R, WS-S BIBREF21, MEN BIBREF22, MC BIBREF23, RG BIBREF24, YP BIBREF25, MTurk-287 ja MTurk-771 BIBREF26, BIBREF27 ja RW BIBREF28.  Taulukossa TABREF19 esitetään GM$\\_$KL-mallin arviointitulokset merkitystietoaineistoissa, kuten WordNetistä luotu merkitysparitietoaineisto BIBREF29, jossa on sekä positiivisia että negatiivisia merkintöjä, joukkoistettu tietokokonaisuus BIBREF30, joka sisältää 79 semanttista suhdetta, jotka on merkitty merkityksi merkityksi tai ei merkityksi, ja annotoitu distributiivisesti samankaltaiset substantiivit -tietokokonaisuus BIBREF31.",
      "id": "task461-7c466d0b9c244ba8aaad774c75ec3ce1",
      "output": [
        "Mitä laadullisia kokeita on tehty vertailutietokannoilla?"
      ]
    },
    {
      "input": "Gensimin julkaiseman D2V-algoritmin virittämiseen käytettävissä olevista parametreista valittiin kuusi parametria BIBREF14-optimointia varten. Parametri window_size vaikuttaa tekstien analysoinnissa käytettävän liukuikkunan kokoon. Parametri alpha edustaa verkon oppimisnopeutta. Sample-asetuksella malli voi vähentää suurtaajuisille sanoille annettua painoarvoa. dm-parametri määrittää koulutuksessa käytettävän arkkitehtuurin (PV-DM tai PV-DBOW). Parametri hs määrittelee, käytetäänkö koulutuksessa hierarkkista softmaxia vai negatiivista näytteenottoa. Lopuksi parametri vector_size vaikuttaa tuloksena saatavan vektorin muodostavien ulottuvuuksien määrään.",
      "id": "task461-6cf23ac9da4a4688842c7de25a0de58f",
      "output": [
        "Mitkä kuusi parametria optimoitiin ruudukkohakua käyttäen?"
      ]
    },
    {
      "input": "Perusasetukset Vertaamme perusteellisesti lähestymistapojamme seuraaviin perusasetuksiin: Suora lähde$\\suora $kohde: Monikielinen: Yksi yhteinen NMT-malli useille käännössuunnille BIBREF6.Moni-moneen: Koulutettu kaikkia mahdollisia suuntia varten lähde-, kohde- ja pivot-kielten välillä: Koulutettu vain kohdekielen suuntiin, eli lähde$\\rightarrow $target ja pivot$\\rightarrow $target, mikä yleensä toimii paremmin kuin many-to-many-järjestelmät BIBREF27.",
      "id": "task461-e844b3cb8d784981a26d34814350fd1a",
      "output": [
        "Mitkä ovat monikieliset mallit, jotka suoriutuivat kokeessa paremmin?"
      ]
    },
    {
      "input": "Wikipedian versiotallenteet, jotka Leskovec et al. leskovec2010governance esitteli aiemmin, sisältävät kahdeksan gigatavua (pakattu koko) versiomuokkauksia metatietoineen.",
      "id": "task461-207f561fe7224fa28906704b64f4c826",
      "output": [
        "Kuinka suuri on Wikipedian revision dump -tietokanta?"
      ]
    },
    {
      "input": "Tietokannan lopulliset merkintäluokat ovat: Ilo, suru, viha, pelko, odotus, yllätys, rakkaus, inho, neutraali.",
      "id": "task461-8486832f1c1b458e9993c6803a4ec249",
      "output": [
        "Kuinka monta tunnetta he katsovat?"
      ]
    },
    {
      "input": " Ehdolliset satunnaiskentätEhdolliset satunnaiskentät (CRF) BIBREF10 ovat vakiintunut lähestymistapa, kun käsitellään peräkkäisiä tietoja sekvenssien merkitsemisen yhteydessä. BiLSTM-CRF Ennen syvien neuraalisten kielimallien syntymistä BiLSTM-CRF-mallit BIBREF11 olivat saavuttaneet huippuluokan tuloksia sekvenssien merkitsemistehtävässä. MonitehtäväoppiminenMulti-Task Learning (MTL) BIBREF15 on tullut suosituksi syväoppimisen edistymisen myötä. BioBERTDeep neuraaliset kielimallit ovat viime aikoina kehittyneet menestyksekkääksi menetelmäksi tekstin esittämiseen. Erityisesti Bidirectional Encoder Representations from Transformers (BERT) päihitti aiemmat huipputason menetelmät huomattavasti eri NLP-tehtävissä BIBREF17.",
      "id": "task461-d161003dcb7d446885908182f6c2772b",
      "output": [
        "Mitä perustasoja ne ottavat käyttöön?"
      ]
    },
    {
      "input": "Sen tuottamiseksi tutkimme kahta implisiittistä käyttäjäpalautteen merkintästrategiaa: viiden minuutin uudelleenkäyttöä ja yhden päivän palautusta. ",
      "id": "task461-1259ee158d2347c4bd3331fd19987a52",
      "output": [
        "Mitä palautelappuja käytetään?"
      ]
    },
    {
      "input": "Suunnittelemme kolme tehtävää seq2seq-mallin esiharjoittelua varten: lauseiden uudelleenjärjestäminen (SR), seuraavan lauseen tuottaminen (NSG) ja peitettyjen asiakirjojen tuottaminen (MDG). ",
      "id": "task461-fa5e686f006246e58f103d0ea57860ad",
      "output": [
        "Mitä on peitettyjen asiakirjojen tuottaminen?"
      ]
    },
    {
      "input": "Korpus koostuu 53 asiakirjasta, joissa on keskimäärin 156,1 lausetta asiakirjaa kohti ja joissa jokaisessa on keskimäärin 19,55 merkkiä. Korpus sisältää yhteensä 8 275 lausetta ja 167 739 sanaa.",
      "id": "task461-2e1beff893c64f92a93b6400699e1237",
      "output": [
        "Kuinka suuri korpus on?"
      ]
    },
    {
      "input": "Raportteja julkaisevat Météo France ja Met Office, sen brittiläinen vastine. Ne ovat julkisesti saatavilla kyseisten organisaatioiden verkkosivuilla. Molemmat korporaatiot kattavat saman ajanjakson kuin vastaavat aikasarjat, ja koska ne ovat luonteeltaan päivittäisiä, saadaan yhteensä 4 261 ja 4 748 asiakirjaa.",
      "id": "task461-6329c652b85645838755f9ee33536746",
      "output": [
        "Kuinka suuri on koulutukseen/testaukseen käytetty tietokokonaisuus?"
      ]
    },
    {
      "input": "Kuten edellä on kuvattu, mukautimme rupnik2016news-sivuston klusterilinkitystietokannan arvioidaksemme kieltenvälistä online-klusterointimenetelmäämme.",
      "id": "task461-c39cee4d84ec48da91306dcc6dd3cdab",
      "output": [
        "Mitkä ovat tietokokonaisuuksien lähteet?"
      ]
    },
    {
      "input": "Tässä luvussa sovellamme syväoppimisen ja kielitieteen yhdistelmää sekä aspektin erottamisen että subjektiivisuuden havaitsemisen ongelman ratkaisemiseen.",
      "id": "task461-4974357a311a4b94996643ba4cb9ff82",
      "output": [
        "Miten aspektit tunnistetaan aspektien louhinnassa?"
      ]
    },
    {
      "input": "Vaikka huumori on yleismaailmallinen konstruktio, on olemassa suuria eroja sen välillä, mitä kukin yksilö voi pitää humoristisena. Pyrimme keskittymään väestön osajoukkoon, jossa voimme mitata reaktioita kvantitatiivisesti: suosittuun Redditin r/Jokes-ketjuun. Tämä foorumi on erittäin suosittu - siellä julkaistaan kuukausittain kymmeniä tuhansia vitsejä ja siellä on yli 16 miljoonaa jäsentä. Vaikka on olemassa suurempia vitsitietokantoja, r/Jokes-ketju on vertaansa vailla sen sisältämien luokiteltujen vitsien määrässä. Tietojemme mukaan vastaavaa luokiteltujen vitsien lähdettä ei ole millään muulla kielellä. Nämä Reddit-postaukset koostuvat vitsin rungosta, iskulauseesta ja reaktioiden eli upvotes-äänten määrästä. Vaikka tämäntyyppinen huumori saattaa olla miellyttävintä vain osalle väestöstä, se on tehokas tapa mitata reaktioita vitseihin suuressa ryhmässä.",
      "id": "task461-c35dd89d5cab4aa6b5971e0a4a93d317",
      "output": [
        "Millaista huumoria he ovat arvioineet?"
      ]
    },
    {
      "input": "Useat artikkelit ovat osoittaneet, että \"matalat\" naive Bayes-luokittelijat BIBREF12, BIBREF8, BIBREF13, BIBREF14, SVM:t BIBREF15 ja vastaavat mallit toimivat erittäin hyvin LID:n tekemiseen. Esimerkiksi DSL 2017 -julkaisussa BIBREF1 annetaan yleiskatsaus kaikkien jaetusta tehtävästä kilpailleiden tiimien ratkaisuihin, ja voittajaksi selviytynyt lähestymistapa BIBREF16 käytti SVM:ää, jossa oli hahmojen n-grammi- ja puheosien tunniste-ominaisuuksia sekä joitakin muita kehitettyjä ominaisuuksia. DSL 2015:n voittajalähestymistapa käytti ensemble-naive Bayes -luokittelijaa. Fasttext-luokittelija BIBREF17 on ehkä yksi tunnetuimmista tehokkaista \"pinnallisista\" tekstiluokittelijoista, joita on käytetty LID:ssä. Useissa artikkeleissa on ehdotettu hierarkkisia pinottuja luokittelijoita (myös leksikoita), jotka esimerkiksi luokittelevat tekstin ensin kieliryhmän ja sitten tarkan kielen mukaan BIBREF18, BIBREF19, BIBREF8, BIBREF0. Tutkijat ovat tutkineet syvempiä LID-malleja li",
      "id": "task461-1927a3c14f404d5797ec5965771c5af5",
      "output": [
        "Mikä on aiempien töiden lähestymistapa?"
      ]
    },
    {
      "input": "Seuraavaksi osoitamme, että MASC-arkkitehtuurin avulla voidaan saavuttaa erittäin korkea paikannustarkkuus, ja se on huomattavasti parempi kuin perusratkaisu, joka ei sisällä tätä mekanismia.",
      "id": "task461-c448ba7eb78241b6bcd545e931d658d4",
      "output": [
        "Mitä arviointimittareita tekijät tarkastelivat?"
      ]
    },
    {
      "input": "Perusarvot. Koska yksikään nykyisistä KBC-menetelmistä ei pysty ratkaisemaan OKBC-ongelmaa, valitsemme perustasoksi LiLin eri versiot: LiLi: LiLi-versio, jossa koulutamme yhden ennustemallin INLINEFORM0 kaikille testisuhteille: Emme siirrä (aiemmin opittuja) painoja INLINEFORM0:n alustamista varten, eli poistamme LL.F-th) käytöstä: Tässä käytämme kiinteää ennustuskynnystä 0,5 relaatiokohtaisen kynnyksen INLINEFORM0 sijasta.BG: Puuttuvat tai yhdistävät linkit (kun käyttäjä ei vastaa) täytetään \"@-RelatedTo-@\" -merkinnällä sokeasti, ei arvausmekanismia.w/o PTS: LiLi ei pyydä lisävihjeitä aiempien tehtävien valinnan kautta taitojen parantamista varten.",
      "id": "task461-d74a51155b9244088b808c069e044a97",
      "output": [
        "Mitä lähtötasoa kokeissa käytetään?"
      ]
    },
    {
      "input": "Lämmittelymenettelynä kaksi kommentoijaa (kirjoittaja ja valvoja) kommentoivat ensimmäiset 100 viestiä ja vertailivat tuloksia keskenään. Loppuosan annotointitehtävästä suoritti kirjoittaja, ja tuloksena oli 3600 annotoitua näytettä.",
      "id": "task461-73d405fdc9064681a58162bc685542bd",
      "output": [
        "Keitä olivat kommentoijat?"
      ]
    },
    {
      "input": "Varmistaaksemme tekniikkamme luotettavuuden harvinaisten sanojen kattavuuden laajentamisessa teimme kokeita harvinaisten sanojen samankaltaisuustietokannalla BIBREF6 . Tietokanta sisältää 2034 paria harvinaisia sanoja, kuten ulcerate-change ja nurturance-care, joita 10 arvioijaa arvioi asteikolla [0,10]. Taulukossa TABREF15 esitetään tulokset aineistosta kolmelle esivalmistetulle sanasulkeumalle (ks. SECREF2 ) niiden alkuperäisessä muodossa sekä WordNetistä saaduilla lisäsanoilla täydennettynä.",
      "id": "task461-ca5b6da46c054716913c3c1524485f96",
      "output": [
        "Miten harvinaiset sanat määritellään?"
      ]
    },
    {
      "input": "Taajuussuodattimen suhde INLINEFORM0 asetetaan matalataajuisten sanojen (harvinaisten sanojen) suodattamiseksi pois hakutaulukosta.",
      "id": "task461-15581ba9eaae4839b93aed4d25e460b0",
      "output": [
        "miten harvinaiset sanat määritellään?"
      ]
    },
    {
      "input": "Parafraaseja saadaan kääntämällä englanninkielinen merkkijono vieraalle kielelle ja kääntämällä se sitten takaisin englanniksi. ",
      "id": "task461-82b39cbfc2f1450caa33db2b2a1c0e94",
      "output": [
        "Vaikuttaa siltä, että kysymysten parafraasien oppimista, neuraalista pisteytysmallia ja vastausten valintamallia ei voida kouluttaa päästä päähän. Miten ne koulutetaan?"
      ]
    },
    {
      "input": "Se sisältää yhteensä 708 tuntia ranskalaisia (Fr), saksalaisia (De), hollantilaisia (Nl), venäjänkielisiä (Ru), espanjalaisia (Es), italialaisia (It), turkkilaisia (Tr), persialaisia (Fa), ruotsalaisia (Sv), mongolialaisia (Mn) ja kiinalaisia (Zh) puheita, joista ranskalaiset ja saksalaiset puheet ovat olemassa olevista julkisista korpuksista pisimpään kestäneet.",
      "id": "task461-91af6ed3b2c2469cbfd4846971e0670a",
      "output": [
        "Mitkä kielet kuuluvat korpukseen?"
      ]
    },
    {
      "input": "Sekä BasicDCGAN:n että MultitaskDCGAN:n havaittu suorituskyky, kun käytetään 3-luokkia, on verrattavissa uusimpaan tekniikkaan: 49,80 % verrattuna 49,99 %:iin, joka on raportoitu BIBREF16:ssa. ",
      "id": "task461-7b0cd21882f144e28019e128949b6cd2",
      "output": [
        "Millä mallilla saavutetaan tässä tehtävässä uusin mahdollinen suorituskyky?"
      ]
    },
    {
      "input": "Tarkastelemme kahdenlaisia arkkitehtuureja: kaksisuuntainen kielimalli, jolla täydennetään sekvenssistä sekvenssiin -kooderia, ja yksisuuntainen malli, jolla täydennetään dekooderia. Molemmissa käytetään itsestään huomiota herättävää BIBREF16 -mallia, ja yksisuuntainen malli sisältää INLINEFORM0-muuntajalohkoja, joiden jälkeen sanaluokittelija ennustaa oikealla olevan seuraavan sanan. kaksisuuntainen kielimalli, joka täydentää sekvenssistä sekvenssiin -kooderia.",
      "id": "task461-629a231f74e74a54a3b0d5a2b4f46095",
      "output": [
        "Mitä kielimalliarkkitehtuureja käytetään?"
      ]
    },
    {
      "input": "Tarjoamme kolme paria lyhyitä ja pitkiä tietokokonaisuuksia eri aloilta (elokuvat ja ravintolat) ja eri kieliltä (englanti ja korea), jotka soveltuvat tehtävään: Mov_en, Res_en ja Mov_ko. Suurin osa aineistoista on peräisin aiemmasta kirjallisuudesta, ja ne on kerätty eri tavoin Mov_en-aineistot on kerätty eri verkkosivustoilta; lyhyt aineisto koostuu BIBREF19:n Rotten Tomatoes -verkkosivuston dokumenttitason arvosteluista käsin poimimista lauseista, kun taas pitkä aineisto koostuu BIBREF20:n saamista arvosteluista IMDB-sivustolta.",
      "id": "task461-b0a36916413f4503badb8f66e045f3e0",
      "output": [
        "Mitä eri aloja ja kieliä uusissa tietokokonaisuuksissa on?"
      ]
    },
    {
      "input": "Vertaamme lauseiden luokittelua LSTM:n perustasoon ja arvioimme suurinta tällä hetkellä saatavilla olevaa PICO-lauseaineistoa BIBREF13. SCIBERT valittiin ylimääräiseksi perusmalliksi hienosäätöä varten, koska se edusti parhaiten upotettuja PICO-lauseiden tietoja. ",
      "id": "task461-2afae3979d6f45a7a855959ee4713f7c",
      "output": [
        "Mitä lähtökohtia he ottivat huomioon?"
      ]
    },
    {
      "input": "Lasketaan ensin yksinkertaisesti sekä INLINEFORM0:n että INLINEFORM1:n tuottamien ennusteiden keskiarvo SECREF-osiossa36 esitetyissä kokeissa.",
      "id": "task461-1a6e31fab0814026965e85f69d5a313c",
      "output": [
        "Mitä kahta mittaria ehdotetaan?"
      ]
    },
    {
      "input": "  Toisessa vaiheessa koulutamme neuraalisen yksikielisen käännösjärjestelmän, joka kääntää PBMT-järjestelmän tuloksesta INLINEFORM0 parempaan kohdelauseeseen INLINEFORM1 .",
      "id": "task461-4f8205d943ae41a58ab4a8c75438ce8a",
      "output": [
        "Koulutetaanko NMT-malli PBMT:n tuotoksilla?"
      ]
    },
    {
      "input": "Uusien avainsanojen tunnistamiseksi valituista mikroposteista hyödynnämme jälleen joukkoistamista, sillä ihmiset ovat yleensä koneita parempia antamaan erityisiä selityksiä BIBREF18, BIBREF19. Joukkoistamistehtävässä työntekijöitä pyydetään ensin etsimään ne mikropostit, joissa mallin ennusteet katsotaan oikeiksi. Sitten työntekijöitä pyydetään etsimään näistä mikroposteista avainsana, joka parhaiten osoittaa mallin ennustaman mikropostin luokan.",
      "id": "task461-282a4d00240f4a8195004f292a07bcf7",
      "output": [
        "Miten avainsanakohtainen odotus herätetään joukosta?"
      ]
    },
    {
      "input": "Morfosyntaktinen annotaatio tehtiin automaattisesti, mikä voi aiheuttaa virheitä erityisesti silloin, kun kyseessä on meluisa verkkoteksti.",
      "id": "task461-c09d40b702c042cea6d07ee518ba52b2",
      "output": [
        "Käyttivätkö he kommenttien tekemiseen joukkoistamisalustaa?"
      ]
    },
    {
      "input": "Yhteistyöelimen hienosäätämiseksi käytimme omaa korpusta, joka koostuu sadoista tuhansista oikeudellisista sopimuksista.",
      "id": "task461-87afe4b59fee468aa2e85aa4546adde0",
      "output": [
        "Kuinka suuri on yhteistyöelimen hienosäätöön käytettävä tietokokonaisuus?"
      ]
    },
    {
      "input": "Tässä jaksossa esitellään yksityiskohtaisesti analyysi, joka on tehty Twitter-viestejä koskevista tiedoista tammikuusta 2020 tähän päivään asti, eli siitä lähtien, kun uutinen Kiinassa puhjenneesta Coronavirus-tartunnasta levisi ympäri kansakuntia. Lisäksi aineisto kattaa erityisesti englannin-, espanjan- ja ranskankieliset twiitit.",
      "id": "task461-9b7ef9dc5a984fe9a7d7ae03afcab64e",
      "output": [
        "Keräävätkö ne vain englanninkielisiä tietoja?"
      ]
    },
    {
      "input": "Luonnollisen kielen käsittelyssä (NLP) kullekin kielelle ominaisen morfologisen monimutkaisuuden huomioon ottaminen voi olla tärkeää nykyisten menetelmien parantamiseksi tai mukauttamiseksi, sillä sanatasolle koodatun semanttisen ja kieliopillisen tiedon määrä voi vaihdella merkittävästi kielestä toiseen. Tämä tieto voisi olla hyödyllistä kielellisessä analyysissä ja mitattaessa eri sanamuotojen normalisointityökalujen vaikutusta kielestä riippuen.",
      "id": "task461-a813175bc4c24e8fb719b59f1ec6cc1f",
      "output": [
        "Mikä on tämän asiakirjan käytännön sovellus?"
      ]
    },
    {
      "input": "Suunnittelimme kolme arviointikokonaisuutta: (1) Perusjoukko (1264 näytettä), joka on peräisin simuloidusta datasta. (2) laajennettu joukko (1280 näytettä), joka muodostettiin lisäämällä perusjoukkoon kaksi jakauman ulkopuolista oiretta ja niitä vastaavat dialogisisällöt ja kyselyt (\"verenvuoto\" ja \"kylmä\", jotka eivät koskaan esiintyneet harjoitusaineistossa). (3) Reaalimaailman joukko (944 näytettä), joka on rajattu manuaalisesti reaalimaailman dialogien oireiden tarkistusosioista (noin 4 tuntia) ja merkitty arviointinäytteiksi.",
      "id": "task461-97525b898ece463d9ff3dad1d90ec1be",
      "output": [
        "Miten he valitsevat testitapaukset pidättäytyneeseen testijoukkoonsa?"
      ]
    },
    {
      "input": "Pyrimme mahdollisuuksien mukaan rajoittamaan kunkin tekstin sisällön alkuperäisen teoksen tiivistelmään ja johtopäätökseen. Koska nämä osiot olivat kuitenkin monissa tapauksissa liian lyhyitä, otimme huomioon myös muita alkuperäisteosten osia, kuten johdannon tai keskusteluosion. Sen varmistamiseksi, että poimitut tekstiosuudet soveltuvat AV-tehtävään, kukin alkuperäisteos esikäsiteltiin manuaalisesti. Tarkemmin sanottuna poistimme taulukot, kaavat, lainaukset, sitaatit ja lauseet, jotka sisälsivät muuta kuin kielellistä sisältöä, kuten matemaattisia konstruktioita tai tutkijoiden, järjestelmien tai algoritmien nimiä.",
      "id": "task461-2cb8b46b059b47239e85ed44c7164037",
      "output": [
        "Mikä on itse koottu korpus?"
      ]
    },
    {
      "input": "Suoritamme myös muita CTC-kokeita 36-kerroksisella muuntajalla (kokonaisparametrit $\\pm $120 miljoonaa). 36 kerroksen perustasolla on sama suorituskyky kuin 24 kerroksella, mutta lisäämällä ehdotetut menetelmät 36 kerroksen suorituskyky parani ja antoi parhaat tulokset. ",
      "id": "task461-3d063f8d81374672b30b9f0fc174a9b7",
      "output": [
        "Kuinka monta kerrosta he käyttävät parhaiten toimivassa verkossaan?"
      ]
    },
    {
      "input": "Taulukon TABREF7 tulokset osoittavat, että SRCC suoriutuu tiedon louhinnasta paljon paremmin. Kahden asiakirjan sisältö sisältää saman ajatuksen, joka on ilmaistu termeillä eri järjestyksessä: John oli pyytänyt Marya naimisiin ennen kuin tämä lähti. On ilmeistä, että kosinin samankaltaisuus ei pysty tunnistamaan tätä yhteyttä, mutta SRCC on tunnistanut sen onnistuneesti ja tuottanut samankaltaisuusarvon -0,285714.",
      "id": "task461-cc42a11f319441a89eb0351e12cb64a5",
      "output": [
        "Miten ne arvioivat tiedon louhinnan suorituskykyä?"
      ]
    },
    {
      "input": "Käytämme Fisherin espanjankielistä puhekorpusta BIBREF11, joka koostuu 819 puhelusta, joiden keskimääräinen kesto on 12 minuuttia, eli yhteensä 160 tuntia dataa.",
      "id": "task461-d81105813f0443c2829360341bae628e",
      "output": [
        "Mitä kieltä he tarkastelevat?"
      ]
    },
    {
      "input": "Kuten taulukosta käy ilmi, ehdotettu PS-rnn-elmo parantaa MAP-suorituskykyä merkittävästi verrattuna edelliseen parhaaseen malliin, CompClip-LM:ään (0,696-0,734 absoluuttista).",
      "id": "task461-24b8268678a44cb6bf9ace20b47b0179",
      "output": [
        "Kuinka paljon parempi suorituskyky ehdotetulla mallilla on verrattuna vastausvalintamalleihin?"
      ]
    },
    {
      "input": "Cambridge Assessment English BIBREF27:n BULATS-testi (Business Language Testing Service) on monitasoinen tietokonepohjainen englannin kielen koe. Se koostuu luetun puheen ja vapaan puhumisen osista, joissa kokelas vastaa kehotuksiin. BULATSin puhutun kielen testissä on viisi osiota, joissa kaikissa on liiketoimintatilanteisiin soveltuvaa materiaalia.  Tässä työssä BULATS-testin ei-äidinkielen puhetta käytetään sekä koulutus- että testiaineistona puhujan todentamisjärjestelmissä. Järjestelmien yleistettävyyden tutkimiseksi testiaineisto otetaan myös Cambridge Assessment English Linguaskill -verkkotestistä. BULATSin tavoin tämäkin testi on monitasoinen, ja sen muoto koostuu samoista viidestä osiosta kuin edellä kuvatun kaltaisesti, mutta siinä arvioidaan yleistä englannin kielen taitoa.",
      "id": "task461-78e8889906b64be9b7c2ead23f8e6287",
      "output": [
        "Mitä standardoitua suurta puhujan todentamiskorpusta käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Vuoropuhelujen kerääminen: Ennen virallisen tiedonkeruun aloittamista vaadimme työntekijöitä tekemään pienen määrän vuoropuheluja ja annoimme heille palautetta vuoropuhelun laadusta. Sitten hyvin koulutetut työntekijät paritettiin keskustelemaan annettujen tavoitteiden mukaisesti. Työntekijöitä pyydettiin myös merkitsemään sekä käyttäjän että järjestelmän tilat. 2. Dialogin merkintä: Käytimme joitakin sääntöjä merkitäksemme automaattisesti dialogin tekoja käyttäjän tilojen, järjestelmän tilojen ja dialogihistorian mukaan. Dialogitapahtumien ja -tilojen annotoinnin laadun arvioimiseksi kolme asiantuntijaa annotoi manuaalisesti 50 dialogin dialogitapahtumat ja -tilat. Tulokset osoittavat, että annotaatiomme ovat korkealaatuisia. Lopuksi jokainen dialogi sisältää strukturoidun tavoitteen, tehtävänkuvauksen, käyttäjän tilat, järjestelmän tilat, dialogitoiminnot ja lausumat.",
      "id": "task461-44c94188737e420792bb42930ef830f6",
      "output": [
        "Miten korpus annotoitiin?"
      ]
    },
    {
      "input": "Koulutamme mallit Sentiment140- ja Amazon-tuotearvosteluilla. Molemmissa tietokokonaisuuksissa keskitytään lyhyen tekstin esittämiin tunnetiloihin.  Kouluttaaksemme softmax-mallia jaamme tekstin sentimentin kahteen tunnetyyppiin, positiiviseen ja negatiiviseen. Tanh-mallin kouluttamista varten muunnamme positiivisen ja negatiivisen tunteen [-1.0, 1.0] jatkuvaksi tunnepisteytykseksi, kun taas 1.0 tarkoittaa positiivista ja päinvastoin. ",
      "id": "task461-2774b1593bc74a21b50f6075fb52b01f",
      "output": [
        "Koulutettiinko käyttöön otettu LSTM+CNN-malli annotoidulla datalla valvotusti?"
      ]
    },
    {
      "input": "Tulokset osoittavat, että CJFA-kooderi saavuttaa huomattavasti paremman puhelimen luokittelutarkkuuden kuin VAE-perusversio ja myös kuin CJFS-kooderi. Nämä tulokset toistuvat myös puhujantunnistustehtävissä.",
      "id": "task461-a72c1b158003495a85796c10a0d13fe5",
      "output": [
        "Kumpi kahdesta paperissa ehdotetusta lähestymistavasta toimi kokeissa paremmin?"
      ]
    },
    {
      "input": "Käytämme kahta suosittua tietopohjaa: WordNet BIBREF0 ja Freebase BIBREF1. Käytämme erityisesti WN18 (WordNetin osajoukko) BIBREF24 ja FB15K (Freebasen osajoukko) BIBREF2, koska niiden tekstikuvaukset ovat helposti julkisesti saatavilla. Taulukossa 1 luetellaan näiden kahden tietokokonaisuuden tilastotiedot.",
      "id": "task461-06c34e1034424c0aa69982c9458390bf",
      "output": [
        "Mitä tietokokonaisuuksia käytetään tämän asiakirjan arvioinnissa?"
      ]
    },
    {
      "input": "Lähestymistapa ::: Menetelmä: Menetelmä: Koulutus ja testaus ::: Osa aiempien lähestymistapojen ongelmista näyttää johtuvan infiksien käytöstä. Tässä kokeessa vertaamme käännöksen BLEU-2-pistemääriä havaitaksemme erot esityksen tulkittavuudessa. Lähestymistapa ::: Menetelmä:: Harjoittelu ja testaus ::: Kokeessa 2: NykytilaTässä kokeessa verrataan verkkojamme viimeaikaisiin aiempiin töihin. Laskemme tietyn testipistemäärän yksinkertaisella \"oikein vs. väärin\" -menetelmällä. Vastaus lausekkeeseen on suoraan sidoksissa siihen, että kaikki käännöstermit ovat oikein, minkä vuoksi emme ota huomioon osittaista tarkkuutta. Vertailemme keskimääräisiä tarkkuuksia kolmen testikokeen aikana eri satunnaisesti poimituilla testijoukoilla kustakin MWP-tietokannasta.",
      "id": "task461-f102d9a40473436b8ffa2b644a2d7292",
      "output": [
        "Miten tätä ongelmaa arvioidaan?"
      ]
    },
    {
      "input": "Kehitimme AdaBoost-pohjaisen luokittelijan, joka koostuu 200 matalasta päätöspuusta (syvyys 2), havaitsemaan uudet väärennetyt arvostelut.",
      "id": "task461-47cc0d06d22040c5a3e8f5a44409cf0f",
      "output": [
        "Millaista mallia he käyttävät havaitsemiseen?"
      ]
    },
    {
      "input": "Tämän tietokokonaisuuden tarkoituksena on auttaa kehittämään puolueellisten uutisten tunnistinta. Tietokokonaisuutta voidaan käyttää useilla eri tavoilla järjestelmän kehittämiseksi. Tunnistin voidaan esimerkiksi kouluttaa käyttämällä kustantajatason merkintöjä ja testata artikkelitason merkinnöillä. On myös mahdollista käyttää puolivalvottua oppimista ja käsitellä kustantajatason osaa valvomattomana tai käyttää vain artikkelitason osaa. Julkaisimme myös tutkimuksen raakadatan, jotta voidaan kehittää uusia mekanismeja artikkelitason merkintöjen päättämiseksi.",
      "id": "task461-0dcc2865d7ef4946a528e1042ccfcf1d",
      "output": [
        "Mitä esimerkkejä sovelluksista mainitaan?"
      ]
    },
    {
      "input": "Tätä tehtävää varten julkaistu harjoitusaineisto sisältää 22 lääkemerkintää, joihin viitataan nimellä Training-22, ja joissa on kultainen standardiannotaatio.  Koska Training-22 on suhteellisen pieni tietokokonaisuus, käytämme lisäksi ulkoista tietokokonaisuutta, jossa on 180 annotoitua lääkemerkintää ja joka on nimeltään NLM-180 BIBREF5 (lisää myöhemmin). ",
      "id": "task461-80a6df64cafa45e799416e73871ca2fe",
      "output": [
        "Mitä koulutustietoja he käyttivät?"
      ]
    },
    {
      "input": "Tarvitsemme suuren määrän dataa kokeillaksemme syväoppimisen huippualgoritmeja. Saatavilla on paljon avoimia tietokokonaisuuksia, jotka koskevat nimiä, paikkoja ja organisaatioita, mutta ei edellä olevassa tiivistelmässä määriteltyjä aiheita. Aiheiden määrittely ja päättely on myös yksilöllistä, eikä niiden määrittelyyn ole olemassa kiinteitä sääntöjä. Määritelmämme mukaan voimme kuitenkin käyttää wikipedian otsikoita kohdeaiheina. Englanninkielisessä wikipedia-aineistossa on yli 18 miljoonaa otsikkoa, jos otetaan huomioon kaikki tähänastiset versiot. Meidän oli siivottava otsikot ja poistettava roskanimikkeet, sillä wikipediaotsikko sisältää lähes kaikki päivittäin käyttämämme sanat.  Joidenkin lisäpuhdistusten jälkeen jäljelle jäi 10 miljoonaa otsikkoa. Meillä on 15 miljoonaa englanninkielistä uutisartikkelia, jotka on julkaistu viimeisten neljän vuoden aikana. Lisäksi vähensimme artikkelien määrää poistamalla päällekkäiset ja lähes samanlaiset artikkelit. Käytimme esivalmennettuja doc2vec-malleja ja kosinin samankaltaisuutta havaitaksemme lähes samanlaiset uutisartikkelit.",
      "id": "task461-99147d33afdf4a1aa818ead641749b45",
      "output": [
        "Kuinka suuri on heidän käyttämänsä aineisto?"
      ]
    },
    {
      "input": "Työmme liittyy myös koneoppimismallien tulkittavuuteen ja läpinäkyvyyteen BIBREF11, BIBREF35, BIBREF12, jossa ihmiset ovat yhä useammin mukana esimerkiksi mallin tulkittavuuden jälkiarvioinnissa. ",
      "id": "task461-a418617a61fc4cd5903d0f834699b59c",
      "output": [
        "Miten lähestymistavan tulkittavuus osoitetaan?"
      ]
    },
    {
      "input": "Saavutimme ensimmäisen sijan 8 suunnan osalta: Kolme muuta suuntaa sijoittui toiseksi (joukkueiden mukaan), mukaan lukien liettualaiset suomen-, liettuan-, suomen- ja kazakstaninkieliset suuntia: liettualaiset suuntia: englanti, suomalaiset suuntia: englanti ja englantilaiset suuntia: kolme muuta suuntaa: liettualaiset suuntia: englanti, suomalaiset suuntia: englanti ja kazakstaninkieliset suuntia: englanti.",
      "id": "task461-8c70803b5eaa49519df6e41b5ca14904",
      "output": [
        "Mihin kielisuuntiin WMT:n konekäännösjärjestelmiä arvioidaan?"
      ]
    },
    {
      "input": "Tämän luokittelutekniikan F1-pistemäärän lopulliset tulokset ovat 0,52 yhden ja 0,31 yhden ja usean käännöksen datan osalta.Vertaamme sekä yhden että usean käännöksen kokeilujen tuloksia testidatan tarkkuuteen BLEU-pistemäärän perusteella.",
      "id": "task461-865ff2beb182409fa55435cfbe27fe26",
      "output": [
        "mihin olemassa oleviin mittareihin niitä verrataan?"
      ]
    },
    {
      "input": "GPT-2 saa korkeimman pistemäärän ja $n$-grammi alhaisimman.",
      "id": "task461-4917ca8215874ca3b112efbd6d12c4ce",
      "output": [
        "Minkä mallin suorituskyky on paras?"
      ]
    },
    {
      "input": "Kiinnostava aiempi työ sosiaalisten normien rikkomisen kvantifioimiseksi on keskittynyt vahvasti tietoon BIBREF8 , BIBREF9 . ",
      "id": "task461-dbd6b463a3ad4406be9c38a33c4ac1b1",
      "output": [
        "Ehdotetaanko tässä asiakirjassa uutta tehtävää, jota muut voivat yrittää parantaa?"
      ]
    },
    {
      "input": "Arvioimme lähestymistapojamme kahdella julkisella kiinalaisella span-extraction machine reading comprehension -tietokannalla: CMRC 2018 (yksinkertaistettu kiina) BIBREF8 ja DRCD (perinteinen kiina) BIBREF9. Näiden kahden tietokokonaisuuden tilastot on lueteltu taulukossa TABREF29.",
      "id": "task461-584aa62853b145ffb208c1e770387e5d",
      "output": [
        "Onko tämä span-pohjainen (uuttamispohjainen) laadunvarmistustehtävä?"
      ]
    },
    {
      "input": "Toisessa, jatkuvassa sanapussissa (CBOW), mallille annetaan sanasarja ilman keskimmäistä sanaa, ja se yrittää ennustaa tämän poisjätetyn sanan. ",
      "id": "task461-7d62917052fd419f8c263daf6a544ea1",
      "output": [
        "Mitä sanojen upotuksia analysoidaan?"
      ]
    },
    {
      "input": "Lisäksi annotaatioiden luotettavuuden arvioimiseksi ja paremman arvioinnin mahdollistamiseksi testijoukon jokaiseen kysymykseen vastaa vähintään kaksi muuta asiantuntijaa.",
      "id": "task461-a12f8afd3f7b410abe87659569195dc9",
      "output": [
        "Ovatko vastaukset kaksinkertaisesti (eikä kolminkertaisesti) merkittyjä?"
      ]
    },
    {
      "input": "Lauseisiin perustuvan SMT:n pohjalta haemme naapureita, joilla on suuri paikallinen, lauseen alainen päällekkäisyys lähdelauseen kanssa. Mukautamme lähestymistapaamme hakemaan n-grammeja lauseiden sijasta. Esitämme jokaisen lauseen sen pelkistetyllä n-grammijoukolla. Jokaisesta INLINEFORM0 -muodossa olevasta n-grammista etsitään lähin n-grammi harjoitusjoukosta käyttämällä edellä määriteltyä IDF- samankaltaisuutta.",
      "id": "task461-38c848d35c3a4310be499be11d91fc19",
      "output": [
        "Mistä he hakevat naapurien n-grammeja lähestymistavassaan?"
      ]
    },
    {
      "input": "POS-tunnisteiden merkitsemisessä havaittiin virheiden vähenemistä 0,71 % GSD:ssä, 0,81 % Sequoiassa, 0,7 % Spokenissa ja 0,28 % ParTUT:ssa. LAS-virheiden vähennykset ovat GSD:n osalta 2,96 %, Sequoian osalta 3,33 %, Spokenin osalta 1,70 % ja ParTUT:n osalta 1,65 %. XNLI-vertailussa CamemBERT parantaa suorituskykyä monikielisiin kielimalleihin verrattuna TRANSLATE-TRAIN-asetuksella (81,2 vs. 80,2 XLM:lle), kun se käyttää alle puolet vähemmän parametreja (110M vs. 250M). Sen suorituskyky jää kuitenkin edelleen jälkeen alkuperäisellä englanninkielisellä harjoitusjoukolla koulutetuista malleista TRANSLATE-TEST-asetuksessa (81,2 vs. 82,91 RoBERTa). Molemmat parannukset johtavat 2,36 pisteen lisäykseen F1-tulokseen verrattuna parhaaseen SEM-arkkitehtuuriin (BiLSTM-CRF), mikä tekee CamemBERT:stä huippuluokan mallin FTB:n kielentämisen alalla.",
      "id": "task461-4ce8c11bc64948f9bdccd03228358873",
      "output": [
        "Kuinka paljon paremmat CamemBERTin tulokset olivat kuin aiemmat tulokset näissä tehtävissä?"
      ]
    },
    {
      "input": "Yksikielisestä mallista tehdään kopiot kutakin kieltä varten ja lisätään kieltenvälisiä latentteja muuttujia (CLV) yksikielisten mallien yhdistämiseksi, jolloin ne kuvaavat kieltenvälisiä semanttisia roolimalleja. Konkreettisesti, kun harjoitellaan rinnakkaisia lauseita, aina kun argumenttien pääsanat ovat samansuuntaisia, lisäämme CLV:n kahden vastaavan roolimuuttujan vanhemmaksi. ",
      "id": "task461-74377a0030604ce8a120ed9ad1ee481c",
      "output": [
        "Mitä muita latentteja muuttujia mallissa käytetään?"
      ]
    },
    {
      "input": "Rikkomukset Haastavimmat ominaisuudet liittyvät kaikki rikkomuksiin. Heikko suorituskyky Infl/Agr Violations -ominaisuudessa, joka merkitsee morfologisia rikkomuksia (Hän pesi itsensä, Tämä on onnellinen), on erityisen silmiinpistävää, koska suhteellisen suuri osa (29 %) näistä lauseista on yksinkertaisia. Nämä mallit ovat todennäköisesti puutteellisia morfologisten piirteiden koodaamisessa, koska ne ovat sanatason malleja, eikä niillä ole suoraa pääsyä sanan alaiseen informaatioon, kuten taivutuspäätteisiin, mikä osoittaa, että näitä piirteitä on vaikea oppia tehokkaasti pelkästään leksikaalisten jakaumien perusteella.",
      "id": "task461-bb9012ff72ff461299e9e523d746c542",
      "output": [
        "Onko kirjoittajilla hypoteesi siitä, miksi morfologista yhteisymmärrystä ei juuri opita millään mallilla?"
      ]
    },
    {
      "input": "Ikkunointi-menetelmästä huolimatta luokkajakauma on edelleen vinoutunut, ja tarkkuusmittarin olisi heijastettava aineistomme erityistä luokkajakaumaa. Sen vuoksi käytämme painottamatonta keskimääräistä palautusprosenttia (UAR), jota käytetään yleisesti tunteiden luokittelututkimuksissa. UAR on uudelleen painotettu tarkkuus, jossa molempien luokkien näytteitä painotetaan yhtä paljon yhteenlaskettuna. UAR simuloi siten tasaista luokkajakaumaa. Tavoitteen saavuttamiseksi luokittimemme koulutetaan asianmukaisesti painotetulla harjoitusaineistolla. Huomaa, että UAR:n sattumanvarainen suorituskyky on määritelmän mukaan 50 %, mikä tekee tuloksista vertailukelpoisempia eri aineistoissa.",
      "id": "task461-6dfbd26594894144a9649eb7bde616a8",
      "output": [
        "Mitä he käyttävät mittarina löytääkseen kuumia kohtia kokouksessa?"
      ]
    },
    {
      "input": "Kontekstit ovat joko kyseisestä tietokokonaisuudesta peräisin olevia todellisia konteksteja tai ne ovat Wikipedian kohtia, jotka on haettu TF-IDF BIBREF24 -toiminnolla HotpotQA-kysymyksen perusteella. Uusi, päällekkäinen joukko konteksteja muodostettiin jälleen Wikipediasta HotpotQA:n avulla käyttäen samaa menetelmää kuin kierroksella 1. Kierroksella 3 Wikipediasta peräisin olevien konteksteiden lisäksi otimme mukaan konteksteja myös seuraavilta aloilta: Uutiset (poimittu Common Crawl -palvelusta), kaunokirjallisuus (poimittu BIBREF27:stä ja BIBREF28:sta), muodollinen puhuttu teksti (poimittu Open American National Corpusin Manually Annotated Sub-Corpus (MASC) -palvelun tuomioistuinten ja presidentinvaalikeskustelujen pöytäkirjoista) ja kausaalinen tai menettelytapateksti, jossa kuvataan tapahtumien tai toimien sarjoja, poimittu WikiHow'sta. Lopuksi keräsimme myös annotaatioita käyttäen GLUE RTE -koulutusaineistossa olevia pidempiä konteksteja, jotka olivat peräisin RTE5-tietokannasta BIBREF29.",
      "id": "task461-c3d9671556c246f2905086f5f81fb16f",
      "output": [
        "Mitä tietolähteitä he käyttävät tietokokonaisuuksiensa luomiseen?"
      ]
    },
    {
      "input": "Käyttäjätutkimuksessamme verrataan kolmen skenaarion oikeellisuutta: jäsentäjän oikeellisuus - perustasomme on niiden esimerkkien prosenttiosuus, joissa semanttisen jäsentäjän palauttama ykköskysely oli oikea.käyttäjän oikeellisuus - niiden esimerkkien prosenttiosuus, joissa käyttäjä valitsi oikean kyselyn jäsentäjän tuottamasta seitsemästä parhaasta kyselystä.hybridi-korrektius - kahden edellisen skenaarion yhdistelmällä palautettujen kyselyjen oikeellisuus. Järjestelmä palauttaa käyttäjän oikeaksi merkitsemän kyselyn; jos käyttäjä merkitsee kaikki kyselyt vääriksi, järjestelmä palauttaa jäsentäjän parhaan ehdokkaan.",
      "id": "task461-e7e96f18f28f4cf9a92d65783e058077",
      "output": [
        "Tehdäänkö käyttäjätutkimus, jossa näytetään NL-käyttöliittymä selityksen kanssa ja ilman selitystä?"
      ]
    },
    {
      "input": "Koulutamme kielimallit kahdella kielellä: Toinen malli on arvioitu WMT'18:n jakaman saksankielisen uutiskatsauksen perusteella, joka käsittää 260 miljoonaa lausetta tai 6 miljardia merkkiä. Toinen malli koulutetaan englanninkielisellä newscrawl-aineistolla, joka käsittää 193 miljoonaa lausetta tai 5 miljardia merkkiä. Opettelemme saksan- ja englanninkielisestä uutisdatasta 37 000 tyypin yhteisen BPE-sanaston (Byte-Pair-Encoding; Sennrich et al., 2016) ja koulutamme kielimallit tällä sanastolla. Tarkastelemme kahta vertailuarvoa: Useimmat kokeet suoritetaan WMT'18 English-German (en-de) -uutiskäännöstehtävässä, ja validoimme tuloksemme WMT'18 English-Turkish (en-tr) -uutistehtävässä. WMT'18 English-German -tehtävän harjoituskorpus koostuu kaikista saatavilla olevista bitext-korpuksista lukuun ottamatta ParaCrawl-korpusta, ja siitä poistetaan yli 250 merkkiä pidemmät lauseet sekä lauseparit, joiden lähde-kohde-pituus-suhde on yli 1,5. Tuloksena on 5,18 miljoonaa lauseparia. Tokenisoimme kaiken aineiston Mosesin tokenizerilla BIBREF8 ja käytämme yksikielisistä korpuksista opittua BPE-sanastoa.",
      "id": "task461-179f188cd82540428ec3311ccd64b962",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Toteutamme vertailua varten kolme perusmallia: Noun WordNet Semantic Text Exchange Model (NWN-STEM), General WordNet Semantic Text Exchange Model (GWN-STEM) ja Word2Vec Semantic Text Exchange Model (W2V-STEM).",
      "id": "task461-23f1199d2b61412c971fa2311c52a58e",
      "output": [
        "Mitkä ovat asiakirjassa mainitut perusmallit?"
      ]
    },
    {
      "input": "Kokonaisuudet muodostettiin yksinkertaisesti keskiarvottamalla yksittäisten mallien ennusteet.",
      "id": "task461-82dfea00846a4eb1bac0a0e8d83081bf",
      "output": [
        "Miten heidän ensemble-menetelmänsä toimii?"
      ]
    },
    {
      "input": "Valvojan arvioinnin korpus sisältää 26972 lausetta. Yhteenvetotilastot sanojen määrästä lauseessa ovat: min:4 max:217 keskiarvo:15.5 STDEV:9.2 Q1:9 Q2:14 Q3:19.",
      "id": "task461-5ae71bcc4f464189af205d7175ad3c3d",
      "output": [
        "Mikä on lauseiden keskimääräinen pituus?"
      ]
    },
    {
      "input": "Tässä artikkelissa käytetyt Hausa-tiedot ovat osa LORELEI-kielipakettia. Se koostuu Broad Operational Language Translation (BOLT) -aineistosta, joka on kerätty uutissivustoilta, foorumeilta, verkkopäiväkirjoista, Wikipedia-artikkeleista ja Twitter-viesteistä. Käytämme 10k harjoitus- ja 1k testitapauksen jakoa. Tässä työssä käytetty Yorùbá NER -data on BIBREFin hiljattain julkaisema Global Voices -uutisartikkelien annotoitu korpus22. Aineisto koostuu 1 101 lauseesta (26k tokenia), jotka on jaettu 709 harjoituslauseeseen, 113 validointilauseeseen ja 279 testilauseeseen 65 %/10 %/25 %:n jakosuhteen perusteella.",
      "id": "task461-dba7e65a15a54bdea97b56671f686226",
      "output": [
        "Kuinka paljon merkittyjä tietoja on saatavilla näistä kahdesta kielestä?"
      ]
    },
    {
      "input": "Aukkojen täyttäminen on tiedonlouhintatehtävä, josta on tullut suosittu viime vuosina BIBREF3 . Tehtävän tarkoituksena on poimia henkilöitä, organisaatioita tai geopoliittisia yksiköitä koskevia tietoja laajasta uutis-, verkko- ja keskustelufoorumidokumenttien kokoelmasta.",
      "id": "task461-d559042b44c54f3c9ce2585e2c18305d",
      "output": [
        "Mikä on lähtö- ja saapumisaikojen täyttämisen tehtävä?"
      ]
    },
    {
      "input": "Vertaillaksemme aiempiin menetelmiin arvioimme malliamme AIDA-B:llä ja muilla tietokokonaisuuksilla.  AIDA-CoNLL BIBREF14 on kommentoitu Reutersin uutisartikkeleihin. Se sisältää harjoitus- (AIDA-Train), validointi- (AIDA-A) ja testijoukot (AIDA-B).ACE2004 BIBREF15 on osajoukko ACE2004 Coreference -asiakirjoista.MSNBC BIBREF16 sisältää kymmenen uutiskategorian (politiikka, liike-elämä, urheilu jne.) kaksi tärkeintä juttua.)AQUAINT BIBREF17 on Xinhua News Service, New York Times ja Associated Press -lehtien uutiskorpus.WNED-CWEB BIBREF18 on satunnaisesti poimittu FACC1-annotoidusta ClueWeb 2012 -tietokannasta.WNED-WIKI BIBREF18 on poimittu Wikipedian sivuilta, joilla on alkuperäiset hyperlinkki-annotaatiot.",
      "id": "task461-afa254459afd4684ac5d8b6f3377eeb6",
      "output": [
        "Mitä tietokokonaisuuksia arvioinnissa käytetään?"
      ]
    },
    {
      "input": "menetelmämme voi silti parantaa BIBREF7-tarkkuutta 60,32 %:sta 60,34 %:iin Vaikka vain 57 % testikysymyksistä voi hyötyä peruskysymyksistä, menetelmämme voi silti parantaa BIBREF7-tarkkuutta 60,32 %:sta 60,34 %:iin, ",
      "id": "task461-26de3511b42842d9b00af6a31dc8f967",
      "output": [
        "Millaista tarkkuutta he lähestyvät ehdotetulla menetelmällä?"
      ]
    },
    {
      "input": " Logician koulutetaan huomiopohjaisella sekvenssistä sekvenssiin -paradigmalla, jossa on kolme mekanismia: rajoitettu kopiointimekanismi kirjaimellisen rehellisyyden varmistamiseksi, kattavuusmekanismi ali- ja liiallisen uuttamisen ongelman lieventämiseksi ja riippuvuushuomiointimekanismi riippuvuustiedon huomioon ottamiseksi (gated dependency attention). ",
      "id": "task461-abd8f3dd91da40efa38802ea1a65ebe0",
      "output": [
        "Miten Logician eroaa perinteisistä seq2seq-malleista?"
      ]
    },
    {
      "input": "Testataksemme, voidaanko aihepiirimalleja käyttää runouden ajoitukseen tai tekijyyden määrittelyyn, suoritamme valvottuja luokittelukokeita Random Forest Ensemble -luokittelijoilla. ",
      "id": "task461-ead1eab48c124626b8659aa1bed973cd",
      "output": [
        "Mitä algoritmia käytetään luokittelutehtävissä?"
      ]
    },
    {
      "input": "Sulauttaminen: Käytimme mallin eri variaatioita, joissa käytimme tyhjästä opittuja yksinkertaisia hakutaulukkomerkintöjä ja tehokkaita kontekstuaalisia merkintöjä, jotka ovat ELMo BIBREF11, BERT BIBREF16 ja ClinicalBERT BIBREF13 (koulutettu ja tekijöiden toimittama).",
      "id": "task461-3f94320ec40c4b99a80aee4a2baa600b",
      "output": [
        "Mitä sulautumia käytetään?"
      ]
    },
    {
      "input": "Haemme jokaisesta ehdokkaasta mainintajaksosta Freebase API:n mukaan 10 tärkeintä oliota. Tämän jälkeen luomme ristikon, jonka solmut vastaavat maininta-entiteettipareja, jotka on pisteytetty Freebase API:n pisteytyksen mukaan, ja särmät kuvaavat sitä, että yksikään entiteettien ja mainintojen yhteistoimitus ei voi sisältää päällekkäisiä ajanjaksoja. Otamme 10 parasta polkua ristikon läpi mahdollisiksi entiteettien yksiselitteisyyksiksi. Kullekin mahdollisuudelle luodaan $n$ -parasta parafraasia, joka sisältää entiteettien mainintojen välit. Lopulta tämä prosessi luo yhteensä $10n$ parafraasia. ",
      "id": "task461-fb829a6bef38498ea340f3ba6fee7c2d",
      "output": [
        "Kuinka monta rinnastusta luodaan kysymystä kohden?"
      ]
    },
    {
      "input": "Jakomenetelmät (satunnaisjaon lisäksi) ovat seuraavat:Output length: BIBREF2:n kuvaaman asetelman muunnelma, jossa harjoitusjoukko koostuu esimerkeistä, joiden ulostulon (sparql-kyselyn tai toimintosarjan) pituus on $\\le \\hspace{-2.5pt}. N$, kun taas testijoukko koostuu esimerkeistä, joiden tuloksen pituus on $> \\hspace{-2.5pt}. N$. CFQ:n osalta käytämme $N = 7$ rajoituksia. Skannauksessa käytämme $N = 22$ toimintoja: Vaihtoehto yllä olevasta asetelmasta, jossa harjoitusjoukko koostuu esimerkeistä, joiden syötteen (kysymyksen tai käskyn) pituus on $\\le N$, kun taas testijoukko koostuu esimerkeistä, joiden syötteen pituus on $> N$. CFQ:ssa käytämme $N=19$ kieliopin lehtiä. SCANissa käytetään $N=8$ merkkejä: BIBREF8:n kuvaaman asetelman muunnelma, jossa jako perustuu sellaisten esimerkkien klustereiden satunnaiseen määrittelyyn, joilla on sama ulostulokuvio (kysely- tai toimintosekvenssi). Kyselymallit määritetään anonymisoimalla entiteetit ja ominaisuudet; toimintojaksomallit yhdistävät primitiiviset toiminnot ja suunnat: Vaihtoehto edellisestä asetelmasta, jossa jako perustuu sellaisten esimerkkien klustereiden satunnaiseen määrittelyyn, joilla on sama syötemalli (kysymys tai käsky). Kysymysmallit määritetään anonymisoimalla entiteettien ja ominaisuuksien nimet; käskymallit yhdistävät verbit ja vaihdettavat parit vasen/oikea, ympäri/vastakkain, kaksi kertaa/kolme kertaa.",
      "id": "task461-30725b30c89c4a04aede017d27d0edef",
      "output": [
        "Mitä muita lähestymistapoja on olemassa komposition yleistämisen vertailuarvojen luomiseen?"
      ]
    },
    {
      "input": "Suoritamme kaikki kokeilumme 635 tunnin audiodatalla seitsemällä intialaisella kielellä, jotka on kerätty $\\textbf {All India Radio}$-uutiskanavalta.  Keräsimme ja kuratoimme noin 635 tuntia audiodataa seitsemästä intialaisesta kielestä, nimittäin kannadasta, hindistä, telugusta, malayalamista, bengalista ja englannista. Keräsimme datan All India Radio -uutiskanavalta, jossa näyttelijä lukee uutisia noin 5-10 minuutin ajan. Kattaaksemme monia puhujia aineistoon, indeksoimme dataa vuodesta 2010 vuoteen 2019. Koska ääni on hyvin pitkä, jotta mitään syvää neuroverkkoa voitaisiin kouluttaa suoraan, segmentoimme äänileikkeet pienempiin palasiin Voice activity detectorin avulla. Koska äänileikkeisiin on uutisten aikana upotettu musiikkia, käytämme Inhouse-musiikin havaitsemismallia musiikin segmenttien poistamiseen tietokokonaisuudesta, jotta tietokokonaisuus olisi puhdas, ja tietokokonaisuutemme sisältää 635 tuntia puhdasta ääntä, joka on jaettu 520 tunnin harjoitusdataan, joka sisältää 165 000 lausumaa, ja 115 tunnin testausdataan, joka sisältää 35 000 lausumaa. ",
      "id": "task461-c621780ba0eb4699b08593ca03ed40e4",
      "output": [
        "Miten äänitiedot kerättiin?"
      ]
    },
    {
      "input": "Tärkeimmissä kokeissa käytetään lineaarista tukivektorikonetta (Joachims, 1998) murteiden luokitteluun CxG-piirteiden avulla. Tässä artikkelissa on käytetty tietoon perustuvaa kielikartoitusta englannin kielen kansallisten murteiden valitsemiseksi maailmanlaajuiseen murteiden tunnistamismalliin. ",
      "id": "task461-20fecd31d6df4875a5aff52bec6e49f2",
      "output": [
        "Mitä vertailtavat mallit ennustavat?"
      ]
    },
    {
      "input": "Löysimme mielenkiintoisia malleja, jotka mallimme oppii ja jotka auttavat ymmärtämään näitä yksikielisiä voittoja. Toistuva malli on esimerkiksi se, että englannin kielen sanat, jotka käännetään kohdekielessä samaksi sanaksi tai semanttisesti läheisiksi sanoiksi, päätyvät muunnoksen jälkeen lähemmäksi toisiaan. Esimerkiksi englannin ja espanjan välisessä tapauksessa seuraavat parit olivat niiden parien joukossa, joiden samankaltaisuus kasvoi eniten muunnostamme soveltaen: kännykkä-puhelin, elokuva-elokuva, kirja-käsikirjoitus tai rytmi-sadenssi, jotka joko käännetään samaksi sanaksi espanjaksi (eli teléfono ja película kahdessa ensin mainitussa tapauksessa) tai jotka ovat jo hyvin lähellä toisiaan espanjankielisessä avaruudessa. Yleisemmin havaitsimme, että sanaparit, jotka liikkuvat eniten yhdessä, ovat yleensä semanttisesti hyvin samankaltaisia ja kuuluvat samaan alueeseen, esimerkiksi auto-polkupyörä, ooppera-kino tai lumi-jää.",
      "id": "task461-2cea83c2569540a6bf0486debce37d39",
      "output": [
        "Miksi malli paranee myös yksikielisissä tiloissa? "
      ]
    },
    {
      "input": "MTMSN BIBREF4 on ensimmäinen ja toistaiseksi ainoa malli, jossa on erityisesti pyritty käsittelemään DROPin monialaisia kysymyksiä. ",
      "id": "task461-29558fb6287247138ac86a52bbe9ac94",
      "output": [
        "Mikä on edellinen malli, jonka suunnittelussa on pyritty käsittelemään monialaisia kysymyksiä?"
      ]
    },
    {
      "input": "Ranskalaisen puheteknologian osalta neljä radio- ja televisiolähetyksiä sisältävää korpusta ovat yleisimmin käytettyjä: ESTER1 BIBREF13, ESTER2 BIBREF14, ETAPE BIBREF15 ja REPERE BIBREF16.",
      "id": "task461-9d1456e2402042e8abf54437267c6f99",
      "output": [
        "Mitkä ovat neljä suurinta ranskankielisen lähetyksen korporaatiota?"
      ]
    },
    {
      "input": "Hajonnan vähentämiseksi ja tarkkuuden lisäämiseksi yhdistämme 10 CNN:ää ja 10 LSTM:ää pehmeän äänestyksen avulla. Yhdistetyillä malleilla on erilaiset satunnaispainojen alustukset, eri epookkien määrä (yhteensä 4-20), eri suodatinkokojen joukko (joko INLINEFORM0 , INLINEFORM1 tai INLINEFORM2 ) ja erilaiset upottamisen esivalmennusalgoritmit (joko Word2vec tai FastText).",
      "id": "task461-36293ebdb89c425ea04b5847a1c4dfe2",
      "output": [
        "Kuinka monta CNN:ää ja LSTM:ää koottiin?"
      ]
    },
    {
      "input": "MATT-BiE-LSTM ja WATT-BiE-LSTM saavuttavat samankaltaisia tuloksia, kun niitä testataan sekä Vaderin että ihmisen kommentoimilla näytteillä, vaikka niiden tavat laskea huomio (painot ja vektorit) eroavat toisistaan siten, että WATT laskee huomiopainot ja senti-emoji-kuvion upotukset kunkin sanan perusteella, kun taas MATT saa senti-emoji-kuvion LSTM-koodaimen perusteella koko kontekstista ja laskee senti-emoji-kuvion upotuksen huomiopainot kaikkien sanojen osalta. Molemmat mallit ylittävät huipputason perusmallit, mukaan lukien ATT-E-LSTM Attention-based LSTM with emojis: Käytämme myös sana-emoji-kuviointia emoji-sanan huomion laskemiseen yhtälön EQREF20 ja EQREF21 mukaisesti, ja ainoa ero on, että korvaamme huomiosta johdetun senti-emoji-kuvioinnin fasttextin ennalta koulutetulla sana-emoji-kuvioinnilla, jota kutsutaan nimellä ATT-E-LSTM. LSTM, jossa on bi-sense-emoji-sulautus (ehdotettu): Kuten SECREF13 -jaksossa esiteltiin, ehdotamme kahta huomiota hyödyntävää LSTM-verkkoa, jotka perustuvat bi-sense-emoji-merkintöjen upottamiseen ja joita kutsutaan nimillä MATT-BiE-LSTM ja WATT-BiE-LSTM.",
      "id": "task461-fb25e331dbe94bfb95dd7ab58474a951",
      "output": [
        "Mitkä SOTA-mallit päihittävät?"
      ]
    },
    {
      "input": "Näytämme lähestymistapamme vastaamalla avoimen alan tyhjään-kenttään täytettäviin luonnollisen kielen kysymyksiin.",
      "id": "task461-3d708b78135e4abf8235596c06330b0c",
      "output": [
        "Minkä tehtävän perusteella he arvioivat?"
      ]
    },
    {
      "input": "Tämän vuoksi tutkimme tapoja havaita epäilyttävät tilit tarkastelemalla niiden twiittejä ryhmissä (chunks). Hypoteesimme on, että epäilyttävillä tileillä on ainutlaatuinen malli twiittijaksojen lähettämisessä. Koska heidän tarkoituksenaan on johtaa harhaan, heidän tapaansa siirtyä twiittien sarjasta toiseen on piilotettu tunnusmerkki, jota heidän aikomuksensa vääristävät. Kun kyseessä on uutisia sisältävä Twitter-tili, luemme sen twiitit tilin aikajanalta. Sitten lajittelemme twiitit julkaisupäivän mukaan nousevaan järjestykseen ja jaamme ne $N$-kappaleisiin. Kukin palanen koostuu lajitellusta twiittien sarjasta, joka on merkitty vastaavan tilin tunnisteella.",
      "id": "task461-b10404140eee470183d05c1303ecf20b",
      "output": [
        "Miten tässä teoksessa määritellään \"virka-apuraha\"?"
      ]
    },
    {
      "input": "Ehdotamme BERT:iin perustuvaa luonnollisen kielen tuottamismallia, jossa käytetään hyväksi valmiiksi koulutettua kielimallia koodaus- ja dekoodausprosessissa, ja malli voidaan kouluttaa alusta loppuun ilman käsityönä tehtyjä piirteitä. Mallin koulutuksen aikana mallimme tavoite on kahden prosessin summa, joka koulutetaan yhdessä \"opettaja-pakottavan\" algoritmin avulla. Koulutuksen aikana syötämme perustotuuden yhteenvedon kullekin dekooderille ja minimoimme tavoitteen.$$$L_{malli} = \\hat{L}_{dec} + \\hat{L}_{refine}$$ (Yht. 23)Testihetkellä jokaisella aika-askeleella valitsemme ennustetun sanan $\\hat{y} = argmax_{y^{\\prime }} P(y^{\\prime }|x)$ , käytämme palkkihakua luonnosyhteenvetojen tuottamiseen ja ahnetta hakua tarkennettujen yhteenvetojen tuottamiseen.",
      "id": "task461-cabebceb764d4952bed50cab56b9ddff",
      "output": [
        "Miten mallin eri osat koulutetaan? Koulutetaanko se alusta loppuun?"
      ]
    },
    {
      "input": "Ilman upotuspainoja mallimme vaatii 100k parametria, kun taas BIBREF8 vaatii 250k parametria.",
      "id": "task461-484daa859dfa4cae816ac329e1c92444",
      "output": [
        "kuinka paljon parametrien ero heidän mallinsa ja aiempien menetelmien välillä oli?",
        "kuinka monta parametria heidän mallinsa käytti?"
      ]
    },
    {
      "input": "Taulukossa TABREF23 esitetään malleidemme ja eri perusmallien merkitsemättömät INLINEFORM0-pisteet.",
      "id": "task461-10c4848e5e1b45b29a4bfad04bcefcf8",
      "output": [
        "mitkä olivat arviointimittarit?"
      ]
    },
    {
      "input": "ACL Anthology Reference Corpus sisältää kanoniset 10 921 laskennallisen kielitieteen artikkelia, joista olen luonut 622 144 lausetta suodatettuani pois heikompilaatuiset lauseet.",
      "id": "task461-894d309f0b144db582a59c1bf11ad910",
      "output": [
        "Mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Jokaisessa koulutusvaiheessa mallia koulutetaan alkuperäisten esimerkkien ja tasapainoisesti merkittyjen vastakkaisten esimerkkien avulla. Vastakkaisten esimerkkien osuus on noin 10 prosenttia erästä. Koulutuksen aikana luomme vastakkaisia esimerkkejä, joiden kohteena on nykyinen malli, ja päivitämme mallin parametrit hybridierän avulla iteratiivisesti.",
      "id": "task461-5672331808b14179b248630ca4a11d62",
      "output": [
        "Mikä on erottelija tässä generatiivisessa vastakkaisasetelmassa?"
      ]
    },
    {
      "input": "Valitsimme perustasoksi Conditional Copy (CC) -mallin, joka on Wisemanin paras malli. ",
      "id": "task461-b4d6609f5f1b471391844121ef6b3995",
      "output": [
        "Mikä on vahva lähtötaso?"
      ]
    },
    {
      "input": "Koulutimme sanojen upotukset joko GloVe BIBREF11- tai SGNS BIBREF12 -ohjelmalla pienellä tai suurella korpuksella.",
      "id": "task461-65dfa1cc0b654c298db0f2aef7f33e22",
      "output": [
        "Minkälaisia sanojen esitystapoja he arvioivat?"
      ]
    },
    {
      "input": "Koulutustietokantojen koko vaihtelee huomattavasti 469 viestistä 17 miljoonaan; ero on neljä suuruusluokkaa.",
      "id": "task461-7853e49e96f948a38bfcaf64c40332f0",
      "output": [
        "Kuinka suuri tämä tietokokonaisuus ja luettelo ovat?"
      ]
    },
    {
      "input": "Kuten jäljempänä osoitamme, STransE toimii paremmin kuin SE- ja TransE-mallit ja muut huipputason linkkien ennustemallit kahdessa vakiomuotoisessa linkkien ennustamiseen tarkoitetussa tietokokonaisuudessa WN18 ja FB15k, joten se voi toimia uutena perustasona KB:n täydentämisessä.",
      "id": "task461-89d8634f259d40c08536377d84dfd50e",
      "output": [
        "Mitä tietokokonaisuuksia käytetään mallin arvioinnissa?"
      ]
    },
    {
      "input": "Käytimme tallenteita sairaanhoitajan aloitteesta käydyistä puhelinkeskusteluista, joita käytiin sairaalasta kotiutumisen jälkeen etäseurannassa olevien sydämen vajaatoimintapotilaiden kanssa. Analysoidaksemme kysely-vastausparien kielellistä rakennetta koko 41 tunnin aineistossa otimme satunnaisotoksen 1 200 vuorosta koostuvasta siemenaineistosta ja luokittelimme ne manuaalisesti eri tyyppeihin, jotka on esitetty taulukossa TABREF14 yhdessä vastaavien esiintymistiheystilastojen kanssa.",
      "id": "task461-82d1f9630bd54123a1a6a148728f6bec",
      "output": [
        "Mitä tietoja he käyttävät vuoropuhelua koskevan tietokokonaisuuden lähtökohtana?"
      ]
    },
    {
      "input": "Arviointimittarina käytettiin oikeiden \"käännöksien\" (vastaavuuksien) suhdelukua.",
      "id": "task461-9332536373b34d4c89614859e6435db7",
      "output": [
        "Mitä arviointimittaria he käyttävät?"
      ]
    },
    {
      "input": "Käytämme päättelyssä säteenhakua, jonka säteen koko on 5 De-En-, En-Fr- ja En-Vi-käännöstehtävissä.",
      "id": "task461-847fe25c90fa482090bfb025a1fecb36",
      "output": [
        "Mitkä ovat kolme tärkeintä konekäännöstehtävää?"
      ]
    },
    {
      "input": "Käytämme väärennettyjen arvostelujen luomiseen Yelp Challenge -tietokokonaisuutta BIBREF2. ",
      "id": "task461-26c0a895a44f4b81ba7ee73ddcb390b3",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät lähtökohtana väärennettyjen arvostelujen luomisessa?"
      ]
    },
    {
      "input": "Tietokanta koostuu 198 112 uutisartikkelista.",
      "id": "task461-b9ca25e92932427492a36e32f6ba9583",
      "output": [
        "Kuinka monta artikkelia heillä oli?"
      ]
    },
    {
      "input": "Tavanomaisesti käytetään yhteisen tavoitteen tarkkuuden mittaria, kun malliamme verrataan aiempiin töihin.",
      "id": "task461-37d1d4731c82474aa024209f857f24c8",
      "output": [
        "Mitä suorituskykymittareita käytetään?"
      ]
    },
    {
      "input": "Yllättäen parhaan laadunvarmistusmallin (bert-large-wwm) käyttäminen ei johda parhaaseen korrelaatioon ihmisen arvioiden kanssa. CNN/DM:ssä bert-large-wwm alittaa hieman bert-base- ja bert-large-mallit.",
      "id": "task461-62fa0e30107e4b50acaf7207b609b8f9",
      "output": [
        "Mitä malleja arvioidaan QAGS:n avulla?"
      ]
    },
    {
      "input": "Muissa tapauksissa malli osoittaa uskottavia signaaleja, jotka annotoija on jättänyt huomiotta ja joita voidaan pitää virheinä kultaisessa standardissa. Malli esimerkiksi huomaa helposti, että kysymysmerkit viittaavat solutionhood-suhteeseen, vaikka kommentoijat ovat ohittaneet ne ja merkinneet WH-sanat:. [RGB]230, 230, 230Mikä [RGB]230, 230, 230Edellinen [RGB]230, 230, 230Virginia [RGB]230, 230, 230Governor(s) [RGB]230, 230, 230, 230tehdä [RGB]230, 230, 230, 230sinä [RGB]230, 230, 230melkein [RGB]230, 230, 230, 230mielessä [RGB]230, 230, 230, 230ja [RGB]230, 230, 230ja [RGB]230, 230, 230miksi [RGB]12, 12, 12? $\\xrightarrow[\\text{pred:solutionhood}]{\\text{gold:solutionhood}}$ [RGB]230, 230, 230Thomas [RGB]230, 230, 230Jefferson [RGB]183, 183, 183. Se tarttuu kuitenkin myös toistuvaan tapaan, joka esiintyy käyttöohjeissa, joissa lukijaan viittaava toisen persoonan pronomini on usein jonkin toimenpiteen hyötyjä, mikä edistää tarkoituksen lukemista ja auttaa erottamaan niin, vaikka annotoijat eivät pidä sitä signaalina.",
      "id": "task461-344e8d08275741dfb915e3b00c20ef43",
      "output": [
        "Missä ehdotettu metriikka eroaa jumanin tuomiosta?"
      ]
    },
    {
      "input": "INLINEFORM0 BIBREF2-harjoitusjoukossa ja kasvattaa solua INLINEFORM1 jokaista tässä ikkunassa esiintyvää INLINEFORM2-sanaa kohti (muodostaen INLINEFORM3-parin). LexVec mukauttaa PPMI-matriisin käyttämällä kontekstijakauman tasoitusta BIBREF3 . Vertailemme 1) n-grammaisten osasanojen käyttöä, kuten fastText, ja 2) Morfessor BIBREF11 -ohjelmalla tunnistettuja valvomattomia morfeemeja, jotta saamme selville, tarjoavatko kielellisesti motivoidummat osasanat etua pelkkiin n-grammeihin verrattuna.",
      "id": "task461-1f8f71a377844cef93ba32b536950fec",
      "output": [
        "Minkälaisia alasanoja he sisällyttävät malliinsa?"
      ]
    },
    {
      "input": "Kanavan kovarianssimatriisin perusteella tapahtuvaan elektrodien välisten tilallisten yhteyksien purkamiseen käytetään CNN BIBREF19 -nimistä CNN:ää, joka on nelikerroksinen 2D-CNN, jossa on kaksi konvoluutiokerrosta ja kaksi täysin kytkettyä piilokerrosta. INLINEFORM0-ominaisuuskartta tietyllä CNN-kerroksella, jossa on tulo INLINEFORM1 , painomatriisi INLINEFORM2 ja bias INLINEFORM3, saadaan seuraavasti: INLINEFORM4 . Tällä ensimmäisellä hierarkiatasolla verkko koulutetaan vastaavilla merkinnöillä tavoitelähdöiksi optimoimalla risti-entropian kustannusfunktiota. Rinnakkain sovellamme nelikerroksista rekursiivista neuroverkkoa kanavien kovarianssimatriiseihin elektrodien piilotettujen ajallisten ominaisuuksien tutkimiseksi. Hyödynnämme nimittäin LSTM BIBREF20 -verkostoa, joka koostuu kahdesta täysin kytketystä piilokerroksesta, jotka on pinottu kahdella LSTM-kerroksella ja koulutettu samalla tavalla kuin CNN.",
      "id": "task461-69e7e572de3b4a8c871134e667ae65da",
      "output": [
        "Miten EEG-signaalin alueellinen aspekti laskettiin?"
      ]
    },
    {
      "input": "Monet käytännön valeuutisten havaitsemisalgoritmit käyttävät tilastollisten ominaisuuksiensa lisäksi eräänlaista semanttista sivutietoa, kuten sitä, onko tuotettu teksti asiallisesti oikein. Vaikka tilastollinen sivutieto olisi helppo sisällyttää hypoteesin testauksen kehykseen, on vielä ymmärrettävä, miten tällainen semanttinen tieto voidaan sisällyttää tilastolliseen päätöksentekoteorian kehykseen.",
      "id": "task461-cbb1d8b5226c43b982f37ebb84b088f9",
      "output": [
        "Mitkä semanttiset piirteet auttavat havaitsemaan, onko teksti aito vai keksitty? of "
      ]
    },
    {
      "input": "DQN-pohjaisen agentin tulokset esitetään kuvassa: skenaarioiden vertailu. Kukin kuvaaja kuvaa kaikkien esitysmenetelmien keskimääräistä palkkiota (5 siemenen osalta). Voidaan nähdä, että NLP-edustus on muita menetelmiä parempi.  NLP-edustukset pysyvät kestävinä ympäristön muutoksille sekä tilassa esiintyville tehtävän aiheuttamille häiriöille. ",
      "id": "task461-d5b028f6fef946e0a6f68c33d008e493",
      "output": [
        "Mitkä kokeiden tulokset viittaavat siihen, että luonnolliseen kieleen perustuvat agentit ovat kestävämpiä?"
      ]
    },
    {
      "input": "Ensinnäkin voimme havaita, että lopullinen malli \"Ours with Mask and Ordered Triplets\" päihittää Baseline- ja Ablation-mallit kaikilla mittareilla aiemmin nähdyissä ympäristöissä. Ero suorituskyvyssä on erityisen selvä Exact Match- ja Goal Match -mittareissa, joissa mallimme parantaa tarkkuutta 35 % ja 25 % verrattuna Baseline- ja Ablation-malleihin. Nämä tulokset viittaavat siihen, että käyttäytymiseen liittyvän navigointigraafin tarjoaminen mallille ja sen antaminen mallin käsitellä tätä tietoa tietopohjana alusta loppuun on hyödyllistä. Lopuksi on syytä huomata, että ehdottamamme malli (taulukon TABREF28 viimeinen rivi) päihittää kaikki muut mallit aiemmin nähdyissä ympäristöissä. Erityisesti saamme yli INLINEFORM0 lisäystä EM- ja GM-arvoissa mallimme ja kahden seuraavaksi parhaan mallin välillä.",
      "id": "task461-2b4443c6b6bb451fb00b0af2b3ba4e14",
      "output": [
        "Kuinka paljon heidän mallinsa oli parempi kuin perusmalli?"
      ]
    },
    {
      "input": "Kvantitatiivisesti arvioidaksemme kaksisuuntaiseen rekursiiviseen lähestymistapaan perustuvan lähestymistapamme suorituskykyä käytämme METEOR-mittaria sen vankan suorituskyvyn vuoksi.",
      "id": "task461-0aaccc2a4bfc4a5986b49da191cd75af",
      "output": [
        "mitä mittareita arvioinnissa käytettiin?"
      ]
    },
    {
      "input": "Tarkemmin sanottuna havaitsemme seuraavien tekijöiden vaikutuksen: (BIBREF11, BIBREF12, rekursiiviset BIBREF13 ja muuntopohjaiset lauseen koodaajat BIBREF14 kysymysten esittämisstrategioina; (ii) visuaalisten piirteiden louhintaan käytetyt erilaiset konvoluutiohermoverkot BIBREF15, BIBREF16, BIBREF17; ja (iii) vakioidut fuusiointistrategiat sekä kahden tärkeimmän huomiomekanismin BIBREF18 ja BIBREF19 merkitys.",
      "id": "task461-47fca2a48a2d43ed9fc5b58f89494f48",
      "output": [
        "Millaisia kokeita tehdään?"
      ]
    },
    {
      "input": "Järjestelmän kuvaus ::: Arkkitehtuuri Prosessiin osallistuvat komponentit ovat: QnAMaker Portal: Tämä on graafinen käyttöliittymä (GUI) QnAMakerin käyttöä varten.  QnaMaker Management API:t: Tätä käytetään kysymys-vastausparien (QA) poimimiseen puolistrukturoidusta sisällöstä.  Azure Search Index: Tallentaa KB:n kysymyksineen ja vastauksineen indeksoitaviksi sarakkeiksi ja toimii siten hakukerroksena. QnaMaker WebApp: Toimii kerroksena botin, hallintasovellusten ja Azure Search Indexin välillä.  Botti: Kutsuu WebAppia käyttäjän kyselyllä saadakseen tuloksia.",
      "id": "task461-6210b50e6b9b47958bbc050303ff2f93",
      "output": [
        "Mistä komponenteista QnAMaker koostuu?"
      ]
    },
    {
      "input": "Style-perustason tarkkuus on 83 %, LDA-ominaisuuksien 89 % ja näiden kahden yhdistelmän 90 %. Harjoittelu täydellisillä runoilla kuitenkin laskee tämän tason 42-52 prosenttiin.",
      "id": "task461-f9e6925240ec425d9569f3c0da84da47",
      "output": [
        "Arvioidaanko LDA-analyysin tuloksia jollakin tavalla?"
      ]
    },
    {
      "input": "Joukkotyöntekijät sijaitsivat Yhdysvalloissa, ja heidät palkattiin BIBREF22-alustan kautta.",
      "id": "task461-b48ee79fd0b249f488a97ff02a10013a",
      "output": [
        "Keitä ovat joukkorakentajat?"
      ]
    },
    {
      "input": "Arkkitehtuurimme arvioinnissa käytämme kahta tärkeintä aineistoa, jotka ovat vuoden 2014 i2b2-haasteen BIBREF2-tietoaineisto ja hoitotyön muistiinpanojen korpus BIBREF3 .",
      "id": "task461-404bc7c6da4b445b985c96f1834e7f3c",
      "output": [
        "Millä kahdella tietokokonaisuudella järjestelmä on testattu?"
      ]
    },
    {
      "input": "Tässä esitelty tehtävä oli helppo ja yksinkertainen analysoida, mutta jatkossa voidaan tehdä työtä luonnollisen kielen tehtävien parissa. Jos nämä ominaisuudet pitävät paikkansa, se saattaa viitata siihen, että NLP:n arvioinnissa olisi edistettävä uutta paradigmaa, jossa korostetaan suorituskykyä epätyypillisillä (mutta rakenteellisesti hyvillä) syötteillä harjoituksessa tyypillisesti esiintyvien tietojen lisäksi.",
      "id": "task461-dede4914aaa14cc8adc5c8f205a7f99a",
      "output": [
        "Voidaanko tämän asiakirjan tulokset yleistää yleiskäyttöiseen tehtävään?"
      ]
    },
    {
      "input": "Jotta löydettäisiin kuhunkin tekstiin liittyvien skalaarien luokitteluun parhaiten soveltuva luokittelija, suoritamme arviointeja käyttämällä stokastista gradienttilaskeutumista, naive bayes-, päätöspuu- ja satunnaismetsäluokittimia.",
      "id": "task461-c8ba502b71bb46b99f7ed8c78b228f7a",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "Perusmallit ja ehdotetut mallit laaditaan seuraavasti: LSTM tekstin upottamisen kanssa: CNN:iä ja LSTM:iä käytetään laajalti tekstisisällön koodaamiseen sentimenttianalyysia varten BIBREF:ssä45 , BIBREF:ssä46 ja monissa verkko-oppaissa. Tässä valitaan syötteeksi tavallinen LSTM, jossa on valmiiksi koulutettu sanojen upotus, ja lisätään LSTM-koodaajan päälle yksi täysin kytketty kerros, jossa on sigmoidiaktivointi (kuten kaikissa muissakin malleissa), jota kutsutaan T-LSTM:ksi. LSTM, jossa on emoji-merkki: Pidämme emojia yhtenä erityisenä sanana ja syötämme sekä esivalmennetun tekstin että emojien upotukset samaan LSTM-verkkoon eli E-LSTM:ään. Vastaavasti yhdistämme esivalmennetut kahden aistimuksen emoji-merkinnät yhdeksi erityiseksi sanaksi ja syötämme ne LSTM-verkkoon. Tätä mallia kutsutaan nimellä BiE-LSTM. Huomioon perustuva LSTM emojien kanssa: Käytämme myös sana-emoji-kuviointia emoji-sanan huomion laskemiseen yhtälön EQREF20 ja EQREF21 mukaisesti, ja ainoa ero on se, että korvaamme huomiosta johdetun senti-emoji-kuvioinnin fasttextin esivalmennetulla sana-emoji-kuvioinnilla, jota kutsutaan nimellä ATT-E-LSTM.",
      "id": "task461-f0e0a58ca4824e8a96d5f730a3e7e5a1",
      "output": [
        "Mikä on kokeilujen lähtökohta?"
      ]
    },
    {
      "input": "Reaaliaikaiset twiittipisteet laskettiin samalla tavalla kuin historialliset tiedot, ja ne laskettiin yhteen minuutin ajalta ja lähetettiin koneoppimismalliin yhdessä Bitcoinin edellisen minuutin hinnan ja liukuvan keskihinnan kanssa. Se ennusti seuraavan minuutin Bitcoin-hinnan annettujen tietojen perusteella. Todellisen hinnan saavuttua laskettiin RMS-arvo ja koneoppimismalli päivitti itseään ennustaakseen seuraavan arvon paremmalla ymmärryksellä.",
      "id": "task461-86d8f04f087e45479a2f3d3334ab7e3f",
      "output": [
        "Mitä kokeellista arviointia käytetään?"
      ]
    },
    {
      "input": "Käytämme sanakohdistuksia, kuten muissakin annotaatioiden projisointityössä, projisoidaksemme AMR-kohdistukset kohdekieliin. Lähestymistapamme perustuu erääseen perusolettamukseen: jos lähdesana on sanavastaavuudeltaan kohdesanan mukainen ja se on AMR-vastaavuudeltaan AMR-solmun mukainen, myös kohdesana on vastaavuudeltaan AMR-solmun mukainen. Sanakohdistukset luotiin fast_align BIBREF10 -ohjelmalla, kun taas AMR-kohdistukset luotiin JAMR BIBREF11 -ohjelmalla.",
      "id": "task461-3fc30ba6150b46e78b5a22fadb31979b",
      "output": [
        "Miten annotaatioprojektio tehdään, kun kielillä on erilainen sanajärjestys?"
      ]
    },
    {
      "input": "Suoritamme ensin kokeen BiLSTM:llä, BiLSTM-CNN:llä, BiLSTM-CRF:llä ja BiLSTM-CNN-CRF:llä käyttäen taulukossa TABREF30 mainittuja hyperparametreja. ",
      "id": "task461-012066438d7b4bd3b7fd19df13b0b2ae",
      "output": [
        "Mitä koneoppimismalleja ne tutkivat?"
      ]
    },
    {
      "input": "Otamme käyttöön Amazonin Mechanical Turk -palvelun avulla toteutetun BIBREF-annotaatiokoneiston5 ja annotoimme jokaisen predikaatin kahdella koulutetulla työntekijällä itsenäisesti, kun taas kolmas yhdistelee heidän annotaationsa lopulliseksi rooli- ja argumenttikokonaisuudeksi. Tässä yhdistämistehtävässä työntekijä validoi kysymykset, yhdistää, jakaa tai muuttaa saman roolin vastauksia ohjeiden mukaisesti ja poistaa turhat roolit valitsemalla luonnollisemmin muotoillut kysymykset. ",
      "id": "task461-8df7f95c6b2246fda8d216d1b27b0f7a",
      "output": [
        "Mitä erilaista parannetussa annotaatioprotokollassa on?"
      ]
    },
    {
      "input": "ILP-pohjaisen lähestymistapamme tuottamia tiivistelmiä verrattiin vastaaviin manuaalisiin tiivistelmiin käyttämällä ROUGE BIBREF22 unigram-pistemäärää.",
      "id": "task461-b0937aade18c4cd88355fdd3ee11adc6",
      "output": [
        "Mitä arviointimittareita käytettiin tiivistämistehtävässä?"
      ]
    },
    {
      "input": "Espanjan kieli (SPA) on sitä vastoin morfologisesti rikas, ja siinä on paljon laajemmat verbiparadigmat kuin englannissa. Englannin tavoin se on suffiksoiva kieli, ja lisäksi se käyttää sisäisiä kantamuutoksia (esim. o $\\rightarrow $ ue). Valitsimme zulun (ZUL), joka on bantoidinen kieli. Kahdesta ensimmäisestä kielestä poiketen se on vahvasti prefiksoiva. Toiseksi, HUN:lla esivalmennettu järjestelmä, joka toimi hyvin, viittaa jälleen kerran siihen, että lähdekielestä, jonka morfologia on agglutinatiivinen eikä fuusionaalinen, näyttää olevan myös hyötyä. TUR ja HUN saavat jälleen korkean tarkkuuden, mikä on lisäindikaattori hypoteesillemme, jonka mukaan lähdekieli, jossa on agglutinatiivinen morfologia, helpottaa taivutuksen oppimista toisessa kielessä.",
      "id": "task461-fc0062a088084269bc51722cddf142fd",
      "output": [
        "Käytetäänkö agglutinatiivisia kieliä sekä prefiksoivien että suffiksoivien kielten ennustamisessa?"
      ]
    },
    {
      "input": "Kokeissa tarkastellaan neljää tietoaineistoa, joista kaksi on äskettäin luotuja ja loput kaksi jo julkisia: CNN, TIME, 20 Newsgroups ja Reuters-21578. Koodi ja kaksi uutta tietoaineistoa ovat saatavilla osoitteessa github.com/baiyangwang/emgan. Kaikkien asiakirjojen esikäsittelyä varten muutimme kaikki merkit pieniksi kirjaimiksi, poistimme asiakirjojen kantoja ja ajoimme word2vec-mallin jokaiselle korpukselle saadaksemme sanojen upotukset, joiden koko on 300. Kaikissa myöhemmissä malleissa otamme huomioon vain yleisimmät INLINEFORM0-sanat kaikissa aineiston korpuksissa.",
      "id": "task461-73f8d90b06bd4fb4b9a1ce188c1918eb",
      "output": [
        "Mitä korporaatioita he käyttävät?"
      ]
    },
    {
      "input": "Tutkiaksemme, voiko BERT-pohjainen mallimme siirtää tietoa kielen ulkopuolelta, pidämme kuvaominaisuuksia yksinkertaisina visuaalisina merkkeinä, jotka voidaan esittää mallille analogisesti tekstimerkkien upotusten kanssa. Jotta $o_j$-vektorit (ulottuvuus $2048+4=2052$) olisivat vertailukelpoisia BERT-merkkiutumisten (ulottuvuus 768) kanssa, käytämme yksinkertaista lineaarista ristikkäismodaalista projektointikerrosta $W$, jonka ulottuvuudet ovat $2052\\hspace{-1.00006pt}\\times \\hspace{-1.00006pt}768$. Kuvassa havaitut $N$ kohdealueet esitetään siten muodossa $X_{img} = (W.o_1,...,W.o_N)$. Kun kuva on kuvattu BERT:n sulautusavaruuteen $W$:n avulla, muu malli näkee kuvan yksikköjen sarjana, jossa ei ole selvää merkintää siitä, onko kyseessä tekstin vai kuvan sulautus.",
      "id": "task461-5294c0e08700454f84b60f5fb634162f",
      "output": [
        "Miten multimodaaliset representaatiot yhdistetään?"
      ]
    },
    {
      "input": "GP-GNN:t rakentavat ensin täysin yhdistetyn graafin $\\mathcal {G} = (\\mathcal {V}, \\mathcal {E})$ , jossa $\\mathcal {V}$ on olioiden joukko ja jokainen reuna $(v_i, v_j) \\in \\mathcal {E}, v_i, v_j \\in \\mathcal {V}$ vastaa tekstistä poimittua sekvenssiä $s = x_0^{i,j}, x_1^{i,j}, \\dots , x_{l-1}^{i,j}}$. ",
      "id": "task461-178fcc8c3797414bbb81d80fec97fe4c",
      "output": [
        "Tässä asiakirjassa siis muutetaan jäsentymätön tekstisisääntulo parametreiksi, joita GNN:t voivat lukea?"
      ]
    },
    {
      "input": "Twiittien tilastollinen analyysi ::: Tutkimuksessa on tarkasteltu kolmea sanamerkkien muotoa eli unigram-, bigram- ja trigram-muotoa.",
      "id": "task461-840afa29e10b496fa2fde0b3b2f13dc9",
      "output": [
        "Mitkä sanafrekvenssit heijastavat kirjoittajien mukaan twitterin käyttäjien psykologiaa?"
      ]
    },
    {
      "input": "Taulukossa TABREF23 esitetään Pearsonin, Spearmanin ja Kendallin korrelaatiot Rougen ja Seran sekä pyramidipisteiden välillä. Mielenkiintoista on havaita, että monilla Rouge-pisteiden muunnelmilla ei ole korkeita korrelaatioita ihmisten pyramidipisteiden kanssa. Alhaisimmat F-pistekorrelaatiot ovat Rouge-1:llä ja Rouge-L:llä (INLINEFORM0 =0,454). Rouge-1:n heikko korrelaatio osoittaa, että ehdokasyhteenvedon ja kultaisten yhteenvetojen välisten unigrammien yhteensovittaminen ei ole tarkka yhteenvedon laadun kvantifioinnissa.",
      "id": "task461-4e858fb853e04c2591f95962b11fd3e7",
      "output": [
        "Mitä erilaisia korrelaatioita saadaan, kun käytetään ROUGE-pisteiden eri muunnelmia?"
      ]
    },
    {
      "input": "Kieliopin matemaattisen rakenteen tutkiminen on osoittanut, että lauseiden perustana eivät ole sanat vaan jotkin atomiset kieliopilliset tyypit, kuten substantiivi- ja lausetyyppi BIBREF23 , BIBREF24 , BIBREF25 . Transitiiviverbityyppi ei ole atomaattinen kieliopillinen tyyppi, vaan kahdesta substantiivityypistä ja yhdestä lausetyypistä koostuva komposiitti. Näin ollen erityisen mielenkiintoista tässä on se, että atomisella ei todellakaan tarkoiteta pienintä....",
      "id": "task461-accade0ace754820872ce022faf92523",
      "output": [
        "Väittävätkö he, että kaikki sanat voidaan johtaa muista (alku)sanoista?"
      ]
    },
    {
      "input": "Tehtävän yksinkertaistamiseksi laadimme binäärisen luokittelun: ehdokkaat, joista on pidetty tai jotka on valittu valintalistalle, katsotaan kuuluviksi haluttavaan luokkaan ja muut kuuluviksi ei-haluttavaan luokkaan.",
      "id": "task461-8d7575c0a2664e04b7e1e29bb65edc6e",
      "output": [
        "Miten \"palkattavuus\" määritellään?"
      ]
    },
    {
      "input": "Tutkimme vastausten leksikaalista ja semanttista monimuotoisuutta tekemällä kolme analyysia. Ensinnäkin yhdistimme kaikki työntekijän vastaukset tiettyyn kysymykseen yhdeksi kysymystä vastaavaksi luetteloksi. Toiseksi verrattiin yksittäisten vastausten monimuotoisuutta kunkin kysymyksen kohdalla valvonta- ja AUI-järjestelmien välillä. Kysymyksen monimuotoisuuden mittaamiseksi laskimme vastausten määrän jaettuna kyseiseen kysymykseen annettujen yksittäisten vastausten määrällä. Kutsumme tätä arvoa vastaustiheydeksi. ",
      "id": "task461-75d87cc8c9124be39b733d046b7b94ea",
      "output": [
        "Miten leksikaalista monimuotoisuutta mitattiin?"
      ]
    },
    {
      "input": "Tulokset ja analyysi",
      "id": "task461-ac797b9129c44e09a45de2b1c821831a",
      "output": [
        "mitä kvantitatiivista analyysia tehdään?"
      ]
    },
    {
      "input": "Jaettua tehtävää varten tarjotaan tasapainoinen tietokokonaisuus, joka koostuu 2 396 ironisesta ja 2 396 ei-ironisesta twiitistä. Ironinen korpus muodostettiin keräämällä itse kommentoituja twiittejä, joissa oli hashtagit #ironia, #sarkasmi ja #ei. Tämän jälkeen twiitit puhdistettiin ja tarkistettiin ja merkittiin manuaalisesti käyttäen hienojakoista annotaatiojärjestelmää BIBREF3 . ",
      "id": "task461-1df82cf36069438a917573b3fb8ee78e",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Menetelmät ::: BIBREF15, BIBREF16. Jaamme ensin harjoituslauseparit kolmeen ryhmään kohde- ja lähteen pituuden suhteen mukaan (merkkeinä). Ihannetapauksessa haluamme ryhmän, jossa kohde on lyhyempi kuin lähde (lyhyt), ryhmän, jossa ne ovat samankokoisia (normaali), ja viimeisen ryhmän, jossa kohde on pidempi kuin lähde (pitkä). Käytännössä valitsemme kaksi kynnysarvoa $t_\\text{min}$ ja $t_\\text{max}$ pituussuhdejakauman mukaan. Kaikki lauseparit, joiden pituussuhde on välillä $t_\\text{min}$ ja $t_\\text{max}$, kuuluvat normaaliryhmään, ne, joiden pituussuhde on alle $t_\\text{min}$, lyhyisiin ja loput pitkiin. Harjoittelun aikana liitämme jokaiseen lähdelauseeseen pituusmerkin sen ryhmän mukaan ($<$lyhyt$>$, $<$normaali$>$ tai $<$pitkä$>$), jotta yksi verkko voi erottaa ryhmät toisistaan (ks. kuva KUVA 2). Päättelyhetkellä pituusmerkin avulla verkko saa aikaan käännöksen, joka kuuluu haluttuun pituusryhmään.",
      "id": "task461-d35777cee4704c97b5635b4cb0e7e655",
      "output": [
        "Miten ne ehdollistavat tuotoksen tiettyyn kohde-lähde-luokkaan?"
      ]
    },
    {
      "input": "Vaikka jokainen kaupunkikuvaus on suhteellisen lyhyt, Calvinon kirjoitus on täynnä harvinaisia sanoja, monimutkaisia syntaktisia rakenteita ja kuvakieltä. Kunkin kaupungin olennaisten osatekijöiden vangitseminen yhteen vektoriin ei siis ole yhtä yksinkertaista kuin tavanomaisempien tekstimuotojen kohdalla. Toivomme kuitenkin, että miljardien sanojen tekstin avulla koulutettujen kielimallien avulla voidaan poimia näistä kuvauksista mielekästä semantiikkaa. Kokeilemme kolmea erilaista esivalmennettua representaatiota: ELMo BIBREF5 , BERT BIBREF6 ja GloVe BIBREF18 . Yhden kaupungin upottamisen tuottamiseksi laskemme TF-IDF-painotetun elementtiviisauden keskiarvon merkkitason representaatioista. Kaikissa esivalmennetuissa menetelmissä pienennämme lisäksi kaupunkikuvioiden ulottuvuuden 40:een PCA:n avulla, jotta ne olisivat yhteensopivampia klusterointialgoritmimme kanssa.",
      "id": "task461-3f40d908dc304e1aa3b9660fe44315ad",
      "output": [
        "Miten he mallintavat kaupunkikuvauksen käyttämällä upotuksia?"
      ]
    },
    {
      "input": "Teemme kokeita (§ SECREF5 ) kahdella englannin ja japanin välisellä käännöskorpuksella arvioidaksemme menetelmän hyödyllisyyttä käännöstarkkuuden parantamisessa ja harjoitteluun tarvittavan ajan lyhentämisessä.",
      "id": "task461-8b6b6e9b04e7483e97e0dadc7cc32a56",
      "output": [
        "Mitä kielipareja he kokeilivat?"
      ]
    },
    {
      "input": "Kuvassa 1 esitetään yksinkertainen lineaarinen malli, jossa on sijoitusrajoitus.",
      "id": "task461-f95dff54b2fa42fba0333b1f6cf0035b",
      "output": [
        "Mitkä ovat niiden perusmenetelmät?"
      ]
    },
    {
      "input": "Tietokanta sisältää noin 6 000 kolmikkoa, jotka koostuvat videoista, kysymyksistä ja vastauksista, jotka on kerätty manuaalisesti kuvankäsittelyohjelmiston opetusvideoista, joissa on puhuttuja selostuksia. ",
      "id": "task461-8c8ac716b3cd48319e6eb02658395d3c",
      "output": [
        "Millaisia opetusvideoita tietokannassa on?"
      ]
    },
    {
      "input": "Vaikka neuraalinen syntaksista riippumaton järjestelmä on parempi L1-tiedoissa, molemmat syntaksiin perustuvat järjestelmät tuottavat parempia analyyseja L2-tiedoissa. Lisäksi, kuten eri jäsentäjien välinen vertailu osoittaa, mitä parempia jäsentämistuloksia saamme, sitä paremman suorituskyvyn saavutamme L2-tiedoissa. Tämä osoittaa, että syntaktinen jäsennys on tärkeää semanttisen rakentamisen kannalta oppijan kiinan kielessä. Analyysimme mukaan tärkein syy on se, että syntaksiin perustuva järjestelmä voi tuottaa oikeita syntaktisia analyysejä osittaisille kieliopillisille fragmenteille L2-teksteissä, mikä tarjoaa ratkaisevaa tietoa SRL:n kannalta.",
      "id": "task461-2a5f1b9b39db44f0b7f95c70749c8c13",
      "output": [
        "Vihjailevatko kirjoittajat, miksi syntaktinen jäsennys on niin tärkeää kieltenvälisten kielten semanttisessa roolimerkinnässä?"
      ]
    },
    {
      "input": "Nämä toimet koostuvat seuraavista osatekijöistä:[leftmargin=*]Yhteisviittausten ratkaiseminen: Joskus on tarpeen käyttää rinnakkaisviittausten ratkaisutekniikoita tehokkaan haun mahdollistamiseksi, jotta voidaan tukea usean käännöksen vuorovaikutusta. Kyselyn luominen: Tämä komponentti luo kyselyn käyttäjän ja järjestelmän aiempien vuorovaikutusten perusteella. Hakumalli: Tämä on keskeinen luokittelukomponentti, joka hakee asiakirjoja tai kohtia suuresta kokoelmasta. Tulosten tuottaminen: Haetut asiakirjat voivat olla liian pitkiä esitettäväksi joidenkin käyttöliittymien avulla.",
      "id": "task461-c47eea8f67864270bea2e6a5a65b837d",
      "output": [
        "Mitä eri moduuleja Macawissa on?"
      ]
    },
    {
      "input": "Teemme kokeita SQuAD-tietokannalla BIBREF3.",
      "id": "task461-c02b0144c95f4c66969550e1dc6fd8da",
      "output": [
        "Millaisilla tietokokonaisuuksilla kokeita tehdään?"
      ]
    },
    {
      "input": "Käytämme kahta lähdettä e-kirjojen merkintätiedoista: (i) toimittajan tunnisteita ja (ii) Amazonin hakusanoja. Toimittajatunnisteita varten keräämme 48 705 e-kirjan tiedot 13 kustantajalta, jotka ovat Kunstmann, Delius-Klasnig, VUR, HJR, Diogenes, Campus, Kiwi, Beltz, Chbeck, Rowohlt, Droemer, Fischer ja Neopubli.  Amazonin hakusanoja varten keräämme 21 243 e-kirjan hakukyselylokit 12 kuukauden ajalta (eli marraskuusta 2017 lokakuuhun 2018). ",
      "id": "task461-4b628f943b5c421fa8b7647e6e2c01a2",
      "output": [
        "mitä tietokokonaisuutta käytettiin?"
      ]
    },
    {
      "input": "Mallinsimme sanojen määrän ja kahden käyttäjän sitoutumista kuvaavan mittarin (kokonaisarvosana, keskimääräinen kierrosten määrä) välistä suhdetta erillisillä lineaarisilla regressioilla.Tulokset osoittivat, että käyttäjät, jotka tuottivat keskimäärin enemmän sanoja sisältäviä lauseita, antoivat merkittävästi korkeampia arvosanoja ($\\beta $=0.01, SE=0.002, t=4.79, p$<$0.001) (ks. kuvio 2) ja osallistuivat Gunrockiin huomattavasti useamman kierroksen ajan ($\\beta $=1.85, SE=0.05, t=35.58, p$<$0.001) (ks. kuvio 2). Nämä tulokset voidaan tulkita todisteeksi Gunrockin kyvystä käsitellä monimutkaisia lauseita, joissa käyttäjät eivät ole sidottuja yksinkertaisiin vastauksiin tullakseen ymmärretyksi ja tunteakseen olevansa mukana keskustelussa - ja todisteeksi siitä, että yksilöt ovat tyytyväisempiä keskusteluun, kun he ottavat aktiivisemman roolin sen sijaan, että järjestelmä hallitsisi vuoropuhelua. Toisaalta toinen tulkinta on se, että puhelias käyttäjät saattavat nauttia keskustelusta botin kanssa yleensä ja siten antaa korkeampia arvosanoja yhdessä korkeamman keskimääräisen sanamäärän kanssa.",
      "id": "task461-16c9c9fbcdef42aea2fc2fba785f7b74",
      "output": [
        "Miten he suhteuttavat käyttäjien taustatietokyselyt käyttäjien tyytyväisyyteen?"
      ]
    },
    {
      "input": "On yleisesti tunnettu tosiasia, että NLP-sovellukset teollisuudessa joutuvat usein käsittelemään meluisia tietoja. Mahdollisia häiriöitä ovat muun muassa ei-kanoninen teksti, kuten kirjoitusvirheet, typografiset virheet, puhekieliset ilmaisut, lyhenteet, slangi, internet-jargon, hymiöt, upotetut metatiedot (kuten hashtagit, URL-osoitteet, maininnat), epätyypilliset syntaktiset rakenteet ja oikeinkirjoitusvariantit, kieliopillisesti virheellinen teksti sekä kahden tai useamman kielen sekoitus. Tällaiset meluiset tiedot ovat tyypillisiä käyttäjien tuottamalle tekstisisällölle, ja niitä esiintyy yleisesti esimerkiksi sosiaalisessa mediassa, keskusteluissa, verkkoarvosteluissa ja verkkofoorumeilla.",
      "id": "task461-f309076b2fd1443dba68ebaf7cd52022",
      "output": [
        "Minkälaista kohinaa esiintyy tyypillisissä teollisuustiedoissa?"
      ]
    },
    {
      "input": "Tässä artikkelissa tarjoamme uudenlaisen reaaliaikaisen ja mukautuvan kryptovaluutan hinnan ennustamisalustan, joka perustuu Twitter-tunnelmiin. Integroiva ja modulaarinen alusta selviytyy kolmesta edellä mainitusta haasteesta monin tavoin. Ensinnäkin se tarjoaa Spark-pohjaisen arkkitehtuurin, joka käsittelee suuren määrän saapuvaa dataa pysyvällä ja vikasietoisella tavalla. Toiseksi ehdotettu alusta tarjoaa lähestymistavan, joka tukee VADERiin perustuvaa tunneanalyysia, joka pystyy vastaamaan suuriin määriin luonnollisen kielen käsittelykyselyjä reaaliajassa. Kolmanneksi alusta tukee verkko-oppimiseen perustuvaa ennakoivaa lähestymistapaa, jossa koneoppimismalli mukauttaa painojaan uusien hintojen ja tunteiden mukaan. Lopuksi, alusta on modulaarinen ja integroiva siinä mielessä, että se yhdistää nämä eri ratkaisut tarjotakseen uudenlaisen reaaliaikaisen työkalutuen bitcoinin hinnan ennustamiseen, joka on skaalautuvampi, tietorikkaampi ja ennakoivampi ja joka voi auttaa nopeuttamaan päätöksentekoa, paljastamaan uusia mahdollisuuksia ja tarjoamaan oikea-aikaisempia oivalluksia saatavilla olevan ja yhä suuremman taloudellisen tiedon määrän ja monipuolisuuden perusteella.",
      "id": "task461-05e87991c059483ebbbbd75f7dcefc12",
      "output": [
        "Mitkä alustan osat ovat modulaarisia?"
      ]
    },
    {
      "input": "Käytämme valvomatonta sanojen segmentointimenetelmää latticelm, jolla voidaan segmentoida sanoja suoraan lausuttujen lauseiden puheentunnistustulosten BIBREF22 ristikoista.",
      "id": "task461-0ff6c3273d944c8cb47244043bca5a55",
      "output": [
        "Mitä menetelmää he käyttävät sanojen segmentointiin?"
      ]
    },
    {
      "input": "Esimerkkinä INLINEFORM0-pisteytyksestä arvioimme ja vertailimme kahden eri SBD-järjestelmän suorituskykyä YouTube-videoiden joukossa moniviiteympäristössä. Ensimmäinen järjestelmä (S1) käyttää konvolutiivista neuroverkkoa määrittämään, vastaako liukuikkunan keskimmäinen sana SU-rajaa vai ei BIBREF30 . Toisessa lähestymistavassa (S2) sen sijaan otetaan käyttöön kaksisuuntainen rekursiivinen neuroverkkomalli, jossa on huomiomekanismi rajojen havaitsemiseen BIBREF31 .",
      "id": "task461-8d9fecc50eeb459685153b79a10d7780",
      "output": [
        "Mitä SBD-järjestelmiä he vertasivat?"
      ]
    },
    {
      "input": "Käytämme Gal & Ghahramani galin pudotustekniikkaa perustasona, koska se on kaikkein samankaltaisin pudotustekniikka kuin meidän lähestymistapamme, ja nimitämme sitä VBD:ksi (variational binary dropout).",
      "id": "task461-d54af2d7efc148f5ab81410e9f892af6",
      "output": [
        "Mikä on binäärinen variaatiopudotus?"
      ]
    },
    {
      "input": "Laadun valvomiseksi varmistimme, että yksi kommentoija kommentoi enintään 120 uutisotsikkoa (tämä suojaa kommentoijia lukemasta liikaa uutisotsikoita ja hallitsemasta annotaatioita). Toiseksi annoimme tehtävään osallistua vain sellaisia annotoijia, jotka asuvat maantieteellisesti Yhdysvalloissa.Testasimme annotoijia 1100 dollarin testikysymysten joukolla ensimmäisessä vaiheessa (noin 10 prosenttia aineistosta) ja 500:lla toisessa vaiheessa. Annotoijien oli läpäistävä 95 prosenttia.",
      "id": "task461-33d2daf35f1144a88a3e65420899cecb",
      "output": [
        "Miten merkintöjen laatua mitataan?"
      ]
    },
    {
      "input": "Menetelmämme perustuu sosiaalipsykologiseen tutkimukseen, erityisesti moraalin perusteita koskevaan teoriaan BIBREF26. MFT pyrkii selittämään ihmisen moraalin rakennetta ja vaihtelua eri kulttuureissa, ja siinä ehdotetaan viittä moraalista perustaa: Huolehtiminen / vahingoittaminen, oikeudenmukaisuus / huijaaminen, uskollisuus / pettäminen, auktoriteetti / kumoaminen ja pyhyys / rappio. Kukin perusta tiivistyy positiiviseen ja negatiiviseen napaan, jolloin saadaan kymmenen hienojakoista moraalikategoriaa.",
      "id": "task461-452dffa7121147818e21fdd1d3b43e8b",
      "output": [
        "Mitä hienojakoisia esimerkkejä moraalisesta ulottuvuudesta ne esittelevät?"
      ]
    },
    {
      "input": "Saadaksemme suuren määrän brasilialaisen musiikin sanoituksia loimme indeksoijan, joka navigoi Vagalume-sivustolla ja poimi kustakin musiikinlajista kaikki kappaleet kaikilta luetelluilta tekijöiltä.",
      "id": "task461-20d7c7798c8d4d23a3abe8c82b506593",
      "output": [
        "mikä on laulun sanoituksen lähde?"
      ]
    },
    {
      "input": " Logistinen regressiomalli, jossa käytetään merkkitason n-grammiominaisuuksia, esitetään vahvana vertailukohtana, koska se on osoittautunut erittäin tehokkaaksi.",
      "id": "task461-d50f12af061748bbba04f7b015cffb55",
      "output": [
        "Mikä on heidän perustasonsa?"
      ]
    },
    {
      "input": "Aiomme soveltaa semanttista aukkotelineistöä uutisten tiivistämiseen. Voimme erityisesti merkitä kriittisiä entiteettejä, kuten henkilöiden tai paikkojen nimiä, varmistaaksemme, että ne on otettu oikein huomioon luodussa tiivistelmässä. Aiomme myös kerätä ihmisen ja ihmisen välisen dialogin tietokokonaisuuden, jossa on monipuolisempia ihmisen kirjoittamia tiivistelmiä.",
      "id": "task461-97360a24654a40b897a21ef4eb0b1c65",
      "output": [
        "Odotetaanko, että puhujan rooli, semanttinen aukko ja dialogialueen annotaatiot löytyvät reaalimaailman tietokannoista?"
      ]
    },
    {
      "input": "Forexiin, erityisesti EUR:iin ja USD:hen, liittyvät twiitit hankittiin Twitterin hakusovellusliittymän kautta seuraavalla kyselyllä: \"EURUSD\", \"USDEUR\", \"EUR\" tai \"USD\". Kolmen vuoden aikana (tammikuusta 2014 joulukuuhun 2016) kerättiin lähes 15 miljoonaa twiittiä. Osajoukko niistä (44 000 twiittiä) leimattiin manuaalisesti asiantuntevien rahoitusalan opiskelijoiden toimesta. ",
      "id": "task461-da506fff255e4ec3a9285d2f1d14effc",
      "output": [
        "Kuinka monta twiittiä merkittiin manuaalisesti? "
      ]
    },
    {
      "input": "Kokoelmassa on lähes 1,1 miljoonaa lausetta. Erilaisia relaatiotyyppejä (ainutlaatuisia predikaatteja) on 119, ja niissä on muutamasta suhteesta muutamaan miljoonaan suhteeseen.",
      "id": "task461-49cf5f9e8b8c447cbbc0efd86d366fc9",
      "output": [
        "Kuinka suuri on heidän tietokokonaisuutensa?"
      ]
    },
    {
      "input": "Kokeissamme käytämme syötteenä Stanford Sentiment Treebank -testijoukon BIBREF2 2210 tokenisoitua lausetta, jotka esikäsittelemme pienentämällä ne, kuten BIBREF8:ssa tehtiin.",
      "id": "task461-9bc94422438045abb0f06a1e1cb4c9f6",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Tässä työssä koulutamme kaksikielisiä UWS-malleja, joissa käytetään uhanalaista kieltä Mboshi kohdekielenä ja erilaisia hyvin resursoituja kieliä yhdenmukaistettuna tietona. Tulokset osoittavat, että samankaltaiset kielet sijoittuvat paremmin segmentointisuorituskyvyn suhteen ja että yhdistämällä eri malleilla opittua tietoa segmentointi paranee entisestään. Tämä saattaa johtua erilaisista kieliriippuvaisista rakenteista, jotka saadaan selville käyttämällä useampaa kuin yhtä kieltä. ",
      "id": "task461-987ccfd1b35c4ff0a81d63c63c7a0a5a",
      "output": [
        "Miten hyvin resursoitu kieli vaikuttaa tuotoksen laatuun?"
      ]
    },
    {
      "input": "Käytämme samaa perustasoa kuin lang2011unsupervised, jota on osoittautunut vaikeaksi päihittää. Tämä lähtötaso määrittää konstituentille semanttisen roolin sen syntaktisen funktion perusteella eli riippuvuussuhteen perusteella sen päähän.",
      "id": "task461-b2720b50b63b438bb34434c1f61642d9",
      "output": [
        "Mitä perusmallia käytetään?"
      ]
    },
    {
      "input": "Espanjan serigos2017using poimi argentiinalaisista sanomalehdistä anglismeja yhdistämällä sanakirjahakuja (TreeTaggerin ja NLTK-lemmatisaattorin avulla), suuraakkosellisten sanojen automaattista suodatusta ja manuaalista tarkastusta. Serigos2017applying-moduulissa lisättiin merkkien n-gram-moduuli, jolla arvioitiin todennäköisyys, että sana on englanninkielinen tai espanjankielinen. moreno2018configuracion käytti erilaisia hahmontäsmäytyssuodattimia ja sanakirjan etsintää poimiakseen anglismikadidaatteja yhdysvaltalaisista espanjankielisistä twiiteistä koostuvasta korpuksesta.",
      "id": "task461-0729833529a84e978fdf766231909f65",
      "output": [
        "Mainitaanko artikkelissa muita teoksia, joissa ehdotetaan menetelmiä espanjan kielen anglismien havaitsemiseksi?"
      ]
    },
    {
      "input": "Esimerkiksi alkuperäinen lause `Kävimme ostoksilla lauantaina' ja korjattu versio `Kävimme ostoksilla lauantaina' tuottavat seuraavan mallin: (VVD shop_VV0 II, VVD shopping_VVG II)Kun taustakorpuksesta on kerätty tilastot, virheet voidaan lisätä virheettömään tekstiin. Opitut kuviot käännetään nyt päinvastaisiksi ja etsitään syötelauseesta tuplan oikea puoli. Käytämme vain kuvioita, joiden frekvenssi on INLINEFORM0 , jolloin harjoitusaineistostamme saadaan yhteensä 35 625 kuviota. ",
      "id": "task461-de4287793bf149e9af366a2443fa5c2d",
      "output": [
        "Mitä tekstikuvioita poimitaan?"
      ]
    },
    {
      "input": "Tässä artikkelissa analysoimme jatkuvien lauseiden automaattista korjaamista. Kehitämme kaksi menetelmää: ehdollisen satunnaiskentän mallin (roCRF) ja Seq2Seq-huomiointimallin (roS2S), ja osoitamme, että ne päihittävät mallit, jotka ovat peräisin sisartehtävistä, kuten välimerkkien palauttamisesta ja koko lauseen kielioppivirheiden korjaamisesta.",
      "id": "task461-7c8de99f11b449d7b1d9243c39324ad6",
      "output": [
        "Millaisia koneoppimismalleja he käyttävät korjatakseen loputetut lauseet?"
      ]
    },
    {
      "input": "Teemme myös kaksi inhimillistä arviointia arvioidaksemme, a) minkä tyyppistä tiivistelmää osallistujat suosivat (vertailemme uuttuvia ja abstrahoivia järjestelmiä) ja b) kuinka paljon asiakirjan keskeistä tietoa tiivistelmässä säilyy (pyydämme osallistujia vastaamaan asiakirjan sisältöön liittyviin kysymyksiin lukemalla järjestelmän tiivistelmiä).",
      "id": "task461-54e476ae64004a41bd25a7862e87d5c2",
      "output": [
        "Käyttävätkö he ROUGEn lisäksi muita arviointimittareita?"
      ]
    },
    {
      "input": "Kieliopin induktiomenetelmä perustuu opetussuunnitelman oppimiseen BIBREF7 , jossa jäsentäjä oppii ensin jäsentämään yksinkertaisia lauseita ja sitten oppimaan monimutkaisempia lauseita. Induktiomenetelmä on iteratiivinen, puoliautomaattinen ja perustuu usein esiintyviin kuvioihin. Tekstistä indusoidaan kontekstivapaa kielioppi (CFG), jota edustavat useat kerrokset semanttisia merkintöjä.",
      "id": "task461-42ad4a41455d4d46a824539f40807cbc",
      "output": [
        "Miten he saivat aikaan CFG:n?"
      ]
    },
    {
      "input": "Käytämme BIBREF5-menetelmää neuraalisten espanjan ja englannin ST-mallien kouluttamiseen sekvenssistä sekvenssiin. Kultaisten teemamerkintöjen saaminen aineistoomme vaatisi huomattavaa manuaalista annotaatiota, joten sen sijaan käytämme 1K (train20h) harjoitusjoukon lausumien ihmiskäännöksiä NMF-teemamallin kouluttamiseen scikit-learn BIBREF14 -ohjelmalla.",
      "id": "task461-8744350b49e74b69abc57a5d805181de",
      "output": [
        "Mikä on mallin arkkitehtuuri?"
      ]
    },
    {
      "input": "Vaikka kirosanat ovat yleisiä twiiteissä, ne edustavat vain 1,15 prosenttia kaikista käytetyistä sanoista BIBREF21 . Sitä vastoin havaitsimme, että 5,72 prosenttia kaikista jengin jäsentilien julkaisemista sanoista oli luokiteltu kirosanoiksi, mikä on lähes viisi kertaa enemmän kuin keskimääräinen kirosanojen käyttö Twitterissä. Pilvet heijastavat myös sitä, että jengiläiset puhuvat usein huumeista ja rahasta termeillä kuten smoke, high, hit ja money, kun taas tavalliset käyttäjät eivät juuri puhu taloudesta ja huumeista. Huomasimme myös, että jengiläiset puhuvat aineellisista asioista termeillä, kuten got, money, make, real, need, kun taas tavalliset käyttäjät pyrkivät ilmaisemaan tunteitaan termeillä, kuten new, like, love, know, want, look, make, us.",
      "id": "task461-a4974c120afa4a1fa5bc3f86dcbba45a",
      "output": [
        "Mitä eroja kielenkäytössä on jengiläisten ja muun Twitter-väestön välillä?"
      ]
    },
    {
      "input": "Twitter tarjoaa hyvin dokumentoidun API:n, jonka avulla voi pyytää mitä tahansa tietoja twiiteistä, käyttäjistä ja heidän profiileistaan sekä nopeusrajoituksista. On olemassa erityyppinen API, jota kutsutaan Streaming API:ksi ja joka tarjoaa reaaliaikaisen twiittien virran. Tärkein ero tavalliseen API:hin on se, että yhteys pidetään yllä mahdollisimman pitkään ja twiitit lähetetään reaaliajassa asiakkaalle. Streaming API:ssa on kolme meitä kiinnostavaa päätepistettä: \"sample\", \"filter\" ja \"firehose\". Ensimmäinen tarjoaa näytteen (satunnainen osajoukko) koko twiittivirrasta. Toisen avulla voidaan vastaanottaa twiittejä, jotka vastaavat joitakin hakukriteerejä: ne vastaavat yhtä tai useampaa hakusanaa, ovat osajoukon käyttäjien tuottamia tai ovat peräisin tietystä maantieteellisestä sijainnista. Viimeinen tarjoaa koko twiittien joukon, vaikka se ei olekaan oletusarvoisesti käytettävissä. Meidän tapauksessamme yksinkertaisin lähestymistapa olisi käyttää \"sample\"-päätepistettä, mutta se tarjoaa twiittejä kaikilla mahdollisilla kielillä kaikkialta maailmasta, kun taas meitä kiinnostaa vain yksi kieli (venäjä). Tämän päätepisteen käyttöä varten toteutimme suodatuksen kielen perusteella. Suodatin on yksinkertainen: jos twiitti ei sisällä vähintään kolmen kyrillisen symbolin muodostamaa merkkijonoa, se katsotaan ei-venäläiseksi. Vaikka tällä lähestymistavalla säilytetään mongolian-, ukrainan- ja muiden slaavilaiskielten twiitit (koska niissä käytetään kyrillisiä aakkosia), väärien positiivisten tulosten kokonaismäärä on tässä tapauksessa häviävän pieni. Osoittaaksemme tämän teimme yksinkertaisen kokeen: satunnaisesta 200 twiitin otoksesta vain 5 twiittiä oli muulla kuin venäjän kielellä. Jotta emme luottaisi Twitterin kielentunnistukseen, päätimme käyttää tätä kielipohjaista suodatusmenetelmää. \"Näyte\"-päätepisteen kautta saatujen twiittien määrä ei kuitenkaan ollut tyydyttävä. Tämä johtuu luultavasti siitä, että \"sample\"-päätteestä lähetetään aina samaa sisältöä kaikille sen asiakkaille, ja pieni osa siitä on venäjänkielistä. Jotta venäjänkielisten twiittien louhinta voitaisiin pakottaa, valitsimme \"filter\"-päätteen, joka vaatii jonkinlaisen hakukyselyn. Rakensimme heuristisen kyselyn, joka sisälsi joitakin venäjänkielisiä apusanoja: konjunktioita, pronomineja ja prepositioita. Täydellinen luettelo on seuraava: russian я, у, к, в, по, на, ты, мы, до, на, она, он, и, да.",
      "id": "task461-44b5b6bdb87a47528c195be85f14e236",
      "output": [
        "Mitä Twitter-korpusta käytettiin sanavektorien kouluttamiseen?"
      ]
    },
    {
      "input": "Arvioidaksemme korpuksen hyödyllisyyttä SMT-tarkoituksiin käytimme sitä automaattisen kääntäjän kouluttamiseen Moses BIBREF8 -ohjelmalla.",
      "id": "task461-f8538f71680c4502bbd718643b7dab38",
      "output": [
        "Mitä SMT-malleja he tarkastelivat?"
      ]
    },
    {
      "input": "Seuraavassa esitellään vaiheet, joita tarvitaan toisiinsa liittyvien tapahtumien tietämysgraafin kehittämiseksi. Kuvassa FIGREF2 esitetään koko prosessin yleiskatsaus. Tämä putki sisältää seuraavat päävaiheet, joita käsitellään yksityiskohtaisesti myöhemmin. (1) Twiittien kerääminen useiden uutiskanavien, kuten BBC:n ja CNN:n, Twitter-virrasta. (2) Taustatietomallista sopiminen. (3) Tapahtumien annotointi sisältää mahdollisesti kaksi osatehtävää (i) tapahtumien tunnistaminen ja (ii) tapahtumien luokittelu. (4) Entiteettien/suhteiden annotointi käsittää mahdollisesti joukon tehtäviä, joita ovat (i) entiteettien tunnistaminen, (ii) entiteettien linkittäminen, (iii) entiteettien disambiguointi, (iv) entiteettien semanttisten roolien merkitseminen ja (v) implisiittisten entiteettien päätteleminen. (5) Tapahtumien linkittäminen toisiinsa yli ajan ja median rajojen. (6) Tapahtumatietograafin julkaiseminen linkitetyn avoimen datan parhaiden käytäntöjen pohjalta.",
      "id": "task461-5c9fb3a779f846e18ac97dad87ed423c",
      "output": [
        "Mistä uutisorganisaatioista otsikot ovat peräisin?"
      ]
    },
    {
      "input": "Puheen sisältö saatiin YouTuben ASR-järjestelmän tarjoamista kuvateksteistä (CC), joita voidaan käyttää tekstityksinä.",
      "id": "task461-318236874b584f5fad394079ef4dfcb5",
      "output": [
        "Mitä ASR-järjestelmää he käyttävät?"
      ]
    },
    {
      "input": "Jotta voimme mukauttaa FactorCell BIBREF4:n tarkoituksiimme, korvaamme käyttäjän upotukset matalaulotteisella kuvaesityksellä. Näin pystymme muokkaamaan jokaisen kyselyn täydennyksen yksilölliseksi tietylle kuvaesitykselle.",
      "id": "task461-08ac3b0ee58749c0a57bdca3bdf8226e",
      "output": [
        "Miten he täydentävät käyttäjän kyselyn etuliitteen, jonka ehtona on kuva?"
      ]
    },
    {
      "input": "Rakennamme ja testaamme MMT-mallejamme Multi30K-tietokannassa BIBREF21 . Jokainen Multi30K:n kuva sisältää yhden englanninkielisen (EN) kuvauksen, joka on otettu Flickr30K:sta BIBREF22 , sekä ihmisen tekemät käännökset saksaksi (DE), ranskaksi (FR) ja tšekiksi BIBREF23 , BIBREF24 , BIBREF25 . Tietokokonaisuus sisältää 29 000 instanssia harjoittelua varten, 1 014 instanssia kehittämistä varten ja 1 000 instanssia testausta varten. Kokeilemme vain saksan- ja ranskankielisiä aineistoja, sillä ne ovat kieliä, joista meillä on sisäistä asiantuntemusta esiteltävän tyyppistä analyysia varten. Virallisen Multi30K-testijoukon (test 2016) lisäksi käytämme myös viimeisimmän WMT-arviointikilpailun testijoukkoa, test 2018 BIBREF25 .",
      "id": "task461-d8c0574ab2bd497f802e4fa7ffc04610",
      "output": [
        "Ilmoitetaanko tulokset vain englanninkielisestä aineistosta?"
      ]
    },
    {
      "input": "Weibo valvoo tiukasti BIBREF0-palvelussaan julkaistavaa sisältöä yhteistyössä vallanpitäjien kanssa. Zhu et al. zhu-etal:2013 mukaan Weibo käyttää sensuroitaviin viesteihin kohdistamiseen erilaisia strategioita, jotka vaihtelevat avainsanalistan suodattamisesta yksittäisten käyttäjien seurantaan. Kaikista lopulta sensuroiduista viesteistä lähes 30 prosenttia sensuroidaan 5-30 minuutin kuluessa ja lähes 90 prosenttia 24 tunnin kuluessa BIBREF1. Oletamme, että edelliset tapahtuvat automaattisesti, kun taas jälkimmäiset poistetaan ihmisen suorittaman sensuurin avulla.",
      "id": "task461-b2e2c8d178284f4abe72219221357fed",
      "output": [
        "Tiedetäänkö, sensuroivatko Sina Weibo -viestit ihmiset vai jokin automaattinen luokittelija?"
      ]
    },
    {
      "input": "Taulukossa TABREF16 esitetään yleiskatsaus toimitetusta tietokokonaisuudesta. Huomaa, että käytettävissä oleva tietomäärä vaihtelee kielittäin.",
      "id": "task461-e33d9f80df034d73bab0e59dab6a346a",
      "output": [
        "Onko tietokokonaisuus tasapainossa kaikkien neljän kielen kesken?"
      ]
    },
    {
      "input": "aika: vuosikymmen (1900-luvun ja 2010-luvun väliset luokat) ja vuosi, jotka edustavat aikaa, jolloin genrestä tuli valtavirta.",
      "id": "task461-1c97f931714a494b9e96eed18345b948",
      "output": [
        "Mitä vuosikymmeniä he tarkastelivat?"
      ]
    },
    {
      "input": "Ensimmäinen dataerä koostuu lumimyrskyihin, hurrikaaneihin ja maastopaloihin liittyvistä twiiteistä sillä rajoituksella, että niitä twiittaavat \"vaikutusvaltaiset\" twiittaajat, jotka määrittelemme henkilöiksi, joilla on varmasti luokiteltavissa oleva tunne kyseisestä aiheesta. Oletamme esimerkiksi, että kaikki Al Goren laatimat ilmastonmuutosta koskevat twiitit ovat positiivinen näyte, kun taas kaikki salaliittotili @ClimateHiJinxin twiitit ovat negatiivinen näyte. Seuraavissa menetelmissä tekemämme oletus (joka on vahvistettu kohtuulliseksi SECREF2 -jaksossa) on, että vaikutusvaltaisia twiittaajia voidaan käyttää twiittien merkitsemiseen massoittain, kun manuaalisesti merkittyjä twiittejä ei ole. ",
      "id": "task461-858df61cdb5b4e9dad9f86209bd3c658",
      "output": [
        "Millä menetelmällä kompensoidaan vähäiset merkityt tiedot?"
      ]
    },
    {
      "input": "Korpuskokeilujen perusteella saamme hyviä tuloksia SarcasmCorpus-korpuksella, joka on ainoa korpus, joka sisältää Amazonin arvosteluja. Valitettavasti, kun koulutamme mallejamme ristikkäiskorporaatiossa tai kaikissa korpuksissa, tuloksemme heikkenevät dramaattisesti, erityisesti ristikkäiskorporaatiossa. Nämä tulokset tarkoittavat, että SarcasmCorpusin sarkasmi välittyy sellaisten piirteiden kautta, joita ei ole muissa korpuksissa.",
      "id": "task461-a943b01ec59541a692b3e8a7446359e5",
      "output": [
        "Millä aloilla sarkasmia välitetään eri tavoin?"
      ]
    },
    {
      "input": "Kaikista kolmesta esiharjoittelutehtävästä SR toimii hieman paremmin kuin kaksi muuta tehtävää (NSG ja MDG).",
      "id": "task461-7a8a938864df472e9481a020fc566dfc",
      "output": [
        "Mikä kolmesta esivalmennustehtävästä on hyödyllisin?"
      ]
    },
    {
      "input": "Olemme keränneet tähän mennessä yli 3 934 610 miljoonaa twiittiä.",
      "id": "task461-3617924e61df4f01bccc65d990e46c5a",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "tietylle kysymykselle vastaamisen kannalta merkitykselliset tosiseikat) merkitään harjoittelun aikana.",
      "id": "task461-3954ceb23c0d48419d2d2370484eebd0",
      "output": [
        "Mitä tarkoittaa tosiasioiden valvonnan tukeminen?"
      ]
    },
    {
      "input": "Merkkijonojen ytimet ovat tapa käyttää tietoa merkkitasolla mittaamalla merkkijonojen samankaltaisuutta merkkien n-grammien avulla.",
      "id": "task461-f3cbde5929de4f189a736f032081cf05",
      "output": [
        "Mikä on merkkijonon ydin?"
      ]
    },
    {
      "input": "BioASQ-järjestäjät toimittavat koulutus- ja testausdatan. Harjoitusaineisto koostuu kysymyksistä, kultaisista standardidokumenteista, pätkistä, käsitteistä ja ideaalivastauksista (joita emme käyttäneet tässä asiakirjassa, mutta käytimme viime vuonna BIBREF2:ta). Testidata on jaettu vaiheisiin A ja B. Vaiheen A tietokokonaisuus koostuu kysymyksistä, yksilöllisistä tunnuksista ja kysymystyypeistä. Vaiheen B tietokokonaisuus koostuu kysymyksistä, kultaisista standardidokumenteista, pätkistä, yksilöllisistä tunnuksista ja kysymystyypeistä.",
      "id": "task461-3a2fe7695f60426b8e2ea7641bfb4db2",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": "Vuoteen 2015 verrattuna meidän QA-SRL-kultamme saatiin 1593 annotaatiota, joista 989 oli ydin- ja 604 liitetietoa, kun taas QA-SRL-kulta tuotti 1315 annotaatiota, 979 ydin- ja 336 liitetietoa. ",
      "id": "task461-298005acadba43e087d574ca1ccb8e61",
      "output": [
        "Kuinka suuri tietokokonaisuus on?",
        "Kuinka paljon suurempi kattavuus on uudessa tietokokonaisuudessa?"
      ]
    },
    {
      "input": "Käsittelemme pääasiassa kahta seuraavaa upotusavaruuden rakennetta.Semanttinen samankaltaisuusrakenne: Semanttisesti samankaltaiset entiteetit ovat lähellä toisiaan upotusavaruudessa ja päinvastoin. Semanttinen suuntarakenne: Upotusavaruudessa on semanttisia suuntia, joiden avulla vain yksi semanttinen aspekti muuttuu, kun taas kaikki muut aspektit pysyvät samoina. Se voidaan tunnistaa vektorierolla, kuten kahden upotusvektorin välisellä vähennyksellä.",
      "id": "task461-16675c16900d4905aa2107fd029b0838",
      "output": [
        "Mitkä ovat upotusavaruuden oudot semanttiset rakenteet?"
      ]
    },
    {
      "input": "Esimerkiksi kysymys ja apulause korreloivat keskenään, koska englannin kielen päälauseen kysymykset edellyttävät subjekti-aux-inversiota ja monissa tapauksissa apulauseen do (Do lions meow?) lisäämistä.  Ekspletiivit eli \"tyhjät\" argumentit ovat semanttisesti inerttejä argumentteja. Yleisimmät ekspletiivit englannissa ovat it ja there, vaikka kaikki näiden kohtien esiintymät eivät olekaan ekspletiivejä.",
      "id": "task461-685ab0e5da3a4df3a85683e944187f3f",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Taulukossa TABREF1 esitetään yhteenveto edellä mainittujen aiempien tutkimusten määrällisistä tuloksista. Taulukossa TABREF1 esitetään yhteenveto edellä mainittujen aiempien tutkimusten määrällisistä tuloksista.",
      "id": "task461-4fae2b4813294ccbb33c644c0bfe3f3c",
      "output": [
        "Mikä on uusimpien menetelmien ilmoittama tarkkuus?"
      ]
    },
    {
      "input": "Kaikki korporaatiot tarjoavat tietokokonaisuuksia/jakoja vastausten valintaa varten, kun taas vain (WikiQA, SQuAD) ja (WikiQA, SelQA) tarjoavat tietokokonaisuuksia vastausten poimimista ja vastausten käynnistämistä varten. SQuAD on kooltaan paljon suurempi, vaikka tämän korpuksen kysymykset ovat usein moninkertaisesti muotoiltuja. Päinvastoin, SQuADin keskimääräinen ehdokkaiden määrä kysymystä kohti ( INLINEFORM0 ) on pienin, koska SQuAD poimii vastausehdokkaat kappaleista, kun taas muut poimivat ne osioista tai tietolaatikoista, jotka koostuvat suuremmista yhteyksistä. Vaikka InfoboxQA on suurempi kuin WikiQA tai SelQA, InfoboxQA:n merkkityyppien määrä ( INLINEFORM1 ) on pienempi kuin näiden kahden, mikä johtuu infolaatikoiden toistuvasta luonteesta.Kaikkien korporaatioiden vastausehdokkaiden keskimääräiset pituudet ( INLINEFORM0 ) ovat samankaltaisia, paitsi InfoboxQA:ssa, jossa jokaista infolaatikon riviä pidetään ehdokkaana. SelQA:ssa ja SQuAD:ssa kysymysten keskimääräiset pituudet ( INLINEFORM1 ) ovat samankaltaisia, koska niiden merkintäjärjestelmät ovat samankaltaisia. Ei ole yllättävää, että WikiQA:n kysymysten keskimääräinen pituus on pienin, kun otetaan huomioon, että kysymykset on otettu hakukyselyistä. InfoboxQA:n keskimääräinen kysymyksen pituus on suhteellisen pieni, mikä johtuu siitä, että infoboxeista voidaan kysyä vain rajoitetusti tietoa. InfoboxQA:lla ja WikiQA:lla on vähiten kysymys-vastaus-sanojen päällekkäisyyksiä kysymyksissä ja vastauksissa ( INLINEFORM2 ja INLINEFORM3 taulukossa TABREF2 ). Päällekkäisten sanojen F1-pistemäärän ( INLINEFORM4 ) osalta SQuAD antaa vähiten päällekkäisyyksiä kysymys-vastaus -parien välillä, vaikka WikiQA on hyvin lähellä.",
      "id": "task461-683f322907ae45418bc0b7e98ed78e41",
      "output": [
        "Miten he analysoivat kontekstuaalisia samankaltaisuuksia eri tietokokonaisuuksien välillä?"
      ]
    },
    {
      "input": "Mallin kestävyyden arvioimiseksi laadimme testijoukon, joka koostuu \"vastakkaisista\" esimerkeistä eli häiriintyneistä esimerkeistä, jotka voivat mahdollisesti muuttaa perusmallin ennustetta. Tällaisia esimerkkejä voivat olla esimerkiksi lauseen parafraasointi, esimerkiksi leksikaaliset ja syntaktiset muutokset. Käytämme kahta kirjallisuudessa kuvattua lähestymistapaa: takaisinkääntämistä ja kohinaista sekvenssin automaattista kooderia. Huomattakoon, että nämä esimerkit muistuttavat mustan laatikon hyökkäyksiä, mutta niitä ei ole tarkoituksellisesti suunniteltu huijaamaan järjestelmää, ja siksi käytämme termiä \"vastahyökkäys\" laajasti. Käytämme näitä tekniikoita tuottaaksemme monia parafraaseja ja löydämme osajoukon lausumia, jotka ovat hyvin samankaltaisia kuin alkuperäinen testisarja, mutta joiden ennusteet ovat vääriä. Mittaamme mallin kestävyyttä tällaisia muutoksia vastaan.",
      "id": "task461-52cd1cec453245eb82e1b44f7208d9fe",
      "output": [
        "Miten kirjoittajat luovat vastakohtaisen testijoukon mallin kestävyyden mittaamiseksi?"
      ]
    },
    {
      "input": "CFQ sisältää suuruusluokaltaan eniten kyselymalleja ja myös huomattavasti enemmän kyselyitä ja kysymyksiä kuin muut tietokokonaisuudet. ",
      "id": "task461-9eb3d4f0e2c5464c9659db0ad4dbe819",
      "output": [
        "Miten kirjoittajat perustelevat, että esitetty kysymysvastaustietokanta on realistinen?"
      ]
    },
    {
      "input": "Arvioimme malliamme ja perusmalleja kolmella versiolla aineistosta. The first one (Inc) only considers the original data, containing naturally incorrect tweets, and achieves accuracy of 80$\\%$ against BERT's 72$\\%$. Toisessa versiossa (Corr) otetaan huomioon korjatut twiitit, ja sen tarkkuus on suurempi, koska se on vähemmän kohinainen. ",
      "id": "task461-1ad9cba23e40408c92e30b6bcc9d9742",
      "output": [
        "Pitäisikö heidän lähestymistapaansa soveltaa vain silloin, kun on kyse epätäydellisistä tiedoista?"
      ]
    },
    {
      "input": "SG-mallin keskimääräinen samankaltaisuuspistemäärä oli korkea, 0,650, ja seuraavaksi korkein oli CBoW, jonka keskimääräinen samankaltaisuuspistemäärä oli 0,632. Myös GloVe saavutti huomattavan keskimääräisen pistemäärän 0,591. SdfastTextin keskimääräinen samankaltaisuuspistemäärä on kuitenkin 0,388, ja sanaparia Microsoft-Bill Gates ei löydy SdfastTextin sanastosta. Lisäksi taulukossa TABREF78 on esitetty maiden ja niiden pääkaupunkien semanttisen sukulaisuuden keskimääräinen samankaltaisuuspistemäärä englanninkielisen käännöksen kanssa, jossa SG:n keskimääräinen pistemäärä on myös paras, 0,663, ja sen jälkeen CBoW:n pistemäärä on 0,611. GloVe tuottaa myös paremman semanttisen samankaltaisuuden (0,576) ja SdfastTextin (0,391).",
      "id": "task461-1dd5ae40c5b04268bd15457367e919d6",
      "output": [
        "Miten ehdotetut sanojen upotukset vertautuvat Sindhi fastText -sanojen esityksiin?"
      ]
    },
    {
      "input": "Kullekin kieliparille tarkastellaan kahta eri mallia: perusmallia ja asiakirjamallia. Arvioimme niitä kolmella testijoukolla ja raportoimme BLEU- ja TER-pisteet. Kaikki kokeet suoritetaan 8 kertaa eri siemenillä, ja raportoimme kunkin kokeen keskiarvotulokset ja p-arvot.",
      "id": "task461-2d13af9949dc43d2aa8db8761e5b47c9",
      "output": [
        "Mitä arviointimittareita he käyttivät?"
      ]
    },
    {
      "input": "Keräsimme Simple English Wikipediasta vapaasti saatavilla olevan yksinkertaistetun aineiston, jota on aiemmin käytetty monissa tekstin yksinkertaistamismenetelmissä BIBREF0 , BIBREF10 , BIBREF3 .",
      "id": "task461-d61c814ca94d42b494867dde3e6a6429",
      "output": [
        "Mihin kieleen tässä asiakirjassa keskitytään?"
      ]
    },
    {
      "input": "Luomme uuden manuaalisesti annotoidun multimodaalisen vihapuheaineiston, joka koostuu 150 000 dollarin twiiteistä, joista jokainen sisältää tekstiä ja kuvan. ",
      "id": "task461-73cb5c93012f4145830d1e46681121a0",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "Kolme annotoijaa, A1-A3, merkitsevät jokaisen datasetin H twiitin humalaiseksi tai selväksi.",
      "id": "task461-a367672317cd484a939f6fef307fb5a4",
      "output": [
        "Tarkistetaanko kaukovalvonnassa hankitut tiedot jossain vaiheessa ihmisten toimesta?"
      ]
    },
    {
      "input": "Ehdotetun menetelmän suorituskyvyn arvioimiseksi NLI-tehtävässä käytetään SNLI BIBREF22- ja MultiNLI BIBREF23 -tietoaineistoja. Käytämme Quora Question Pairs -tietokokonaisuutta BIBREF24 arvioidessamme menetelmämme suorituskykyä PI-tehtävässä. Tunteiden luokittelun suorituskyvyn arvioinnissa käytetään Stanford Sentiment Treebank (SST) BIBREF25 -tietokantaa.",
      "id": "task461-4367f1254cf8475aa4f99d3af1509ac5",
      "output": [
        "Mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Tämän jälkeen lasketaan käsitteiden upotukset (GloVe) erikseen haastattelukuvauksille ja tutkintokuvauksille. Yksinkertaisin tapa tuottaa tekstin upotuksia termien upotusten perusteella on käyttää jonkinlaista termien upotusten aggregaatiota, kuten keskiarvoa. Tätä lähestymistapaa testattiin esimerkiksi BIBREF21:ssä ja BIBREF13:ssa. BIBREF22 laski termien upotusten painotetun keskiarvon rakentamalla häviöfunktion ja harjoittelemalla painotukset gradienttilaskeutumismenetelmällä.Käyntien lopulliset upotukset saadaan yhdistämällä erikseen haastattelulle ja lääkärintarkastukselle lasketut keskimääräiset upotukset, ks. kuva KUVA FIGREF4 .",
      "id": "task461-e9015a860c564731be482e084eb937c1",
      "output": [
        "Millaisia sanasulkeumia he käyttävät edustamaan lääkärikäyntejä?"
      ]
    },
    {
      "input": "Tämän huomioimiseksi laskemme tasapainotetun tarkkuuden eli kunkin luokan kolmen tarkkuuden keskiarvon.",
      "id": "task461-d36e3fa3f73a4b25863f39da37de16f4",
      "output": [
        "Arvioidaanko mallin selityksen tulosta, mitä mittaria käytettiin?"
      ]
    },
    {
      "input": "Kun ennustetaan vihaa, iloa tai valenssia, niiden järjestelmien määrä, jotka johdonmukaisesti antavat korkeammat pisteet lauseille, joissa on naispuolisia substantiivilausekkeita (21-25), on selvästi suurempi kuin niiden järjestelmien määrä, jotka antavat korkeammat pisteet lauseille, joissa on miespuolisia substantiivilausekkeita (8-13). (Muistutettakoon, että korkeampi valenssi tarkoittaa positiivisempaa tunnetta.) Sitä vastoin pelkotehtävässä useimmat järjestelmät antoivat korkeammat pisteet lauseille, joissa oli miespuolisia substantiivilausekkeita (23), verrattuna niiden järjestelmien määrään, jotka antoivat korkeammat pisteet lauseille, joissa oli naispuolisia substantiivilausekkeita (12). Surua ennustettaessa niiden järjestelmien määrä, jotka antoivat korkeammat pisteet naispuolisten substantiivilauseiden lauseille (18), on lähellä niiden järjestelmien määrää, jotka antoivat korkeammat pisteet miespuolisten substantiivilauseiden lauseille (16). Nämä tulokset ovat linjassa joidenkin yleisten stereotypioiden kanssa, kuten että naiset ovat tunteikkaampia ja tilanteet, joissa miespuoliset toimijat ovat mukana, ovat pelokkaampia BIBREF27 Suurin osa järjestelmistä antoi korkeammat pisteet lauseille, joissa oli afroamerikkalaisia nimiä, vihaa, pelkoa ja surua ennustettaessa. Iloa ja valenssia koskevissa tehtävissä useimmat järjestelmät antoivat korkeammat pisteet lauseille, joissa oli eurooppalaisamerikkalaisia nimiä. Nämä suuntaukset heijastavat joitakin yleisiä stereotypioita, joiden mukaan afroamerikkalaiset liitetään kielteisempiin tunteisiin BIBREF28 .",
      "id": "task461-6d97293a5c464b12b27cbf83d6154d96",
      "output": [
        "Mikä rotu ja sukupuoli saavat korkeamman tunteen voimakkuusennusteen?"
      ]
    },
    {
      "input": "Rinnakkainen skannauksen päättelySemiring-algoritmien kommutatiiviset ominaisuudet mahdollistavat joustavuuden siinä järjestyksessä, jossa laskemme $A(\\ell )$. Dynaamisen ohjelmoinnin algoritmien tyypilliset toteutukset ovat järjestyksen pituuden suhteen sarjamuotoisia. Vektoroitu jäsennysLaskennan monimutkaisuus on vielä suurempi ongelma jäsennysalgoritmeille, joita ei voi yhtä helposti rinnakkaistaa. Semiring-matriisioperaatiotKaksi edellistä optimointia vähentävät suurimman osan semiring-matriisikertolaskennan kustannuksista. Erityistapauksessa $(\\sum , \\times )$ semiringin tapauksessa nämä voidaan laskea erittäin tehokkaasti käyttämällä matriisikertolaskentaa, joka on hyvin viritetty GPU-laitteistoon. Valitettavasti muiden semiringien, kuten login ja maxin, tapauksessa nämä operaatiot ovat joko hitaita tai hyvin muistitehottomia. Esimerkiksi matriiseille $T$ ja $U$, joiden koko on $N \\times M$ ja $M \\times O$, voimme lähettää $\\otimes $:lla tensorin, jonka koko on $N \\times M \\times O$, ja sitten pienentää dim $M$:n $\\bigoplus $:lla, mikä maksaa valtavasti muistia.",
      "id": "task461-d5cf9ce98f0a46f9941330f0f77949ae",
      "output": [
        "Mitä lähtötasoja kokeissa käytetään?"
      ]
    },
    {
      "input": "Kutsumme tätä elinikäiseksi vuorovaikutteiseksi oppimiseksi ja päättelyksi (LiLi). Elinikäinen oppiminen näkyy siinä, että äskettäin hankitut tiedot säilytetään tietovarastossa ja niitä käytetään tulevien kyselyjen päättelyssä ja että päivitetyn tietovaraston lisäksi kertynyttä tietoa, mukaan lukien aiemmat päättelytulokset, hyödynnetään tulevan vuorovaikutuksen ja oppimisen ohjaamisessa.",
      "id": "task461-b5b247bf8f874c189dc20afb400c43fc",
      "output": [
        "Millä tavoin LiLi jäljittelee sitä, miten ihmiset hankkivat tietoa ja tekevät päätelmiä vuorovaikutteisen keskustelun aikana?"
      ]
    },
    {
      "input": "Tavoitteenamme on irrottaa sisällön valinta dekooderista ottamalla käyttöön ylimääräinen sisällönvalitsin. Intuitiivisin tapa on kouluttaa sisällönvalitsin kohdentamaan jotakin heuristisesti poimittua sisältöä. Voimme esimerkiksi kouluttaa valitsijan valitsemaan päällekkäiset sanat lähteen ja kohteen välillä BIBREF6 , lauseet, joilla on korkeampi tf-idf-pistemäärä BIBREF20 , tai tunnistetut kuvakohteet, jotka esiintyvät kuvatekstissä BIBREF21 . INLINEFORM0 latenttina muuttujana: Toinen tapa on käsitellä INLINEFORM1:tä latenttina muuttujana ja kouluttaa valitsija ja generaattori yhdessä maksimoimalla marginaalisen datan todennäköisyys. Tällä tavoin valitsijalla on mahdollisuus tutkia automaattisesti optimaalisia valintastrategioita, jotka sopivat parhaiten vastaavaan generaattorikomponenttiin. Reinforce-select (RS) BIBREF24 , BIBREF9 käyttää vahvistusoppimista marginaalisen todennäköisyyden lähentämiseen. Ehdotamme Variational Reinforce-Select (VRS) -menetelmää, jossa sovelletaan variationaalista päättelyä BIBREF10 varianssin vähentämiseksi.",
      "id": "task461-2c589030862e46da8c861b3151149717",
      "output": [
        "Miten malli koulutetaan tekemään vain sisällön valinta?"
      ]
    },
    {
      "input": "Luokittelijoita arvioitaessa käytetään yleisesti tarkkuutta, täsmällisyyttä ja palautusta sekä Hammingin häviötä.  On osoitettu, että laskettaessa tarkkuutta ja palautusta monimerkkiluokittelijoille voi olla edullista käyttää mikrokeskiarvoista tarkkuutta ja palautusta BIBREF6 . Mikrokeskiarvoistetun tarkkuuden kaavat ovat seuraavat: DISPLAYFORM0 DISPLAYFORM1",
      "id": "task461-f26f2500ca474d5884bc6b048ca59652",
      "output": [
        "mitä arviointimittareita käsitellään?"
      ]
    },
    {
      "input": "Yksikielisestä mallista tehdään kopiot kutakin kieltä varten ja lisätään kieltenvälisiä latentteja muuttujia (CLV) yksikielisten mallien yhdistämiseksi, jolloin ne kuvaavat kieltenvälisiä semanttisia roolimalleja. Konkreettisesti, kun harjoitellaan rinnakkaisia lauseita, aina kun argumenttien pääsanat ovat samansuuntaisia, lisäämme CLV:n kahden vastaavan roolimuuttujan vanhemmaksi.",
      "id": "task461-edab51fc2bbf4814bae3768d2d8128a4",
      "output": [
        "Lisäävätkö he Bayesin malliin yhden latentin muuttujan kutakin kieliparia varten?"
      ]
    },
    {
      "input": "Olemme samoilla linjoilla kuin äskettäisessä BIBREF-työssä16 , jossa ehdotetaan arvioinnin siirtämistä absoluuttisista arvoista tutkivampiin arviointeihin, joissa keskitytään sulautumien heikkouksiin ja vahvuuksiin eikä niinkään yleisiin pisteytyksiin. Yksi mittari voisi esimerkiksi olla sen tarkistaminen, ovatko kaikki sanat, joiden tiedetään kuuluvan samaan luokkaan, lähempänä toisiaan kuin eri luokkiin kuuluvat sanat, riippumatta todellisesta kosinuksesta.",
      "id": "task461-8fb54aa197c44a82bf5c03caa06d978f",
      "output": [
        "Mitä uusia mittareita ehdotetaan edistymisen seuraamiseksi?"
      ]
    },
    {
      "input": "Visual Question Generation (VQG) on toinen nouseva aihealue, jossa pyritään esittämään kysymyksiä kuvan perusteella. BIBREF10 ehdotti tämän innoittamana avointa VQG:tä, jonka tarkoituksena on luoda luonnollisia ja kiinnostavia kysymyksiä kuvasta.",
      "id": "task461-3c781dd3c461403a82573f0b0c5c3171",
      "output": [
        "Tekevätkö he kyselytutkimuksen visuaalisen kysymyksenasettelun?"
      ]
    },
    {
      "input": "Tutkijat ovat kiinnittäneet yhä enemmän huomiota emojien laajamittaiseen käyttöön BIBREF4 , BIBREF5 , koska emojit välittävät hedelmällistä semanttista ja tunnepohjaista tietoa täydentämään visuaalisesti tekstimuotoista tietoa, mikä on erittäin hyödyllistä tekstiin sisältyvien tunnesignaalien ymmärtämisessä BIBREF6 . Aiemmassa kirjallisuudessa ei kuitenkaan ole otettu huomioon emojien kielellistä monimutkaisuutta ja monimuotoisuutta. Tämän vuoksi aiemmat emojien upotusmenetelmät eivät pysty käsittelemään tilannetta, jossa opittujen emojien upotusten semantiikka tai tunteet ovat ristiriidassa vastaavista yhteyksistä saatavan tiedon kanssa BIBREF5 , tai kun emojit välittävät useita semanttisia ja tunnetason merkityksiä, kuten ( ja ). Käytännössä emojit voivat joko tiivistää ja korostaa kontekstiensa alkuperäistä sävyä tai ilmaista monimutkaisempaa semantiikkaa, kuten ironiaa ja sarkasmia, yhdistämällä ne konteksteihin, joiden semantiikka tai tunteet ovat ristiriitaisia. Perinteinen emoji-analyysi voi poimia kustakin emojista vain yhden upotuksen, ja tällaiset upotukset hämmentävät seuraavaa tunneanalyysimallia, koska syötetekstien ja emojien tunnesignaalit ovat epäjohdonmukaisia.",
      "id": "task461-b28f4d6c74894d0bba9dc3f9d4673288",
      "output": [
        "Mikä on motivaatio bi-sense embedding -koulutukselle?"
      ]
    },
    {
      "input": "Tulosten analysoimiseksi päätimme käyttää BIBREF10:n tarjoamaa testiä, joka koostuu 19 eri luokkaan jaetuista 19 791 $ analogioista: (8915 analogiaa) ja 13 \"syntaktiseen\" makroalueeseen (10876 analogiaa). Kaikki analogiat koostuvat kahdesta sanaparista, joilla on yhteinen suhde, joka on kaavamaisesti ilmaistu yhtälöllä: $a:a^{*}=b:b^{*}$ (esim. \"mies : nainen = kuningas : kuningatar\"); missä $b^{*}$ on arvottava sana (\"kuningatar\"), $b$ on siihen kytketty sana (\"kuningas\"), $a$ on poistettavien komponenttien sana (\"mies\") ja $a^{*}$ on lisättävien komponenttien sana (\"nainen\").",
      "id": "task461-816078c0df6a4c9e903d53f9d280fe02",
      "output": [
        "Testataanko sanasulkeumia NLP-tehtävässä?"
      ]
    },
    {
      "input": "Oikeudenmukaisen vertailun varmistamiseksi koulutimme kutakin mallia samalla 10 miljoonan lauseen korpuksella, joka oli kerätty Wikipediasta.",
      "id": "task461-7a8d311907af4bdf98d6e866ef0fcef1",
      "output": [
        "Millä aineistolla (aineistoilla) he laskevat sanojen upotukset?"
      ]
    },
    {
      "input": "Strategiapohjaiset menetelmät poikkeavat esivalmennusvaiheesta ja pyrkivät hyödyntämään esivalmennettuja malleja kohdetehtävän oppimisprosessin aikana. Näihin lähestymistapoihin kuuluvat hienosäätöaikataulut, joissa oppimisnopeuden ohjausta suunnitellaan tarkkaan optimointia varten, sijaistehtävät, joissa käytetään merkittyjä tietoja, jotta esivalmennettu malli sopisi paremmin kohdetiedon jakaumaan, ja tiedon tislausta koskevat lähestymistavat, joissa luovutaan esivalmistettujen parametrien avulla tapahtuvasta alustamisesta omaksumalla esivalmennettu malli opettajaverkoksi.",
      "id": "task461-72be8941e6b44161a7342de23b16063b",
      "output": [
        "Miten strategiapohjaiset menetelmät käsittelevät NLG:n esteitä?"
      ]
    },
    {
      "input": "Sekä POS-taggausta että riippuvuuksien jäsentämistä varten suoritamme kokeita Penn Treebankin Wall Street Journal (WSJ) -osuudella.",
      "id": "task461-7fa5a053405244828e1a868e939401ce",
      "output": [
        "Arvioidaanko ne vain englanninkielisillä tietokokonaisuuksilla?",
        "Millaisia tietokokonaisuuksia he arvioivat?"
      ]
    },
    {
      "input": "Seuraavaksi tarkastelemme seuraavaa ongelmaa: kun on annettu kaksi BabelNet-luokkaa $A$ ja $B$, ennustetaan, ovatko ne todennäköisesti käsitteellisiä naapureita niiden tekstikorpuksen lauseiden perusteella, joissa ne molemmat mainitaan. Tällaisen luokittelijan kouluttamiseksi käytämme harjoitusdatana SECREF8-jaksosta saatuja etävalvontalappuja. Kun tämä luokittelija on koulutettu, voimme käyttää sitä ennustamaan sellaisten luokkien käsitteellistä naapuruutta, joista tiedetään vain vähän tapauksia. Löytääksemme lauseet, joissa sekä $A$ että $B$ mainitaan, käytämme yksiselitteistä tekstikorpusta, jossa BabelNet-kategorioiden maininnat on nimenomaisesti merkitty. Tällainen yksiselitteinen korpus voidaan rakentaa automaattisesti esimerkiksi BIBREF30 mancini-etal-2017-embeddingin ehdottamien menetelmien kaltaisilla menetelmillä. Jokaisen ehdokasluokkaparin osalta haemme siis kaikki lauseet, joissa ne esiintyvät yhdessä. Seuraavaksi esitämme jokaisen poimitun lauseen vektorina. ",
      "id": "task461-ddc4d1eda1084dd0b082b4f2c15ff88c",
      "output": [
        "Miten he tunnistavat käsitteelliset naapurit?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF46 käy ilmi, konsensusfuusio parantaa NDCG:n pistemäärää noin 1,0:lla yhteisen mallin pistemäärään verrattuna, mutta antaa silti vertailukelpoiset pisteet muille mittareille. Kuten taulukosta TABREF46 käy ilmi, ensemble-malli näyttää ottavan parhaat tulokset kustakin mallista.",
      "id": "task461-b886398ce0854c5ca0e4333cde1241fb",
      "output": [
        "Kumpi integraatiomenetelmä toimii paremmin ensemble- tai konsensusfuusio jaetuilla parametreilla?"
      ]
    },
    {
      "input": "Käytimme annotaatioiden tekemiseen Amazon Mechanical Turk (AMT) -palvelua ja rajasimme tehtävän koskemaan työntekijöitä viidessä englanninkielisessä maassa (Yhdysvallat, Yhdistynyt kuningaskunta, Kanada, Uusi-Seelanti ja Australia), joilla oli yli 1000 valmista HIT:tä ja vähintään 95 prosentin hyväksymisprosentti.",
      "id": "task461-ac5750311b7e465caf2d999814db6678",
      "output": [
        "Mitä joukkoistamisalustaa he käyttivät?"
      ]
    },
    {
      "input": "Ennustustehtävämme on siis suoraviivainen sanatason binääriluokittelutehtävä. Kehitämme seuraavat viisi piirreryhmää, jotka kuvaavat ominaisuuksia, jotka liittyvät siihen, miten sanaa käytetään selityksessä (ks. taulukko TABREF18 täydellisen luettelon osalta):[itemsep=0pt,leftmargin=*,topsep=0pt]Sanan kontekstittomat ominaisuudet. Nämä ominaisuudet johdetaan suoraan sanasta, ja ne kuvaavat yleistä taipumusta siihen, että sana kaikuu selityksissä. sanan käyttö OP:ssa tai PC:ssä (kaksi ryhmää). Nämä piirteet kuvaavat sitä, miten sanaa käytetään OP:ssa tai PC:ssä. Näin ollen jokaiselle piirteelle on kaksi arvoa OP:lle ja PC:lle.Miten sana yhdistää OP:n ja PC:n. Nämä piirteet tarkastelevat sanan käytön eroa OP:ssa ja PC:ssä. Odotamme, että tämä ryhmä on tehtävämme kannalta tärkein. yleiset OP/PC-ominaisuudet. Nämä piirteet kuvaavat keskustelun yleisiä ominaisuuksia. Niitä voidaan käyttää luonnehtimaan kaikujen taustajakaumaa.Taulukossa TABREF18 esitetään lisäksi intuitio kunkin ominaisuuden sisällyttämiselle ja tiivistetyt $t$-testitulokset Bonferroni-korjauksen jälkeen. Erityisesti testataan, onko selityksissä kaikuuntuneilla sanoilla erilaiset ominaisuusarvot kuin niillä sanoilla, joita ei kaikuuntunut. Kaikkien sanojen tarkastelun lisäksi tarkastelemme myös erikseen stop-sanoja ja sisällön sanoja kuvion FIGREF8 valossa. Korostamme tässä muutamia havaintoja:[itemsep=0pt,leftmargin=*,topsep=0pt]Vaikka odotamme, että monimutkaisempia sanoja (#merkkejä) kaikuisi useammin, näin ei kuitenkaan keskimäärin ole. Havaitsemme myös mielenkiintoisen esimerkin Simpsonin paradoksista Wordnetin syvyyttä BIBREF38 koskevissa tuloksissa: matalammat sanat kaikuvat todennäköisemmin kaikissa sanoissa, mutta syvemmät sanat kaikuvat todennäköisemmin sisältö- ja stop-sanoissa.",
      "id": "task461-4e03f57d51dc46d49dc8ba4294ae33ca",
      "output": [
        "Mitä ominaisuuksia ehdotetaan?"
      ]
    },
    {
      "input": "Sen sijaan analyysimme paljastaa, että tämä käyttäytyminen johtuu käännösprosessista itsestään johtuvista hienovaraisista artefakteista. Erityisesti osoitamme, että kunkin instanssin eri osien kääntäminen erikseen (esim. premissi ja hypoteesi NLI:ssä) voi muuttaa aineiston pinnallisia malleja (esim. niiden välisen leksikaalisen päällekkäisyyden astetta), mikä vaikuttaa vakavasti nykyisten mallien yleistämiskykyyn. Saatujen oivallusten perusteella parannamme XNLI:n nykytilaa ja osoitamme, että joitakin aiempia havaintoja on harkittava uudelleen tämän ilmiön valossa. Vertailuanalyysi koostuu pätevyystestistä, jossa arvioidaan kykyä ymmärtää antonyymisuhde ja suorittaa numeerista päättelyä, häiriötestistä, jossa arvioidaan kestävyyttä matalien mallien, kuten leksikaalisen päällekkäisyyden ja kieltosanojen esiintymisen, suhteen, ja kohinatestistä, jossa arvioidaan kestävyyttä kirjoitusvirheiden suhteen. Aiempien kokeiden tapaan raportoimme tulokset kunkin testisarjan parhaasta epookin tarkistuspisteestä.",
      "id": "task461-6f349c65c69548529bc32d79ef8b71f8",
      "output": [
        "Mitkä ovat esimerkkejä näistä keinotekoisista toimista?"
      ]
    },
    {
      "input": "Kokeissamme babidatasetissa ehdotetut Memory Neural Networks (MemNNs) toimivat perustasona.",
      "id": "task461-297f6c5285424feebc22da83366115b6",
      "output": [
        "Mitä sanatason ja merkkitason mallien perustasoja käytetään?"
      ]
    },
    {
      "input": "Verrattaessa yhtälöä DISPLAY_FORM14 yhtälöön DISPLAY_FORM22 voidaan havaita, että yhtälö DISPLAY_FORM14 on itse asiassa $F1$:n pehmeä muoto, jossa käytetään jatkuvaa $p$:tä binäärisen $\\mathbb {I}( p_{i1}>0.5)$:n sijasta. Tämä ero ei ole suuri ongelma tasapainoisissa aineistoissa, mutta se on erittäin haitallinen, jos suuri osa harjoitusesimerkkejä on helposti negatiivisia: helposti negatiiviset esimerkit voivat helposti hallita harjoittelua, koska niiden todennäköisyydet voidaan melko helposti painaa nollaan. Samaan aikaan malli tuskin pystyy erottamaan vaikeasti negatiivisia esimerkkejä positiivisista, millä on valtava negatiivinen vaikutus lopulliseen F1-suorituskykyyn.Tämän ongelman ratkaisemiseksi ehdotamme, että pehmeä todennäköisyys $p$ kerrotaan pienenevällä kertoimella $(1-p)$, jolloin yhtälö DISPLAY_FORM22 muuttuu seuraavaan muotoon: Voidaan ajatella, että $(1-p_{i1})$ on kuhunkin esimerkkiin liitetty painoarvo, joka muuttuu harjoittelun edetessä. Kun $p_{i1}$ muutetaan $(1-p_{i1}) p_{i1}$:ksi, tarkoituksena on alentaa helppojen esimerkkien painoa. Helppojen esimerkkien, joiden todennäköisyys lähestyy 0:a tai 1:tä, $(1-p_{i1}) p_{i1}$ saa mallin painottamaan niitä huomattavasti vähemmän. Kuvassa KUVA23 annetaan selitys derivaatan näkökulmasta: $\\frac{(1-p)p}{1+(1-p)p}$:n derivaatta $p$:n suhteen lähestyy 0:aa heti, kun $p$ lähestyy 0:aa, mikä tarkoittaa, että malli kiinnittää vähemmän huomiota esimerkkeihin sen jälkeen, kun ne on luokiteltu oikein.Yhtälön Eq.DISPLAY_MUOTO14 tarkempi tarkastelu paljastaa, että se itse asiassa jäljittelee ajatusta fokusmenetyksestä (focal loss, lyhyesti FL) BIBREF16 kohteiden havaitsemisessa näkökentässä. Fokaalihäviötä ehdotettiin yksivaiheista objektinilmaisinta varten, jotta voidaan käsitellä harjoittelun aikana esiintyvää etualan ja taustan välistä kompromissia. Se pienentää hyvin luokitelluille esimerkeille määritettyä tappiota lisäämällä $(1-p)^{\\beta }$-kertoimen, jolloin lopullinen tappio on $(1-p)^{\\beta }\\log p$.",
      "id": "task461-59c4c18199d0438290239f26cf1ea8e2",
      "output": [
        "Miten painotuksia säädetään dynaamisesti?"
      ]
    },
    {
      "input": "Suoritamme myös manuaalisen arvioinnin, joka osoittaa En-It-tehtävän kohdalla lievää laadun heikkenemistä, minkä vastineeksi keskimääräinen pituussuhde pienenee tilastollisesti merkittävästi, 1,05:stä 1,01:een.",
      "id": "task461-4795e77518174ffd9ef0a67941aa9290",
      "output": [
        "Suorittavatko he minkäänlaista ihmisarviointia?"
      ]
    },
    {
      "input": "MSA:n osalta hankimme diakritisoidun korpuksen, jota käytettiin RDI BIBREF7 -diakritisaattorin ja Farasa BIBREF31 -diakritisaattorin kouluttamiseen. Korpus sisältää 9,7 miljoonaa merkkiä, joissa on noin 194 000 ainutlaatuista pintamuotoa (lukuun ottamatta numeroita ja välimerkkejä). Testaukseen käytimme vapaasti saatavilla olevaa WikiNews-testijoukkoa BIBREF31, joka koostuu 70 MSA WikiNews-artikkelista (18 300 tokenia) ja kattaa tasaisesti eri genrejä, kuten politiikka, talous, terveys, tiede ja teknologia, urheilu, taide ja kulttuuri. CA:ta varten saimme kirjankustantajalta suuren kokoelman täysin diakritisoituja klassisia tekstejä (2,7 miljoonaa merkkiä), ja pidimme testausta varten poissa pienen 5 000 lauseen (noin 400 000 sanaa) osajoukon.",
      "id": "task461-197260b5183045568daa4b2bd8c7be23",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Sanakohdistusten lisääminen rinnakkaisiin lauseisiin johtaa pieniin, ei merkittäviin parannuksiin, vaikka lähdekielestä olisi saatavilla jonkin verran merkittyä tietoa. Tämä vaikeus osoittaa rinnakkaisten korpusten hyödyllisyys SRI:n kannalta voi johtua nykyisistä oletuksista, jotka koskevat roolien kohdistuksia ja joiden mukaan vain pieni osa rooleista on kohdistettu. Lisäanalyysit paljastavat, että pienten tietomäärien merkitsemisellä voidaan helposti saavuttaa parempi suorituskyky kuin lisäämällä suuria merkitsemättömiä tietokokonaisuuksia ja rinnakkaisia korpuksia.",
      "id": "task461-c8c65da42182465586e69b819610da25",
      "output": [
        "Parantaako rinnakkainen data kaiken kaikkiaan semanttisten roolien induktiota useilla kielillä?"
      ]
    },
    {
      "input": "Koulutus ja testaus suoritetaan vuorotellen: Kussakin epookissa LSTM-verkolle esitetään koulutusta varten ensin 1000 näytettä tietyllä kielellä, jotka on luotu tietyn diskreetin todennäköisyysjakauman mukaan, joka on tuettu suljetulle äärelliselle aikavälille. Tämän jälkeen jäädytämme kaikki painot mallissamme, luettelemme tyhjentävästi kaikki kielen jaksot niiden pituuksien mukaan ja määrittelemme ensimmäiset $k$ lyhimmät jaksot, joiden tulosteet malli tuottaa epätarkasti. kokeilimme 1, 2, 3 ja 36 piilotettua yksikköä $a^n b^n$:lle; 2, 3, 4 ja 36 piilotettua yksikköä $a^n b^n c^n$:lle; ja 3, 4, 5 ja 36 piilotettua yksikköä $a^n b^n c^n d^n$:lle.  BIBREF7 , BIBREF12 , BIBREF9 ja monissa muissa tutkimuksissa omaksutun perinteisen lähestymistavan mukaisesti koulutamme neuroverkkomme seuraavasti. Kullakin ajanhetkellä esitämme mallillemme yhden syötemerkin ja pyydämme sitä sitten ennustamaan seuraavien mahdollisten merkkien joukon nykyisen merkin ja aiempien piilotettujen tilojen perusteella. Koska sanasto $\\mathcal {V}^{(i)}$ on kooltaan $d$ , käytämme yhden pisteen esitystä tuloarvojen koodaamiseen; näin ollen kaikki tulovektorit ovat $d$ -ulotteisia binäärivektoreita. Lähtöarvot ovat kuitenkin $(d+1)$ -ulotteisia, koska ne voivat sisältää $\\mathcal {V}^{(i)}$ -symbolien lisäksi lopetussymbolin $\\dashv $ . Lähtöarvoja ei aina koodata yhden kuuman esityksen avulla, koska sarjan seuraavalle merkille voi olla useita vaihtoehtoja, joten käytämme sen sijaan $k$ -kuuman esityksen lähtöarvojen koodaamiseen. Tavoitteenamme on minimoida sekvenssiennusteiden keskimääräinen neliövirhe (MSE).",
      "id": "task461-cebdcf77d58347fc88b54e345b813416",
      "output": [
        "Mitä koulutusasetuksia he kokeilivat?"
      ]
    },
    {
      "input": "Työn lisäsovelluksena olemme toteuttaneet valvotun luokittelutehtävän, jonka tarkoituksena on ennustaa vaaratapahtuman vahingollisuuden aste suoraan tekstin ja käsin koodattujen ominaisuuksien (esim. ulkoinen luokka, lääketieteen erikoisala, sijainti) perusteella.  Tarkistimme myös, voiko valvomattoman sisällönohjautuvan klusterimerkintämme käyttäminen lisäominaisuuksina parantaa valvotun luokittelun suorituskykyä.",
      "id": "task461-e91a39e8de334524a5f8c4478d86d543",
      "output": [
        "Miten sisällön klustereita käytetään parantamaan vaaratilanteiden vakavuuden ennustamista?"
      ]
    },
    {
      "input": "Rakennamme docqan julkisesti saatavilla olevan huipputason kysymysten vastausjärjestelmän varaan. Järjestelmä laajentaa BiDAF BIBREF4:ää itsetarkkailulla ja suoriutuu hyvin asiakirjatason laadunvarmistuksesta. ",
      "id": "task461-5953e77f0a5e417d9c4cf01b083d2673",
      "output": [
        "Mikä on kysymysten vastausalgoritmi?"
      ]
    },
    {
      "input": " Jaksossa SECREF16 kerromme ensin tarkemmin noudattamastamme koeasetelmasta.  Kuten kohdassa SECREF3 selitetään, käytimme BabelNet BIBREF29 -vertailutaksonomiaa. BabelNet on laajamittainen täysimittainen taksonomia, joka koostuu heterogeenisistä lähteistä, kuten WordNet BIBREF36, Wikidata BIBREF37 ja WiBi BIBREF38 , joten se soveltuu hypoteesimme testaamiseen yleisessä ympäristössä.  Testataksemme ehdotettua luokkainduktiomallia tarkastelemme kaikkia BabelNetin luokkia, joissa on alle 50 tunnettua tapausta. Tämä johtuu siitä, että käsitteellinen naapuruus on hyödyllinen lähinnä tapauksissa, joissa tunnettujen tapausten määrä on pieni. Kunkin kategorian osalta jaamme tunnettujen tapausten joukon 90 prosenttiin harjoittelua ja 10 prosenttiin testausta varten. Näiden luokkien ennakkotodennäköisyyden $\\lambda _A$ virittämiseksi pidämme 10 prosenttia koulutusjoukosta validointijoukkona.",
      "id": "task461-3d2960ee6c3048c5bade3c2e8ecb1776",
      "output": [
        "Mitä kokeita he tekevät osoittaakseen, että heidän lähestymistapansa johtaa tarkempiin aluepohjaisiin esityksiin?"
      ]
    },
    {
      "input": "Taulukon TABREF13 tuloksissa on kymmenen koetinta. ELMo-transformerin ja mSynC:n suorituskyky on jälleen samankaltainen, mutta mSynC suoriutuu hieman huonommin seitsemästä yhdeksästä tehtävästä. Odotetusti mSynC saavuttaa kappaletunnisteiden ennustamista koskevassa tehtävässä 96,9 $F_1$ ja ELMo-transformer 92,2 $F_1$, mikä osoittaa, että mSynC todellakin koodaa matalaa syntaksia. Kaiken kaikkiaan tulokset vahvistavat edelleen, että eksplisiittinen matala syntaksi ei tarjoa mitään etuja ELMo-transformeriin verrattuna.",
      "id": "task461-b1f6a088094643a1a1b87bddb72d5ecf",
      "output": [
        "Mitä parannuksia nämä kaksi lähestymistapaa tuovat pelkkään ELMo-perusasetukseen verrattuna?"
      ]
    },
    {
      "input": "RNN-pohjainen NMT-malliAluksi esittelemme lyhyesti RNN-pohjaisen neuraalisen konekäännöksen (RNN-pohjainen NMT) mallin. Transformer-NMTR Viime aikoina Transformer-malli BIBREF4 on edistynyt merkittävästi konekääntämisessä. Tässä mallissa on monipäinen itsetarkkailukooderi ja monipäinen itsetarkkailun dekooderi.",
      "id": "task461-29b8e983e7044231bbb4b55bf2c9803c",
      "output": [
        "mihin NMT-malleihin niitä verrattiin?"
      ]
    },
    {
      "input": "Yhden merkin aihepiiriluokituskokeissa käytämme Switchboard Telephone Speech Corpus BIBREFiä21 , joka on kokoelma kaksipuolisia puhelinkeskusteluja. Lisäksi arvioimme aiheen tunnistussuorituskykyämme DARPA:n LORELEI-ohjelman (Low Resource Languages for Emergent Incidents) julkaisemilla kolmen kielen puhekorpuksilla.",
      "id": "task461-5bf7819bbb5d458b8076b8a88f1e12d9",
      "output": [
        "Mitä tietokokonaisuuksia käytetään järjestelmän suorituskyvyn arvioinnissa?"
      ]
    },
    {
      "input": "Tämän jälkeen poimimme nämä ominaisuudet kahdesta kontekstitekstilähteestä, erityisesti sen uutisartikkelin otsikosta, johon kommentti on lähetetty, ja kommentin lähettäneen käyttäjän näytön nimestä.",
      "id": "task461-22fce2273c2d46aa8f891e0eec79cae8",
      "output": [
        "Mitä asiayhteyttä he käyttävät?"
      ]
    },
    {
      "input": "Menetelmämme demonstroimiseksi mustassa laatikossa keskitämme kokeilumme Googlen konekäännösjärjestelmään (GMT), jota käytetään sen Cloud API:n kautta.",
      "id": "task461-c1748992dd374eab9ba9c4f930e136f8",
      "output": [
        "Mitä neuraalista konekäännösjärjestelmää käytetään?"
      ]
    },
    {
      "input": "Perusmalli, INLINEFORM0 , koulutetaan 190 tunnin ( INLINEFORM1 100K instansseja) transkriptoidulla puheaineistolla. Sen jälkeen se valitsee osajoukon 1700 tunnin ( INLINEFORM2 1,1M instanssia) merkitsemättömästä tietokokonaisuudesta. Kyselemme valitun osajoukon etiketit ja otamme ne mukaan harjoitteluun. Oppimisnopeudet viritetään pienellä 2048 instanssin validointijoukolla. Koulutettua mallia testataan 156 tunnin ( INLINEFORM3 100K instansseja) testijoukolla, ja raportoimme CTC-tappion, merkkivirheprosentin (CER) ja sanavirheprosentin (WER).",
      "id": "task461-92638fe0d3fc4f9a8fae15b2c9988f92",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Korkea lähimpien naapureiden tarkkuus osoittaa, että syntaksitieto on onnistuttu tallentamaan upotuksiin.",
      "id": "task461-f762c33609514a3eb5a57daf0fc5895f",
      "output": [
        "Tehdäänkö opittujen upotusten kvantitatiivinen laatuanalyysi?"
      ]
    },
    {
      "input": "Koska malleissamme ei käytetty RL-jalostusta, nämä tulokset merkitsevät 1,34 ja 1,12 BLEU-pisteen merkittävää parannusta BIBREF3:n vahvoihin perusmalleihin verrattuna. Myös perpleksisyyspisteet ovat paremmat. Google Production -tietokannassa mallimme saavutti 1,01 korkeamman testin BLEU-pistemäärän, vaikka sitä oli harjoiteltu vain yksi kuudesosa ajasta.",
      "id": "task461-1b2e4fdeeb8b429b9b2d17881ad9eb58",
      "output": [
        "Miten MOE-malli parantaa konekääntämistä SOTA-malliin verrattuna?"
      ]
    },
    {
      "input": "Järjestelmämme sijoittui 43 tiimin joukosta 421:nneksi virallisen F1-pistemäärän ollessa 0,2905 testijoukossa. Vaikka mallimme on validointijoukossa F1-pistemäärän osalta parempi kuin perusjoukko, havaitsemme kaikkien mittareiden osalta huomattavia pudotuksia testijoukkoon verrattuna, mikä osoittaa, että arkkitehtuuri ei näytä kykenevän yleistämään hyvin.",
      "id": "task461-d4816b85a7cd42f5b5a6ea501ec2f6eb",
      "output": [
        "Millaisia tuloksia he saivat testijoukossa?"
      ]
    },
    {
      "input": "Käytämme valmista jäsentäjää, tässä tapauksessa Stanford CoreNLP BIBREF11 , binääristen vaalipiiriparssien luomiseen.",
      "id": "task461-0a23027f09524e04b0450b32b74e56e5",
      "output": [
        "Miten he saavat analysoituja lähdelauseet?"
      ]
    },
    {
      "input": " Vaiheessa yksi sekoitimme ja jaoimme datan (1913 signaalia 14 yksilöltä) satunnaisesti harjoittelu- (80 %), kehitys- (10 %) ja testisarjoihin (10 %). Jotta PHASE-TWO:ssa voitaisiin tehdä oikeudenmukainen vertailu aiempiin menetelmiin, jotka on raportoitu samasta tietokokonaisuudesta, suoritamme ristiinvalidointikokeen, jossa jätetään yksi koehenkilö pois ja käytetään parhaita PHASE-ONE:ssa opittuja asetuksia.",
      "id": "task461-42671e44ff854aa0b712d29bedf667fa",
      "output": [
        "Kuinka monta elektrodia tutkittavaan käytettiin EEG-istunnoissa?"
      ]
    },
    {
      "input": "Maksimaalinen sovittaminen (MM) on yksi suosituimmista sanojen segmentoinnin perus- ja rakennealgoritmeista BIBREF19 .  Se ei kuitenkaan ratkaise moniselitteisten sanojen ja tuntemattomien sanojen ongelmaa, joita ei ole sanakirjassa.",
      "id": "task461-92facb7b639140f1a53c075619be1d6f",
      "output": [
        "Mitkä ovat nykyisten vietnaminkielisten sanojen segmentointijärjestelmien rajoitukset?"
      ]
    },
    {
      "input": "Tässä kokeilussa vertaamme Enitity-GCN:ää samaa tehtävää käsitteleviin viimeaikaisiin aiempiin töihin. Taulukossa 2 esitetään testi- ja kehitystulokset (jos niitä on) molemmille tietokokonaisuuden versioille. BIBREF0:sta luetellaan ihmissuoritukseen perustuva oraakkeli sekä kaksi tavallista luetun ymmärtämisen mallia, nimittäin BiDAF BIBREF3 ja FastQA BIBREF6 . Vertaamme myös Coref-GRU BIBREF12 , MHPGM BIBREF11 ja Weaver BIBREF10 . Lisäksi otamme mukaan tuloksia MHQA-GRN BIBREF23 , joka on peräisin hiljattain julkaistusta arXiv-preprintistä, jossa kuvataan samanaikaista työtä. Niissä koulutetaan yhdessä graafisia neuroverkkoja ja rekursiivisia koodaajia. Raportoimme kahden parhaan yksittäisen mallin ja ensemblen yksittäiset ajot peittämättömässä testijoukossa (muistutettakoon, että testijoukko ei ole julkisesti saatavilla, ja tehtävän järjestäjät raportoivat vain peittämättömät tulokset) sekä validointijoukon molemmat versiot.",
      "id": "task461-812d4b8ca2eb4d788b33347aee2e2894",
      "output": [
        "Mihin perustasoon he vertasivat Entity-GCN:ää?"
      ]
    },
    {
      "input": "Jos harjoittelemme skip-gram-mallin uudelleen ja päivitämme emoji-kartan säännöllisesti uusien escort-ilmoitusten perusteella, kun ihmiskauppiaat siirtyvät uusiin emojeihin, kartta voi yhdistää uudet emojit vanhoihin, mikä auttaa ihmiskaupan vastaisia asiantuntijoita laajentamaan ihmiskauppaa koskevien merkkien sanastoa. Tämä lähestymistapa toimii myös lyhenteiden ja tahallisten kirjoitusvirheiden osalta.",
      "id": "task461-9f3867f814a24f38af34e00d2f8ff32f",
      "output": [
        "Miten salakuljetuslippujen sanastoa laajennetaan?"
      ]
    },
    {
      "input": "Parannus on 3,5 F1-pistettä, kun vaikea osajoukko, johon on lisätty asiantuntijalausuntoja, sekoitetaan jäljelle jäävään joukkorekisteröintiin, mikä on paljon enemmän kuin silloin, kun siihen lisätään satunnainen joukko asiantuntijalausuntoja.",
      "id": "task461-eded16a1b43247aeb126981aaf8b5dad",
      "output": [
        "Kuinka paljon laadukkaampi on tuloksena saatava kommentoitu tieto?"
      ]
    },
    {
      "input": "oss-analyysi. Perusteellisemman arvioinnin suorittamiseksi tutkimme edelleen mallin käyttäytymistä sekä rekonstruoinnin että uudelleenrakentamisen kannalta.",
      "id": "task461-b2a8ae2ed466442592254be754a88993",
      "output": [
        "Miten he arvioivat tuotetun tekstin laatua?"
      ]
    },
    {
      "input": "Tietokanta koostuu kyselyistä ja niitä vastaavista kuvahaun tuloksista. Kunkin kyselyn jokaiselle merkille annetaan kielimerkintä, joka perustuu Google Images -hakua tekevän käyttäjän asettamaan kotikieleen.",
      "id": "task461-f12e3659574a4c3f89e9d58a8b78dc17",
      "output": [
        "Onko kuvissa monikielisiä vai yksikielisiä merkintöjä?"
      ]
    },
    {
      "input": "Vertailemme käännöslähestymistapojen suorituskykyä neljän mittarin perusteella:[align=left,leftmargin=0em,labelsep=0.4em,font=]Kuten BIBREF20:ssä, EM on 1, jos ennustettu suunnitelma vastaa täsmälleen pohjatotuutta, muuten se on 0.Tarkkuuden ja palautuksen harmoninen keskiarvo koko testijoukon BIBREF26 yli.Vähimmäismäärä lisäyksiä, poistoja tai vaihto-operaatioita, jotka tarvitaan ennustetun käyttäytymissarjan muuttamiseksi perustotuuden mukaiseksi BIBREF27 .GM on 1, jos ennustettu suunnitelma saavuttaa perustotuuden määränpään (vaikka koko käyttäytymissarja ei vastaisi täsmälleen perustotuutta). Muussa tapauksessa GM on 0.",
      "id": "task461-46c2c9aa782e4d049ec0b2fe70138e50",
      "output": [
        "Mitä arviointimittareita käytetään?"
      ]
    },
    {
      "input": "Ensimmäinen tietokokonaisuus on laajennettu versio BIBREF9:n kommentoidusta Wikipedian keskusteluja koskevasta tietokokonaisuudesta. Tässä tietokokonaisuudessa käytetään tarkoin valvottuja joukkoresurssien antamia merkintöjä, jotka on suodatettu tiukasti sen varmistamiseksi, että keskustelut ovat sivistyneitä aina henkilökohtaisen hyökkäyksen hetkeen asti. Tämä on hyödyllinen ominaisuus mallianalyysin kannalta, ja siksi keskitymme tähän ensisijaisena tietokokonaisuutena. Olemme kuitenkin tietoisia siitä, että nämä tiukat merkinnät eivät ehkä täysin kuvaa sellaista käyttäytymistä, josta moderaattorit käytännössä välittävät. Siksi otamme käyttöön toissijaisen tietokokonaisuuden, joka on muodostettu ChangeMyView (CMV) -alipalvelusta, jossa ei käytetä post-hoc-merkintöjä. Sen sijaan ennustustehtävänä on ennustaa, joutuuko keskustelu tulevaisuudessa moderaattorin toimenpiteiden kohteeksi. Wikipedia-aineisto. BIBREF9:n `Conversations Gone Awry'-tietokanta koostuu 1 270 keskustelusta, jotka käytiin Wikipedian toimittajien välillä julkisesti saatavilla olevilla keskustelusivuilla. Keskustelut ovat peräisin WikiConv-tietoaineistosta BIBREF59 ja joukkoistajat ovat merkinneet ne joko sisältävän henkilökohtaisen hyökkäyksen sisältäpäin (eli yhden käyttäjän vihamielinen käytös keskustelussa, joka kohdistuu toiseen käyttäjään) tai pysyvän koko ajan kohteliaana. Redditin CMV-tiedot. CMV-aineisto on muodostettu Redditin API:n kautta kerätyistä keskusteluista. Toisin kuin Wikipediaan perustuvassa tietokannassa, vältämme nimenomaisesti jälkikäteisen merkinnän käyttöä. Sen sijaan käytämme merkkinä sitä, onko moderaattori poistanut kommentin keskustelusta säännön 2 (älä ole epäkohtelias tai vihamielinen muita käyttäjiä kohtaan) rikkomisen vuoksi.",
      "id": "task461-ed0d3768f8de413cbec6c84314738e2b",
      "output": [
        "Mitä merkintöjä epäsosiaalisista tapahtumista on saatavilla tietokannoissa?"
      ]
    },
    {
      "input": "Tässä työssä esittelemme uuden loogisen päättelymoottorin nimeltä MonaLog, joka perustuu luonnolliseen logiikkaan ja vanBenthemEssays86:sta peräisin olevaan monotonisuutta koskevaan työhön. Koska logiikkamme operoi pintamuotojen yli, on suoraviivaista hybridisoida mallimme. Tutkimme MonaLogin käyttöä yhdessä BERT BIBREF20 -kielimallin kanssa, mukaan luettuna kompositionaalinen datan lisääminen, eli harjoitusjoukkojen esimerkkien sisältämien versioiden luominen uudelleen.  Teemme kaksi kokeilua MonaLogin testaamiseksi. Ensin käytämme MonaLogia ratkaisemaan ongelmia yleisesti käytetyssä luonnollisen kielen päättelyaineistossa SICK BIBREF1 ja vertaamme tuloksiamme aiempiin järjestelmiin. Toiseksi testaamme MonaLogin tuottaman datan laatua. Tätä varten luomme lisää harjoitusaineistoa (lausepareja) SICKin harjoitusaineistosta järjestelmämme avulla ja suoritamme hienosäätöä BERT BIBREF20:llä, joka on muunnosarkkitehtuuriin BIBREF23 perustuva kielimalli, laajennetulla aineistolla. ",
      "id": "task461-b0410519386949fc83bb9915190ecfca",
      "output": [
        "Miten he yhdistävät MonaLogin ja yhteistyöelimen?"
      ]
    },
    {
      "input": "Avoimen toimialueen chatbotit ovat yleisempiä dialogijärjestelmiä. Esimerkkinä tästä on BIBREF7 humeau2019real:n Poly-enkooderi. Se on parempi kuin Bi-enkooderi BIBREF8, BIBREF9 ja vastaa Cross-enkooderin BIBREF10, BIBREF11 suorituskykyä samalla kun laskenta-aika on kohtuullinen. Se suoriutuu erinomaisesti pareittaisia vertailuja sisältävistä myöhemmistä kielenymmärtämistehtävistä ja osoittaa huipputuloksia ConvAI2-haasteessa BIBREF12. Feed Yourself BIBREF13 on avoimen alueen dialogiagentti, jossa on itseään ruokkiva malli. Kun keskustelu sujuu hyvin, dialogista tulee osa harjoitusdataa, ja kun keskustelu ei suju, agentti pyytää palautetta. Kvmemnn BIBREF14 on avainarvomuistiverkko, jossa on tietopohja, joka käyttää avainarvojen hakumekanismia harjoitellakseen samanaikaisesti useilla aloilla. Käytämme kaikkia kolmea näistä malleista vertailukohtina.  Vertailemme neljään dialogijärjestelmän perusmalliin: Kvmemnn, Feed Yourself, Poly-encoder ja BERT bi-ranker -perustason, joka on koulutettu Persona-Chat-tietokannalla käyttäen samoja koulutushyperparametreja (mukaan lukien oppimisnopeuden aikataulutus- ja pituuden rajausasetukset), jotka on kuvattu kohdassa SECREF20.",
      "id": "task461-43f677d413ec4ad7804381e2f5140530",
      "output": [
        "Mitä perusmalleja käytetään?"
      ]
    },
    {
      "input": "Keskeinen etu on se, että RNN päättelee tilan latentin esityksen, jolloin ei tarvita tilamerkintöjä.",
      "id": "task461-ee3c2d555137442487b2c1ad074cdc2c",
      "output": [
        "Auttaako latentti vuoropuhelun tila heidän malliaan?"
      ]
    },
    {
      "input": "kun yhteinen CLWE-avaruus on luotu, tehtävänä on hakea kohdekielen käännöksiä lähdekielen sanojen testijoukosta hakea kohdekielen käännöksiä lähdekielen sanojen testijoukosta BLI on BLI-asetelmassamme ranking-tehtävä, jossa on vain yksi oikea käännös kullekin \"kyselysanalle\", MAP on yhtä suuri kuin keskimääräinen vastavuoroinen sijoitus (MRR).",
      "id": "task461-36d6568a45c049acbe35616b19a0f220",
      "output": [
        "Miten BLI mittaa linjauksen laatua?"
      ]
    },
    {
      "input": "Alun perin siemensanakirjat kattoivat tyypillisesti useita tuhansia sanapareja BIBREF15 , BIBREF18 , BIBREF19 , mutta uudempi työ on osoittanut, että CLWE:t voidaan indusoida jopa heikommalla valvonnalla pienistä sanakirjoista, jotka kattavat useita satoja sanapareja BIBREF20 , identtisiä merkkijonoja BIBREF21 tai jopa vain yhteisiä numeroita BIBREF22 .",
      "id": "task461-95ed5b6edd7343f59592f64ebec9d86e",
      "output": [
        "Miten siemensanakirjat saadaan täysin valvomattomilla menetelmillä?"
      ]
    },
    {
      "input": "Bengali, gujarati, marathi, malayalam ja tamil ovat ensisijaiset lähdekielet, ja kääntäminen näistä kielistä hindiksi on lasten tehtävä. ",
      "id": "task461-419f264a0f1341d7b667fe25507cfad3",
      "output": [
        "Kuinka monen kieliparin kohdalla he osoittavat, että avustavan kielen lauseiden esijärjestäminen auttaa käännöksen laatua?"
      ]
    },
    {
      "input": "Koulutustietokannan luomisessa noudatimme samanlaista lähestymistapaa kuin LASERissa. Tietokanta sisältää 6 kieltä: Kielet ovat englanti, espanja, saksa, hollanti, korea ja kiinan mandariini. Tietokokonaisuus luotiin käyttämällä Tatoeban ja OpenSubtitles BIBREF16:n tarjoamia käännöksiä.",
      "id": "task461-9bd3778aae0a497f8007aa70425cd6ce",
      "output": [
        "Mitä korpusta he käyttävät?"
      ]
    },
    {
      "input": "Vertaamme tuloksia uudempaan monikieliseen kielimalliin XLM BIBREF12 sekä uusimpaan CoNLL 2018 -tehtävän jaetun tehtävän tuloksiin, joissa on ennustettu tokenisointi ja segmentointi, artikkelin päivitetyssä versiossa. Ranskan kielellä ei ole tehty laajaa työtä, koska NER-korporaatioita on vain vähän saatavilla. Vertaamme malliamme vahvoihin peruslinjoihin, joihin BIBREF49 asettui, jossa koulutettiin sekä CRF- että BiLSTM-CRF-arkkitehtuurit FTB:llä ja parannettiin niitä heuristiikoilla ja esivalmistetuilla sanojen upotuksilla. TRANSLATE-TRAIN-asetelmassa ilmoitamme aiemmasta kirjallisuudesta saadut parhaat tulokset yhdessä omamme kanssa. BiLSTM-max on paras malli alkuperäisessä XNLI-julkaisussa, mBERT, joka on raportoitu ranskaksi BIBREFissä52, ja XLM (MLM+TLM) on paras esitelty malli BIBREFissä50.",
      "id": "task461-9200d5fd3ef14270a2c1a01efc12da08",
      "output": [
        "Mikä on tekniikan nykytila?"
      ]
    },
    {
      "input": "Korpus koostuu 2 346 kliinisen muistiinpanon kokoelmasta (vastaanottokertomukset, potilaskertomukset ja kotiutuskertomukset), joissa on yhteensä 2 372 323 tokenia (keskimäärin 1 011 tokenia per muistiinpano). Kaikki muistiinpanot kirjoitettiin englanniksi ja poimittiin 183 psykoosipotilaan sähköisestä potilastietojärjestelmästä McLean Psychiatric Hospitalista Belmontissa, MA:ssa, ja kaikilla potilailla oli historiassaan vähintään yksi 30 päivän takaisinottotapaus.",
      "id": "task461-582228c9be534927ab4ca2688c258ada",
      "output": [
        "Mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Havaittujen tarkistusten arviointiin käytetään tarkkuutta, palautusta ja F-mittaa.",
      "id": "task461-eb0a4dcc996e410eb0f3243e7cf50abe",
      "output": [
        "Mitä mittareita käytetään tarkistusten havaitsemisen arvioinnissa?"
      ]
    },
    {
      "input": "Toisaalta Go-Explore Seq2Seq osoittaa lupaavia tuloksia, sillä se ratkaisee lähes puolet näkymättömistä peleistä. Kuva FIGREF62 (liitteessä SECREF60) osoittaa, että suurin osa hävityistä peleistä kuuluu vaikeimpaan joukkoon, jossa pelin voittaminen edellyttää hyvin pitkää toimintasarjaa. Nämä tulokset osoittavat sekä Seq2Seq-mallin kouluttamisen suhteellisen tehokkuuden Go-Explore-pelien liikeradoilla että sen, että tarvitaan lisäponnistuksia sellaisten vahvistusoppimisalgoritmien suunnittelemiseksi, jotka yleistyvät tehokkaasti näkymättömiin peleihin.",
      "id": "task461-33f34cbbbb2841c28ce66146c358d73e",
      "output": [
        "Miten kirjoittajat osoittavat, että heidän oppimansa toimintatapa yleistyy olemassa olevia ratkaisuja paremmin näkymättömiin peleihin?"
      ]
    },
    {
      "input": "Lause-korpus (S) koostuu 80 000 lauseesta ja 280 gigatavusta tavallista tekstiä, jotka on poimittu BIBREF6 aristo2016:combiningin käyttämiltä verkkosivuilta. Käytämme BIBREF6 aristo2016:combiningin tekstikorpusta (S) rakentaaksemme tuple KB:n.  Otamme 200 parasta osumaa, ajamme Open IE v4:n ja yhdistämme tuloksena saadut tuplat kaikkiin $a \\ in A$ ja kaikkiin kysymyksiin $Q_\\mathit {tr}$:ssa luodaksemme tuple KB:n (T).",
      "id": "task461-4def5423d3d44dee8aa0d097ce7425bc",
      "output": [
        "Mikä oli tekstilähde, johon OpenIE:tä sovellettiin?"
      ]
    },
    {
      "input": "Työssämme käytetään neljää tietokokonaisuutta, joita ovat CoNLL 2003 German BIBREF9 , CoNLL 2002 Spanish BIBREF10 , OntoNotes 4 BIBREF11 ja Weibo NER BIBREF12 .  Taulukossa TABREF22 esitetään kiinalaisen OntoNotes 4.0:n tulokset. ",
      "id": "task461-e4b48760ccc14872a170c11e9a7a6194",
      "output": [
        "Millä kielillä he työskentelevät?"
      ]
    },
    {
      "input": "Algoritmi \"Online-oppiminen\" osoittaa, miten CNN-mallimme voidaan kouluttaa puhtaasti verkossa. Aluksi alustetaan mallin parametrit $\\theta _0$ (rivi 1), joka voi olla muista katastrofitapahtumista koulutettu malli tai se voidaan alustaa satunnaisesti tyhjästä.Kun uusi erä merkittyjä twiittejä $B_t= \\lbrace \\mathbf {s}_1 \\ldots \\mathbf {s}_n \\rbrace $ saapuu, lasketaan ensin yhtälön 11 mukainen log-loss (ristiinentropia) $B_t$:lle suhteessa nykyisiin parametreihin $\\theta _t$ (rivi 2a). Sitten laskemme takaisinkulkeutumisen avulla häviön gradientit $f^{\\prime }(\\theta _{t})$ nykyisten parametrien suhteen (rivi 2b). Lopuksi päivitämme parametrit oppimisnopeudella $\\eta _t$ ja gradienttien keskiarvolla (rivi 2c). Käytämme gradienttien keskiarvoa, jotta voimme käsitellä erikokoisia minieriä. Huomaa, että otamme huomioon vain nykyisen minierän saadaksemme päivitetyn mallin. ",
      "id": "task461-f86e060269f644c6807384ffe91bada2",
      "output": [
        "Mitä uutta tässä stokastisessa gradienttilaskeutumisalgoritmissa on?"
      ]
    },
    {
      "input": " Koska olemme kiinnostuneita esityksemme nollakuvauskyvystä, koulutimme sentimenttianalyysimallimme vain englanninkielisellä IMDB Large Movie Review -tietokannalla ja testasimme sitä kiinalaisella ChnSentiCorp-tietokannalla ja saksankielisillä SB-10K BIBREF24 , BIBREF25 . Luonnollisen kielen päättelytehtävä koostuu kahdesta lauseesta; premissi ja hypoteesi, jotka ovat joko ristiriitoja, seurauksia tai neutraaleja. NLI-tehtävän oppiminen edellyttää tiettyä vivahteikasta kielen ymmärtämistä. Siksi on kiinnostavaa, pystyykö UG-WGAN ymmärtämään tarvittavat kielelliset piirteet. ",
      "id": "task461-57e4146f1b054581b9e4f4beac772251",
      "output": [
        "Kokeilivatko he matematiikassa muita tehtäviä kuin sanaongelmia?"
      ]
    },
    {
      "input": "Käytämme yksikielisenä perusmallina garg2012unsupervised Bayes-mallia. Semanttiset roolit ovat predikaattikohtaisia.",
      "id": "task461-64fa7debe662408f9015b756e7e2608e",
      "output": [
        "Mistä yksittäinen malli koostuu?"
      ]
    },
    {
      "input": "Koko tietokokonaisuus koostuu 81 826 näytteestä, jotka englannin äidinkieliset puhujat ovat kommentoineet. Niistä 80 prosenttia käytetään harjoitusjoukkona. Niistä 10 prosenttia käytetään validointijoukkona ja loput testijoukkona. Testijoukosta valitaan 3000 kovaa näytettä.",
      "id": "task461-07db5ca5fb3d4b2c9d210abc9c7176aa",
      "output": [
        "Mitä eroa on täydellisellä testisarjalla ja kovalla testisarjalla?"
      ]
    },
    {
      "input": "N-grammit, POS, hierarkkiset ominaisuudet: sanasäkkimalli, joka sisältää sekä merkityt että merkitsemättömät unigrammit ja bigammit.  CNN: Kim BIBREF28 osoitti lähes huippuluokan suorituskyvyn useissa lauseiden luokittelutehtävissä (mukaan lukien TREC-kysymysten luokittelu) käyttämällä esivalmennettuja sanojen upotuksia BIBREF40 CNN-mallin ominaisuuksien poimijoina.",
      "id": "task461-37ba1782ade34905b1d2c1a699fcf5b8",
      "output": [
        "Mihin aiempiin menetelmiin heidän malliaan verrataan?"
      ]
    },
    {
      "input": "Loimme tämän CORD-19-NER-tietokokonaisuuden, jossa on kattava nimettyjen entiteettien annotaatio CORD-19-korpuksesta (2020-03-13).  Korpus on luotu CORD-19-korpuksen (2020-03-13) 29 500 asiakirjasta. ",
      "id": "task461-e541c265d164472387d61faba8c5e05e",
      "output": [
        "Mikä on tämän tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Taulukossa 2 luetellaan kaikkien menetelmien tarkkuudet kahdella luokitteluarkkitehtuurilla. Tulokset osoittavat, että eri luokittimien arkkitehtuurien eri tietokokonaisuuksissa ehdollisen BERT-yhteenliittymän lisääminen parantaa mallin suorituskykyä eniten. BERT voi myös lisätä lauseita jossain määrin, mutta ei yhtä paljon kuin ehdollinen BERT.",
      "id": "task461-c6ba790098964f2f845de9c79d0276a5",
      "output": [
        "Ilmoittavatko kirjoittajat ehdollisen bertin suorituskyvyn tehtävissä, joissa tietoja ei ole lisätty?"
      ]
    },
    {
      "input": "Kuvakokoelmaa tarkastelemalla voi olla vaikea havaita kuvioita. Toinen menetelmä on merkitä kaikki kuvaukset puhekielitiedoilla, jolloin voidaan esimerkiksi nähdä, mitä adjektiiveja käytetään yleisimmin tietyistä substantiiveista. Eräs menetelmä, jota lukijat saattavat pitää erityisen hyödyllisenä, on hyödyntää Flickr30K Entities BIBREF8 -tietokannan rakennetta. Tämän jälkeen sovelsin Louvainin klusterointia BIBREF9 coreference-graafiin, minkä tuloksena saatiin samanlaisiin entiteetteihin viittaavien ilmausten klustereita.",
      "id": "task461-6cce166f953f47fcad15c01f04e09d26",
      "output": [
        "Millä menetelmillä voidaan löytää esimerkkejä ennakkoluuloista ja perusteettomista päätelmistä??"
      ]
    },
    {
      "input": "Määritämme tehokkuuden ja tarkkuuden välisen kompromissin verrattuna kahteen sääntöpohjaiseen perusratkaisuun: Unif ja Stopword. ",
      "id": "task461-3a1964d31c014bb39af2f6520e7ed3cb",
      "output": [
        "Mitkä ovat käytetyt perustasot?"
      ]
    },
    {
      "input": "Jopa niiden tutkijoiden keskuudessa, jotka tunsivat edellä esitetyt määritelmät, yksimielisyys oli edelleen vähäistä (Krippendorffin INLINEFORM0 ).",
      "id": "task461-a909a4bd2ce54e4684a5fe6a6a142ff4",
      "output": [
        "Miten luotettavuutta mitattiin?"
      ]
    },
    {
      "input": " Käytämme myös neuroverkon viimeistä piilokerrosta väitteen tehtäväkohtaisena upottamisena yhdessä verkkotodisteiden kanssa. ",
      "id": "task461-6e30f2b7397f456abb150ea771539087",
      "output": [
        "Mitä tietoja käytetään tehtäväkohtaisten sulautusten rakentamiseen?"
      ]
    },
    {
      "input": "vastaamaan, kuinka loukkaavana he pitivät twiittiä 6-pisteisellä Likertin asteikolla 1:stä (ei lainkaan loukkaava) 6:een (erittäin loukkaava). Jos osallistujat vastasivat 4 tai korkeampi, heillä oli mahdollisuus ilmoittaa, mitkä sanat olivat heidän mielestään loukkaavia.",
      "id": "task461-ee34bbcff914452e9c545de117abd4f8",
      "output": [
        "Tarkoitettiinko loukkaavuuden asteella sitä, kuinka yleisesti loukkaava teksti oli vai kuinka henkilökohtaisesti loukkaava se oli kommentoijalle?"
      ]
    },
    {
      "input": "Jotta voimme arvioida tämän ja muiden mallien ennustuskykyä, tarvitsemme jonkin menetelmän, jolla voimme vertailla malleja. Tätä tarkoitusta varten käytämme ROC-käyriä (receiver operating characteristic curves), joka on visuaalinen esitys ennustuskyvystä. ROC-käyrillä verrataan mallin ennusteiden todellisten positiivisten ennusteiden (TPR) ja väärien positiivisten ennusteiden (FPR) osuutta eri kynnystasoilla. Käyrän alle jäävä pinta-ala (AUC) (0:n ja 1:n välillä) on numeerinen mittari, jossa mitä suurempi AUC on, sitä paremmin malli toimii. Ristiinvalidoimme mallimme jakamalla korpuksen ensin satunnaisesti koulutusjoukkoon (95 % korpuksesta) ja testijoukkoon (5 % korpuksesta). Sovitamme sitten mallin harjoitusjoukkoon ja käytämme sitä ennustamaan testijoukon asiakirjojen vastauksia. Toistamme tämän prosessin 100 kertaa. Näistä ennusteista saadaan kynnyskeskiarvoinen ROC-käyrä BIBREF13 , joka on esitetty kuvassa 3 . Taulukossa 1 esitetään kunkin tarkastellun mallin AUC-arvo.",
      "id": "task461-b57cca7dc4d24ba29f774d07faec27f8",
      "output": [
        "Miten suorituskykyä mitataan?"
      ]
    },
    {
      "input": "Tulkittavuuden vuoksi projisoimme myös upotusten ja PCA-mallien kertoimet takaisin dummy-muuttuja-avaruuteen.",
      "id": "task461-99af13de3ce84ac0b82bc7baad33f250",
      "output": [
        "Miten niiden tulkita kertoimia?"
      ]
    },
    {
      "input": "Näissä nauhoituksissa on taustahälyä (kuten ostoskeskuksessa on odotettavissa) ja eri kieliä (intialaiset puhuvat englantia ja hindiä sekaisin).",
      "id": "task461-58eb421446034bd3a4d002fde9ffeea3",
      "output": [
        "Mitä kieliä otetaan huomioon?"
      ]
    },
    {
      "input": "Yksinkertainen, mutta toistuva tekstimalli on tunnettu sanojen yhteisesiintymisverkko. Valinnaisten tekstin esikäsittelyvaiheiden jälkeen yhteisesiintymisverkossa jokaisesta eri sanasta tulee solmu, ja särmät muodostetaan yhteisesiintymisen avulla halutussa ikkunassa. Yleinen strategia yhdistää vain vierekkäiset sanat ns. sanojen vierekkäisyysverkoissa. Vaikka yhteisesiintymisesitys tuottaa hyviä tuloksia luokittelutilanteissa, mallissa ei oteta huomioon joitakin tärkeitä ominaisuuksia. Esimerkiksi pitkän matkan syntaktiset yhteydet, vaikka ne ovatkin harvinaisempia kuin vierekkäiset syntaktiset suhteet, saatetaan jättää huomiotta yksinkertaisessa sanojen vierekkäisyyttä koskevassa lähestymistavassa BIBREF12.",
      "id": "task461-49b7a8941a6545798a5abdad626c7bfd",
      "output": [
        "Mistä johtuu, että perinteiset esiintymisverkot eivät onnistu luomaan yhteyksiä samankaltaisten sanojen välille aina, kun ne esiintyvät tekstissä kaukana toisistaan?"
      ]
    },
    {
      "input": "Sekä ääni että transkriptio on poistettu (poistamalla tunnistetiedot) digitaalisilla nollilla ja [de-identified]-tunnisteilla.",
      "id": "task461-de9a0629ad4643cf955955b1e2658101",
      "output": [
        "Ovatko tiedot tunnistamattomia?"
      ]
    },
    {
      "input": "Keskitymme seuraaviin NLP-tutkimuksen näkökohtiin: koko, demografiset tiedot, tutkimusalat, vaikutus ja viittausten ja demografisten ominaisuuksien (ikä ja sukupuoli) välinen korrelaatio.",
      "id": "task461-ffcca6f8b91f4404b5802255810f4964",
      "output": [
        "Mitä NLP-tutkimuksen osa-aluetta tarkastellaan?"
      ]
    },
    {
      "input": "Kolmannen persoonan monikossa olevalla pronominilla `they' ei ole sukupuolta englannissa ja useimmissa muissa kielissä (toisin kuin kolmannen persoonan yksikössä olevilla pronomineilla `he', `she' ja `it').  Jos nämä lauseet käännetään ranskaksi, ensimmäisessä lauseessa oleva `they' pitäisi kääntää `elles', joka viittaa Janeen ja Susaniin, ja toisessa lauseessa oleva `they' pitäisi kääntää `ils', joka viittaa Frediin ja Georgeen. Pari esimerkkiä: Saksan kielessä sana `sie' toimii sekä muodollisena toisen persoonan prounominina (aina isolla alkukirjaimella), kolmannen persoonan feminiinisenä yksikössä että kolmannen persoonan monikossa. ",
      "id": "task461-d755091537974e1a9aa6f9ac3d097aed",
      "output": [
        "Mitä kieltä he tutkivat?"
      ]
    },
    {
      "input": "Tässä luvussa esitellään todennäköisyysmallimme, joka johtaa avainsanan odotuksen ja kouluttaa kohdemallin samanaikaisesti.",
      "id": "task461-086bd69d122d4a3795e73c987a011c38",
      "output": [
        "Millaisia luokittelijoita käytetään?"
      ]
    },
    {
      "input": "Yksi puhuja kertoi 2000 lausetta, mikä kesti useita päiviä. ",
      "id": "task461-6d00c47a9f8d447d813dcc05cfc27e36",
      "output": [
        "Kuinka monta kommentoijaa osallistui?"
      ]
    },
    {
      "input": "Ensimmäinen perustasomme on ROUGE-L BIBREF1 , koska se on yleisimmin käytetty metriikka pakkaustehtävissä. Vertaamme sitä toutanova2016datasetista löytyviin parhaisiin n-grammi-overlap-mittareihin; lisäksi vertaamme sitä negatiiviseen LM-ristientropiaan eli log-todennäköisyyteen, joka on normalisoitu vain lauseen pituuden mukaan. Seuraavana vertailukohtana on perpleksisyys, joka vastaa eksponentoitua risti-entropiaa: Sen suosion vuoksi teimme alustavia kokeita myös BLEU BIBREF17 -menetelmällä. ",
      "id": "task461-f995ec7c66fa4c0fb279b4cabfb49b0a",
      "output": [
        "Onko ROUGE heidän ainoa perustasonsa?"
      ]
    },
    {
      "input": "Testaamme ehdotettua lähestymistapaamme sarkasmin tai ironian binääriseen luokitteluun seitsemällä vertailutietoaineistolla, jotka on haettu eri medialähteistä. Seuraavassa kuvataan kukin tietokokonaisuus, ja taulukossa TABREF1 on yhteenveto. Twitter: Käytämme SemEval 2018 Task 3, Irony Detection in English Tweets BIBREF18 -tehtävää varten toimitettua Twitter-tietokokonaisuutta. Lopuksi käytämme BIBREF20 -tietokokonaisuutta, joka keräsi käyttäjän itsensä kommentoiman korpuksen twiittejä, joissa oli #sarcasm-hashtag. Reddit: BIBREF21 keräsi SARC-korpuksen, joka koostuu 600 000 sarkastisesta kommentista Redditissä. Käytämme pääjoukkoa SARC 2.0 ja poliittista osajoukkoa SARC 2.0 pol. Verkkodialogit: Käytämme Sarcasm Corpus V1:tä (SC-V1) ja Sarcasm Corpus V2:tä (SC-V2), jotka ovat Internet Argument Corpusin (IAC) osajoukkoja. Verrattuna muihin valikoimassamme oleviin tietokokonaisuuksiin nämä eroavat lähinnä tekstin pituuden ja rakenteen monimutkaisuuden BIBREF22 osalta.  Jotta kutakin tietokokonaisuutta voidaan täydentää ulkoisilla tiedoilla, suodatamme ensin kieliarvoitusjärjestelmien avulla pois twiitit, jotka eivät ole englanninkielisiä.",
      "id": "task461-9e60494991fd45c3b64f32cac17bc056",
      "output": [
        "Arvioivatko he vain englannin kieltä?"
      ]
    },
    {
      "input": "Käytämme kokeissamme TB-Dense- ja MATRES-ohjelmia, ja taulukossa TABREF33 on lyhyt yhteenveto datatilastoista.",
      "id": "task461-fb52c17183c1464bb0d79665cf76fe8d",
      "output": [
        "Mitä tietokokonaisuuksia tässä työssä käytettiin?"
      ]
    },
    {
      "input": "Valitsemalla englannin (En) kääntökieleksi suoritamme identtisten englanninkielisten segmenttien kääntökohdistukset Europarlin Fr-En- ja En-De-rinnakkaiskorpuksissa BIBREF18 , jolloin muodostuu moniparalliskorpus Fr-En-De. Tämän jälkeen kukin Fr*-De- ja Fr-De*-pseudorinnakkaiskorpuksista muodostetaan moniparallisaineistosta soveltamalla edellisessä jaksossa kuvattua pivot-kielipohjaista käännöstä. Automaattisessa kääntämisessä käytetään valmiiksi koulutettua ja julkisesti julkaistua NMT-mallia En $\\rightarrow $ De:lle ja koulutetaan toinen NMT-malli En $\\rightarrow $ Fr:lle WMT'15 En-Fr-paralleelikorpuksen BIBREF19 avulla.",
      "id": "task461-ded69869e20b407a8d7a311cc617c7d6",
      "output": [
        "Mistä synteettiset tiedot kerätään?"
      ]
    },
    {
      "input": "Näiden kokoonpanojen aikaansaamiseksi TIMIT-tiedot jaettiin. Kuvassa FIGREF12 esitetään tietojen jakaminen kahdeksaan osajoukkoon (A-H). TIMIT-tietokokonaisuus sisältää 462 puhujan puhetta harjoittelussa ja 168 puhujan puhetta testijoukossa, ja jokaisella puhujalla on 8 lausumaa. TIMIT-koulutus- ja testijoukko on jaettu kahdeksaan lohkoon, joissa kussakin lohkossa on kaksi satunnaisesti valittua lausumaa kutakin puhujaa kohti. Näin ollen kukin lohko A,B,C,D sisältää dataa 462 puhujalta, joiden 924 lausumaa on otettu koulutusjoukoista, ja kukin lohko E,F,G,H sisältää puhetta 168:lta testijoukon puhujalta, joiden 336 lausumaa on otettu. Testidata on loput eli lohkot (D+H). Tehtävässä b sulautusten ja luokittelijoiden koulutuksessa käytetään lohkoja (A+B+E+F) ja (C+G) ja testissä taas lohkoja (D+H). Tehtävä c pitää molemmat erillään: upotukset koulutetaan lohkoissa (A+B+C+D), luokittelijat lohkoissa (E+G) ja testit suoritetaan lohkoissa (F+H). Huomaa, että H on osa kaikkia tehtäviä ja että tehtävä c on huomattavasti helpompi, koska erotettavien puhujien määrä on vain 168, vaikka koulutusolosuhteet ovat vaikeammat.",
      "id": "task461-e56acb56337d43e3a8dd8613ea06ae79",
      "output": [
        "Mitä TIMIT-tietoaineistoja käytetään testauksessa?"
      ]
    },
    {
      "input": "Formalisoimme tämän intuition NextSum-nimisessä mallissa, joka valitsee seuraavan yhteenvetolauseen lähdetekstin ominaisuuksien lisäksi myös yhteenvedon aiemmin valittujen lauseiden perusteella.",
      "id": "task461-9d05a60fd5744cf88dc674cd112c5a43",
      "output": [
        "Miten nextsum toimii?"
      ]
    },
    {
      "input": "Olemme havainneet, että epookkien määrä on tärkeä parametri, ja sen lisääminen johtaa tuloksiin, joissa kaksi huonointa malliamme ovat lähes yhtä hyviä tai jopa parempia kuin muut.",
      "id": "task461-067b5cc915ca491c82b06821e5e7325c",
      "output": [
        "Miten eri parametriasetukset vaikuttavat tuloksena olevan mallin suorituskykyyn ja semanttiseen kapasiteettiin?"
      ]
    },
    {
      "input": "Esikäsitellyssä aineistossa on 8757 uutistietuetta. ",
      "id": "task461-cac7449568b64172bceccc12d2367109",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "Tätä varten ehdotetaan menetelmää, jolla käytetyn tietokokonaisuuden (DSTC2) tavoitetunnisteet muunnetaan tunnisteiksi, joiden käyttäytyminen voidaan jäljitellä käyttöönoton aikana.",
      "id": "task461-b705bc909ad24a27b9ddc05a6a8dedbb",
      "output": [
        "mitä korpusta käytetään käyttäytymisen oppimiseen?"
      ]
    },
    {
      "input": "Kohteen tyypin löytämiseksi SimplerVoice rakentaa ensin ontologiapohjaisen tietopuun. Ehdotamme, että kohdeobjektiin sopivien verbien luomiseen käytetään kahta menetelmää: heuristiikkapohjaista ja n-grammimallia.",
      "id": "task461-684392bfd1564e94a6bd6b6ff957cc1a",
      "output": [
        "Mitä mallia he käyttävät avainviestien tuottamiseen?"
      ]
    },
    {
      "input": "Kouluttaaksemme ja arvioidaksemme avoimen alueen faktatietokannan laadunvarmistusjärjestelmää reaalimaailman kysymyksiin, luomme uuden kiinalaisen laadunvarmistustietokannan nimeltä WebQA.",
      "id": "task461-826bc96698ea4627886687d68ab72dec",
      "output": [
        "Mitä kieliä he kokeilevat?"
      ]
    },
    {
      "input": "Ehdotamme uudenlaista suhdesuositusongelmaa (RSR). DSN-verkkojen vastavuoroisen suosittelun ongelmasta poiketen RSR-tehtävämme toimii tavallisissa sosiaalisissa verkostoissa (RSN) ja arvioi pitkäaikaisten ja vakavien suhteiden yhteensopivuutta sosiaalisten viestien, kuten twiittien, perusteella.",
      "id": "task461-b9333e02a31b47ba8eebb670dccafbbb",
      "output": [
        "Ovatko muut ihmiset työskennelleet tämän tehtävän parissa?"
      ]
    },
    {
      "input": "UTD:n tarkoituksena on tunnistaa ja klusteroida automaattisesti toistuvia termejä (esim. sanoja tai lauseita) puheesta. Kiertääksemme tyhjentävän DTW-pohjaisen haun, jota rajoittaa INLINEFORM0 -aika BIBREF6 , hyödynnämme Zero Resource Toolkitin (ZRTools) BIBREF7 skaalautuvaa UTD-kehystä, joka mahdollistaa haun INLINEFORM1 -ajassa.",
      "id": "task461-373324e4b86340539d4a38586e20a8d2",
      "output": [
        "Miten sanan kaltaisten yksiköiden tai foneemien kaltaisten yksiköiden sanasto löydetään automaattisesti?"
      ]
    },
    {
      "input": "Järjestelmät koulutettiin kaikilla WMT 2016 -tapahtumasta saatavilla olevilla rinnakkaisilla tiedoilla. Uutiskommenttikorpuksen, Euroopan parlamentin istuntoselostusten ja yhteisen ryömintäkorpuksen yhteenlaskettu määrä on 3,7 miljoonaa lausetta ja noin 90 miljoonaa sanaa.",
      "id": "task461-3ac1e5e9d441426cbe7eda85b73dd827",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Moniluokkaista luokittelua varten käytettiin One-Vs-The-Rest-strategiaa, ja raportoin F-pisteet, mikro-F-, makro-F- ja painotetut F-pisteet käyttäen 10-kertaista ristiinvalidointia. ",
      "id": "task461-f877e9bdd87940be8046e259f40520b9",
      "output": [
        "Mitä mittareita otetaan huomioon?"
      ]
    },
    {
      "input": "Argus-tietoaineisto AI2-8grade/CK12-tietoaineisto Pidämme tätä aineistoa alustavana, koska sitä ei ole tarkistanut ihminen ja koska monet hypoteesit ovat ilmeisesti todistamattomia keräämiemme todisteiden perusteella (eli teoreettinen huipputarkkuus on paljon pienempi kuin 1,0).  MCTest-tietokanta Käytämme RTE-arviointiin tietokannan virallista laajennusta, jossa kysymykset ja vastaukset yhdistetään tekstin avulla.",
      "id": "task461-860cee3f0d6f4acaab1353d07f2e2576",
      "output": [
        "mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Arvioimme monikieliseen esivalmennukseen perustuvaa siirtomenetelmäämme useita vahvoja perusratkaisuja vastaan kahdella julkisella tietokokonaisuudella, Europarl BIBREF31 ja MultiUN BIBREF32, jotka sisältävät useita rinnakkaisia arviointitietoja nollapisteen suorituskyvyn arvioimiseksi.",
      "id": "task461-a2bdae93a5f64f10b5cffba845cacac5",
      "output": [
        "millä tietokokonaisuuksilla he tekivät kokeita?"
      ]
    },
    {
      "input": "Käytimme Levenshteinin etäisyysmittaria BIBREF8 , joka on toteutettu Apache Lucene -kirjastossa BIBREF9 . Toinen yksinkertainen lähestymistapa on edellä mainittu diakriittinen vaihtaminen, joka on termi, jonka otamme tässä käyttöön viitatakseen BIBREF4:n työn innoittamaan ratkaisuun. Eräs lupaava menetelmä, joka on peräisin englannin kielen oppijoiden tekstien korjaamista käsittelevästä työstä BIBREF11 , perustuu käsitteeseen, jonka mukaan oikeinkirjoitusvirhettä lähimpänä oleva korjaus valitaan jonkin etäisyyskäsitteen mukaan. Tässä Levenshteinin etäisyyttä käytetään painotettuna summana sanavektoreiden väliseen kosinietäisyyteen. ELMo-lisäyksellä varustettu LSTM on kaksisuuntainen.",
      "id": "task461-a5679fe60cee4e3e93435acf5081f183",
      "output": [
        "Mitä menetelmiä PIEWi testaa?"
      ]
    },
    {
      "input": "Kokeissa, joissa käytetään rinnakkaista dataa ulkomaisten parametrien alustamiseen, käytämme samoja tietokokonaisuuksia kuin BIBREF6:n työssä. Erityisesti käytämme United Nations Parallel Corpus BIBREF18 -korpusta en-ru, en-ar, en-zh ja en-fr -kieleen. Keräämme en-hi-rinnakkaisdataa IIT Bombayn korpuksesta BIBREF19 ja en-vi-dataa OpenSubtitles 2018:sta.",
      "id": "task461-855b4d8e034e453d88065e07f4977def",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Rakensimme vihamielisen puheen havaitsemista meemeistä varten tietokokonaisuuden, jossa oli 5 020 kuvaa, jotka oli heikosti merkitty vihamielisiksi tai ei-vihamielisiksi meemeiksi niiden lähteen mukaan.",
      "id": "task461-5ebf2e7d670d482e84110923120425f0",
      "output": [
        "Miten kukin tietokokonaisuuden instanssi on kommentoitu?"
      ]
    },
    {
      "input": "Kunkin testijoukon osalta käytämme vastaavia harjoituskysymyksiä $Q_\\mathit {tr}$ hakeaksemme alaan liittyviä lauseita S:stä. Tarkemmin sanottuna käytämme jokaisen Q_\\mathit {tr}$:n monivalintakysymyksen $(q,A) \\ ja jokaisen A$:n vaihtoehdon $a \\a$ kohdalla kaikkia $q$:n ja $a$:n sisältämiä ei-stop-sanamerkkejä ElasticSearchin kyselynä S:lle. Otamme 200 parasta osumaa, suoritamme Open IE v4:n ja yhdistämme tuloksena saadut tuplat kaikkien $a \\ A$:n ja kaikkien $Q_\\mathit {tr}$:n kysymysten yli luodaksemme tuplan KB (T).",
      "id": "task461-9ab696667711455b8231c846af06454a",
      "output": [
        "Mitä menetelmää käytettiin OpenIE-uutteiden tuottamiseen?"
      ]
    },
    {
      "input": "Arvioimme kysymysten tuottamisessa yleisesti käytetyillä mittareilla BIBREF13: BLEU-1 (B1), BLEU-2 (B2), BLEU-3 (B3), BLEU-4 (B4) BIBREF17, METEOR (MET) BIBREF18 ja ROUGE-L (R-L) BIBREF19. Käytämme Chen2015MicrosoftCC:n julkaisemaa arviointiskriptiä.",
      "id": "task461-0f10a77c205e410bad0c1bfb3ba83078",
      "output": [
        "Mitä mittareita he käyttävät?"
      ]
    },
    {
      "input": "Huomaa, että vain noin 12 prosentissa (7 kärkeä 59:stä) eniten siteeratuista tutkimusaloista naiset saivat keskimäärin enemmän viittauksia kuin miehet. Näihin kuuluvat: sentimenttianalyysi, tiedonlouhinta, asiakirjojen tiivistäminen, puhuttu dialogi, monikielisyys (tutkimus), dialogi, järjestelmät, kielen tuottaminen. (Huomaa tietysti, että osa 59:stä alueesta, kuten otsikkotermien bigrammien avulla arvioituna, on päällekkäisiä. Emme myöskään sisällyttäneet edellä olevaan luetteloon suursanastoa, koska keskiarvojen ero on hyvin pieni ja koska se ei ole varsinainen tutkimusalue). Siten viittauskuilu on yleistä suurimmalla osalla NLP:n korkean viittausmäärän alueista.",
      "id": "task461-b4768156d85f4828982139704bc113e2",
      "output": [
        "Millä NLP-alueella on korkein keskimääräinen siteeraus naiskirjoittajalle?"
      ]
    },
    {
      "input": "Käytimme vain 300 ulottuvuuden malleja ja Word2Vec-, Wang2Vec- ja FastText-malleissa skip-grammiarkkitehtuurin malleja.",
      "id": "task461-3c4af254f17240bfb84ebb0c2c5fa448",
      "output": [
        "mitä sanojen upottamistekniikoita he kokeilivat?"
      ]
    },
    {
      "input": "Vertaamme ehdotettuja malleja olemassa oleviin sanojen upottamismenetelmiin. Nämä ovat: Bernoulli embeddings (b-emb) BIBREF1 , continuous bag-of-words (CBOW) BIBREF5 , Distributed Memory version of Paragraph Vector (PV-DM) BIBREF11 ja Global Vectors (GloVe) BIBREF6.",
      "id": "task461-5c45869f507047c69ebd785e309d31cb",
      "output": [
        "Mitä sanasulkeumia he testaavat?"
      ]
    },
    {
      "input": "Nämä ominaisuudet saadaan yleensä kouluttamalla syvää neuroverkkoa yhdessä useilla kielillä, joista on saatavilla merkittyjä tietoja. Verkon alimmat kerrokset ovat yleensä yhteisiä kaikille harjoituskielille. Tämän jälkeen verkko jakautuu erillisiin osiin kutakin kieltä varten tai sillä on yksi yhteinen ulostulo. Viimeisen ulostulokerroksen kohteina ovat puhelimien merkinnät tai HMM-tilat. Viimeisen jaetun kerroksen dimensiot ovat usein pienempiä kuin tulokerroksen, ja siksi sitä kutsutaan \"pullonkaulaksi\".",
      "id": "task461-848f901ded2544a9a83b5956e8408d72",
      "output": [
        "Mitkä ovat pullonkaulaominaisuuksia?"
      ]
    },
    {
      "input": "Korpus koostuu 53 asiakirjasta, joissa on keskimäärin 156,1 lausetta asiakirjaa kohti ja joissa jokaisessa on keskimäärin 19,55 merkkiä.",
      "id": "task461-b2c9743d5ad54caf8d77b521bff77db6",
      "output": [
        "Kuinka monta asiakirjaa uudessa korpuksessa on?"
      ]
    },
    {
      "input": "Tässä jaksossa raportoidaan kahdella aineistolla suoritettujen kokeiden tulokset, joilla arvioidaan wDTW:n ja wTED:n suorituskykyä muihin perusmenetelmiin verrattuna. Merkitsemme seuraavia etäisyys- ja samankaltaisuusmittoja. WMD: kohdassa SECREF1 esitelty Word Mover's Distance. VSM: jaksossa UID12 esitelty samankaltaisuusmitta. PV-DTW: PV-DTW on sama kuin algoritmi SECREF21 , paitsi että kahden kappaleen välinen etäisyys ei perustu algoritmiin SECREF20, vaan se lasketaan INLINEFORM0:n avulla, jossa INLINEFORM1 on kappaleen INLINEFORM2 PV-sisällyttäminen. PV-TED: PV-TED on sama kuin algoritmi SECREF23 , paitsi että kahden kappaleen välinen etäisyys ei perustu algoritmiin SECREF20 vaan lasketaan INLINEFORM0:n avulla.",
      "id": "task461-63d2a28b4cdd476b86b1f567bc039a4d",
      "output": [
        "Mitkä ovat uusimmat mallit?"
      ]
    },
    {
      "input": "Olemme osoittaneet, että muuntajapohjaiset kooderit yhdessä GRU-mallien kanssa tarjoavat parhaan suorituskyvyn kysymysten esittämisessä. Erityisesti osoitimme, että esivalmennettujen tekstiedustusten käyttö parantaa suorituskykyä johdonmukaisesti useilla hyperparametrikokoonpanoilla. Olemme myös osoittaneet, että ulkoisen datan avulla hienosäädetyn objektinilmaisimen käyttö parantaa tarkkuutta huomattavasti. Lisäksi olemme osoittaneet, että huomiomekanismit ovat ensiarvoisen tärkeitä huippusuorituskykyisten verkkojen oppimisessa, kun ne mahdollistavat kysymystietoisten kuvarepresentaatioiden tuottamisen, jotka kykenevät koodaamaan avaruudellisia suhteita. On käynyt selväksi, että Top-Down on suositeltavin huomiomenetelmä, kun otetaan huomioon sen tulokset ReLU-aktivoinnin kanssa.",
      "id": "task461-4a68d0d6794f4e0c859f3fb19b3e3c5b",
      "output": [
        "Mitkä osatekijät on määritelty VQA-mallien koulutuksen keskeisiksi osatekijöiksi?"
      ]
    },
    {
      "input": "He käyttivät 20 miljoonan sanan dataa, joka oli satunnaisesti poimittu CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings BIBREF8 -tehtävässä julkaistusta raakatekstistä, joka on yhdistelmä Wikipedian tyhjennystä ja yleistä indeksointia.  Vertasimme esimerkiksi ELMoForManyLangsin latvian kielen mallia malliin, jonka koulutimme täydellisellä (wikidump + common crawl) latvian kielen korpuksella, jossa on noin 280 miljoonaa merkkiä.",
      "id": "task461-92ceee5092804a9bb20bbcb57feac0f5",
      "output": [
        "Kuinka suuret ovat näiden ELMo-versioiden harjoitusjoukot verrattuna aiempiin versioihin?"
      ]
    },
    {
      "input": "Menetelmämme avulla merkitsimme 10 000 arabiankielisen twiitin aineiston loukkaavuuden perusteella, ja loukkaavien twiittien osuus oli noin 19 prosenttia twiiteistä. Lisäksi merkitsimme twiitit mauttomiksi tai vihapuheiksi. ",
      "id": "task461-61f26498f7654caabbf8e7a3ddb546d7",
      "output": [
        "Kuinka monta twiittiä tietokannassa on?"
      ]
    },
    {
      "input": "Huomasimme, että kaikki testaamamme tekijät voivat vaikuttaa laadullisesti siihen, miten malli yleistyy kysymyksenmuodostustehtävässä. Näitä tekijöitä ovat toistuvan yksikön tyyppi, huomion tyyppi ja peräkkäisen vs. puupohjaisen mallin rakenteen valinta.",
      "id": "task461-efc5ba5bd3574d1a98fe7b133e3c9500",
      "output": [
        "Mitä arkkitehtonisia tekijöitä tutkittiin?"
      ]
    },
    {
      "input": "Vertaamme ehdottamaamme diskreettiä CVAE:tä (DCVAE) kaksivaiheisella otantamenetelmällä kolmeen luokkaan kuuluviin vasteiden muodostamismalleihin: Perusasetukset: CVAE BIBREF14: Mukautamme alkuperäisen työn, joka koskee monikierroksista keskustelua, yhden kierroksen asetelmaa varten. Oikeudenmukaisen vertailun vuoksi käytämme samoja avainsanoja, joita käytimme verkon esivalmennuksessa, tietoon perustuvina ominaisuuksina tässä mallissa. muut parannetut koodaaja-dekooderimallit: Hierarchical Gated Fusion Unit (HGFU) BIBREF12, joka sisällyttää dekooderiin pistemäisen keskinäisen informaation (PMI) avulla poimitun vihjesanan mielekkäiden vastausten luomiseksi; Mechanism-Aware Neural Machine (MANM) BIBREF13, joka ottaa käyttöön latentteja upotuksia, jotta voidaan luoda useita erilaisia vastauksia.",
      "id": "task461-b36a7682869e4e87bbe003f9e9a21da0",
      "output": [
        "Millaisia muita sukupolvimalleja kokeissa käytetään?"
      ]
    },
    {
      "input": "(ehdotettu) Bi-LSTM/CRF + Bi-CharLSTM ja modaliteettihuomio (W+C): käyttää modaliteettihuomiota yhdistämään sana- ja merkkikokoelmia. (ehdotettu) Bi-LSTM/CRF + Bi-CharLSTM + Inception (W+C+V): ottaa syötteenä InceptionNetistä poimittuja visuaalisia konteksteja, jotka on yhdistetty sana- ja merkkikokoelmavektoreihin.(ehdotettu) Bi-LSTM/CRF + Bi-CharLSTM + Inception with modality attention (W+C+V): käyttää modaliteettihuomiota yhdistämään sana-, merkki- ja visuaaliset upotukset syötteenä entiteetti-LSTM:lle.",
      "id": "task461-36931185333d4f1086cccaf89da4e8df",
      "output": [
        "Oppiiko heidän NER-mallinsa NER:ää sekä tekstistä että kuvista?"
      ]
    },
    {
      "input": "Koska muuntosääntöjämme on tulkittavissa, tunnistamme puutteet molemmissa resursseissa ja käytämme kumpaakin toistensa validoimiseksi. Pystyimme löytämään tiettyjä tapauksia, joissa UniMorph-merkintöjä oli sovellettu virheellisesti, sekä erityisiä tapauksia, joissa molemmissa resursseissa oli kieltenvälisiä epäjohdonmukaisuuksia.",
      "id": "task461-ecc6941c108046a5b153d12ba5525a81",
      "output": [
        "Etsitäänkö UniMorphissa eri kielten annotaatioiden välisiä epäjohdonmukaisuuksia?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa kokeillaan neljää erilaista luokittelumallia, mukaan lukien logistinen regressio (LR), rekursiivinen neuroverkko (RNN) BIBREF35, konvoluutio-neuroverkko (CNN) BIBREF36 ja Google BERT BIBREF37. ",
      "id": "task461-dd4dd197042a4c138b78938cb47b5c67",
      "output": [
        "Mitä asiakirjaluokittelijoita he kokeilevat?"
      ]
    },
    {
      "input": "Käytämme 16 erilaista tietokokonaisuutta, jotka ovat peräisin useista suosituista BIBREFissä20 käytetyistä arvostelukorpuksista. Nämä tietokokonaisuudet koostuvat 14 tuotearvostelutietokokonaisuudesta ja kahdesta elokuva-arvostelutietokokonaisuudesta. Käytämme CoNLL 2000 BIBREF22 -jaksomerkintätietokokonaisuutta sekä POS Tagging- että Chunking-tehtävissä.",
      "id": "task461-dcf33b506ca740f7b2ef4a1db841189a",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": ". Vaikka automaattiset arviointimittarit, kuten ROUGE, mittaavat koneellisten ja inhimillisten tiivistelmien välistä leksikaalista samankaltaisuutta, ihmiset voivat mitata paremmin sitä, kuinka johdonmukainen ja luettava tiivistelmä on. Arviointitutkimuksessamme tutkitaan, lisääkö PG-net-mallin virittäminen tiivistelmän johdonmukaisuutta pyytämällä arvioijia valitsemaan, mistä kolmesta saman asiakirjan tiivistelmästä he pitävät eniten: CNN/DM:llä koulutetusta PG-net-mallista, opiskelijoiden pohdinnoilla koulutetusta mallista ja lopuksi CNN/DM:llä koulutetusta ja opiskelijoiden pohdinnoilla viritetystä mallista. Laitoksestamme rekrytoitiin 20 arvioijaa, joita pyydettiin tekemään kukin 20 annotaatiota. Yhteenvedot esitetään arvioijille satunnaisessa järjestyksessä. Arvioijia pyydetään sitten valitsemaan tiivistelmä, joka on heidän mielestään luettavin ja johdonmukaisin.",
      "id": "task461-59f7997224c54d679eecff8a166ccc2f",
      "output": [
        "Keitä käytettiin ihmisarvioijina?"
      ]
    },
    {
      "input": "Taulukossa 1 on esimerkki vaikeista ja helpoista esimerkeistä vaikeuden määritelmämme mukaisesti. Alleviivattu teksti kuvaa toimialan asiantuntijoiden antamaa (yksimielistä) viitemerkintää. Vaikeissa esimerkeissä joukko työntekijöitä merkitsi tekstin, joka erosi näistä referenssimerkinnöistä, kun taas helpoissa tapauksissa he toistivat ne kohtuullisen tarkasti. Vaikeat lauseet ovat yleensä rakenteeltaan monimutkaisia ja niissä on jargonia.",
      "id": "task461-b0cf96df3f1e41c7979a4fe6fb4c8827",
      "output": [
        "Onko instanssi lause vai IE-tuple?"
      ]
    },
    {
      "input": "Kommentoija äänestää yhtä seitsemästä tunteesta eli Ekmanin kuutta perustunnetta BIBREF1 sekä neutraalia.",
      "id": "task461-47ede58175b344fd99ec15a66c1a7227",
      "output": [
        "Mitä merkintöjä tietokokonaisuudella on?"
      ]
    },
    {
      "input": "Määritimme palkkion arvoksi 1, jos tehtävä on suoritettu onnistuneesti, ja 0, jos se ei ole suoritettu onnistuneesti. $0.95$:n alennusta käytettiin kannustamaan järjestelmää suorittamaan dialogit nopeammin kuin hitaammin, jolloin palautus oli 0 epäonnistuneista dialogeista ja $G = 0.95^{T-1}$ onnistuneista dialogeista, missä $T$ on järjestelmän vuorojen määrä dialogissa.   0.95^{T-1} palkinto 0.95^{T-1} ",
      "id": "task461-93271390f83c46e1aeaef757619b0948",
      "output": [
        "Mikä on vahvistusoppimisen sovelluksen palkitsemismalli?"
      ]
    },
    {
      "input": "Kokeiluaineisto on peräisin Microsoft Research (MSR) -yritykseltä. Se sisältää kolme aluetta: elokuva, taksi ja ravintola. Taulukossa TABREF11 ilmoitetaan dialogien kokonaismäärä alueittain ja koulutus-/validointi-/testijakauma. Joka käänteessä sekä käyttäjän että agentin tekoja kommentoidaan, mutta käytämme kokeessamme vain agenttipuolta kohteina. Teot on järjestetty tietokokonaisuudessa (jokainen tulostettu lause vastaa yhtä tekoa).",
      "id": "task461-b5812e4bbf4d46c5b56b24a5bbc0d675",
      "output": [
        "Mitä tietokokonaisuuksia käytetään mallien harjoittelussa/testauksessa? "
      ]
    },
    {
      "input": "KryptoOracle on rakennettu Apachen ekosysteemiin ja käyttää Apache Sparkia. Sparkin tietorakenteet perustuvat resilientteihin hajautettuihin datajoukkoihin (RDD), jotka ovat vain lukukelpoisia moniulotteisia datajoukkoja, jotka voidaan hajauttaa koneklusteriin ja jotka ovat vikasietoisia.  Spark RDD:llä on luontainen kyky toipua itsestään, koska se tallentaa kaikki suoritusvaiheet lineage-graafiin. Jos järjestelmässä ilmenee vikoja, Spark tekee uudelleen kaikki aiemmat suoritukset rakennetusta DAG:sta ja palautuu edelliseen vakaaseen tilaan mistä tahansa viasta, kuten muistin ylikuormittumisesta. Spark RDD:t ovat KryptoOracin ytimessä ja helpottavat siksi sen toipumista vioista. Lisäksi muistin ylikuormituksen tai järjestelmän kaatumisen kaltaiset viat saattavat vaatia koko järjestelmän kovaa uudelleenkäynnistystä. Koska Apache Hivessä on kuitenkin monistetut kopiot RDD-tietueista ja koneoppimismallin aiempi tila on tallennettu, KryptoOracle voi helposti palautua edelliseen vakaaseen tilaan.",
      "id": "task461-9dee0f574ca940718e11b5590875bf99",
      "output": [
        "Miten arkkitehtuuri on vikasietoinen?"
      ]
    },
    {
      "input": " Kehitystietojen merkitsemätöntä joukkoa käytettiin sekä UBM:n että i-vektorin poimijan koulutuksessa.",
      "id": "task461-82b751cdda0a476c82cd6bbfa503d36f",
      "output": [
        "Valitaanko kiinteästä SRE-koulutusjoukosta validointijoukko?"
      ]
    },
    {
      "input": "Tässä tehtävässä käytetty aineisto on peräisin Switchboardin englanninkielisestä keskustelukorpuksesta BIBREF31 .",
      "id": "task461-cc5192d4262b47d9aa4db3ffe4997808",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Tässä artikkelissa esitellään kuvassa 1 esitetty koneellisen luetun ymmärtämisen ekstraktio- ja synteesi-kehys, jossa vastaus syntetisoidaan ekstraktiotulosten perusteella. Rakennamme todisteiden louhintamallin, jolla ennustetaan tärkeimpiä osa-alueita tekstikappaleista todisteiksi, ja sitten kehitämme vastauksen synteesimallin, joka ottaa todisteet lisäominaisuuksina yhdessä kysymyksen ja tekstikappaleen kanssa lopullisen vastauksen tarkentamiseksi.",
      "id": "task461-4212d53a559249768445a1b4f20a8c4f",
      "output": [
        "Mitä puitteita he ehdottavat tässä asiakirjassa?",
        "Mitkä kaksi osatekijää sisältyvät heidän ehdottamaansa kehykseen?"
      ]
    },
    {
      "input": "Jokaista syötteen Open IE -tuplan $(S; P; O_1; O_2 \\ldots )$ kohdetta $O_i$ varten lisätään tähän taulukkoon kolmikko $(S; P; O_i)$.",
      "id": "task461-53fa0429e68342238a0e764f5e4165ed",
      "output": [
        "Ovatko OpenIE-uutteet kaikki kolmosia?"
      ]
    },
    {
      "input": "Testaamme merkki- ja sanatason variantteja ennustamalla hashtageja pidättäytyneelle testiviestien joukolle.",
      "id": "task461-c56967a76c4747959231798b9ba98fee",
      "output": [
        "Millä muilla tehtävillä he testaavat menetelmäänsä?"
      ]
    },
    {
      "input": "Moduulit: Moduulit ovat erilaisten mallien perusrakennuspalikoita. LeafNATSissa tarjoamme valmiita moduuleja, joilla voidaan rakentaa NATS:lle RNN-pohjaisia sekvenssistä sekvenssiin (Seq2Seq) perustuvia malleja, esimerkiksi osoitinverkkogeneraattoriverkko BIBREF1 . Näihin moduuleihin kuuluvat muun muassa upottaja, RNN-kooderi, huomio BIBREF24 , ajallinen huomio BIBREF6 , huomio dekooderissa BIBREF2. Käytämme näitä perusmoduuleja myös kootaksemme osoitingeneraattorin dekooderimoduulin ja vastaavat palkkihakualgoritmit. Upotuskooderin avulla voidaan myös toteuttaa upotus-painojen jakomekanismi BIBREF2 .",
      "id": "task461-d5ac4fc5890e471fbb59cbb683b1b08f",
      "output": [
        "Mitä malleja työkalupakki sisältää?"
      ]
    },
    {
      "input": "Järjestelmämme oppii Perceptron-malleja BIBREF37 käyttäen Apache OpenNLP -projektin tarjoamaa koneoppimiskoneistoa ja omia räätälöityjä (paikallisia ja klusterointi-) ominaisuuksia.  Paikalliset piirteet muodostavat perusjärjestelmämme, jonka päälle lisätään klusterointipiirteet.",
      "id": "task461-1d17d469ea914f65af2423cec37fdedb",
      "output": [
        "mitkä ovat peruslinjat?"
      ]
    },
    {
      "input": "Facebook-sivujen lopullinen kokoelma tässä artikkelissa kuvattuja kokeita varten on seuraava: The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Paavo, Disney.",
      "id": "task461-b469386262b24116b90d9c796eefb568",
      "output": [
        "Mitä Facebook-sivuja he katsoivat?"
      ]
    },
    {
      "input": "Käytämme kolmea luovaa englanninkielistä tietokokonaisuutta, joilla on erilaiset kielelliset ominaisuudet: (1) 740 klassisen ja nykyaikaisen englanninkielisen runon korpus, (2) 14950 metaforalauseen korpus, joka on haettu metaforatietokannan verkkosivulta, ja (3) 1500 laulun sanoituksen korpus, joka koostuu eri genreistä.  Ensin esivalmennamme generaattorimme Gutenbergin tietokokonaisuudella BIBREF24 20 epookin ajan ja sitten hienosäädämme BIBREF19 niitä kohdetietokantojamme varten kielimallinnustavoitteella.",
      "id": "task461-3c01613b4503491ab074b5010abbb31c",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Ehdotimme yhteisesti oppivia NLP-malleja, joissa käytetään perusyksikköinä konvoluutiohermoverkkoa (convolutional neural network, CNN) BIBREF8 ja kaksisuuntaista pitkää lyhytkestoista muistia (bi-directional long short-term memory, BiLSTM) BIBREF9, BIBREF10. Mallimme voivat automaattisesti poimia seksuaalista häirintää koskevista tarinoista keskeiset elementit ja samalla luokitella tarinat eri ulottuvuuksiin. Ehdotetut mallit päihittivät yhden tehtävän mallit ja saavuttivat korkeamman tarkkuuden kuin aiemmin raportoidut tarkkuudet ahdistelulomakkeiden luokittelussa BIBREF6.",
      "id": "task461-29e018e836e743b6a44dfeeae74fa169",
      "output": [
        "Mitä mallia he käyttivät?"
      ]
    },
    {
      "input": "Merkintöihin osallistui kaikkiaan noin 500 eri työntekijää. noin 500",
      "id": "task461-a0979dcf631c49b5951b37551a0fbe39",
      "output": [
        "Kuinka monta henkilöä osallistui heidän taulukoista tekstiksi -mallien arviointitutkimukseensa?"
      ]
    },
    {
      "input": "Taulukossa TABREF31 esitetään ehdotettujen mallien F-tulos, ROC-käyrän alapuolinen alue (AUC) ja keskimääräinen tarkkuus (ACC), kun käytettävissä on erilaisia syötteitä. Kuvassa FIGREF32 esitetään eri mallien Precision vs Recall -diagrammi ja ROC-käyrä (jossa esitetään True Positive Rate vs False Positive Rate).",
      "id": "task461-9ecedc66ebac42df84f66caf95309c72",
      "output": [
        "Mitä mittareita käytetään tulosten vertailemiseksi?"
      ]
    },
    {
      "input": "Turisti: Matkailija: En voi mennä enää suoraan eteenpäin.Opas: Selvä: Opas: Joo. Katsoin väärää pankkiaTuristi: Matkailija: Ilmoitan, kun olen takaisin Brooks Brothersin ja pankin luona.Matkailija: OPAS: käänny oikealle, kun pankki on vasemmalla puolellasiTuristi: käänny oikealle, kun pankki on vasemmalla puolellasiTuristi: käänny oikealle, kun pankki on vasemmalla puolellasi: TOIMINTA:ETEENPÄIN TOIMINTA:ETEENPÄIN TOIMINTA:KÄÄNTÄÄNOIKEALLETuristi: Oikealle kääntyminen pankin kohdalla.turisti: ACTION:FORWARD ACTION:FORWARDTourist: Turisti: En voi mennä tuohon suuntaan: ACTION:TURNLEFTTuristi: Turisti: Pankki on edessäni oikeallaTuristi: KÄÄNTYMINEN: Käänny oikealle: ACTION:FORWARD ACTION:FORWARD ACTION:TURNLEFTGuide: käänny ympäri tuossa risteyksessäTuristi: Matkailija: Voin mennä vain vasemmalle tai takaisin sitä tietä, jota juuri tulin.Matkailija: Turisti: Voin mennä vain vasemmalle tai takaisin sitä tietä, jota juuri tulin: Näetkö kulmilla olevia kauppoja?Opas: Opas: Käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle, käänny vasemmalle: Turisti: Jos olet pankin kulmassa, mene kadun yliTuristi: Jos olet pankin kulmassa, mene kadun yliTuristi: Jos olet pankin kulmassa, mene kadun yli: Turisti: Olen takaisin siinä, mistä aloitin, kaupan ja pankin luona.Turisti: Opas: Mene takaisin: KÄÄNNY OIKEALLE.",
      "id": "task461-41892966398c486aa273cd33b8d66a0e",
      "output": [
        "Millä kielellä agentit puhuvat?"
      ]
    },
    {
      "input": "Vertailukohteiden arviointi ::: luokittelumallitSVM: MLP: Monikerroksinen perceptron, jonka syötteenä on USE embeddings BIBREF4.FastText: Pinnallinen neuroverkko, joka keskiarvoistaa n-grammien upotukset BIBREF5.CNN: Convolutional neural network with non-static word embeddings initialized with GloVe BIBREF6.BERT: Neuroverkko, joka on koulutettu ennustamaan tekstissä esiintyviä väistyneitä sanoja ja joka on sitten hienosäädetty aineistollamme BIBREF1.Platforms: Alustat: Tehtäväkeskeisten agenttien kehittämiseen on olemassa useita alustoja. Tarkastelemme Googlen DialogFlowta ja Rasa NLU:ta spacy-sklearnilla.",
      "id": "task461-248cb6b68a1044be88e32b2509e437d4",
      "output": [
        "Mitkä luokittelijat arvioidaan?"
      ]
    },
    {
      "input": "Hypoteesi 4 (H4) : Ehdotettu mallipohjainen synteesimalli on parempi kuin pelkkä sanojen korvausmalli. Taulukko TABREF13 tukee H4:ää osoittamalla, että ehdotettu synteesimalli on parempi kuin WordNet-perusmalli koulutuksessa (rivit 7, 8 ja 19, 20) lukuun ottamatta Stat2016:ta ja virityksessä (10, 11 ja 22, 23) kaikilla kursseilla. Se osoittaa myös, että vaikka synteettisen datan lisääminen perustasosta ei aina auta, synteettisen datan lisääminen mallimallista auttaa parantamaan sekä koulutus- että viritysprosessia. Sekä CS- että ENGR-kursseilla synteettisen datan virittäminen parantaa kaikkia ROUGE-pistemääriä verrattuna virittämiseen vain alkuperäisellä datalla. (rivit 9 ja 11). Stat2015-kurssin osalta R-1 ja R-$L$ paranivat, kun taas R-2 heikkeni. Stat2016:n osalta R-2 ja R-$L$ paranivat ja R-1 heikkeni (rivit 21 ja 23). Harjoittelu sekä opiskelijoiden pohdintatiedoilla että synteettisillä tiedoilla verrattuna harjoitteluun vain opiskelijoiden pohdintatiedoilla tuottaa samanlaisia parannuksia, mikä tukee H3:a (rivit 6, 8 ja 18, 20).",
      "id": "task461-26224f6593fa457989d322b49852cff7",
      "output": [
        "Onko mallipohjainen malli realistinen?  "
      ]
    },
    {
      "input": "Samoin kuin BIBREF9:ssä, kokeilemme SVM:ää RBF-ytimellä, jonka piirteet edustavat (1) argumenttipuun yksinkertaisia ominaisuuksia ja (2) väitteen kielellisiä ominaisuuksia.",
      "id": "task461-0ed7e044ba22430f95f01cff8910736a",
      "output": [
        "Mitä malleja, jotka perustuvat ainoastaan väittämäkohtaisiin kielellisiin piirteisiin, käytetään vertailukohtina?"
      ]
    },
    {
      "input": "Kun tarkastellaan nykyistä WinoGrande-listaa, näyttää siltä, että tekniikan edellinen taso perustuu RoBERTa BIBREF2:een, jota voidaan luonnehtia pelkän koodaimen muuntimen arkkitehtuuriksi.",
      "id": "task461-0439625bc2a44e55b1abc157103ec901",
      "output": [
        "Mikä on tekniikan aiempi taso?"
      ]
    },
    {
      "input": "Jotta oppisimme paremman graafisen esityksen usean osapuolen dialogeista, otamme käyttöön dialogit, joissa on 8-15 lausetta ja 3-7 puhujaa. Tehtävän yksinkertaistamiseksi suodatamme dialogit, joissa on pitkiä lauseita (yli 20 sanaa). Lopulta saamme 52 053 dialogia ja 460 358 lausumaa.",
      "id": "task461-12a036decd194afeaa5a7fb40c3083fe",
      "output": [
        "Kuinka suuri ehdotettu tietokokonaisuus on?"
      ]
    },
    {
      "input": "Kokeissamme vertailimme noin 60 perusmittaria, jotka voidaan jakaa seuraavasti:MT-mittaritBLEU, ROUGE, METEOR, TERpBLEU:n muunnokset: BLEU_1gram, BLEU_2gram, BLEU_3gram, BLEU_4gram ja seitsemän tasoitusmenetelmää NLTK:n BIBREF32:sta.TERp:n väliosat, jotka ovat BIBREF18:n innoittamia: esim. lisäysten, poistojen, siirtojen jne. määrä.Luettavuusmetriikat ja muut lausetason ominaisuudet: BIBREF28 , kuten sanojen lukumäärää, sanojen pituuksia, kielimallin todennäköisyyttä ja INLINEFORM0 -grammitaajuutta koskevat tilastot, kielimallin todennäköisyyttä ja INLINEFORM0 -grammitaajuutta koskevat metriikat.Muihin piirteisiin perustuvat metriikat: frekvenssitaulukon sijainti, konkreettisuus sellaisena kuin se on poimittu BIBREF33 'n BIBREF33 -luettelosta, sanojen kielimallin todennäköisyys käyttäen BIBREF:n34 konvoluutio-sekvenssi-sekvenssimallia, vertailumenetelmät käyttäen valmiiksi koulutettuja fastText-sanojen upotuksia BIBREF35 tai Skip-thought-lauseiden upotuksia BIBREF36 .",
      "id": "task461-07c45beeb486459e995607f672b8ad69",
      "output": [
        "mitä lähestymistapoja verrataan?"
      ]
    },
    {
      "input": "Yhdistämme yhteistyö- ja e-yhteistyöelimet a) yhdistämällä niiden tuotokset (AVG) tai b) yhdistämällä kokonaisuuden ja sen nimen vinoviivalla (CONCAT), esim. seuraavasti: Jean_Marais / Jean Mara ##on.",
      "id": "task461-2935983b15e9476ca3f80761ae02cc3f",
      "output": [
        "Mitkä ovat kaksi tapaa koota yhteen yhteistyö- ja e-yhteistyömuodot?"
      ]
    },
    {
      "input": "Sovelsimme malliamme myös MCTest-tietokantaan, jossa koneiden on vastattava fiktiivisiä tarinoita koskeviin monivalintakysymyksiin. ",
      "id": "task461-528e2fd776634aae8c9c5eb8122674b6",
      "output": [
        "Kokeilevatko he ehdotettua mallia muilla kuin MovieQA:n aineistoilla?"
      ]
    },
    {
      "input": "Tässä työssä tutkimme menetelmämme soveltuvuutta kolmeen suosittuun arkkitehtuuriin: LSTM-pohjaiseen, CNN-pohjaiseen ja muuntajaan perustuvaan arkkitehtuuriin. Taulukossa TABREF46 esitetään menetelmämme suorituskyky eri sekvenssimallinnusarkkitehtuureilla. Taulukosta nähdään ensinnäkin, että LSTM-pohjainen arkkitehtuuri suoriutui paremmin kuin CNN- ja transformer-pohjaiset arkkitehtuurit. ",
      "id": "task461-414800fa899a46fa95bc2e54363a5ad9",
      "output": [
        "Mihin sekvenssimalliarkkitehtuureihin tämä menetelmä voidaan siirtää?"
      ]
    },
    {
      "input": " Annotaatiojärjestelmä kehitettiin kuvaamaan kolmea luokkahuonekeskustelun näkökohtaa, joiden on kirjallisuudessa katsottu olevan tärkeitä keskustelun laadun ja oppimismahdollisuuksien kannalta: argumentointi (prosessi, jossa idean tueksi esitetään systemaattisia perusteluja), spesifisyys (laatu, joka kuuluu tai liittyy yksiselitteisesti tiettyyn aiheeseen) ja tietämysalue (asiantuntemuksen alue, jota keskustelun sisältö edustaa).",
      "id": "task461-18a2f62291a643e084dfaaeefff19749",
      "output": [
        "miten he mittaavat keskustelun laatua?"
      ]
    },
    {
      "input": "Taulukossa TABREF32 esitetään mallien perpleksisyys kussakin testijoukossa. Odotetusti kukin malli suoriutuu paremmin testijoukossa, johon se on koulutettu. Kun mallia sovelletaan toiseen testijoukkoon, kummankin mallin perpleksiteetti kasvaa. Leipzigin mallilla näyttää kuitenkin olevan enemmän vaikeuksia yleistää: sen perpleksiteetti lähes kaksinkertaistuu SwissCrawl-testijoukossa ja nousee kaksikymmentä kertaa yhdistetyssä testijoukossa.",
      "id": "task461-08c235edd87942eb8c6a5d50238db0ff",
      "output": [
        "Miten kielen mallintamista arvioidaan?"
      ]
    },
    {
      "input": "Lisäksi käytämme myös kahta sen vastakohtajoukkoa, nimittäin AddSent ja AddOneSent BIBREF6 , arvioidaksemme MRC-mallien kestävyyttä kohinan suhteen. Vastakohtajoukkojen kohdat sisältävät harhaanjohtavia lauseita, joiden tarkoituksena on häiritä MRC-malleja.  Emme arvioi KAR:n suorituskykyä ainoastaan kehitysjoukolla ja testijoukolla, vaan teemme sen myös vastakkaisilla joukoilla. ",
      "id": "task461-1a497cf61268483da0d219481c8bdb7d",
      "output": [
        "Miten kirjoittajat tutkivat, onko malli kestävä kohinan suhteen vai ei?"
      ]
    },
    {
      "input": "Edellä esitetystä musiikin genrejen kuvauksesta käy ilmi, että supergenrejä ja johdannaislinjoja BIBREF19, BIBREF20 on rajallinen määrä, kuten kuviossa KUVIO 1 esitetään.Laskennallisesta näkökulmasta genret ovat luokkia, ja vaikka niitä voidaan käsitellä koneoppimisalgoritmeilla, ne eivät sisällä tietoa niiden välisistä suhteista. Jotta genrejen väliset suhteet voitaisiin virallistaa laskennallisia tarkoituksia varten, määrittelemme jatkuvan genreasteikon, joka ulottuu kokeellisimmasta ja introvertoiduimmasta supergenrestä euforisoivimpaan ja osallistavimpaan genreen. Valitsimme Wikipediasta 77 genreä, jotka mainitsimme lihavoituna edellisessä kappaleessa, ja pyysimme kahta riippumatonta arvioijaa lukemaan genrejen Wikipedian sivut, kuuntelemaan genren näytteitä tai artisteja (jos he eivät tienneet niitä jo ennestään) ja sitten kommentoimaan seuraavia ulottuvuuksia:",
      "id": "task461-fc8d367f8bb742db8853ac4de94f4bbd",
      "output": [
        "Kuinka monesta genrestä he keräsivät?"
      ]
    },
    {
      "input": "Tietokanta sisältää yhteensä 9710 kohtaa, joissa on keskimäärin 6,24 lausetta kohtaa kohti, 16,16 sanaa lausetta kohti ja joiden keskipituus on 86 sanaa.",
      "id": "task461-30e70244da134379a2f26743b689ff49",
      "output": [
        "Mikä on tämän tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Yksittäisten lauseiden esittämiseksi lisäämme ulkoisia [cls]-merkkejä kunkin lauseen alkuun, ja jokainen [cls]-symboli kerää sitä edeltävän lauseen piirteitä. Käytämme myös intervallin segmenttien upotuksia erottaaksemme useita lauseita asiakirjan sisällä. Tällä tavoin asiakirjan representaatiot opitaan hierarkkisesti, jolloin alemmat Transformer-kerrokset edustavat vierekkäisiä lauseita, kun taas ylemmät kerrokset yhdessä itsehuomautuksen kanssa edustavat usean lauseen diskurssia. Alkuperäisessä Bert-mallissa sijaintikoodausten enimmäispituus on 512. Ylitämme tämän rajoituksen lisäämällä lisää sijaintikoodauksia, jotka alustetaan satunnaisesti ja joita hienosäädetään koodaajan muiden parametrien avulla.",
      "id": "task461-c8ad7218cc854cc0a4f794836a594533",
      "output": [
        "Mitä uutta heidän asiakirjatason koodaajassaan on?"
      ]
    },
    {
      "input": "Osallistujat nauhoittavat äänileikkeitä lukemalla lahjoitetuista lauseista.",
      "id": "task461-cc1a2953924c46629c9fd5d02362f4f7",
      "output": [
        "Mitä aloja korpus kattaa?"
      ]
    },
    {
      "input": "Laskemme lauseen todennäköisyyden pitkä-lyhytkestoisen muistin (LSTM, korkereiter1997long) LM:llä eli erityisellä RNN LM:llä, joka on koulutettu suurella korpuksella. Koulutamme LSTM LM:t englanninkielisellä Gigaword-korpuksella BIBREF15 , joka koostuu uutisdatasta.",
      "id": "task461-407d547d3bae4266a309f40d7c933041",
      "output": [
        "mitä kielimalleja ne käyttävät?"
      ]
    },
    {
      "input": "Torch-Struct-kirjaston rakenne noudattaa sekä TensorFlow'n että PyTorch BIBREF29:n käyttämää jakeluliitäntää.",
      "id": "task461-5bce7a495e9640ff8435d2830e4dfa7f",
      "output": [
        "Antaako API mahdollisuuden liittää malleja, jotka on kirjoitettu jollakin muulla syväoppimiskehyksellä?"
      ]
    },
    {
      "input": "Käytämme luokittelukokeissamme BIBREF4:n käyttöön ottamaa MH17 Twitter -tietokokonaisuutta, joka on kerätty tutkimaan MH17-lento-onnettomuutta koskevan (epä)tiedon kulkua Twitterissä.",
      "id": "task461-28f7935d89fe45d28a1f72ab8a675ba5",
      "output": [
        "Mitä tietokokonaisuutta tässä tutkimuksessa käytetään?"
      ]
    },
    {
      "input": "Keräämme syötteeksi $37 263$ käsitejoukkoja, joista kukin sisältää kolmesta viiteen yhteistä käsitettä. Nämä käsitejoukot on poimittu useista suurista kuva-/videotekstien korpuksista siten, että niiden sisältämät käsitteet esiintyvät todennäköisemmin yhdessä luonnollisissa kohtauksissa. Tehtävässämme odotettujen käsitejoukkojen oletetaan esiintyvän luonnollisissa, jokapäiväisessä elämässä esiintyvissä kohtauksissa. Kuvien/videoiden kuvateksteissä olevilla käsitteillä, jotka yleensä kuvaavat jokapäiväisen elämämme kohtauksia, on siis haluttu ominaisuus. Keräämme siksi suuren määrän kuvatekstilauseet eri tietokannoista, kuten VATEX BIBREF4, LSMDC BIBREF12, ActivityNet BIBREF13 ja SNLI BIBREF15, ja muodostamme yhteensä 1 040 330 lausetta.",
      "id": "task461-a966f71630fe45feac8e35e43e3cff7c",
      "output": [
        "Mistä konseptisarjat tulevat?"
      ]
    },
    {
      "input": "Rekrytoimme 102 osallistujaparia Amazon Mechanical Turkista ja jaoimme satunnaisesti puhujan ja kuuntelijan roolit.",
      "id": "task461-fa87d502e4ec4d198e1512bb117e03c1",
      "output": [
        "Tehtiinkö tämä koe laboratoriossa?"
      ]
    },
    {
      "input": "Kunkin mallin osalta tarkasteltiin sanatason perpleksiteettiä, R@3 seuraavan sanan ennustamisessa, latenssia (ms/q) ja energiankulutusta (mJ/q). Tutkiaksemme perpleksiteetin ja palautuksen välistä suhdetta keräsimme yksittäisiä perpleksiteetti- ja palautustilastoja jokaisesta testisarjan lauseesta.",
      "id": "task461-731eb93d152b400c8d9503cfc6ba4a3e",
      "output": [
        "Mitä näkökohtia on vertailtu eri kielimallien välillä?"
      ]
    },
    {
      "input": "Siemenleksikko koostuu positiivisista ja negatiivisista predikaateista. Jos uutetun tapahtuman predikaatti on siemenleksikossa eikä siihen liity monimutkaisia ilmiöitä, kuten negaatiota, annamme tapahtumalle vastaavan polariteettipisteytyksen ($+1$ positiivisille tapahtumille ja $-1$ negatiivisille tapahtumille). Se on ",
      "id": "task461-cedb2fc1fa0d4016b968163490073880",
      "output": [
        "Mikä on siementen sanasto?"
      ]
    },
    {
      "input": "Kieliopillisten virheiden korjaaminen on haastava tehtävä, koska virhetyypit vaihtelevat ja virheet ovat syntaktisesti ja semanttisesti riippuvaisia ympäröivästä kontekstista. Useimmissa kielioppivirheiden korjausjärjestelmissä käytetään luokittelua ja sääntöpohjaisia lähestymistapoja tiettyjen virhetyyppien korjaamiseen. Nämä järjestelmät käyttävät kuitenkin useita kielellisiä vihjeitä ominaisuuksina. Tavanomaiset kielianalyysityökalut, kuten POS-taggerit (part-of-speech) ja jäsentimet, on usein koulutettu hyvin muodostetulle tekstille, ja ne toimivat huonosti epäkieliopillisessa tekstissä. Tämä aiheuttaa lisää virheitä ja rajoittaa sääntöpohjaisten ja luokitteluun perustuvien lähestymistapojen suorituskykyä GEC:ssä. Tämän seurauksena lausepohjainen tilastollinen konekääntäminen (SMT) on saavuttanut suosiota, koska se pystyy oppimaan tekstin muunnoksia virheellisestä tekstistä oikeaksi tekstiksi virheiden korjaamista rinnakkaisista korpuksista ilman kielellistä lisätietoa.  Me mallinnamme GEC-järjestelmämme fraasipohjaisen SMT-lähestymistavan pohjalta. Perinteiset fraasipohjaiset SMT-järjestelmät käsittelevät kuitenkin sanoja ja fraaseja erillisinä kokonaisuuksina. Hyödynnämme jatkuvan tilan esittämistä lisäämällä kaksi neuroverkkokomponenttia, joiden on osoitettu parantavan SMT-järjestelmiä BIBREF3 , BIBREF4 . NNJM:n kouluttamiseen käytämme julkisesti saatavilla olevaa toteutusta, Neural Probabilistic Language Model (NPLM) BIBREF14 . Mosesin uusin versio voi sisällyttää NPLM:n avulla koulutetun NNJM:n ominaisuudeksi dekoodauksen aikana. NNGLM:n tavoin käytämme NNJM:n kouluttamiseen käännösmallin kouluttamiseen käytettyä rinnakkaistekstiä. Lähdekonteksti-ikkunan koko on 5 ja kohdekonteksti-ikkunan koko 4. Valitsemme lähdekontekstin sanastoon 16 000 yleisintä sanaa lähdepuolelta. Kohdekontekstin sanastoksi ja tulostussanastoksi asetetaan 32 000 yleisintä sanaa. Käytämme yhtä piilokerrosta nopeuttaaksemme harjoittelua ja dekoodausta, kun syötteen upotusulottuvuus on 192 ja piilokerroksen solmut 512. ",
      "id": "task461-746e3d105640404f80f9f429f3ce3024",
      "output": [
        "Käyttävätkö ne neuroverkkomalleissaan esivalmennettuja sanarepresentaatioita?"
      ]
    },
    {
      "input": "Suoritamme kokeita SQuAD-tietokannan BIBREF1 asiakirjatason muunnoksilla.",
      "id": "task461-5b2335b0dab54bb497c8ffacef7046af",
      "output": [
        "Millä aineistoilla tätä menetelmää on arvioitu?"
      ]
    },
    {
      "input": "Valvojan arvioinnin korpus sisältää 26972 lausetta. ",
      "id": "task461-849e27dc2969403899d98113ad439027",
      "output": [
        "Mikä on todellisen tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Vaiheessa 1 (jota kutsutaan myös \"etsintävaiheeksi\") algoritmi tutkii tilaavaruutta pitämällä kirjaa aiemmin käytetyistä tiloista ylläpitämällä arkistoa. Tämän vaiheen aikana algoritmi ei jatka etsintää tyhjästä, vaan alkaa tutkia arkiston lupaavia tiloja löytääkseen tehokkaita ratoja.",
      "id": "task461-8f0581b96afc4f399f606effb18929b1",
      "output": [
        "Miten on kehityskaari miten palkkiot uutetaan?"
      ]
    },
    {
      "input": "Käytämme kokeissamme julkisesti saatavilla olevaa tietokokonaisuutta KVRET BIBREF5.  Tämä tietokokonaisuus sisältää vuoropuheluja kolmelta alueelta: kalenteri, sää ja navigointi (POI), mikä soveltuu eri alojen vuoropuhelukokeiluihin. ",
      "id": "task461-a36724be560f4c3d952bc679398ca677",
      "output": [
        "Mitä alueita he tutkivat?"
      ]
    },
    {
      "input": "Tässä jaksossa tarkastelemme kahdenlaisia relaatioiden luokittelutehtäviä: (1) relaatioiden ennustaminen ja (2) relaatioiden poimiminen.  Toivomme voivamme suunnitella yksinkertaisen ja selkeän koeasetelman, jonka avulla voimme tehdä virheanalyysin relaatioiden ennustamista varten. Siksi tarkastelemme tyypillistä menetelmää TransE BIBREF3:n kohteena ja FB15K BIBREF3:n tietokokonaisuutena. Relaatioiden louhintaa varten tarkastelemme valvottua relaatioiden louhinta-asetusta ja TACRED-tietokokonaisuutta BIBREF10 . Aiheen mallina käytämme TACRED-tietokannan parasta mallia - sijaintitietoista hermosekvenssimallia. ",
      "id": "task461-35bb583a8c5449db8114bd7796173cf7",
      "output": [
        "Mitä kilpailukykyisiä relaatioluokitusmalleja ne testaavat?"
      ]
    },
    {
      "input": "Jokainen twiitti tunnistettiin NLTK TweetTokenizer -ohjelmalla ja luokiteltiin yhdeksi kymmenestä mahdollisesta tilistä, jolta se saattoi olla peräisin. Tilit valittiin sen perusteella, mistä aiheista kunkin tiedetään yleensä twiittaavan.",
      "id": "task461-9094d468bd6f464da556289372872a01",
      "output": [
        "Mitä tekstin luokittelutehtävää tarkastellaan?"
      ]
    },
    {
      "input": "Kokeemme tehdään todellisella uhanalaisella kielellä, Mboshi (Bantu C25), jota puhutaan Kongo-Brazzavillessa, käyttäen BIBREF17:n kaksikielistä ranska-mboshi 5K -korpusta. Mboshi-kielen osalta tarkastelemme aakkosellista esitystapaa, jossa ei ole ääntämistietoa. Ranskan puolella otetaan huomioon vain oletusarvoinen segmentointi sanoihin.",
      "id": "task461-bebce46015e0428db60f0b1137858329",
      "output": [
        "Mitä tietokokonaisuutta käytetään tutkimuksessa?"
      ]
    },
    {
      "input": "Tässä mallissa käytetään tiettyä RNN-solua tallentamaan vain olennaiset tiedot annetusta kysymyksestä.  Dynaaminen muisti tallentaa tietoa $T$:ssä olevista olioista. Tärkein panoksemme on $s_t^T q$-termin lisääminen porttifunktioon. ",
      "id": "task461-9a03fec32f1f4eb3857efe26c338e2dc",
      "output": [
        "Miten malli tunnistaa entiteetit ja niiden suhteen vastauksiin päättelyhetkellä, kun vastaukset eivät ole saatavilla?"
      ]
    },
    {
      "input": "Koe-erässä 4 järjestelmämme (nimeltään FACTOIDS) saavutti korkeimman recall-pistemäärän 0,7033, mutta alhaisen tarkkuuden 0,1119, mikä jättää avoimeksi kysymyksen siitä, miten olisimme voineet tasapainottaa näitä kahta mittaria paremmin.",
      "id": "task461-262f24e457b24de8a7245b7ec9be0b7d",
      "output": [
        "Mikä oli heidän korkein muistipistemääränsä?"
      ]
    },
    {
      "input": "Käytämme ylimääräisiä INLINEFORM0-harjoitusartikkeleita, jotka on merkitty kustantajan mukaan, ohjaamattomana aineistona BERT-mallin harjoitteluun. Tutkimme ensin esivalmennuksen vaikutusta BERT-BASE:n suorituskykyyn.  Samalla tietokoneella mallin hienosäätö pienellä harjoitusjoukolla kesti vain noin 35 minuuttia sekvenssin pituuden 100 osalta. ",
      "id": "task461-8193e085893c402fa786d06c06b69294",
      "output": [
        "Miten nämä kaksi eri mallia koulutetaan?"
      ]
    },
    {
      "input": "Arvioidaksemme näytteenottostrategiaamme vertaamme sitä esivalmistettuun malliin ja hienosäädettyyn malliin 16 eri korpuksen avulla. Tulokset osoittavat, että lähestymistapamme on kaikissa korporaatioissa parempi kuin perusmenetelmämme: se saavuttaa keskimäärin 1,6 % alhaisemman puhelinvirheprosentin.",
      "id": "task461-055c0165d6044d68b6d6a0593eeb06ac",
      "output": [
        "Kuinka paljon ne ovat keskimäärin parempia kuin monikielinen perusmalli 16:ssa vähäisten resurssien tehtävässä?"
      ]
    },
    {
      "input": "Vertaamme lähestymistapaamme useisiin menetelmiin BIBREF1 , BIBREF31 , BIBREF11 , BIBREF8 , BIBREF10 , BIBREF39 kahdessa eri toimialueiden välisessä ympäristössä. Giménez-Pérez et al. BIBREF10 raportoi merkkijonoytimiä käyttäen paremmasta suorituskyvystä kuin SST BIBREF31 ja KE-Meta BIBREF11 monilähdealueilla. Lisäksi vertaamme lähestymistapaamme SFA BIBREF1:een, CORAL BIBREF8:aan ja TR-TrAdaBoost BIBREF39:ään yhden lähteen alueella. Transduktiiviset merkkijonojen ytimet. Esittelemme yksinkertaisen ja suoraviivaisen lähestymistavan merkkijonoille soveltuvan transduktiivisen samankaltaisuusmitan tuottamiseksi. Transduktiivinen ydinluokittimemme (TKC) koostuu kahdesta oppimisiteraatiosta. ",
      "id": "task461-c9bb1aa1917a43ae83f3682f84386f2b",
      "output": [
        "Mitä koneoppimisalgoritmeja käytetään?"
      ]
    },
    {
      "input": " Ensimmäinen, jäljempänä seq2seq, on tavallinen RNN-pohjainen neuraalinen konekäännösjärjestelmä, jossa kiinnitetään huomiota BIBREF0 . Tässä perustasossa ei käytetä jäsenneltyä dataa. Monilähdejärjestelmät parantavat huomattavasti molempia perustasoja, jopa 1,5 BLEU:n parannukset seq2seq-perustasoon verrattuna ja jopa 1,1 BLEU:n parannukset parse2seq-perustasoon verrattuna.",
      "id": "task461-6a79ef8317744181acb06432f8feebb8",
      "output": [
        "Mikä on heidän mallinsa suorituskyvyn lasku, kun ei ole analysoitua syötettä?"
      ]
    },
    {
      "input": "Arvioimme muunnettuja upotusmalleja ensin monikielisillä leksikaalisen samankaltaisuuden ja sukulaisuuden tehtävillä, jotta voimme varmistaa, että sanamerkityksen induktioprosessi ei haittaa upotusten yleistä suorituskykyä. Sen jälkeen testaamme merkityssisällön sulautuksia WSD-tehtävässä.",
      "id": "task461-625cc8d3a48749beaeb787ad200f4aeb",
      "output": [
        "Suoritettiinko ulkopuolinen arviointi?"
      ]
    },
    {
      "input": "Yksi monista muodoista, joihin FHIR voidaan sarjallistaa, on RDF. Koska RDF on kuitenkin suunniteltu abstraktiksi tietomalliksi ja FHIR on suunniteltu terveydenhuollon operatiiviseen käyttöön, mallien välillä voi olla pieni epäsuhta. Tämä ilmenee kahdella tavalla: Ensinnäkin RDF:ssä esitetään tosiseikkoja koskevia lausumia, kun taas FHIR:ssä esitetään tapahtumia koskevia tietueita. Toiseksi RDF:n on tarkoitus olla monotoninen, mikä tarkoittaa, että uudet tosiasiat eivät voi mitätöidä aiempia tosiasioita.",
      "id": "task461-93fbd3205e214347a2d77a935c8c7551",
      "output": [
        "Miten FHIR ja RDF yhdistetään?"
      ]
    },
    {
      "input": " Base koulutetaan vain puhtaalla datalla, kun taas Base+Noise koulutetaan sekä puhtaalla että meluisella datalla ilman kohinan käsittelyä. Global-CM käyttää kohinan mallintamiseen globaalia sekoitusmatriisia kaikille meluisille tapauksille, kuten BIBREF3:ssa ehdotetaan ja SECREF3-jaksossa esitellään. Samaa arkkitehtuuria käytetään Global-ID-CM:ssä, mutta sekoitusmatriisi alustetaan identiteettimatriisilla (kaavan DISPLAY_FORM5 sijaan) ja sitä mukautetaan vain harjoittelun aikana.Klusteripohjaiset mallit, joita ehdotamme jaksossa SECREF4, ovat Brown-CM ja K-Means-CM. Kokeilimme klusterien lukumäärää 5, 10, 25 ja 50. Mallit, jotka valitsevat vain suurimmat ryhmät $G$, on merkitty *-Freq-merkinnällä, ja ne valitsevat joko 30 tai 50 % klustereista. Interpolointimalleilla on jälkiliite *-IP, jossa $\\lambda \\in \\lbrace 0,3, 0,5, 0,7\\rbrace $ . Molempien yhdistelmää kutsutaan nimellä *-Freq-IP. Kuten kaikkien muidenkin hyperparametrien osalta, valinta tehtiin kehityssarjasta. toteutimme Cleaning BIBREF15- ja Dynamic-CM BIBREF14-mallit. Molempia malleja ei ollut kehitetty sekvenssien merkintätehtäviä varten, joten niitä oli mukautettava. Cleaning-mallin osalta noudatimme BIBREF3:n ohjeita. Dynamic-CM-mallin sulauttamis- ja ennustuskomponentit korvattiin perusmallimme mukaisesti. Tiheän kerroksen tulosta käytettiin syötteenä dynaamisen matriisin generoinnissa. Kokeilimme niiden ehdottaman jälkihäviön kanssa ja ilman sitä.",
      "id": "task461-6d6b19589468437ba5d88cd8ba9c7ce4",
      "output": [
        "Mitä käytetään perustasona?"
      ]
    },
    {
      "input": " Recurrent Neural Network (RNN) -kielimallit koulutetaan tuottamaan tulevan sanan todennäköisyysjakauma kontekstin perusteella ilman, että kontekstin rakennetta esitetään eksplisiittisesti BIBREF9, BIBREF10. ActionLSTMmallintaa lauseen linearisoidun sulkeistetun puurakenteen oppimalla ennustamaan seuraavaa toimintoa, jota tarvitaan lauseen rakenteen jäsentämiseen BIBREF16. Generatiiviset rekursiiviset neuroverkkokieliopit (RNNG)mallintavat yhdessä sanasekvenssin sekä taustalla olevan syntaktisen rakenteen BIBREF18.",
      "id": "task461-aa65ee19afb246dd9770bcad934bcde1",
      "output": [
        "Mitkä ovat perusmallit?"
      ]
    },
    {
      "input": "Arvioimme menetelmäämme IWSLT16:n saksan ja englannin (DE-EN) välisessä käännöksessä molempiin suuntiin, WMT15:n englannin ja saksan välisessä käännöksessä (EN-DE) molempiin suuntiin ja NIST:n kiinan ja englannin välisessä käännöksessä (ZH$\\rightarrow $EN). ",
      "id": "task461-3f8c7fea02724f3bb6fe64eb273cb757",
      "output": [
        "Mitä korpuksia käytetään?"
      ]
    },
    {
      "input": "Ilman ELMo:ta (sama asetus kuin taulukon 3 4. rivi ), data-asetuksemme ovat samat kuin qin-EtAl:2017:Long, jonka suorituskyky oli huippuluokkaa ja jota verrataan suoraan. Huomaamme, että suorituskykymme on parempi myös ilman esivalmennettua ELMo-kooderia, mikä johtuu pääasiassa paremmista lausepariedustuksistamme.",
      "id": "task461-6d4a4d8c8fd243a19035c1fcde6d5d38",
      "output": [
        "Miksi heidän mallinsa toimii paremmin kuin aiemmat mallit?"
      ]
    },
    {
      "input": "cQA-foorumien automatisointi voidaan jakaa kolmeen tehtävään: kysymyksen ja kommentin relevanssi (tehtävä A), kysymyksen ja kysymyksen relevanssi (tehtävä B) ja kysymyksen ja ulkoisen kommentin relevanssi (tehtävä C). Meidän cQA-tehtävissämme objektiparit ovat (kysymys, kysymys) tai (kysymys, kommentti), ja suhde on relevantti/relevantti. Tehtävässä C alkuperäisen kysymyksen (oriQ) ja ulkoisen kommentin (relC) lisäksi annetaan myös kysymys, jota relC kommentoi (relQ). Tämän lisätiedon sisällyttämiseksi tarkastelemme monitehtäväistä oppimiskehystä, joka oppii yhdessä ennustamaan kolmen parin (oriQ/relQ, oriQ/relC, relQ/relC) suhteet.",
      "id": "task461-56201848001849c2b54bed2cbd85bc2c",
      "output": [
        "Mitä täydentäviä tehtäviä käytetään monitehtäväoppimisessa?"
      ]
    },
    {
      "input": "Ehdotetun luokittelumallin validoimiseksi todellisissa joukkoistamisympäristöissä Amazon Mechanical Turk (AMT) -palvelua käytettiin useiden kommentoijien merkintöjen saamiseksi kahdesta suositusta tietokokonaisuudesta: Reuters-21578 BIBREF30 ja LabelMe BIBREF31 . Jotta ehdotettu malli voitaisiin ensin validoida luokitusongelmiin hieman kontrolloidummassa ympäristössä, käytettiin tunnettua 20-Newsgroups-vertailukorpusta BIBREF29 simuloimalla useita annotoijia, joilla oli eritasoista asiantuntemusta. ",
      "id": "task461-3c454bf381a64d3086ce654e25b93727",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Näissä malleissa määritellään parametrisoidut samankaltaisuuspisteytysfunktiot $: Q\\times T\\rightarrow \\mathbb {R}$ , jossa $Q$ on luonnollisen kielen kysymysten joukko ja $T$ on loogisten muotojen parafraasien joukko.",
      "id": "task461-addb4dc5d0c54066b2be2fee0427c5b9",
      "output": [
        "Ottaako neuraalinen pisteytysfunktio syötteenä sekä kysymyksen että loogisen muodon?"
      ]
    },
    {
      "input": "Ensinnäkin monet uutisartikkelit alkavat toimittajien nimillä, mediatoimistoilla, päivämäärillä tai muulla sisällön kannalta epäolennaisella sisällöllä, esimerkiksi \"New York (CNN) -\", \"Jones Smith, 10. toukokuuta 2018:\". Siksi käytämme yksinkertaisia säännöllisiä lausekkeita poistaaksemme nämä etuliitteet. Toiseksi, varmistaaksemme, että tiivistelmä on tiivis ja että artikkeli sisältää riittävästi keskeistä tietoa, säilytämme vain artikkelit, joiden kolme ensimmäistä lausetta sisältävät 10-150 sanaa ja loput 150-1200 sanaa ja jotka sisältävät yhteensä vähintään kuusi lausetta. Tällä tavoin suodatamme pois i) artikkelit, joiden sisältö on liian pitkä, jotta muistin kulutusta voidaan vähentää; ii) hyvin lyhyet johtavat lauseet, joissa on vain vähän tietoa ja jotka eivät todennäköisesti ole hyvä tiivistelmä. Kannustaaksemme mallia tuottamaan abstrakteja tiivistelmiä poistamme myös artikkelit, joissa jokin kolmesta ylimmästä lauseesta toistuu täsmälleen samassa kohdassa artikkelin loppuosassa.Kolmanneksi pyrimme poistamaan artikkelit, joiden kolme ylimpää lausetta eivät välttämättä muodosta relevanttia tiivistelmää.",
      "id": "task461-ee7a714fa6a94a31a3b0ed4286a37d3c",
      "output": [
        "Mistä tietojen puhdistus- ja suodatusprosessi koostuu?"
      ]
    },
    {
      "input": "Menetelmät ::: Baselines ::: Tämä on hyvin samanlainen kuin Sum-QE, mutta nyt $\\mathcal {E}$ on pino BiGRU:ita, joilla on oma huomio BIBREF21, BERT-instanssin sijaan. Lopullinen yhteenvetorepresentaatio ($h$) on tuloksena saatujen kontekstitietoisten merkkien upotusten summa ($h = \\sum _i a_i h_i$), joka on painotettu niiden itsetarkkailupisteillä ($a_i$). Meillä on jälleen kolme makua: yksi yksitehtäväinen (BiGRU-ATT-S-1) ja kaksi monitehtäväistä (BiGRU-ATT-M-1 ja BiGRU-ATT-M-5).Menetelmät ::: Baselines ::: ROUGE: Tämä perustaso on ROUGE-versio, joka toimii parhaiten kussakin tietokokonaisuudessa BIBREF13:n tarkastelemien versioiden joukossa. Vaikka ROUGE keskittyy vertais- ja viitetiedostojen välisiin pintapuolisiin yhtäläisyyksiin, odotamme, että pitkiin $n$-grammeihin tai pisimpiin yhteisiin osasekvensseihin perustuvilla ROUGE-versioilla voidaan jossain määrin ottaa huomioon sellaiset ominaisuudet kuin kieliopillisuus, viittausten selkeys ja johdonmukaisuus: Baselines ::: Kielimalli (LM): Vertaisvertailun yhteenvedon osalta kohtuullinen arvio $\\mathcal {Q}1$ (kieliopillisuudesta) on esivalmennetun kielimallin palauttama perpleksisyys. Kokeilemme esivalmennetulla GPT-2-mallilla BIBREF22 ja todennäköisyysestimaateilla, jotka BERT voi tuottaa kullekin merkille, kun merkkiä käsitellään peitettynä (BERT-FR-LM). Koska yhteenvedon kieliopillisuutta voi pilata vain muutama huono merkki, laskemme perpleksisyyden ottamalla huomioon vain $k$ huonoimmat (pienimmän LM-todennäköisyyden omaavat) merkit vertaisyhteenvedosta, jossa $k$ on viritetty hyperparametri. methods ::: Baselines ::: Seuraavan lauseen ennustaminen: BERT-koulutus perustuu kahteen tehtävään: peitettyjen merkkien ennustamiseen ja seuraavan lauseen ennustamiseen. Jälkimmäinen näyttää olevan linjassa $\\mathcal {Q}3$ (Referential Clarity), $\\mathcal {Q}4$ (Focus) ja $\\mathcal {Q}5$ (Structure & Coherence) määritelmien kanssa. Intuitiivisesti, kun lause seuraa toista suurella todennäköisyydellä, siihen pitäisi sisältyä selkeitä viittausilmaisuja ja sen pitäisi säilyttää tekstin fokus ja paikallinen koherenssi. Siksi käytämme esivalmennettua BERT-mallia (BERT-FR-NS) laskeaksemme kunkin yhteenvedon lausetason monitulkintaisuuden: missä $p(s_i|s_{i-1})$ on todennäköisyys, jonka BERT antaa lauseiden $\\left< s_{i-1}, s \\right>$ järjestykselle, ja $n$ on lauseiden lukumäärä vertaisyhteenvedossa.",
      "id": "task461-ac03d462d8c04870af3c4664db1fcd6e",
      "output": [
        "Mitä yksinkertaisempia malleja he tarkastelevat?"
      ]
    },
    {
      "input": "Tässä työssä ehdotamme vastaamattomien kysymysten luomista muokkaamalla vastauksen sisältävää kysymystä ja ehdollistamalla vastauksen sisältävän kappaleen. Näin luodut vastaamattomat kysymykset ovat leksikaalisesti samankaltaisempia ja asiaankuuluvampia asiayhteyden kannalta. Lisäksi käyttämällä vastattavaa kysymystä prototyyppinä ja sen vastausväliä uskottavana vastauksena, luodut esimerkit voivat tarjota erottelevamman harjoittelusignaalin kysymyksiin vastaamisen mallille.",
      "id": "task461-4710b52d35ff48e2b37239bbab3797c8",
      "output": [
        "Edellyttääkö heidän lähestymistapansa tietokokonaisuutta, jossa vastaamattomat kysymykset on yhdistetty vastaaviin kysymyksiin, joihin voidaan vastata?"
      ]
    },
    {
      "input": "Arviointimittari. Koska ongelmamme on epätasapainoinen, käytämme arviointimittarina F1-pistemäärää. Merkintämenetelmää käytettäessä keskiarvoistamme sellaisten sanojen merkinnät, joilla on sama kantasanaversio, jotta saamme yhden ennusteen kantasanalle. Perustason määrittämiseksi tarkastelemme satunnaista menetelmää, joka ennustaa positiivisen merkinnän 0,15 todennäköisyydellä (positiivisten tapausten perusprosentti).",
      "id": "task461-4e320a1c33ab4fc6a74f13361d5d9b50",
      "output": [
        "Mitä mittareita käytetään tämän tehtävän arvioinnissa?"
      ]
    },
    {
      "input": "Alkuperäisen WikiQA:n tulokset osoittavat, että kaikki kolme siirto-oppimismenetelmää eivät ainoastaan paranna tuloksia, vaan myös heikentävät F1-tulosta. Tämä johtuu siitä, että muut tietokokonaisuudet eivät pysty lisäämään uutta tietoa alkuperäiseen tietokokonaisuuteen tai ne ilmeisesti lisäävät turhaa tietoa, joka ei ole samanlaista kuin kohdetietokokonaisuus.",
      "id": "task461-e2de9ecf48744c23a18e07788564ac95",
      "output": [
        "Onko siirtäminen haittaa suorituskykyä on korporaatioiden eivät liity?"
      ]
    },
    {
      "input": "Syötämme nämä esitykset klusterointialgoritmiin, joka tuottaa tarkalleen yksitoista viiden kaupungin klusteria, ja arvioimme niitä sekä Calvinon alkuperäisiä merkintöjä että joukkoruokiteltuja ihmisten tekemiä arvioita vastaan. Vaikka yleinen korrelaatio Calvinon merkintöjen kanssa on alhainen, sekä tietokoneet että ihmiset pystyvät tunnistamaan luotettavasti joitakin konkreettisiin kohteisiin liittyviä temaattisia ryhmiä.",
      "id": "task461-d53421d4fce84ab78d16c5f502338661",
      "output": [
        "Miten ne saavat inhimillisiä tuomioita?"
      ]
    },
    {
      "input": "Kun S-V-O on luotu, Text2Visual tarjoaa käyttäjille visuaalisia komponentteja, jotka välittävät S-V-O-tekstin merkitykset.",
      "id": "task461-d8eaf44b111e41d3b739b015686baad0",
      "output": [
        "Sisältyykö heidän ratkaisuunsa kuvien ja tekstin yhdistäminen?"
      ]
    },
    {
      "input": "GhostVLAD on laajennus NetVLAD-lähestymistavasta, jota käsittelimme edellisessä jaksossa. GhostVLAD toimii täsmälleen samalla tavalla kuin NetVLAD, paitsi että se lisää Ghost-klustereita NetVLAD-klustereiden rinnalle. Nyt meillä on siis K:n klusterin sijasta K+G:n määrä klustereita. Ghost-klusterit lisätään, jotta kaikki meluisa tai epäolennainen sisältö voidaan kuvata haamuklustereiksi, eikä niitä oteta mukaan ominaisuuksien yhdistämisvaiheeseen, kuten kuvassa 1 (oikealla) on esitetty.",
      "id": "task461-9bfe858c3c834395828eb3c432d07a9d",
      "output": [
        "Mikä on GhostVLAD-lähestymistapa?"
      ]
    },
    {
      "input": "Esittelemme kaksi käyttötapausta, joiden pohjalta Seshatia kehitettiin: kliiniset haastattelut ja päiväkohtaiset lapsikohtaiset nauhoitukset.",
      "id": "task461-e8dde02327eb4b05847c5f56981f0267",
      "output": [
        "Kokeilivatko he työkalua?"
      ]
    },
    {
      "input": "käytämme terveen järjen mukaista määritelmää rasistisesta kielestä, johon kuuluvat kaikki negatiiviset lausahdukset, negatiiviset yleistykset ja loukkaukset, jotka koskevat etnistä alkuperää, kansallisuutta, uskontoa ja kulttuuria.",
      "id": "task461-9c4fa0fe5f2947daa639e68337752d93",
      "output": [
        "miten he kysyivät, oliko twiitti rasistinen?"
      ]
    },
    {
      "input": "Tämä työ tarjoaa myös uuden INLINEFORM0-tietokannan, joka koostuu vapaamuotoisista luonnollisen kielen ohjeista ja korkean tason navigointisuunnitelmista. Tämä tietokokonaisuus kerättiin Mechanical Turkin kautta käyttäen 100 simuloitua ympäristöä ja vastaavaa topologista karttaa, ja tietojemme mukaan se on ensimmäinen laatuaan käyttäytymisnavigointia varten. ",
      "id": "task461-ce7ef2d4dc1f4828ab40e208aa742617",
      "output": [
        "Käyttivätkö kirjoittajat joukkoistamisalustaa?"
      ]
    },
    {
      "input": "Matkustamon AV-tietoaineistomme sisältää 30 tuntia multimodaalista dataa, joka on kerätty 30 matkustajalta (15 naiselta ja 15 mieheltä) 20 kyydissä/sessiossa. Matkustajien 10 erilaista aikomusta on tunnistettu ja kommentoitu seuraavasti: Muun muassa seuraavat: Aseta/muuta määränpäätä, Aseta/muuta reittiä (mukaan luettuna käännöksen mukaan annetut ohjeet), Aja nopeammin, Aja hitaammin, Pysähdy, Pysäköi, Pysähdy sivuun, Pysähdy pois, Avaa ovi ja Muut (musiikin/radion kytkeminen päälle/pois, ikkunan/ tavaratilan avaaminen/sulkeminen, ilmastointilaitteen/lämpötilan muuttaminen, kartan näyttäminen jne.). Asiaankuuluvat lähtö- ja saapumisajat yksilöidään ja merkitään seuraavasti: Sijainti, sijainti/suunta, kohde, aikaohjaus, henkilö, ele/katse (tämä, tuo, tuolla jne.) ja ei mitään. Lausetason aikomustyyppien ja niiden paikkojen lisäksi myös sanatason aikomusavainsanat merkitään aikomukseksi. ",
      "id": "task461-c0a999829b9a41f2844c6318b1d59265",
      "output": [
        "Mitä aikomuksia paperi tutkii?"
      ]
    },
    {
      "input": "Rekrytoimme 176 AMT-työntekijää osallistumaan käsitteellistämistehtävään.",
      "id": "task461-6bdeaa177767463ca27823ee1a25af61",
      "output": [
        "Mikä oli työntekijöille annettu tehtävä?",
        "Mitä joukkoistamisalustaa käytettiin?"
      ]
    },
    {
      "input": "Päätelmä",
      "id": "task461-a8c3512d09aa4a90b5611c0497c6b339",
      "output": [
        "Mitä on kolmiomittaus?"
      ]
    },
    {
      "input": "Tarjoamalla ohjatulle useita dialogivaihtoehtoja (vapaan tekstin lisäksi) ohjasimme keskustelua ja pystyimme ottamaan käyttöön toimia, jotka muuttavat järjestelmän sisäistä tilaa. Tämä tarjoaa useita etuja: Ohjattu vuoropuhelu mahdollistaa asetettujen menettelyjen oppimisen ja vähentää sitä tietomäärää, joka tarvitaan vuoropuhelun hallintaan tarkoitetun koneoppimismallin lähentymiseen.Useiden vuoropuheluvaihtoehtojen tarjoaminen ohjatulle lisää vuorovaikutuksen vauhtia ja mahdollistaa monimutkaisempien skenaarioiden ymmärtämisen ja navigoinnin. Dialogin rakenne: Otimme käyttöön strukturoidut dialogit FSM-koneen (Finite State Machine) avulla, joka hallitsee nykyistä dialogin tilaa ja tarjoaa ohjatulle useita sopivia ja asiaankuuluvia tilasiirtymiä (toimia) vuorovaikutuksen pisteen, maailman tilan ja historian mukaan. Dialogitilojen, siirtymien ja lausumien graafi ladataan, kun järjestelmä käynnistetään, ja jokaisella keskusteluhuoneella on oma dialogitilansa, joka muuttuu toimien kautta. FSM:n tarjoamien siirtymien lisäksi käytettävissä on aina myös muita kiinteitä dialogivaihtoehtoja, kuten \"Odota, 2 sekuntia\", \"Okay\" tai \"Anteeksi, voisitko toistaa sen?\", jotka ovat oikoteitä yleisesti käytetyille dialogitoimille, sekä mahdollisuus kirjoittaa viesti vapaasti. Vuoropuhelussa on useita polkuja päästä samoihin tiloihin, joissa operaattorin hallinnan tai sitoutumisen taso vaihtelee, mikä rikastuttaa keskustelujen heterogeenisuutta.",
      "id": "task461-87fb56d7ab144ef7a2c266f422ba325b",
      "output": [
        "Mitä tarkoitetaan puoliksi ohjatulla vuoropuhelulla, mikä osa vuoropuhelusta on ohjattua?"
      ]
    },
    {
      "input": "Esikoulutettu englanninkielinen NER-malli Rakennamme englanninkielisen NER-järjestelmän BIBREF:n7 mukaisesti. Järjestelmä käyttää kaksisuuntaista LSTM-mallia merkkitason kielimallina, joka ottaa kontekstitietoa sanojen upottamista varten.  Englannin kielen esivalmennetussa NER-järjestelmässä käytämme Flairin oletusarvoista NER-mallia.",
      "id": "task461-689dcaa7d8e245bba7008596d89c187f",
      "output": [
        "Mitä valmiiksi koulutettua englanninkielistä NER-mallia he käyttävät?"
      ]
    },
    {
      "input": "Huomaamme, että visuaalinen huomio on hyvin harva, sillä vain yhteen lähdekoodaukseen kiinnitetään huomiota (suurin visuaalinen huomio lähdekoodausten osalta koko testijoukossa on keskimäärin 0,99 ja keskihajonta 0,015), mikä rajoittaa modulaation käyttöä. Molemmissa tapauksissa havaitsemme, että huomion visuaalinen komponentti ei ole oppinut mitään vaihtelua lähdekoodausten yli, mikä taas viittaa siihen, että visuaaliset upotukset eivät sovellu parantamaan token-tason erottelukykyä ennustamisen aikana. Huomaamme tämän olevan johdonmukaista eripituisten lauseiden kohdalla.",
      "id": "task461-da1229590eed431ba78626bc55dfe828",
      "output": [
        "Mikä on niiden huomion jakautumisen analyysin tulos?"
      ]
    },
    {
      "input": "Tuloksena saatu 46 asiakirjan joukko muodostaa perusjoukkomme. Huomaa, että näiden asiakirjojen koko vaihtelee suuresti, joten tuloksena oleva korpus on monipuolinen, mutta ei tasapainoinen koon suhteen (taulukko TABREF43).",
      "id": "task461-40702cf26b7c48a28ff0a245db692e03",
      "output": [
        "Kuinka suuria PIE-tietoaineistoja saadaan sanakirjoista?"
      ]
    },
    {
      "input": "Tutkimme molempia menetelmiä joko erikseen tai yhdistettynä kahdella käännössuunnalla (En-It ja En-De), joissa kohteen pituus on keskimäärin pidempi kuin lähteen pituus. En-It, En-De molempiin suuntiin.",
      "id": "task461-c26c5aa21942412da5f77445b19f6736",
      "output": [
        "Mihin kieliin he keskittyvät?"
      ]
    },
    {
      "input": "Tässä työssä esiteltiin MVCNN, uusi CNN-arkkitehtuuri lauseiden luokitteluun. Siinä yhdistyvät monikanavainen alustaminen - käytetään erilaisia versioita esivalmennetuista sanojen upotuksista - ja vaihtelevan kokoiset suodattimet - monisanaisia lauseita koskevat piirteet uutetaan vaihtelevan kokoisilla konvoluutiosuodattimilla. ",
      "id": "task461-54748967cb9445629d9a697ee5ac4079",
      "output": [
        "Millainen MVCNN on verrattuna CNN:ään?"
      ]
    },
    {
      "input": "Tehtävä: Kun annetaan kuvateksti ja kuvapari (jos käytetään), tavoitteena on merkitä jokainen kuvatekstin merkki BIO-kaavalla (B: alku, I: sisällä, O: ulkopuolella) BIBREF27 . ",
      "id": "task461-686662449e674e168215807ad95e2f28",
      "output": [
        "Voivatko SnapCaptionsin nimetyt yksiköt olla epäsovinnaisia?"
      ]
    },
    {
      "input": "Videokysymyksiin vastaaminen on uusi tehtävä, ja tietojemme mukaan mitään mallia ei ole suunniteltu erityisesti tätä tehtävää varten. Ensimmäisenä askeleena kohti tämän ongelman ratkaisemista arvioimme muihin laadunvarmistustehtäviin, kuten lausetason ennustustehtävään ja kahteen segmenttien hakutehtävään, kehitettyjen uusimpien mallien suorituskykyä. Perustasot ::: Baseline1: Baseline1 ennustaa (alkavan lauseen indeksi, päättyvän lauseen indeksi), kun kyseessä on transkriptio (lauseiden sarja) ja kysymys. Malli perustuu RaSor BIBREF13 -malliin, joka on kehitetty SQuAD QA -tehtävää BIBREF6 varten. RaSor ketjuttaa aloittavan ja päättyvän sanan upotusvektorit edustamaan jänneväliä. Tämän ajatuksen mukaisesti Baseline1 edustaa lauseiden jaksoa ketjuttamalla aloitus- ja lopetuslauseiden vektorit. Kuvion FIGREF15 vasemmanpuoleinen kaavio havainnollistaa Baseline1-mallia.Model. Malli ottaa vastaan kaksi syötettä, transkripti, $\\lbrace s_1, s_2, ... s_n\\rbrace $, jossa $s_i$ on yksittäisiä lauseita, ja kysymys, $q$. Tuloksena saadaan span-pisteet, $y$, eli pisteet kaikista mahdollisista span-pisteistä. GLoVe BIBREF14:ää käytetään transkriptin ja kysymysten sanojen esittämiseen. Käytämme kahta bi-LSTM:ää BIBREF15 koodaamaan transkriptiota.missä n on lauseiden lukumäärä . Kulkutason koodauksen tuloksena $p$ on vektorijakso $p_i$, joka edustaa kunkin lauseen latenttia merkitystä. Sitten malli yhdistää jokaisen lauseen upotusparin ($p_i$, $p_j$) luodakseen span embeddingin.jossa [$\\cdot $,$\\cdot $] tarkoittaa ketjuttamista. Lopuksi käytämme yksikerroksista feed forward -verkkoa laskemaan kunkin spanin ja kysymyksen välisen pistemäärän.Koulutuksessa käytämme ristiinentropiaa tavoitefunktiona. Testauksessa vastaukseksi valitaan korkeimman pistemäärän saanut span. Peruslinjat ::: Baseline2: Tarkastelemme myös yksinkertaisempaa tehtävää, kun ongelmamme muotoillaan hakutehtäväksi. Tarkemmin sanottuna annoimme mallille pelkän transkriptin lisäksi myös segmentointitiedot, jotka luotiin tiedonkeruulausekkeen aikana (ks. kohta SECREF3). Huomaa, että jokainen segmentti vastaa vastausehdokasta. Tehtävänä on sitten valita paras segmentti annettua kyselyä varten. Tämä tehtävä on helpompi kuin Baseline1:n tehtävä, koska segmentointitiedot annetaan mallille. Toisin kuin Baseline1, se ei kuitenkaan pysty palauttamaan vastausskaalaa eri rakeisuuksilla. Baseline2 perustuu Attentive LSTM BIBREF17 -malliin, joka on kehitetty InsuranceQA-tehtävää varten. Kuvan FIGREF15 oikeanpuoleinen kaavio havainnollistaa Baseline2-mallia.Model. Kaksi syötettä, $s$ ja $q$, edustavat segmenttitekstiä ja kysymystä. Malli koodaa ensin nämä kaksi syötettä.$h^s$ painotetaan sitten uudelleen huomiopainojen avulla.missä $\\odot$ tarkoittaa elementtiviisasta kertolaskuoperaatiota. Lopullinen pistemäärä lasketaan käyttämällä yksikerroksista feed-forward-verkkoa.Koulutuksen aikana malli tarvitsee negatiivisia näytteitä. Kunkin positiivisen esimerkin (kysymys, perustotuussegmentti) osalta kaikkia muita saman transkriptin segmenttejä käytetään negatiivisina näytteinä. Tavoitefunktiona käytetään ristikkäistä entropiaa. Peruslinjat ::: Baseline3: Laskemme segmentin ja kysymyksen upotusten väliset kosinuskohtaiset samankaltaisuudet laskemalla segmentin ja kysymyksen upotusten väliset kosinuskohtaiset samankaltaisuudet. Tässä tehtävässä haluamme kuitenkin testata segmenttien hakutarkkuutta, kunhan ensin haemme oikean videon 76 videon joukosta. Ensin luodaan TF-IDF-merkinnät koko videon transkripteille ja kysymyksille. Seuraavassa vaiheessa haetaan ne videot, joiden kosini-etäisyys videokirjoitusten ja kysymyksen välillä on pienin. Tämän jälkeen suodatamme ja tallennamme kymmenen parasta videota, mikä vähentää seuraavassa vaiheessa tarvittavien laskutoimitusten määrää. Lopuksi laskemme kysymyksen ja niiden segmenttien väliset kosinusetäisyydet, jotka kuuluvat suodatettuihin 10 parhaaseen videoon, ja merkitsemme kysymyksen oikeaksi, jos se löytyy näistä videoista. Vaikka tehtävä on laskennallisesti vähemmän kallis kuin edellinen perustaso, emme opi segmenttien esityksiä, koska tämä tehtävä on yksinkertainen hakutehtävä, joka perustuu TF-IDF-merkintöihin. Kaksi ensimmäistä syötettä ovat kysymys q ja videon transkriptio v, jotka on koodattu niiden TF-IDF-vektoreilla: BIBREF18: Tämän jälkeen suodatetaan 10 parasta videokirjoitusta (76:sta), joilla on pienin kosinusetäisyys, ja lasketaan niiden segmenttien TF-IDF-vektorit, Stop10n, jossa n = 10. Tämän jälkeen lasketaan TF-IDF-vektorit. Toistamme prosessin vastaaville segmenteille: valitsemme segmentin, jonka kosinietäisyys kyselyyn on pienin.",
      "id": "task461-06ee6cedc5234b9ab0583c0b9e66a51e",
      "output": [
        "Mitä perusalgoritmeja esiteltiin?"
      ]
    },
    {
      "input": "Sovellamme Hania tällaisiin keskusteluihin peräkkäin syöttämällä jokaisen käyttäjän vuoron Hanille sitä mukaa, kun ne tapahtuvat, jotta voidaan määrittää, pitäisikö keskustelun eskaloitua. Jos näin on, käyttäjä siirretään live-chatin edustajalle keskustelun jatkamista varten. Käyttäjän on odotettava, että inhimillinen edustaja tarkastelee IVA-keskusteluhistoriaa ja jatkaa epäonnistunutta tehtävää.",
      "id": "task461-d7ce53f5b8d348e18657b73ac024c432",
      "output": [
        "Miten he keräävät ihmisten arvioita?"
      ]
    },
    {
      "input": "Latasimme 76 videota kuvankäsittelyohjelmasta kertovalta opetusohjelmasivustolta. ",
      "id": "task461-156d561151c54808a03c25b55a2e696b",
      "output": [
        "Mikä on kolmikoiden lähde?"
      ]
    },
    {
      "input": "Tässä yhteydessä ehdotamme vankkaa monikielistä tunteiden analysointimenetelmää, jota testattiin kahdeksalla eri kielellä: Espanjaa, englantia, italiaa, arabiaa, saksaa, portugalia, venäjää ja ruotsia.",
      "id": "task461-50fabb8fe0104d5eb6afe140ebf0dfae",
      "output": [
        "Mitä kahdeksaa kieltä raportoidaan?"
      ]
    },
    {
      "input": "CRF-moduuli saavutti parhaan tuloksen thaimaalaisen lauseen segmentointitehtävässä BIBREF8 , joten otamme Bi-LSTM-CRF-mallin perustasoksi. ",
      "id": "task461-f1404c01a9184998af997a2ea7266d8c",
      "output": [
        "Mitä syväoppimisarkkitehtuuria he käyttävät lauseiden segmentointiin?"
      ]
    },
    {
      "input": "Testit ja kultainen standardi aineisto sisäistä arviointia vartenKäyttäen kultaista standardi aineistoa (kuvattu alla), suoritimme kolmenlaisia testejä:Luokanjäsenyystestit: kahden samaan semanttiseen luokkaan kuuluvan jäsenen (esim. \"Vuoden kuukaudet\", \"Portugalin kaupungit\", \"hymiöt\") upotusten pitäisi olla lähellä toisiaan, koska niiden oletetaan esiintyvän pääosin samoissa konteksteissa.Luokan erottelukykytesti: tämä on edellisen luokanjäsenyystestin käänteisluku. Eri luokkiin kuuluvien elementtien upotusten pitäisi olla erilaisia, koska eri luokkiin kuuluvien sanojen oletetaan esiintyvän huomattavasti erilaisissa yhteyksissä. sanojen vastaavuustestaus: synonyymejä, antonyymejä, lyhenteitä (esim. \"porque\" lyhennettynä \"pq\") ja osittaisia viittauksia (esim. \"p\") vastaavat upotukset. \"slb ja benfica\") pitäisi olla lähes yhtä suuria, koska molempia vaihtoehtoja on tarkoitus käyttää vaihdettavissa kaikissa yhteyksissä (joko säilyttäen tai kääntäen merkityksen).Näin ollen testeissämme kaksi sanaa katsotaan:erillisiksi, jos vastaavien upotusten kosinus on pienempi kuin 0,70 (tai 0,80).kuuluviksi samaan luokkaan, jos niiden upotusten kosinus on suurempi kuin 0,70 (tai 0,80).samanarvoisiksi, jos upotusten kosinus on suurempi kuin 0,85 (tai 0,95).",
      "id": "task461-24a5dae069f4414fb153c758e1aaf8e4",
      "output": [
        "Mitä sisäisiä arviointimittareita käytetään?"
      ]
    },
    {
      "input": "Laskimme Fliessin INLINEFORM0:n koejoukosta viidelle annotoijalle 21 twiitistä. INLINEFORM1 on .83 kerrokselle A (OFF vs. NOT), mikä osoittaa suurta yksimielisyyttä. Mitä tulee normalisointiin ja anonymisointiin, käyttäjän metatietoja tai Twitter-tunnuksia ei ole tallennettu, ja URL-osoitteet ja Twitter-maininnat on korvattu paikannimillä. ",
      "id": "task461-b522ecf644ff4d488b9efa5fc138ffca",
      "output": [
        "Kuinka monta kommentoijaa osallistui?"
      ]
    },
    {
      "input": "Vihamieliset meemit haettiin Google Imagesista lataustyökalun avulla. Käytimme seuraavia kyselyjä kerätäksemme yhteensä 1695 vihameemiä: rasistinen meemi (643 meemiä), juutalainen meemi (551 meemiä) ja muslimimeemi (501 meemiä). Muut kuin vihamemit saatiin Reddit Memes Dataset -aineistosta .",
      "id": "task461-b0e2766557c145b880947ea4f60b657d",
      "output": [
        "Mikä on meemien lähde?"
      ]
    },
    {
      "input": "Käytämme ensin ennusteita, jotka perustuvat kirjallisuudessa aiemmin ehdotettuihin sääntöihin: sanan pituus, foneemien määrä, tavujen määrä, aakkosjärjestys ja taajuus. Keräämme kaikki binomit, mutta teemme ennusteita vain binomeille, jotka esiintyvät yhteensä vähintään 30 kertaa, jaoteltuna subredditin mukaan. Mikään näistä piirteistä ei kuitenkaan näytä olevan erityisen ennustava kaikkialla (taulukko TABREF15). Yksinkertainen lineaarinen regressiomalli ennustaa lähellä satunnaisuutta, mikä vahvistaa näyttöä siitä, että nämä jäädytettyjä binomeja koskevat klassiset säännöt eivät ennusta yleisiä binomeja.",
      "id": "task461-53952f28392c49f89b3d67fcecfdecdc",
      "output": [
        "Miten aiemmin ehdotetut säännöt toimivat hyvin laajassa mittakaavassa?"
      ]
    },
    {
      "input": "Koska näiden sarjojen odotetaan heijastavan sosiaalisia normeja, niistä käytetään jäljempänä nimitystä \"Dos\" ja \"Don'ts\". Vastaavasti jotkut negatiivisista sanoista kuvaavat vain sopimatonta käytöstä, kuten herjaus tai väärinkäytös, kun taas toiset ovat todellisia rikoksia, kuten murha.",
      "id": "task461-efd53c22d4944d1abe2f939f2fb1ce47",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Keskustelupohjaiset ominaisuudetNämä ominaisuudet pyrkivät hyödyntämään tietokokonaisuuden erityispiirteitä, sillä tietokokonaisuus on puurakenteinen ja kuvastaa keskusteluketjua.Tekstin samankaltaisuus lähdetwiittauksen kanssa: Tekstin samankaltaisuus vastatun twiitin kanssa: twiitin ja keskusteluketjun edellisen twiitin samankaltaisuuden aste (twiitti on vastaus kyseiseen twiittiin).Twiitin syvyys: syvyysarvo saadaan laskemalla solmuja lähteistä (juurista) kuhunkin twiittiin niiden hierarkiassa.",
      "id": "task461-78abedc8beaf4b3bb34cff3804b421e5",
      "output": [
        "Mitä keskustelupohjaisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "WN18RR-tietokanta koostuu kahdenlaisista suhteista: symmetrisistä suhteista, kuten $\\_similar\\_to$, jotka yhdistävät luokkaan (b) kuuluvia entiteettejä, ja muista suhteista, kuten $\\_hypernym$ ja $\\_member\\_meronym$, jotka yhdistävät luokkaan (a) kuuluvia entiteettejä. Itse asiassa RotatE pystyy mallintamaan luokkaan (b) kuuluvia entiteettejä erittäin hyvin BIBREF7. HAKE saa kuitenkin 0,021 korkeamman MRR-arvon, 2,4 % korkeamman H@1-arvon ja 2,4 % korkeamman H@3-arvon RotatE:hen verrattuna. FB15k-237-tietokannassa on monimutkaisempia relaatiotyyppejä ja vähemmän entiteettejä kuin WN18RR:ssä ja YAGO3-10:ssä. Vaikka FB15k-237:ssä on suhteita, jotka kuvastavat hierarkiaa, on myös paljon suhteita, kuten \"/location/location/time_zones\" ja \"/film/film/prequel\", jotka eivät johda hierarkiaan. Tämän tietokokonaisuuden ominaispiirteet selittävät sen, miksi ehdotetut mallit eivät ylitä aiempaa huipputekniikkaa yhtä paljon kuin WN18RR- ja YAGO3-10-tietokokonaisuuksien mallit. AGO3-10-tietokanta sisältää entiteettejä, joilla on korkea relaatiokohtainen indegree BIBREF18. Esimerkiksi linkkien ennustustehtävässä $(?, hasGender, male)$ on yli 1000 oikeaa vastausta, mikä tekee tehtävästä haastavan. Onneksi voimme pitää \"urosta\" hierarkian korkeamman tason entiteettinä ja ennustettuja pääentiteettejä alemman tason entiteetteinä. Näin ollen YAGO3-10 on tietokokonaisuus, jolla on selvästi semanttinen hierarkiaominaisuus, ja voimme olettaa, että ehdottamamme mallit pystyvät toimimaan hyvin tässä tietokokonaisuudessa. Taulukko TABREF19 vahvistaa odotuksemme. Sekä ModE että HAKE ylittävät merkittävästi aiemmat huipputason mallit. Erityisesti HAKE saa 0,050 korkeamman MRR-arvon, 6,0 % korkeamman H@1-arvon ja 4,6 % korkeamman H@3-arvon kuin RotatE.",
      "id": "task461-67906f68b0624c408d20ced86108951d",
      "output": [
        "Kuinka hyvin HAKE-malli toimii nykyisiä menetelmiä paremmin?"
      ]
    },
    {
      "input": "Huomioon perustuva sekvenssistä sekvenssiin -malli, jossa emoji-vektori on lisäsyötteenä, kuten MojiTalk BIBREF16:ssä kuvataan. CVAE.RNN-pohjainen ehdollinen varioiva autokooderi dialogivastausten tuottamiseen BIBREF16, joka käyttää monimuuttujaista Gaussin latenttia muuttujaa vastauksen mallintamiseen ja liittää sen koodaajan viimeiseen piilotetun tilan kanssa dekooderin alkutilaksi. Koulutuksen aikana käytetään KL-hehkutusta, varhaisen pysäytyksen strategiaa ja sanapussin apuhäviötä. Käytämme BIBREFin julkaisemaa toteutusta16.",
      "id": "task461-5243b5e6400144c18ee9ed576966676b",
      "output": [
        "Mitä muita perusmuotoja kuin vakiomuuntajia käytetään kokeissa?"
      ]
    },
    {
      "input": "Käytämme kokeissamme julkisesti saatavilla olevaa tietokokonaisuutta KVRET BIBREF5. Tämä tietokokonaisuus sisältää vuoropuheluja kolmelta alueelta: kalenteri, sää ja navigointi (POI), mikä soveltuu eri alojen vuoropuhelukokeiluihin. ",
      "id": "task461-dfa7539949ec407aa0a4c7aa475a4332",
      "output": [
        "Mitä monialuetietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Poimimme viisi pinta- ja leksikaalista piirrettä, nimittäin sekvenssin pituuden merkkien lukumääränä, sanan keskimääräisen pituuden, tyypin ja merkin suhteen sekä leksikaalisen ja merkkien suhteen (adjektiivien, verbien, substantiivien ja adverbien suhde merkkeihin). Poistimme kaksi piirrettä, jotka käyttävät opittua esitystä: Ensinnäkin saamme lauseen upotusominaisuuden, joka muodostetaan keskiarvottamalla syötetyn lauseen sanojen upotukset. Toiseksi louhimme fastText-edustuksen käyttämällä fastText-kirjastoa samoilla parametreilla kuin Joulin et al. joulin2016bag raportoi.",
      "id": "task461-ef06cf6db36b462eaedc4e51608f6531",
      "output": [
        "Eroavatko ne toisistaan oivallukset, joissa on kyse opituista tai kehitetyistä representaatioista?"
      ]
    },
    {
      "input": "Käyttäjän aikomusten ja tunteiden ymmärtäminen on äärimmäisen tärkeää, jotta nykyiset älykkäät chatbotit voivat vastata asianmukaisesti ihmisten pyyntöihin. Nykyiset järjestelmät eivät kuitenkaan pysty toimimaan parhaalla mahdollisella tavalla, kun niille esitetään epätäydellisiä tietoja eli lauseita, joista puuttuu sanoja tai joissa on virheellisiä sanoja. Tämä skenaario on todennäköinen, kun otetaan huomioon kirjoittamisessa tehdyt inhimilliset virheet. Itse asiassa on melko naiivia olettaa, että käyttäjät kirjoittavat aina kieliopillisesti täysin oikeita lauseita. ",
      "id": "task461-8380121337b240b18f465e4a3684c0e5",
      "output": [
        "Miten kirjoittajat määrittelevät tai havainnollistavat \"virheelliset sanat\"?"
      ]
    },
    {
      "input": "Adaptiivinen monioppimisjärjestelmä perustuu vahvistusoppimisen (RL) paradigmaan. Kuvassa FIGREF18 havainnollistetaan koko oppimisprosessi. Monikurssioppimisjärjestelmä ajoitetaan sen mukaan, miten malli on suoriutunut validointijoukosta, ja ajoitusmekanismi toimii politiikkana $\\pi$, joka on vuorovaikutuksessa vuoropuhelumallin kanssa oppimistilan $s$ hankkimiseksi. Monikurrikulaarisen oppimismekanismin palkkio $m_t$ osoittaa, kuinka hyvin nykyinen dialogimalli suoriutuu. Positiivinen palkkio on odotettavissa, jos monikurrikulaarinen aikataulutustoimi $a_t$ parantaa mallin suorituskykyä, ja nykyinen harjoitusnäytteiden pienoiserä otetaan aikataulutustoimen $a_t$ avulla.",
      "id": "task461-3f1187e43d0946d4bfd45b0bd507a4af",
      "output": [
        "Miten kehys valitsee automaattisesti erilaisia opetussuunnitelmia kehittyvän oppimisprosessin aikana neuraalisen dialogin luomisen mallin oppimistilanteen mukaan?"
      ]
    },
    {
      "input": "Parhaiden tulosten (BLSTM-CNN-CRF) perusteella suoritetaan virheanalyysi, joka perustuu viiteen virhetyyppiin (ei poimintaa, ei merkintöjä, väärä alue, väärä tunniste, väärä alue ja tunniste), samalla tavalla kuin BIBREF10:ssä, mutta analysoimme sekä kultaiset että ennustetut tunnisteet (lisätietoja kuvissa 1 ja 2).",
      "id": "task461-9afbaf2c0f31499e830537b867366eb6",
      "output": [
        "Millaisia virheitä BLSTM-CNN-CRF-järjestelmä tuotti?"
      ]
    },
    {
      "input": "Ensimmäisessä tehtävässä käytämme SST-2 (Stanford Sentiment Treebank, versio 2) -tietokokonaisuutta BIBREF25 sentimenttianalyysikokeilujen tekemiseen. SST-2 on lauseiden binääriluokittelutietokanta, jossa on train/dev/test-jako ja kahdenlaiset lauseiden merkinnät, positiiviset ja negatiiviset. Tässä kokeilemme Snips-tietokokonaisuutta BIBREF26 , jota käytetään laajasti SLU-tutkimuksessa. Tämä tietokokonaisuus sisältää testattuja puhuttuja lauseita (tekstiä), jotka on luokiteltu johonkin seitsemästä tarkoituksesta.",
      "id": "task461-875736d98f6e4cdfb528f7e69ea88abc",
      "output": [
        "Mitä reaalimaailman tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Kuvion Y-akseli on agentin onnistumisprosentti (mitattuna taitoon johtaneiden dialogien määränä jaettuna dialogien kokonaismäärällä) ja X-akseli on oppimisvaiheiden määrä. ",
      "id": "task461-b459e440ec87451bb4aa79ecc3678a11",
      "output": [
        "Miten he mittasivat tehokkuutta?"
      ]
    },
    {
      "input": "Tutkimme kolmea eri epäjohdonmukaisuuden näkökohtaa ja suunnittelimme mittareita niiden mittaamiseksi.  Sanatason ominaisuus, jossa käytetään tf-idf BIBREF22 -merkintää, on lisätty kestävyyden lisäämiseksi.",
      "id": "task461-4315a29541904ce8933d0be986304fc0",
      "output": [
        "Mitä ominaisuuksia ne poimivat?"
      ]
    },
    {
      "input": "Itsensä huomioiminen kysymyksessä. Koska kysymykseen on integroitu aiempia lausumia, mallin on yhdistettävä aiemmin mainittu käsite suoraan nykyiseen kysymykseen. Tämä on hyödyllistä käsitteiden siirtämisen ja ydinviittausten ratkaisemisen kannalta. Käytämme siis kysymyksen itsehuomiota.",
      "id": "task461-4a96f59e0f7d491587449e6976b6c212",
      "output": [
        "Sisältyykö malliin coreference ja entailment?"
      ]
    },
    {
      "input": "Tämän vuoksi emme väitä, että tätä tietokokonaisuutta voidaan pitää perustotuutena.",
      "id": "task461-637d72e6e8244067941293499f89e469",
      "output": [
        "Miten väärennettyjen uutisten pohjatotuus muodostetaan?"
      ]
    },
    {
      "input": " Tämän väitteen tueksi mittaamme järjestelmämme suorituskykyä eri alojen tietokokonaisuuksissa. Arvioinnit tehdään ohjattujen tuomareiden toimesta, jotka ymmärtävät tietopohjan ja arvioivat sitten käyttäjän kyselyjen relevanssia QA-parien (binäärilappujen) kannalta. Kutakin kysely-QA-paria arvioi kaksi tuomaria. Suodatamme pois tiedot, joiden kohdalla tuomarit eivät ole samaa mieltä etiketistä. Chit-chat itsessään voidaan katsoa toimialueeksi. Näin ollen arvioimme suorituskykyä tietyllä KB:lla sekä chit-chat-tietojen kanssa että ilman niitä (taulukon TABREF19 kaksi viimeistä riviä) sekä suorituskykyä pelkillä chit-chat-tiedoilla (taulukon TABREF19 toinen rivi).",
      "id": "task461-6184b7025e654d66a7b23232b23b4365",
      "output": [
        "Mitä kokeita kirjoittajat esittävät validoidakseen järjestelmänsä?"
      ]
    },
    {
      "input": "Parhaiten hahmoyksikön osalta toimi RNN-muunnin, jossa oli ylimääräinen huomiomoduuli, jonka CER-arvo oli 7,8 % ja WER-arvo 17,6 %. Alasanayksiköiden osalta klassinen RNN-transducer, RNN-transducer, johon on liitetty huomio, ja yhteinen CTC-attention -moduuli osoittavat vertailukelpoista suorituskykyä alasanojen virhemäärän ja WER:n osalta, joista ensimmäinen on hieman parempi WER:n osalta (17,4 %) ja jälkimmäisen alhaisempi virheprosentti alasanojen osalta (14,5 %).",
      "id": "task461-0f57b71197f04a9fb3f8269b015a2635",
      "output": [
        "Minkä mallin merkkivirheprosentti on pienin ja minkä sanavirheprosentti on pienin?"
      ]
    },
    {
      "input": "Käytämme MS COCO-, Bing- ja Flickr-tietoaineistoja BIBREF26:sta kysymysten luomiseksi käytettävän mallin kouluttamiseen. Nämä tietokokonaisuudet sisältävät kuvia koskevia luonnollisia kysymyksiä, joiden tarkoituksena on saada lisätietoja kuvasta. Kuten kuvasta FIGREF8 voidaan nähdä, kysymyksiin ei voida vastata vain katsomalla kuvaa. Kukin lähde sisältää 5 000 kuvaa, joissa on 5 kysymystä kuvaa kohti, joten yhteensä 15 000 kuvaa ja 75 000 kysymystä.",
      "id": "task461-e3d55567978244dbb45b5e8b549e0938",
      "output": [
        "Kuinka monta kysymystä kuvaa kohti on keskimäärin saatavilla tietokannassa?"
      ]
    },
    {
      "input": "Laskimme annotoijien välisen sopimuksen Krippendorffin Alpha BIBREF23 -menetelmällä, jossa otetaan huomioon eri annotoijaparit ja tyhjät arvot. Jotta voisimme myös tarkentaa kategorioittain erityistä yhteisymmärrystä, laskimme kunkin luokan keskinäiset F-pisteet. Tätä mittaria käytetään tavallisesti arvioitaessa järjestelmän suorituskykyä luokittain gold standard -aineistolla, mutta sitä voitaisiin soveltaa myös annotaatiopareihin vaihtamalla kahden annotaattorin roolia luokittelijan ja perustotuuden välillä. Vaikka sekä Relevance- että Subject-luokitusten annotointiprosentit ovat $0.71$ ja $0.70$, niiden yhteisymmärryspisteet ovat vain kohtuulliset, $\\alpha =0.27$ ja $\\alpha =0.29$. Stance- ja Sentiment-luokkien, joihin sisältyy enemmän kategorioita kuin kahteen edelliseen, yhteisymmärrysprosentti on molemmilla 0,54 $. Myös niiden yksimielisyyspisteet ovat kohtuulliset: $\\alpha =0,35$ ja $\\alpha =0,34$. Keskinäiset F-pisteet osoittavat huomattavia eroja kategorioiden välisessä yhteisymmärryksessä, jossa useimmin annotoidut kategoriat tuottavat yleensä korkeamman tuloksen. Tämä pätee luokkiin Relevant (0,81$), Vaccine (0,79$) ja Positive (0,64$). Negatiivinen kategoria tuottaa yhteisen F-pistemäärän 0,42 $, joka on korkeampi kuin useammin annotoidut kategoriat Neutraali (0,23 $) ja Ei selvä (0,31 $). Havaitsimme, että nämä kategoriat sekoittuvat usein keskenään. Kun näiden kahden luokan annotaatiot on yhdistetty, kantasopimus kasvaa arvoon $\\alpha =0.43$.",
      "id": "task461-90036bc0c10147e6a1787781f71df2ba",
      "output": [
        "Mikä on heidän kommentoidun tietokokonaisuutensa yhteisymmärryspistemäärä?"
      ]
    },
    {
      "input": "Taulukosta TABREF14 käy ilmi mallimme (monitehtävämuuntaja) tehokkuus verrattuna perusmuuntajaan BIBREF8 . ",
      "id": "task461-7615f56e706d4d3295d41adf513ca820",
      "output": [
        "mitkä ovat peruslinjat?"
      ]
    },
    {
      "input": " Taulukossa 1 esitetään kaikkien mallien tulokset WikiLarge-tietokannassa. Näemme, että menetelmämme (NMT+synteettinen) saavuttaa korkeamman BLEU-arvon, alhaisemman FKGL-arvon ja korkean SARI-arvon verrattuna muihin malleihin, lukuun ottamatta Dressiä FKGL:n osalta ja SBMT-SARIa SARI:n osalta. Se vahvisti, että synteettisen datan sisällyttäminen harjoitteluun on erittäin tehokasta ja parantaa perus-NMF-malliamme 2,11 BLEU:lla, 1,7 FKGL:llä ja 1,07 SARI:llä.  WikiSmall-tietokannan tulokset esitetään taulukossa 2. NMT:hen verrattuna huomattavia parannuksia (6,37 BLEU) saadaan lisäämällä yksinkertaistettu harjoitusaineisto, jossa on synteettisiä tavallisia lauseita. ",
      "id": "task461-3d3c2045ea824875a5474856b71d5c81",
      "output": [
        "Kuinka paljon heidän mallinsa parani?"
      ]
    },
    {
      "input": "Span-ilmaisin. Otamme käyttöön monikierroksisen vastausmoduulin span-ilmaisimessa BIBREF1 . Muodollisesti aika-askeleella INLINEFORM0 alueella INLINEFORM1 tila on määritelty INLINEFORM2 . Alkutila INLINEFORM3 on yhteenveto INLINEFORM4 : INLINEFORM5 , jossa INLINEFORM6 . Tässä INLINEFORM7 lasketaan edellisestä tilasta INLINEFORM8 ja muistista INLINEFORM9 : INLINEFORM10 ja INLINEFORM11 . Lopuksi käytetään bilineaarista funktiota, jolla etsitään vastausvälien alku- ja loppupiste kussakin päättelyvaiheessa INLINEFORM12 : DISPLAYFORM0 DISPLAYFORM1 Lopullinen ennuste on kunkin aika-askeleen keskiarvo: INLINEFORM0 . Sovellamme satunnaista pudotusta askeleen tasolla jokaisessa aika-askeleessa harjoittelun aikana, kuten BIBREF1:ssä on tehty.",
      "id": "task461-769018a5828246d0a47d6a965df4a31d",
      "output": [
        "Mikä on jännevälien ilmaisimen arkkitehtuuri?"
      ]
    },
    {
      "input": "Keskitymme tässä Europarl-alueeseen, josta meillä on runsaasti tietoja useilla kielillä, ja käytämme alan sisäisenä harjoitusaineistona Europarl-korpusta BIBREF5 kahta käännössuuntaa varten: Englanti INLINEFORM0 saksa ja englanti INLINEFORM1 ranska. Kun mittaamme out-of-domain-suorituskykyä, käytämme WMT newstest 2014. tai ranskan kielessä käytämme näytteitä News-Commentary-11- ja Wikipedia-korpuksista WMT 2014:n jaetusta käännöstehtävästä sekä korpuksista Multi-UN BIBREF9 ja EU-Bookshop BIBREF10. Saksan osalta käytämme näytteitä News-Commentary-11:stä, Rapidista, Common-Crawlista (WMT 2017) ja Multi-UN:sta (ks. taulukko TABREF5 ). ",
      "id": "task461-daf502485e91439f9e38f887c5f956ca",
      "output": [
        "mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Tuloksemme tasoittavat tietä useiden uusien tutkimussuuntien tutkimukselle. Vaikka testasimme virtuaalisten reunojen tehokkuutta tietyssä tekstiluokittelutehtävässä, voisimme laajentaa tätä lähestymistapaa yleisiin luokittelutehtäviin. Sulauttamistekniikoiden järjestelmällinen vertailu voitaisiin tehdä myös muiden viimeaikaisten tekniikoiden BIBREF54, BIBREF55 sisällyttämiseksi. Voisimme myös tunnistaa muita asiaankuuluvia tekniikoita virtuaalisten reunojen luomiseksi, jolloin menetelmää voitaisiin käyttää muissakin verkottuneissa järjestelmissä kuin teksteissä. Verkko voitaisiin esimerkiksi rikastaa graafien sulauttamistekniikoilla saaduilla sulautuksilla. Yksinkertaisemmassa lähestymistavassa voitaisiin myös ottaa huomioon linkkien ennustaminen BIBREF56 virtuaalisten reunojen luomiseksi. Toinen mielenkiintoinen tutkimusryhmä koskee rinnakkaisesiintymisen ja virtuaalisten reunojen erottamista toisistaan, mahdollisesti luomalla uusia verkkomittauksia, joissa otetaan huomioon heterogeeniset linkit.",
      "id": "task461-8751191efcf14dd39af55c4153736cdb",
      "output": [
        "Mitä muita luonnollisen prosessoinnin tehtäviä voitaisiin kirjoittajien mielestä tutkia käyttämällä sanojen upotuksia?"
      ]
    },
    {
      "input": " Tietokokonaisuus jaettiin ajallisesti harjoittelu-, validointi- ja testikokonaisuuksiin, ja hyperparametrit optimoitiin siten, että AUC-ROC-arvo maksimoitiin validointikokonaisuudessa. ",
      "id": "task461-de6ae8d9863547cf8297a674baea19a3",
      "output": [
        "Mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Sen sijaan meidän mallimme on koulutettu vain 76 000 kysymyksellä harjoitusjoukossa.",
      "id": "task461-e3f631ecc3234b6ba97120ddb8380b7c",
      "output": [
        "Kokeilevatko kirjoittajat mallia myös muilla aineistoilla?"
      ]
    },
    {
      "input": " Käytämme mittauksina vakiomittauksia Precision, Recall ja F1 maininnan tasolla (Micro) ja asiakirjan tasolla (Macro). Näemme, että WW:n keskimääräinen linkitystarkkuus (Micro) on alhaisempi kuin TAC2010:n, ja NCEL päihittää kaikki perusmenetelmät sekä helpoissa että vaikeissa tapauksissa.",
      "id": "task461-ad584e3aef8e4ccf95c398e22e0a05cb",
      "output": [
        "Miten he varmistavat yleistämiskyvyn?"
      ]
    },
    {
      "input": "Monet keskittyvät sanan vektoriesityksen antamiseen, mutta yhä useammat antavat vektoriesityksen koko lauseesta tai tekstistä. Tämän työn jatkoksi pyrimme kehittämään järjestelmän, joka voi toimia verkossa ja joka suorittaa tekstin klusterointia tekstien upotusten perusteella yksi kerrallaan.",
      "id": "task461-d8e1c27fe4544b7499c81ff01617fa29",
      "output": [
        "Miten saapuvaa väittämää käytetään samankaltaisten faktatarkastettujen väittämien hakemiseen?"
      ]
    },
    {
      "input": "Koska BERT on jo saavuttanut huippuluokan suorituskyvyn kysymysten vastaamisessa, tässä jaksossa vertaamme ehdotettua malliamme huippuluokan kysymysten vastaamismalleihin (eli QANet BIBREF39) ja BERT-Base BIBREF26:een. BERT-mallilla on kaksi versiota: BERT-Base ja BERT-Large, mutta laskentaresurssien puutteen vuoksi voimme verrata vain BERT-Base-mallia BERT-Large-mallin sijaan.",
      "id": "task461-d50d57487e4546fd8d7c1cb8d1c02469",
      "output": [
        "Mitkä ovat vahvat perusmallit tietyissä tehtävissä?"
      ]
    },
    {
      "input": "Kokeissamme käytetään E2E NLG -haastetietokokonaisuutta BIBREF21, joka on 50 000 ravintola-alan instanssin joukkoistettu tietokokonaisuus. Mallimme koulutetaan virallisella koulutusjoukolla ja verifioidaan virallisella testausjoukolla. ",
      "id": "task461-b81d715bca3844578e781694213e45bd",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Arvioimme ehdotettuja malleja kolmella keskustelutietokokonaisuudella, kuten MojiTalk BIBREF16, PersonaChat BIBREF11 ja Empathetic-Dialogues BIBREF26.",
      "id": "task461-0da805e0b3764491a88de4ca40441728",
      "output": [
        "Mitä kolmea keskustelutietoaineistoa käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Ehdotetun interaktiivisen MRC:n (iMRC) keskeinen idea on rajoittaa asiakirjakontekstia, jota malli havaitsee kerrallaan. Tarkemmin sanottuna jaamme tukevan asiakirjan sen sisältämiin lauseisiin ja pidättelemme nämä lauseet mallilta. Kun mallille annetaan kysymys, sen on annettava komentoja, joilla se voi tarkkailla pidätetyn joukon lauseita; varustamme mallit toiminnoilla, kuten Ctrl+F (etsi merkki) ja stop, joilla se voi etsiä osittain tarkkailtuja asiakirjoja. Malli hakee iteratiivisesti ja ehdollistaa jokaisen komennon syötetyn kysymyksen ja aiemmin havaitsemiensa lauseiden perusteella. Tehtävämme edellyttää siis, että mallit \"ruokkivat itseään\" sen sijaan, että ne syöttäisivät niille tietoa lusikalla. Tämä tekee MRC:stä peräkkäisen päätöksenteko-ongelman, johon voidaan soveltaa vahvistusoppimista (RL).",
      "id": "task461-6aaf3790ea6843c1be38ae6dd52cd6a8",
      "output": [
        "Miten he kouluttavat malleja tässä asetelmassa?",
        "Tarjotaanko malleja koulutettaessa päätöksentekosekvenssejä valvontaan?"
      ]
    },
    {
      "input": "Molempien tehtävien syöttöaineisto koostuu 36:sta propagandistisesta ja 12:sta ei-propagandistisesta uutistoimituksesta kerätyistä vapaatekstimuotoisista uutisartikkeleista, jotka ammattimaiset kommentoijat ovat kommentoineet. ",
      "id": "task461-646542e9b1bf4e69b89c091163ddcd5a",
      "output": [
        "Mitä tietokokonaisuutta käytettiin?"
      ]
    },
    {
      "input": "Tämän ansiosta Macaw voi tukea multimodaalista vuorovaikutusta, kuten tekstiä, puhetta, kuvaa, klikkausta jne.",
      "id": "task461-726b55fdb90a43e6972187e8f333b572",
      "output": [
        "Mitä toimintatapoja Macaw tukee?"
      ]
    },
    {
      "input": "Tietojemme mukaan kaikki nykyiset järjestelmät käsittelevät tätä tehtävää kahden erillisen osatehtävän, eli tapahtumien louhinnan ja ajallisten suhteiden luokittelun, muodostamana putkistona, ja ne myös olettavat, että kultaiset tapahtumat on annettu, kun relaatioluokittelijaa koulutetaan BIBREF0, BIBREF1, BIBREF2, BIBREF3, BIBREF4 ja BIBREF5. Tarkemmin sanottuna he rakensivat päästä päähän -järjestelmiä, jotka ensin poimivat tapahtumat ja sitten ennustavat niiden väliset ajalliset suhteet (kuva FIGREF1). Näissä putkimalleissa tapahtumien poimintavirheet leviävät suhteiden luokitteluvaiheeseen, eikä niitä voida korjata jälkikäteen. Ensimmäinen panoksemme on ehdotus yhteiseksi malliksi, joka poimii sekä tapahtumia että ajallisia suhteita samanaikaisesti (ks. kuva FIGREF1).",
      "id": "task461-ae825391410149ec8770b0911af775f2",
      "output": [
        "Onko tämä ensimmäinen julkaisu, jossa ehdotetaan yhteistä mallia tapahtumien ja ajallisten suhteiden erottamiseen?"
      ]
    },
    {
      "input": "Käytimme SemEval 2010 -tehtävän 8 BIBREF8 relaatioluokitteluaineistoa. Se koostuu lauseista, jotka on manuaalisesti merkitty 19 relaatiolla (9 suunnattua relaatiota ja yksi keinotekoinen luokka Other). Harjoitusjoukkona on käytetty 8 000 lausetta ja testijoukkona 2 717 lausetta.",
      "id": "task461-daac6e711f634212b3f517f91d8ca95f",
      "output": [
        "Millä aineistolla he kouluttavat mallinsa?"
      ]
    },
    {
      "input": "Akkadin kieli on jaettu aineistossa kuuteen murteeseen: Vanha babylonialainen, keskibabylonialainen perifeerinen, standardibabylonialainen, uusbabylonialainen, myöhäisbabylonialainen ja uusassyrialainen BIBREF14 .",
      "id": "task461-3a23604da1ab4619a2f80fd552b919d1",
      "output": [
        "Mikä kieli on jaettu kuuteen murteeseen paperissa mainitussa tehtävässä?"
      ]
    },
    {
      "input": "Vaikka täydellisiä vastineita ei ole olemassa, päätimme valita parhaaksi vastineeksi Quoran kaksoiskysymyksiä koskevan tietokokonaisuuden BIBREF22. Tutkiaksemme sulautuksia laskimme euklidisen etäisyyden kahden kysymyksen välillä käyttämällä erilaisia sulautuksia, jotta voimme tutkia semanttisesti samankaltaisten ja erilaisten kysymysten välistä etäisyyttä.",
      "id": "task461-2f274457f2d4456ebfabcf593f950d54",
      "output": [
        "Mitä olemassa olevaa korpusta käytetään vertailukohtana näissä kokeissa?"
      ]
    },
    {
      "input": "Klusterointituloksen mittaamiseen käytetään kahta mittaria, tarkkuutta (ACC) ja normalisoitua keskinäistä informaatiota (NMI) BIBREF38 , BIBREF48 . ",
      "id": "task461-946d355c9b8942a296a5f59c2559a9c3",
      "output": [
        "Mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Esitämme mielipidesuositusten lopulliset tulokset, joissa vertaamme ehdotettua malliamme seuraaviin uusimpiin perusjärjestelmiin: RS-Average on laajalti hyväksytty perusjärjestelmä (esim, Yelp.com), joka käyttää keskiarvotettuja arvostelupisteitä lopullisena pistemääränä.RS-Linear arvioi arvostelupistemäärän, jonka käyttäjä antaisi INLINEFORM0 BIBREF49 , jossa INLINEFORM1 ja INLINEFORM2 ovat käyttäjän INLINEFORM3 ja tuotteen INLINEFORM4 koulutuspoikkeamat.RS-Item soveltaa INLINEFORM0 NN:ää arvostelupistemäärän BIBREF50 arvioimiseksi. Valitsemme INLINEFORM1:n välisen kosinin samankaltaisuuden mittaamaan tuotteen välistä etäisyyttä.RS-MF on uusin suosittelumalli, joka käyttää matriisifaktorointia ennustamaan luokituspistemäärää BIBREF8 , BIBREF41 , BIBREF25 .Sum-Opinosis käyttää graafipohjaista kehystä tuottamaan abstrakteja yhteenvetoja, kun otetaan huomioon redundantit mielipiteet BIBREF51 .Sum-LSTM-Att on uusin neurologinen abstrahoiva tiivistelmäohjelma, joka käyttää tarkkaavaisuuteen perustuvaa neuromallia yhdistämään tietoa useista tekstilähteistä ja tuottamaan tiivistelmiä LSTM-purkua käyttäen BIBREF44 , BIBREF3 Kaikki perusmallit ovat yhden tehtävän malleja, joissa ei oteta huomioon arvosanan ja tiivistelmän ennustamista yhdessä. Tulokset esitetään taulukossa TABREF46 . ",
      "id": "task461-918c2d5f164c4cb68591c5156a4a4e5d",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua mallia käyttämällä julkisesti saatavilla olevaa LibriSpeech ASR-korpusta BIBREF23. LibriSpeech-tietokanta koostuu 970 tunnista äänitietoja ja niitä vastaavista tekstitranskripteistä (noin 10 miljoonaa sanamerkkiä) sekä lisäksi 800 miljoonan sanamerkin pelkkä tekstiaineisto.",
      "id": "task461-6fe26965406e4f04a6227c664c3e654e",
      "output": [
        "Kuinka suuri LibriSpeech-tietokanta on?"
      ]
    },
    {
      "input": "Multimodaalinen esitys.Yhdistimme teksti- ja kuvaesitykset kahdella yksinkertaisella tavalla. Ensimmäinen tapa on tekstin ja kuvan yhdistäminen (concat). Ennen ketjuttamista sovellimme L2-normalisointia kuhunkin modaliteettiin. Toinen menetelmä on oppia yhteinen tila kahdelle modaliteetille ennen ketjuttamista (projektio).Kummankin modaliteetin projektio oppii $d$-ulottuvuusavaruuden niin, että $h_{1}, h_{2} \\ in \\mathbb {R}^{d}$. Kun multimodaalinen esitys on tuotettu ($h_{m}$) vasemman ja oikean parin osalta, vektorit liitetään suoraan regressiokerroksiin. Projektiot opitaan päästä päähän regressiokerrosten kanssa ja MSE:tä käytetään tappiofunktiona.",
      "id": "task461-bdb805bf343641ac99f2e1ac1f6676dd",
      "output": [
        "Mitä multimodaalisia representaatioita kokeissa käytetään?"
      ]
    },
    {
      "input": "Yleisessä muodossaan tyyppiloginen kielioppi koostuu seuraavista osista:",
      "id": "task461-eabff37b97a64d76a6c9a610de77d57f",
      "output": [
        "Hyväksyykö Grail Prolog-syötteet?"
      ]
    },
    {
      "input": "Seuraavaksi pyrimme selvittämään, pystyykö valmiiksi koulutettu moniyhteenliitäntäinen yhteistyöjärjestelmä ratkaisemaan RC-tehtäviä nollakuvausasetelmassa.",
      "id": "task461-5f04b9d2aa194e3988358e7aa8e72acd",
      "output": [
        "Mitä mallia käytetään lähtötasona?  "
      ]
    },
    {
      "input": "Testataksemme tietokokonaisuutemme vaikeusastetta tarkistimme enemmistöluokkatunnisteen ja viiden eri lähestymistapoja käyttävän uusimman NLI-mallin tarkkuuden: BiMPM (Bilateral Multi-Perspective Matching Model; BIBREF31 , BIBREF31 ), ESIM (Enhanced Sequential Inference Model; BIBREF32 , BIBREF32 ), Decomposable Attention Model BIBREF33 , KIM (Knowledge-based Inference Model; BIBREF34 , BIBREF34 ) ja BERT (Bidirectional Encoder Representations from Transformers model; BIBREF35 , BIBREF35 ). BERT:n osalta tarkistimme Wikipedian ja BookCorpusin avulla esivalmennetun ja SNLI:llä ja MultiNLI:llä koulutetun mallin suorituskyvyn.",
      "id": "task461-9390a250eef84d528eb22c25efa532b9",
      "output": [
        "Mitä NLI-malleja he analysoivat?"
      ]
    },
    {
      "input": "Arvioimme CBA:ta, LSA:ta, DCA:ta ja GMMv2b:tä käyttäen MOS-luonnollisuustuomioita (Mean Opinion Score), jotka on tuottanut joukko arvioijia. Pisteet vaihtelevat välillä 1-5, ja 5 tarkoittaa \"täysin luonnollista puhetta\".",
      "id": "task461-48e951d5300249b48a1b5f41952fb584",
      "output": [
        "Miten he vertaavat erilaisia mekanismeja luonnollisuuden kannalta?"
      ]
    },
    {
      "input": "Taulukossa TABREF1 esitetään yhteenveto edellä mainittujen aiempien tutkimusten määrällisistä tuloksista. Se sisältää mallipohjan, ominaisuuksien kuvauksen, luokitellut kielet ja käytetyn tietokokonaisuuden sekä saavutetun tarkkuuden. Taulukossa luetellaan myös ehdottamiemme mallien kokonaistulokset (ylhäällä). Eri kirjoittajien käyttämät kielet ja niiden lyhenteet ovat englanti (En), espanja (Es), ranska (Fr), saksa (De), venäjä (Ru), italia (It), bengali (Ben), hindi (Hi) ja telegu (Tel).",
      "id": "task461-25c3ac6e7d114aa2a04b11fc2683a0c9",
      "output": [
        "Verrataanko suorituskykyä perusmalliin?"
      ]
    },
    {
      "input": " Tässä työssä pidämme sanoja, jotka voivat osoittaa naapurisanojen ominaisuudet, kontekstuaalisina avainsanoina ja kehitämme lähestymistavan, jolla automaattisesti poimituista kontekstuaalisista avainsanoista voidaan luoda piirteitä.",
      "id": "task461-4c597fabe0ac4b89ad6a25ddc957ac01",
      "output": [
        "Mitä kontekstuaalisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Tärkein varoitus tämän esivalmennuksen yhteydessä on kuitenkin se, että lähdekooderi koulutetaan käyttämään englanninkielistä dekooderia, kun taas kohdekooderi koulutetaan käyttämään englanninkielisen kooderin - ei lähdekooderin - tuotoksia.",
      "id": "task461-8372f3edce6e4831aca68f8df44fa210",
      "output": [
        "Käytetäänkö pivot-kieltä kokeissa englanniksi vai jollakin muulla kielellä?"
      ]
    },
    {
      "input": "Toisin kuin nykyiset pullonkaulat, tässä työssä kohteena on kolme erityyppistä sosiaalista verkostoa (Formspring: kysymys- ja vastausfoorumi, Twitter: mikrobloggaus ja Wikipedia: yhteistoiminnallinen tietovarasto) kolmea verkkokiusaamisen aihetta (henkilökohtainen hyökkäys, rasismi ja seksismi) varten ilman eksplisiittistä ominaisuuksien suunnittelua kehittämällä syväoppimiseen perustuvia malleja yhdessä siirto-oppimisen kanssa.",
      "id": "task461-91b6ea55536e47668a7ff6cb3f6780e0",
      "output": [
        "Mitä kyberbulling-aiheita he käsittelivät?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme kattaa 218 videota NALCS:stä ja 103 LMS:stä, eli yhteensä 321 videota viikolta 1 viikolle 9 kevään 2017 turnaussarjassa kummastakin turnauksesta. ",
      "id": "task461-75bbc6f950734a4c9985317d6a73a45d",
      "output": [
        "Kuinka suuri esitelty tietokokonaisuus oli?"
      ]
    },
    {
      "input": "Enemmistö: teksti valitsee suurimman kokoisen etiketin. ESA: BIBREF0:ssa ehdotettu dataton luokittelija. Se kartoittaa sanat (tekstissä ja etikettien nimissä) Wikipedia-artikkelien otsikkoavaruuteen ja vertaa sitten tekstiä etikettien nimiin. Tämä menetelmä ei ole riippuvainen junasta. toteutimme ESA:n 08/01/2019 Wikipedia-dumppiin perustuen. Siinä on noin 6,1M sanaa ja 5,9M artikkelia. Word2Vec BIBREF23: Sekä tekstin että etikettien representaatiot ovat sanojen upotusten lisäys elementtiviisaasti. Tämän jälkeen kosinin samankaltaisuus määrittää etiketit. Tämäkään menetelmä ei perustu trainiin. Binary-BERT: Hienosäädämme BERT:n harjoituksessa, jolloin saadaan binäärinen luokittelija, joka päättää, onko kyseessä seuraamus vai ei; sitten testaamme sitä testissä - valitsemme yhden merkin skenaarioissa merkinnän, jolla on suurin todennäköisyys, ja usean merkin tapauksissa valitsemme kaikki merkinnät, joiden perusteella tehdään \"seuraamus\"-päätös.",
      "id": "task461-714f483d8f2441d4a9ef8a16664f7549",
      "output": [
        "Mitkä ovat niiden perusmallit?"
      ]
    },
    {
      "input": "RoBERTa-perusversiomme suoriutuu HotpotQA:sta melko hyvin (77,0 F1), vaikka jokainen kappale käsitellään erikseen, mikä estää kappaleiden välisen päättelyn. Hienosäädämme esivalmennetun mallin, joka ottaa kysymyksen ja useita kappaleita ja ennustaa vastauksen samalla tavalla kuin BIBREF21:n yhden askeleen QA-malli.  Käytämme $\\textsc {RoBERTa}_{\\textsc {LARGE}}}$ BIBREF24:ää esivalmennettuna alustuksena. ",
      "id": "task461-c5b8f40bae3548b280c18214a275fab9",
      "output": [
        "Mikä on se vahva lähtökohta, jonka tämä työ ylittää?"
      ]
    },
    {
      "input": "Tietokanta koostuu 90 annotoidusta asiakirjasta, joissa kussakin on 5 viittausta, jotka on luokiteltu 1-5, jossa 1 on vähiten merkityksellinen ja 5 on merkityksellisin, eli yhteensä 450 annotoitua viittausta.",
      "id": "task461-a244a535fc9c4e60ae7b886af490fdad",
      "output": [
        "Mikä on tämän rakennetun korpuksen koko?"
      ]
    },
    {
      "input": "Kokeissa verrataan GluonCV/NLP:n ja muiden avoimen lähdekoodin toteutusten välisiä mallisuorituksia Caffe-, Caffe2-, Theano- ja TensorFlow-malleilla, mukaan lukien ResNet BIBREF8 ja MobileNet BIBREF9 kuvien luokittelua varten (ImageNet), Faster R-CNN BIBREF10 objektien havaitsemiseen (COCO), Mask R-CNN BIBREF11 instanssien segmentointiin, Simple Pose BIBREF12 asennon estimointiin (COCO), textCNN BIBREF13 tunteiden analysointiin (TREC) ja BERT BIBREF14 kysymyksiin vastaamiseen (SQuAD 1).1), tunteiden analysointiin (SST-2), luonnollisen kielen päättelyyn (MNLI-m) ja parafraasointiin (MRPC).",
      "id": "task461-b2d05b5a219646cc8e98b47198a4f8e0",
      "output": [
        "Kokeilevatko he työkalupakkeja?"
      ]
    },
    {
      "input": "Lause todistetaan konstruktiivisesti valitsemalla monipäisen itsetarkkailukerroksen parametrit siten, että se toimii konvoluutiokerroksen tavoin.",
      "id": "task461-c91a28c6aa1646a6bb7c2fe4053d7185",
      "output": [
        "Miten he todistavat, että usean pään itsetarkkailu on vähintään yhtä tehokasta kuin konvoluutiokerros? "
      ]
    },
    {
      "input": "Teemme laajan joukon kokeita kaksikielisten sanakirjojen induktiota ja yksikielistä ja monikielistä sanojen samankaltaisuutta koskevilla vakiomittareilla sekä ulkoisella tehtävällä, joka on monikielisten hypernymien löytäminen. Sekä yksikielisissä että monikielisissä asetuksissa voimme havaita, että mallimme ovat yleisesti ottaen parempia kuin vastaavat perusmallit.  Kuten taulukosta 1 käy ilmi, tarkennusmenetelmämme parantaa jatkuvasti perusmalleja (eli VecMapia ja MUSEa) kaikissa kielipareissa ja kaikilla mittareilla. Ennen kaikkea mallikohtaisissa vertailuissa havaitaan, että ehdotetut muutokset sekä VecMapiin että MUSEen parantavat niiden laatua johdonmukaisesti useimpien mittareiden ja datakokoonpanojen osalta.",
      "id": "task461-72121e53cc6943a896268e185c04a934",
      "output": [
        "Mitä tehtäviä tämä menetelmä on parantanut?"
      ]
    },
    {
      "input": "Valvomattomassa skenaariossa samankaltaisuus lasketaan tuotettujen $h_{L}$- ja $h_{R}$-lauseen/kuvan esitysten kosinuksena.",
      "id": "task461-f0c08a2d5ecf4e22a52edb7a2a5eeffc",
      "output": [
        "Miten ne laskevat esitysten välisen samankaltaisuuden?"
      ]
    },
    {
      "input": "Tässä jaksossa tarkastelemme kolmea eri luokkaa tietojen lisäämiseen liittyviä tekniikoita, joita voidaan soveltaa tehokkaasti videotietoaineistoihin. Koulutusdatan koon ja monimuotoisuuden lisäämiseksi voimme luoda uusia äänitiedostoja asettamalla kunkin alkuperäisen äänitiedoston päälle uusia meluisia äänitiedostoja aika-alueella. Monipuolisten meluisten äänitiedostojen saamiseksi käytämme AudioSet-tietokokonaisuutta, joka koostuu 632 äänitapahtumaluokasta ja kokoelmasta, joka sisältää yli 2 miljoonaa manuaalisesti kommentoitua 10 sekunnin mittaista äänileikettä YouTube-videoista BIBREF28. Harkitsemme taajuus- ja aikapeittotekniikoiden - joiden on osoitettu parantavan huomattavasti end-to-end ASR-mallien suorituskykyä BIBREF23 - soveltamista hybridijärjestelmiimme. Vastaavasti niitä voidaan soveltaa verkossa LF-MMI-koulutuksen jokaisen epookin aikana ilman uudelleensuuntausta. luvussa SECREF5 esitetyn äänen segmentoinnin jälkeen), ja laskemme sen log mel -spektrogrammin, jonka ulottuvuus on $\\nu $ ja aika-askeleet $\\tau $:Taajuusmaskurointia sovelletaan $m_F$ kertaa, ja joka kerta maskoidaan taajuuskaistat $[f_0$, $f_0+ f)$, missä $f$ on näytteistetty alueelta $[0, F]$ ja $f_0$ on näytteistetty alueelta $[0, \\nu - f)$.Aikapeittoa sovelletaan valinnaisesti $m_T$ kertaa, ja joka kerta peitetään aika-askeleet $[t_0$, $t_0+ t)$, jossa $t$ on näytteistetty alueelta $[0, T]$ ja $t_0$ on näytteistetty alueelta $[0, \\tau - t)$. Tietojen lisääminen ::: Sekä nopeus- että tilavuushäiriö jäljittelevät spektrin keskisiirtymiä BIBREF18, BIBREF19. Koulutusdatan nopeushäiriöiden suorittamiseksi tuotetaan kustakin äänitteestä kolme versiota nopeuskertoimilla $0.9$, $1.0$ ja $1.1$. Harjoitusdatan koko kolminkertaistuu näin ollen. Äänenvoimakkuuden häirintää varten jokainen ääni skaalataan satunnaismuuttujalla, joka on poimittu tasaisesta jakaumasta $[0.125, 2]$.",
      "id": "task461-a600bfda57624c40a2b4e248c8b4661a",
      "output": [
        "Mitkä ovat parhaat kielensisäiset tiedonlisäysmenetelmät?"
      ]
    },
    {
      "input": "Se kehitettiin tekemällä kysely Followerwonk-verkkopalvelun sovellusliittymästä sijaintineutraaleilla alkusanoilla, joita jengiläisten tiedetään käyttävän Twitter-profiileissaan eri puolilla Yhdysvaltoja.",
      "id": "task461-e765d5b1b0064ab1874c9c1e63721e10",
      "output": [
        "Raportoivatko kirjoittajat vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Tietokanta koostuu yli 0,3 miljoonasta tietueesta, ja se on asetettu saataville tulevaa tutkimusta varten.",
      "id": "task461-5ba48d8efebd437d8caa3dfb17f9f480",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Tietokokonaisuus MSParS on julkaistu NLPCC 2019 -arviointitehtävässä. Koko tietokokonaisuus koostuu 81 826 näytteestä, jotka ovat englannin äidinkielisten puhujien kommentoimia. Niistä 80 prosenttia käytetään harjoitusjoukkona. Niistä 10 prosenttia käytetään validointijoukkona ja loput testijoukkona. Testijoukosta valitaan 3000 kovaa näytettä. Tämän tietokokonaisuuden mittari on täsmällinen vastaavuustarkkuus sekä koko testijoukon että kovan testijoukon osalta. Kukin näyte koostuu kysymyksestä, loogisesta muodosta, parametreista (entiteetti/arvo/tyyppi) ja kysymystyypistä, kuten taulukko TABREF3 osoittaa.",
      "id": "task461-7ffcbf07a23e4ed68d816aa9e68f2ac4",
      "output": [
        "Tarjoavatko harjoitusaineistot loogisen lomakevalvonnan?"
      ]
    },
    {
      "input": "Keräämme ihmisten arvioita Amazon Mechanical Turk -palvelussa ParlAI BIBREF18 -palvelun kautta.",
      "id": "task461-1ad8fdd6b25d4df4af1d1cbf3aac39eb",
      "output": [
        "Käyttävätkö ne joukkoistamista ihmisarvioiden keräämiseen?"
      ]
    },
    {
      "input": "Sanaleikit ovat sanaleikkivitsejä, joissa yksi merkki (esim. sana tai lause) viittaa kahteen tai useampaan merkitykseen hyödyntämällä polysemiaa, homonymiaa tai fonologista samankaltaisuutta toisen merkin kanssa tarkoituksenmukaisesti humoristisen tai retorisen vaikutuksen aikaansaamiseksi BIBREF3 .",
      "id": "task461-1339e91e32184810988b035c30da2b44",
      "output": [
        "Mitä ovat sanaleikit?"
      ]
    },
    {
      "input": "Oletetaan, että asiakirjoissa on keskimäärin INLINEFORM0 mainintaa, ja näistä globaaleista malleista NCEL:llä on yllättäen pienin aikakompleksisuus INLINEFORM1, koska se ottaa huomioon vain vierekkäiset maininnat, jossa INLINEFORM2 on ala-GCN-kerrosten määrä, joka osoittaa iteraatiot konvergenssiin asti.",
      "id": "task461-eee32a6ddc6045dfb836cbeee14ca644",
      "output": [
        "Käytetäänkö vain vierekkäisten yksiköiden mainintoja vai käytetäänkö joissakin tapauksissa useampia mainintoja (vierekkäisten lisäksi)?"
      ]
    },
    {
      "input": "Tässä työssä käytämme esivalmennusta kunkin tehtävän merkitsemättömiin tietoihin ja osoitamme, että se voi parantaa luokittelujärjestelmien suorituskykyä.",
      "id": "task461-b9781d50bee34fedaa6506bdfacbacb5",
      "output": [
        "Mihin MVCNN liittyy?"
      ]
    },
    {
      "input": "Voimme siis asettaa rajoituksen, jonka mukaan mallimme esitys syötteen syntaksista ei voi sisältää tätä kontekstista riippumatonta tietoa. Tämä säännönmukaistaminen on ehdottomasti parempi vaihtoehto kuin se, että sanojen merkityksen kaikkien näkökohtien sallitaan siirtyä syötteen syntaksirepresentaatioon. Ilman tällaista rajoitusta kaikille syötteille voitaisiin periaatteessa antaa omat syntaktiset luokkansa.",
      "id": "task461-291102e55b304c36b39f19ad73b92fb9",
      "output": [
        "Tarkoittaako rajoitettujen hermoyksiköiden olemassaolo sitä, että sanojen merkitykset ovat kiinteitä eri yhteyksissä?"
      ]
    },
    {
      "input": "Varmistaaksemme ehdotetun mallin tehokkuuden suoritamme useita kokeita kolmella kiinalaisella koneellisella luetun ymmärtämisen tietokokonaisuudella, nimittäin CMRC-2017 BIBREF17 , People's Daily (PD) ja Children Fairy Tales (CFT) BIBREF2. Lisäksi käytämme myös Children's Book Test (CBT) -tietokokonaisuutta BIBREF1 testataksemme yleistämiskykyä monikielisessä tapauksessa.",
      "id": "task461-ce2f07363e6b44e0b8422f77ed61dfcb",
      "output": [
        "mitä julkisia tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Jotta voimme testata tämän uuden arkkitehtuurin tehokkuutta verkkokeskustelujen suistumisen ennustamisessa, kehitämme ja levitämme kaksi uutta tietokokonaisuutta. Ensimmäinen kolminkertaistaa laajasti kuratoidun \"Conversations Gone Awry\" -tietokannan BIBREF9, jossa Wikipedian keskustelusivun keskustelut on merkitty joukolla sen mukaan, johtavatko ne lopulta henkilökohtaisiin hyökkäyksiin; toinen perustuu suositun ChangeMyView-alipalvelun moderoinnin \"in-the-wild\" -tilanteeseen, jossa pyritään ennustamaan, joutuuko keskustelu myöhemmin moderaattorin toimenpiteisiin \"epäkohteliaan tai vihamielisen\" käyttäytymisen vuoksi. ",
      "id": "task461-f912456f74104b40b220cdd73aea620c",
      "output": [
        "Mihin kahteen tietokokonaisuuteen mallia sovelletaan?"
      ]
    },
    {
      "input": "Työmme tärkein anti on siis uusi rinnakkainen data-teksti NLG-korpus, joka (1) on pikemminkin keskustelunomainen kuin tiedonhaku- tai kysymysvastaustyyppinen ja soveltuu siten paremmin avoimen alueen dialogijärjestelmään, (2) edustaa uutta, tutkimatonta aluetta, jolla on kuitenkin erinomaiset mahdollisuudet sovelluksiin keskustelevissa asiamiehissä, ja (3) sisältää korkealaatuisia, manuaalisesti puhdistettuja, ihmisten tuottamia lausumia.",
      "id": "task461-5908f99c296d400fbf8de0ace0768e3a",
      "output": [
        "Miten kirjoittajat varmistivat, että korpus on puhdas, vaikka se on joukkorahoitettu?"
      ]
    },
    {
      "input": "Arvioidaksemme järjestelmällisesti EHR:ien vapaasta tekstistä poimittujen kliinisten tunnearvojen merkitystä, rakennamme ensin perusmallin käyttämällä strukturoituja ominaisuuksia, jotka ovat samankaltaisia kuin aiemmissa tutkimuksissa, jotka koskevat takaisinottoriskin ennustamista BIBREF6.",
      "id": "task461-1de9ed6844344071b4c5b21e99d9bafa",
      "output": [
        "Vertailevatko ne aiempia malleja?"
      ]
    },
    {
      "input": "Olemme toteuttaneet seuraavat rajapinnat Macaw'ta varten:[leftmargin=*]File IO: Tämä rajapinta on suunniteltu kokeellisiin tarkoituksiin, kuten keskustelevan hakutekniikan suorituskyvyn arvioimiseen tietokokonaisuudessa, jossa on useita kyselyjä. Tämä ei ole vuorovaikutteinen käyttöliittymä.Standard IO: Tämä vuorovaikutteinen komentorivikäyttöliittymä on suunniteltu kehitystarkoituksiin, jotta voidaan olla vuorovaikutuksessa järjestelmän kanssa, tarkastella lokitietoja ja debugata tai parantaa järjestelmää.Telegram: Tämä interaktiivinen käyttöliittymä on suunniteltu vuorovaikutukseen todellisten käyttäjien kanssa (ks. KUVA 4). Telegram on suosittu pikaviestipalvelu, jonka asiakaspuolen koodi on avointa lähdekoodia. Olemme toteuttaneet Telegram-botin, jota voidaan käyttää eri laitteilla (henkilökohtaiset tietokoneet, tabletit ja matkapuhelimet) ja eri käyttöjärjestelmillä (Android, iOS, Linux, Mac OS ja Windows). Tämä käyttöliittymä mahdollistaa multimodaalisen vuorovaikutuksen (teksti, puhe, klikkaus, kuva). Sitä voidaan käyttää myös pelkkään puheeseen perustuvaan vuorovaikutukseen. Puheentunnistuksessa ja puheen tuottamisessa Macaw tukeutuu online-rajapintoihin, esimerkiksi Google Cloudin ja Microsoft Azuren tarjoamiin palveluihin. Lisäksi Telegramissa on useita suosittuja ryhmiä ja kanavia, mikä mahdollistaa sosiaalisten verkostojen integroinnin edelleen keskustelujärjestelmiin. Katso esimerkiksi Naserin ja Zamanin tutkimus uutisten suosiosta Telegramissa BIBREF12.",
      "id": "task461-509f074899b64abdab37b04e459b2412",
      "output": [
        "Mikä käyttöliittymä Macawilla on tällä hetkellä?"
      ]
    },
    {
      "input": "holistic: Perusmalli, joka kartoittaa holistisen kuvan ominaisuuden ja LSTM-koodatun kysymysominaisuuden yhteiseen avaruuteen ja suorittaa elementtiviisaasti kertolaskun niiden välillä.TraAtt: Perinteinen huomiomalli, WTL-mallin BIBREF9 toteutus, jossa käytetään samoja $3\\times 3$ alueita kuin SalAtt-mallissa.RegAtt: Alueiden huomiomalli, joka käyttää uutta huomiomenetelmäämme, joka on samanlainen kuin SalAtt-malli, mutta jossa ei ole alueiden esivalintaa.ConAtt: Konvoluutiomalli, jossa SalAtt-mallissa käytetty BiLSTM korvataan painoja jakavalla lineaarisella kartoituksella, joka on toteutettu konvoluutiokerroksella.Lisäksi vertaamme SalAtt-malliamme suosittuihin perusmalleihin i.iBOWIMG BIBREF4 , VQA BIBREF1 , ja uusimpia huomiointimalleja eli WTL BIBREF9 , NMN BIBREF21 , SAN BIBREF14 , AMA BIBREF33 , FDA BIBREF34 , D-NMN BIBREF35 , DMN+ BIBREF8 kahdessa COCO-VQA:n tehtävässä.",
      "id": "task461-cc002c0509ed4e0d824e25cd6b7f1d8b",
      "output": [
        "Mihin aiempiin julkaisuihin tämä työ vertaa tuloksiaan?"
      ]
    },
    {
      "input": "Numeerisesti mallimme parantaa DAR-tarkkuutta verrattuna Bi-LSTM-CRF:ään 2,1 %:lla ja 0,8 %:lla SwDA:ssa ja MRDA:ssa.",
      "id": "task461-03e78e68579d4e3395065875f848d5a9",
      "output": [
        "Kuinka paljon paremmat ne ovat kuin uusimmat ratkaisut SWDA:ssa ja MRDA:ssa?"
      ]
    },
    {
      "input": "Koska yksi tavoitteistamme on verrata automaattisessa käännöksessä käytettävien ydinviittausketjujen ominaisuuksia lähdetekstien ja ihmisen tekemien viittausten ominaisuuksiin, käytämme tietoja ParCorFull-korpuksesta, joka on englannin ja saksan välinen korpus, johon on merkitty täydelliset ydinviittausketjut BIBREF46.",
      "id": "task461-69452955579f48fab91e6b22df4cc6f4",
      "output": [
        "Mitä kieliä uutis- ja TED-tietoaineistoissa esiintyy?"
      ]
    },
    {
      "input": "1) Tyypilliset menetelmät. Perusmenetelmiksi valitaan kolme tyypillistä tietämysgraafin sulauttamismenetelmää: TransE, TransR ja TransH. 2) Polkupohjaiset menetelmät. Vertaamme menetelmäämme kahteen tyypilliseen polkupohjaiseen malliin, joihin kuuluvat PTransE ja ALL-PATHS BIBREF18. 3) Attribuutteihin perustuvat menetelmät. Useita uusimpia attribuutteihin perustuvia menetelmiä, kuten R-GCN BIBREF24 ja KR-EAR BIBREF26 , käytetään vertaamaan menetelmiimme kolmessa todellisessa tietokokonaisuudessa.",
      "id": "task461-c84b733b437c445984ba00562f694758",
      "output": [
        "Mitä seitsemää uusinta menetelmää käytetään vertailussa?"
      ]
    },
    {
      "input": "Lisäksi ehdotamme uutta vakiomuotoista kokeiluprotokollaa IBM-UB-1-tietokannalle BIBREF25 (SECREF50 ), jotta lähestymistapojen vertailu olisi tulevaisuudessa helpompaa. IAM-OnDB-tietokanta BIBREF42 on luultavasti käytetyin arviointitietokanta online-käsialan tunnistukseen. Se koostuu 298 523 merkistä 86 272 sanatapauksessa 221 kirjoittajan kirjoittamasta 11 059 sanasta koostuvasta sanakirjasta. Käytämme IAM-OnDB-tietokannan vakiomuotoista erottelua: yksi harjoitussarja, kaksi validointisarjaa ja testisarja, jotka sisältävät 5 363, 1 438, 1 518 ja 3 859 kirjoitettua riviä. Viritämme dekooderin painot käyttäen validointijoukkoa, jossa on 1 438 nimikettä, ja ilmoitamme virheprosentit testijoukon osalta. Esitämme arvioinnin tuotantojärjestelmästämme, joka on koulutettu omilla tietokokonaisuuksillamme ja jota on sovellettu useisiin kirjallisuudesta saataviin julkisesti saatavilla oleviin vertailutietokokonaisuuksiin. Huomattakoon, että kaikissa tässä jaksossa esitetyissä kokeissa arvioimme nykyistä järjestelmäämme ilman mitään virityksiä, jotka on tehty kyseisiä tehtäviä varten.ICDAR-2013 Competition for Online Handwriting Chinese Character Recognition BIBREF45 -kilpailussa esiteltiin tietokokonaisuus yleisimpien kiinalaisten merkkien luokittelua varten. Taulukossa TABREF56 ilmoitetaan virhetasot verrattuna kilpailussa julkaistuihin tuloksiin ja muiden tekemiin uudempiin töihin. ICFHR2018 Competition on Vietnamese Online Handwritten Text Recognition using VNOnDB BIBREF50 -kilpailussa tuotantojärjestelmäämme arvioitiin muita järjestelmiä vastaan. Kilpailussa käytetty järjestelmä on se, joka on raportoitu ja kuvattu tässä asiakirjassa. Lisenssirajoitusten vuoksi emme voineet tehdä kokeita kilpailun harjoitusaineistolla tai erityisiä virityksiä kilpailua varten, mikä ei koskenut muita tässä mainittuja järjestelmiä.",
      "id": "task461-552007452b9c4599809cddb8caa8e371",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Kirjallisuudessa on jo ehdotettu erilaisia NMT:n monikielisiä laajennuksia. Kirjojen BIBREF18 ja BIBREF19 kirjoittajat soveltavat monitehtäväoppimista kouluttaakseen malleja useille kielille. Zoph ja Knight BIBREF20 ehdottavat monilähdemallia, ja BIBREF21 esittelee merkkitason koodaimen, joka on yhteinen useille lähdekielille. Omassa asetuksessamme noudatamme Johnson et al. BIBREF22 ehdottamaa pääideaa. Kyseisen artikkelin kirjoittajat ehdottavat yksinkertaista lisäystä lähdekielen puolella olevalla kielilipukkeella (ks. kuva 2 ), jolla osoitetaan kohdekieli, joka dekooderin on tuotettava. Tämä lippu liitetään tiheään vektoriesitykseen, ja sitä voidaan käyttää käynnistämään valitun kielen tuottaminen. Artikkelin kirjoittajat väittävät, että malli mahdollistaa siirto-oppimisen ja tukee kääntämistä sellaisten kielten välillä, jotka eivät ole eksplisiittisesti käytettävissä koulutuksessa.",
      "id": "task461-85e3586345eb41b880265f37210e1757",
      "output": [
        "Mitä neuraalisia konekäännösmalleja voidaan oppia siirto-oppimisen kannalta?"
      ]
    },
    {
      "input": "Ensimmäisessä tehtävässä ihmisarvioijia pyydetään arvioimaan näitä tuotoksia kolmesta ensimmäisestä näkökulmasta, jotka ovat merkityksellisyys, houkuttelevuus ja kielen sujuvuus, Likertin asteikolla 1-10 (kokonaislukuarvot). Houkuttelevuuden osalta kommentoijilta kysytään, kuinka houkuttelevia otsikot ovat.",
      "id": "task461-bff039534c7045b68d87743c68a98bef",
      "output": [
        "Miten vetovoimapisteet mitataan?"
      ]
    },
    {
      "input": "Saaduista tuloksista käy ilmi, että muuntajamalli saavuttaa korkeamman BLEU-pistemäärän kuin sekä Attention-kooderi-dekooderi että sekvenssi-sekvenssi-malli.",
      "id": "task461-48496efd90454405929505a50c851c65",
      "output": [
        "Millaisia tuloksia he saivat verrattuna uusimpaan tekniikkaan?"
      ]
    },
    {
      "input": "Kuten kirjallisuudessa BIBREF4 , BIBREF8 on tavallista, käytämme 300-ulotteisia vektoreita upotuksissa, ja kaikki sanavektorit normalisoidaan yksikköpituisiksi ennen arviointia.",
      "id": "task461-5bba37aff456491aaa0374f9691dda1e",
      "output": [
        "Millaisia ulottuvuuksia sanojen upotukset tuottavat käyttämällä faktorointia?"
      ]
    },
    {
      "input": "Sanasto muodostetaan koko datan perusteella, joten se sisältää sekä harjoitus- että testausjoukon sanaston.",
      "id": "task461-560f434f843745e4ab77092b91dd8a77",
      "output": [
        "Onko sanasto sama kaikissa kielissä?"
      ]
    },
    {
      "input": "Kultaiseksi standardiksi sentimenttileksikoksi valitsimme manuaalisesti luodun sanaston tšekin BIBREF11 , saksan BIBREF12 , ranskan BIBREF13 , makedonian BIBREF14 ja espanjan BIBREF15 .",
      "id": "task461-8ad5dbb261474e30b5f59a23ed3c6b0e",
      "output": [
        "mihin tunnelähteisiin niitä verrataan?"
      ]
    },
    {
      "input": "Tavanomaisen SMT:n valvotun uudelleenjärjestelyn innoittamana ehdotamme tässä artikkelissa valvottuun tarkkaavaisuuteen perustuvaa NMT-mallia (Supervised Attention based NMT, SA-NMT). Perinteisen SMT:n tapaan käytämme ensin valmiita kohdistimia (GIZA++ BIBREF3 tai fast_align BIBREF4 jne.) saadaksemme kaksikielisen harjoituskorpuksen kohdistuksen etukäteen. Sitten, kun tätä kohdistustulosta pidetään tarkkaavuuden valvontana, opimme yhdessä tarkkaavuutta ja käännöstä, molemmat valvotusti. Koska tavanomaiset kohdistimet tuottavat laadukkaampia kohdistuksia, odotetaan, että valvotun huomion NMT:n kohdistus paranee, mikä johtaa parempaan käännössuorituskykyyn.",
      "id": "task461-8a1ee20ce4324e53b2f2c3272beba567",
      "output": [
        "Mitä perinteisiä linjausmalleja he käyttävät ohjeena?"
      ]
    },
    {
      "input": "Yhteenvetojen arvioinnissa käytämme vakiomittausta ROGUE. Vertailun vuoksi aiempiin AMR-pohjaisiin tiivistämismenetelmiin ilmoitamme ROGUE-1:n Recall-, Precision- ja INLINEFORM0-pisteet.",
      "id": "task461-8bd396663c2b43468062753ea15531f7",
      "output": [
        "Mitä arviointimenetelmiä käytetään?"
      ]
    },
    {
      "input": "Wen et al. wensclstm15 ehdottivat hiljattain RNN-pohjaista lähestymistapaa, joka päihitti aiemmat menetelmät useilla mittareilla. Tuotetut lauseet eivät kuitenkaan useinkaan sisältäneet kaikkia haluttuja attribuutteja.",
      "id": "task461-5645373915c6442ca2bdc4d6fa2fd206",
      "output": [
        "Miten RNN-pohjaisissa generointimalleissa menetetään jonkin verran tietoa?"
      ]
    },
    {
      "input": "Indusoituja latentteja rakenteita sisältävien koodaajien on osoitettu hyödyttävän useita tehtäviä, kuten asiakirjojen luokittelua, luonnollisen kielen päättelyä BIBREF12, BIBREF13 ja konekääntämistä BIBREF11. ",
      "id": "task461-9a9b5c62a82d41809424e68c30a96bda",
      "output": [
        "Onko näyttöä siitä, että latentteja rakenteita sisältävät kooderit toimivat hyvin muissa tehtävissä?"
      ]
    },
    {
      "input": "VG-harjoitusjoukkomme koostuu 85 prosentista datasta: 16k kuvaa ja 740k vastaavaa aluekuvausta.",
      "id": "task461-41644c2ea31243c2955cb9b7097d5720",
      "output": [
        "Kuinka suuria tietoja tämä tutkimus tarjoaa?"
      ]
    },
    {
      "input": "Hyödynsimme olemassa olevaa, annotoitua Twitter-tietokokonaisuutta, joka on rakennettu masennukseen liittyvien oireiden hierarkkisen mallin BIBREF12 , BIBREF13 perusteella. Tietokanta sisältää 9 473 annotaatiota 9 300 twiitille. Kukin twiitti on annotoitu siten, että siinä ei ole todisteita masennuksesta (esim. \"Kansalaiset pelkäävät taloudellista masennusta\") tai että siinä on todisteita masennuksesta (esim. \"masentunut pettymyksestä\"). ",
      "id": "task461-d522c8f1c2794f49bd78ade0105859ab",
      "output": [
        "Arvioidaanko ne vain englanninkielisillä tietokokonaisuuksilla?"
      ]
    },
    {
      "input": "Käytämme kahta tietokokonaisuutta, NELL-Onea ja Wiki-Onea, jotka on muodostettu BIBREF-tietokannassa11 .",
      "id": "task461-af97fa8e903f4dd0b21bd11b9cec640e",
      "output": [
        "Mitä tietokokonaisuuksia käytetään lähestymistavan arvioinnissa?"
      ]
    },
    {
      "input": "Recurrent +ELMo -mallimme käyttää BIBREF9:n kielimallia tarjoamaan kontekstualisoituja upotuksia edellä esitetylle perusmallille, kuten kirjoittajat suosittelevat.OpenAI GPT -mallimme hienosäätää 12-kerroksista 768-ulotteista 768-ulotteista yksisuuntaista muuntajaa BIBREF:stä27 , joka on esivalmennettu kielimallina Books-korpuksella BIBREF36 .",
      "id": "task461-1cdef56d8b7a4263bd44c5dc033c7640",
      "output": [
        "käyttivätkö he muita esivalmisteltuja kielimalleja kuin bertiä?"
      ]
    },
    {
      "input": "Vastausten valinnan tulosten raportoinnissa käytetään MAP- ja MRR-arvoja, mutta vastausten käynnistämistehtävä arvioidaan F1-pistemäärän avulla. MULT-menetelmän tulos raportoidaan taulukossa. 1.",
      "id": "task461-bfefbbc1694248abbafc6806f3e91890",
      "output": [
        "Onko tarkkuus ainoa mittari, jota he käyttävät järjestelmien vertailussa?"
      ]
    },
    {
      "input": "Kun annetaan monivalintakysymys $qa$, jossa on kysymysteksti $q$ ja vastausvaihtoehdot A= $\\lbrace a_i\\rbrace $ , valitsemme merkityksellisimmät tuplat $T$:stä ja $S$:sta seuraavasti. Valinta Tuple KB:stä: Käytämme käänteistä indeksiä löytääksemme ne 1000 tuplea, joissa on eniten päällekkäisiä merkkejä kysymyksen merkkien $tok(qa).$ kanssa.",
      "id": "task461-39b184915b2e439698141cd5790b93f6",
      "output": [
        "Käytetäänkö kokonaisuuksien yhdistämisprosessia?"
      ]
    },
    {
      "input": "Aineistomme on kehitetty indeksoimalla ja esikäsittelemällä OSG-verkkofoorumi. Foorumilla on paljon erilaisia ryhmiä, kuten masennus, ahdistus, stressi, parisuhde, syöpä, sukupuolitauti jne.",
      "id": "task461-ce336fd18fc845919e21023adc8ba789",
      "output": [
        "Miten he saivat OSG-tietokannan?"
      ]
    },
    {
      "input": "Arvioimme ehdotettuja malleja neljällä eri NLG-alueella: ravintolan ja hotellin löytäminen, kannettavan tietokoneen ostaminen ja television ostaminen. Ravintola- ja hotellitietokannat kerättiin BIBREF4 -tietokannassa, kun taas kannettavan tietokoneen ja television tietokannat on julkaistu BIBREF22 -tietokannassa, jossa on paljon suurempi syöttöavaruus, mutta vain yksi harjoitusesimerkki kutakin DA:ta varten, joten järjestelmän on opittava käsitteiden osittainen toteuttaminen ja kyettävä yhdistämään ne uudelleen ja soveltamaan niitä näkymättömiin DA:iin. ",
      "id": "task461-18595a7f91e244e6a8f4b034497fbb18",
      "output": [
        "Arvioidaanko mallia NLG- vai dialogitietoaineistoilla?"
      ]
    },
    {
      "input": "Tietokannan rakentaminen: keräsimme Pekingin matkailutietoja verkosta, mukaan lukien hotelli-, nähtävyys- ja ravintola-alueita (jäljempänä näitä kolmea aluetta kutsutaan HAR-aluetiedoiksi). Sen jälkeen käytimme HAR-verkkotunnusten yksiköiden metrotietoja metrotietokannan rakentamiseen. Tavoitteiden luominen: tietokannan perusteella suunniteltiin monialueen tavoitegeneraattori. Verkkotunnusten välinen suhde on kuvattu kahdella tavalla. Yksi on kahden lähellä toisiaan sijaitsevan tavoitteen rajoittaminen. Toinen tapa on käyttää taksia tai metroa kahden HAR-alueilla sijaitsevan, kontekstissa mainitun kohteen välillä kulkemiseen.  Vuoropuhelujen kerääminen: Ennen virallisen tiedonkeruun aloittamista vaadimme työntekijöitä tekemään pienen määrän vuoropuheluja ja annoimme heille palautetta vuoropuhelun laadusta. Sitten hyvin koulutetut työntekijät paritettiin keskustelemaan annettujen tavoitteiden mukaisesti.  Vuoropuhelujen merkinnät: Käytimme joitakin sääntöjä, joiden avulla merkitsimme automaattisesti vuoropuhelun tekoja käyttäjän tilojen, järjestelmän tilojen ja vuoropuheluhistorian mukaan. ",
      "id": "task461-104e4ad82c4b4ce88793e3620bc8e4ae",
      "output": [
        "Miten aineisto kerättiin?"
      ]
    },
    {
      "input": "NER-kokeiden tulokset raportoidaan erikseen ehdotetun järjestelmän kolmelle eri osalle. Tulokset osoittavat, että ensimmäisessä tapauksessa F1-tulos on harjoitusjoukossa aina yli 97 prosenttia, ja maksimiarvo on 99,65 prosenttia. Molemmilla testijoukoilla suorituskyky laskee ja vaihtelee välillä 94-97 %. UGC:n tapauksessa F1-pistemääriä vertaamalla voidaan havaita, että suorituskyky laskee merkittävästi.",
      "id": "task461-101c8fda33b84965b7bc6c81fe8815ef",
      "output": [
        "Millaisia tuloksia he ovat saaneet entiteettien tunnistustehtävässä?"
      ]
    },
    {
      "input": "Vertaamme lähestymistapaamme kahteen muuhun, joista ensimmäisessä käytetään lähes samaa twiittidataa kuin koulutuksessa, ja toisessa CrowdFlower-tietokokonaisuutta, johon on merkitty tunteita. Ensimmäisessä Wang et al. BIBREF21 latasivat yli 5 miljoonaa twiittiä, jotka sisälsivät yhden 131:stä emotionaalisesta hashtagista, jotka perustuvat Parrottin kolmitasoiseen tunteiden luokitteluun seitsemään kategoriaan: ilo, suru, viha, rakkaus, pelko, kiitollisuus, yllätys. ",
      "id": "task461-6aea77bf31d64aacb53b140e959404ce",
      "output": [
        "Mitä tietoja kokeissa käytetään?"
      ]
    },
    {
      "input": "Ryhmittelemme mallit sen perusteella, mitä tavoitetehtävää ne optimoivat. Uskomme, että tämä työ voi auttaa ymmärtämään olemassa olevaa kirjallisuutta.  Uskomme, että näiden mallien suorituskyky on hyvin riippuvainen siitä, mitä tavoitetehtävää se optimoi - vierekkäisen sanan (twiitin sisäiset suhteet), vierekkäisen twiitin (twiittien väliset suhteet), itse twiitin (autokooderi), strukturoitujen resurssien, kuten parafraasitietokantojen, mallintaminen ja heikko valvonta. ",
      "id": "task461-f6dc632606ad4df2af4b12b733f366b9",
      "output": [
        "Miten ne edistävät kirjallisuuden ymmärtämistä osana tavoitetehtäväänsä?"
      ]
    },
    {
      "input": "Kokeilujemme perusmalli on selitetty Alec Go:n artikkelissa [1]. Malli käyttää kokeessaan Naive Bayes-, SVM- ja Maximum Entropy -luokittelijoita.",
      "id": "task461-b7fbefa1a7544ea1a7ee78f7bbef8601",
      "output": [
        "Mihin aiemmin ehdotettuihin menetelmiin tätä menetelmää verrataan?"
      ]
    },
    {
      "input": "N-GrAM sijoittui ensimmäiselle sijalle kaikissa muissa tapauksissa paitsi kielten moninaisuutta koskevassa tehtävässä. Tässä tapauksessa perusjärjestelmä oli parhaalla sijalla, ja meidän järjestelmämme sijoittui toiseksi pienellä marginaalilla. Järjestelmämme päihitti perustason huomattavasti yhteisessä tehtävässä, sillä perustason tulokset olivat huomattavasti alhaisemmat sukupuolitehtävässä kuin kielilajitehtävässä.",
      "id": "task461-532758b33f644b079e848792958df1df",
      "output": [
        "Missä tehtävässä malli menestyy huonoimmin?"
      ]
    },
    {
      "input": "Peruskonseptina on käyttää puhelimia erottelevaa mallia tuottamaan kehystason foneettisia piirteitä ja sitten käyttää näitä piirteitä parantamaan RNN LID-järjestelmiä, jotka on alun perin rakennettu raakojen akustisten piirteiden avulla. Ensimmäinen vaihe on siis piirteiden yhdistäminen, ja foneettista piirrettä käytetään aputietona akustisen RNN LID:n apuna. Tätä parannetaan edelleen, sillä lisätutkimuksissa havaittiin, että yksinkertaisempi malli, jossa RNN LID-syötteenä käytetään vain äänteellistä piirrettä, tuottaa vielä parempaa suorituskykyä. Kutsumme tätä foneettisiin piirteisiin perustuvaa RNN-mallia foneettiseksi temporaaliseksi neuraaliseksi LID-lähestymistavaksi eli PTN LID:ksi. Yksinkertaisemman mallirakenteen lisäksi PTN tarjoaa syvällisemmän näkemyksen LID-tehtävään löytämällä uudelleen foneettisen temporaalisen ominaisuuden arvon kielen erottelussa. ",
      "id": "task461-10055a0fee044b8ca797948374c768ee",
      "output": [
        "Mikä on tutkielman tärkein anti? "
      ]
    },
    {
      "input": "Arvioimme SECREF5:ssä kuvattua sekvenssistä sekvenssiin - QRNN-arkkitehtuuria haastavassa neuraalisessa konekäännöstehtävässä, IWSLT-saksan ja englannin käännöksessä, jossa käytetään täysin merkkitason segmentointia. ",
      "id": "task461-0814acf4210b4c9ca8192016f234d94c",
      "output": [
        "Mitä kielipareja käytetään konekääntämisessä?"
      ]
    },
    {
      "input": "käytämme CORD-19-tietokokonaisuutta BIBREF2, joka sisältää yli 45 000 tieteellistä artikkelia, joista yli 33 000 on kokotekstejä COVID-19:stä, SARS-CoV-2:sta ja niihin liittyvistä koronaviruksista. Kehitämme lauseiden luokittelumenetelmiä kaikkien COVID-19:n radiologisia löydöksiä kuvaavien lauseiden tunnistamiseksi.  Teemme kokeita menetelmämme tehokkuuden todentamiseksi. Menetelmämme löytää CORD-19-tietokannasta onnistuneesti joukon kliinisiä löydöksiä, jotka liittyvät läheisesti COVID-19:ään.",
      "id": "task461-ebf9c4b1b09d424b956e261a96e51da5",
      "output": [
        "Kuinka laaja on COVID-19-kirjallisuuden kokoelma?"
      ]
    },
    {
      "input": "Tietokanta koostuu 5000 bahasa indonesian kielisestä arvostelusta.",
      "id": "task461-6540d4afbb9542eeab9a8f4ec627df25",
      "output": [
        "Sisältyykö tietokantaan muita kuin englanninkielisiä arvioita?"
      ]
    },
    {
      "input": "Jotta voidaan mallintaa vastausta, joka on kokoelma span-merkkejä, usean span-merkinnän pää käyttää $\\mathtt {BIO}$-merkintäformaattia BIBREF8: $\\mathtt {B}$ merkitään span-merkinnän alkuun, $\\mathtt {I}$ merkitään span-merkinnän sisälle ja $\\mathtt {O}$ merkitään merkkeihin, jotka eivät sisälly span-merkintään. Tällä tavoin saamme sarjan kappaleita, jotka voidaan purkaa lopulliseksi vastaukseksi - kokoelmaksi spaneja.",
      "id": "task461-95afcc99452d49fdb8d1ed78373adf19",
      "output": [
        "Miten he käyttävät sekvenssin merkitsemistä vastatakseen monitulkintakysymyksiin?"
      ]
    },
    {
      "input": "Wikilinkit voidaan nähdä laajamittaisena, luonnollisesti esiintyvänä, joukkoresursoituna tietokokonaisuutena, jossa tuhannet inhimilliset kommentoijat tarjoavat perustotuuksia kiinnostavista maininnoista. Tämä tarkoittaa, että tietokokonaisuus sisältää monenlaista kohinaa, joka johtuu erityisesti epäjohdonmukaisista yhteyksistä. Valmistelemme tietokokonaisuutemme Wikilinksin paikallisen kontekstin versiosta ja ratkaisemme ground-truth-linkit käyttämällä Wikipedia-dumppia huhtikuulta 2016. Käytämme sivu- ja redirect-taulukoita resoluutioon ja pidämme tietokannan pageid-saraketta Wikipedian entiteettien yksilöllisenä tunnisteena. Hylkäämme maininnat, joiden perustotuutta ei pystytty selvittämään (vain 3 % maininnoista).",
      "id": "task461-b38548150bd44b43829dfd727a8705f8",
      "output": [
        "Miten laadunvalvonta suoritettiin, jotta teksti on meluisaa mutta huomautukset ovat tarkkoja?"
      ]
    },
    {
      "input": "Tämä toiminta-avaruus on suuruusluokkaa $A=\\mathcal {O}(|V| \\times |O|^2)$, jossa $V$ on toimintaverbien määrä ja $O$ on niiden erillisten objektien määrä maailmassa, joiden kanssa agentti voi olla vuorovaikutuksessa. Koska tämä on liian suuri tila, jota RL-agentti ei voi tehokkaasti tutkia, tietämysgraafia käytetään tämän tilan karsimiseen asettamalla toiminnot paremmuusjärjestykseen niiden esiintymisen perusteella nykyisessä tietämysgraafissa ja graafin objektien välisten suhteiden perusteella, kuten BIBREF7",
      "id": "task461-74f8eefad53248428da7c4f677830d6c",
      "output": [
        "Miten aluetiedon siirto esitetään tietämysgraafina?"
      ]
    },
    {
      "input": "Aiempien töiden BIBREF56 , BIBREF57 , BIBREF17 mukaisesti käytämme MNCut-spektristä klusterointialgoritmia BIBREF58 , jota voidaan soveltaa laajalti samankaltaisiin NLP-tehtäviin, joissa on kyse suuriulotteisista ominaisuusavaruuksista BIBREF59 , BIBREF60 , BIBREF18 .",
      "id": "task461-62fac629a46048bfbc1dd76695d5eb04",
      "output": [
        "Mitä klusterointialgoritmia käytetään VerbNet-erikoistuneiden esitysten päällä?"
      ]
    },
    {
      "input": "Siksi ehdotamme tässä asiakirjassa monimodaalista STT:tä, jossa on kaksi komponenttia: (i) englanninkielinen ASR-järjestelmä, joka on koulutettu How2-tietokannalla, ja (ii) muuntajaan perustuva BIBREF0-perusteinen visuaalisesti perustuva MMT-järjestelmä.",
      "id": "task461-c7b345bf067a4b969175c9ddf308ad13",
      "output": [
        "Mitä tietokokonaisuutta tässä työssä käytettiin?"
      ]
    },
    {
      "input": "Diskurssiominaisuuksien johtamiseksi rakennetaan entiteettiruudukko syöttämällä asiakirja NLP-putken läpi, jotta voidaan tunnistaa erottuvat entiteetit. Kaksi erilaista diskurssipiirrettä luodaan täyttämällä olioruudukko joko i) kieliopillisilla suhteilla (GR) tai ii) RST-diskurssisuhteilla (RST).  Kun piirre merkitään sellaisenaan INLINEFORM4 , muodostetaan poolausvektori INLINEFORM5 char-bigrammeja varten ja ketjutetaan INLINEFORM6 INLINEFORM7:ään ennen kuin tuloksena oleva vektori syötetään softmax-kerrokselle.",
      "id": "task461-ea78f344f2404be4b1ace007f7968443",
      "output": [
        "Miten diskurssiominaisuudet sisällytetään malliin?"
      ]
    },
    {
      "input": "Verrattuna yhden tehtävän perustasoon suorituskyky parani vähäisten resurssien En-De-tehtävässä ja oli vertailukelpoinen runsaasti resursseja sisältävässä En-Fr-tehtävässä.",
      "id": "task461-e222a527ad864bb39d6bada03f3ed532",
      "output": [
        "Kuinka suuria kielteisiä vaikutuksia ehdotetuilla tekniikoilla on paljon resursseja vaativiin tehtäviin?"
      ]
    },
    {
      "input": "Mitä tulee nopeuteen, järjestelmämme pystyi lemmatisoimaan 7,4 miljoonaa sanaa kannettavalla tietokoneella lähes kahdessa minuutissa verrattuna MADAMIRA-järjestelmän 2,5 tuntiin, eli 75 kertaa nopeammin. ",
      "id": "task461-21a33df1bf884976b178bebad6533420",
      "output": [
        "Miten nopeus mitattiin?"
      ]
    },
    {
      "input": "Vertasimme monikierroksista emotionaalisesti sitouttavaa dialogimalliamme (MEED) kahteen perusmalliin - vaniljaiseen sekvenssistä sekvenssiin -malliin (S2S) ja HRAN:iin.",
      "id": "task461-f55eb6bb779a41ef8907f53641c27ee1",
      "output": [
        "Mitä kahta perusmallia käytetään?"
      ]
    },
    {
      "input": "Kokeilemme pienillä feed-forward-verkoilla neljää erilaista NLP-tehtävää varten: kielen tunnistaminen, puhekielisten osien merkitseminen, sanojen segmentointi ja tilastollisen konekääntämisen esijärjestäminen.",
      "id": "task461-68ae97741c28478eb878e8e9b3c94978",
      "output": [
        "Millaisissa NLP-tehtävissä kirjoittajat arvioivat feed-forward-verkkoja?"
      ]
    },
    {
      "input": "Kokeet suoritettiin useilla erityyppisillä luokittelijoilla: Gaussian Naive Bayes, Multinomial Naive Bayes, Decision Trees, Random Forests ja Maximum Entropy -luokitin.",
      "id": "task461-ddd401eadbe94c92a9414c9ebc929cf2",
      "output": [
        "Mitä mallia he kouluttavat?"
      ]
    },
    {
      "input": "Kuten kuvasta 1 käy ilmi, kahden tutkimusartikkelin samankaltaisuuden arvioimiseksi tehokkaampi strategia vertailee ja yhdenmukaistaa (paikallisen painotuksen avulla) yksittäisiä tärkeitä sanoja (avainsanoja) tiivistelmäparin sisällä, kun taas muiden sanojen (esim. lopetussanojen) sisältämä informaatio, joka on yleensä vähemmän merkityksellistä, voidaan tehokkaasti jättää huomiotta (painottaa pienemmäksi).  Ehdotamme, että opitaan semanttisesti tietoinen Network Embedding (NE), joka sisältää sanatason kohdistamisominaisuuksia, jotka on abstrahoitu tekstisekvensseistä, jotka liittyvät vertikaalipareihin. Kun annetaan lauseiden pari, mallimme yhdenmukaistaa ensin jokaisen sanan toisessa lauseessa toisen lauseen avainsanojen kanssa (joita painotetaan adaptiivisesti ylöspäin huomiomekanismin avulla), jolloin saadaan joukko hienojakoisia vastaavuusvektoreita.",
      "id": "task461-8e0a4ae6e6e845918f0a6454f5d5753d",
      "output": [
        "Mitä tekstisekvenssejä kuhunkin kärkeen liittyy?"
      ]
    },
    {
      "input": "Ennen SAOKE-tietokokonaisuutta julkaistiin OIE-algoritmien arvioimiseksi BIBREF20:ssä OIE-tehtäviä varten annotoitu tietokokonaisuus, joka sisälsi 3 200 lausetta kahdelta alalta. BIBREF20:n mukaan tietokokonaisuus oli \"13 kertaa suurempi kuin edellinen suurin annotoitu Open IE -korpus\".",
      "id": "task461-0b018e7bd2d64a00b5c0ab5f25654f40",
      "output": [
        "Mikä on edellisen suurimman OpenIE-tietokannan koko?"
      ]
    },
    {
      "input": "Analysoimalla suuria määriä vuoropuhelun tekosekvenssejä, jotka korreloivat tiettyihin lopputuloksiin, voidaan johtaa erilaisia sääntöjä, esimerkiksi: \"Tietojen pyytämisen jatkaminen keskustelun loppuvaiheessa johtaa usein asiakkaan tyytymättömyyteen.\" Tämä voidaan sitten kodifioida automatisoituja järjestelmiä varten laadituiksi parhaiden käytäntöjen mallisäännöiksi, kuten \"Tietopyyntö olisi esitettävä keskustelun alkuvaiheessa, ja vastauksen, informatiivisen lausunnon tai anteeksipyynnön olisi seurattava keskustelun loppupuolella.\". Analyysimme auttaa rajaamaan, miten tiettyjen vuoropuhelulakien käyttö voi todennäköisesti johtaa erilaisiin lopputuloksiin. Havaitsemamme painotukset vaihtelevat tarjotun ymmärryksen määrän suhteen: esimerkiksi lisäavun tarjoaminen keskustelun lopussa tai asiakkaan kiittäminen tuottaa enemmän tyytyväisiä asiakkaita ja enemmän ratkaistuja ongelmia (suhdeluvut ovat yli 6:1). Jotkin tulokset ovat kuitenkin paljon hienovaraisempia: esimerkiksi kyllä-ei-kysymysten esittäminen keskustelun alkuvaiheessa on vahvasti yhteydessä ongelmanratkaisuun (suhde 3:1), mutta niiden esittäminen keskustelun lopussa on yhtä vahvasti yhteydessä tyytymättömiin asiakkaisiin. Kun keskustelun keskivaiheilla annetaan yksityiskohtaisia vastauksia, jotka eivät ole pelkkiä myöntäviä, kieltäviä tai vastauksen kuittaavia vastauksia (esim. vastaus (muu)), saadaan tyytyväisiä asiakkaita, jotka eivät ole turhautuneita. Vastaavasti tietojen pyytäminen keskustelun loppupuolella (mikä viittaa siihen, että lisätietoja tarvitaan vielä keskustelun päättyessä) johtaa tyytymättömiin ja tyytymättömiin asiakkaisiin, ja suhde on vähintään 4:1.",
      "id": "task461-c8aeffe3f7384208bd8609819bb24bf1",
      "output": [
        "Mitä malleja ja sääntöjä johdetaan?"
      ]
    },
    {
      "input": "Samaan aikaan tietty tieto taivutetuista sanamuodoista kontekstissa voi olla hyödyllistä, mutta se häviää lemmatisoinnin aikana, ja tämä johtaa pisteiden laskuun. Tämä tarkoittaa, että lemmatisointi tuo mukanaan sekä etuja että haittoja WSD:lle ELMon avulla. ",
      "id": "task461-3c33d6822f3d449e939cb7e9cf37e8af",
      "output": [
        "Mainitsevatko kirjoittajat mitään haittapuolia siitä, että syötteet lemmatoidaan ennen ELMon harjoittelua?"
      ]
    },
    {
      "input": "Klusterointituloksen arvioinnissa käytetään Calinski-Harabaszin BIBREF-pistemäärää42 , joka tunnetaan myös nimellä varianssisuhdekriteeri. CH-pistemäärä määritellään klusterin sisäisen hajonnan ja klusterin välisen hajonnan välisenä suhteena. CH-pistemäärän vaihteluväli on $[0, +\\infty ]$, ja korkeampi CH-pistemäärä vastaa parempaa klusterointia.  Visuaalista validointia varten piirrämme ja tarkastelemme myös opittujen representaatioiden t-Distributed Stochastic Neighbor Embedding (t-SNE) BIBREF52- ja Uniform Manifold Approximation and Projection (UMAP) BIBREF53 -karttoja.",
      "id": "task461-0a7818ffd8294b62b2d0c32f2b75ae50",
      "output": [
        "Miten he arvioivat menetelmäänsä?"
      ]
    },
    {
      "input": "Tulokset on esitetty kuvassa FIGREF87 eri aiheiden lukumäärille, ja niistä nähdään, että ehdotettu malli on parempi kuin kaikki perusmallit, ja svi-versio suoriutuu niistä parhaiten. Jotta voitaisiin arvioida stokastisen variationaalisen päättelyn (svi) laskennallisia etuja eräalgoritmiin verrattuna, log marginaalinen todennäköisyys (tai log evidenssi) piirrettiin iteraatioiden lukumäärän funktiona. Kuvassa FIGREF88 esitetään tämä vertailu. Ei ole yllättävää, että svi-versio konvergoituu paljon nopeammin suurempiin log marginaalisen todennäköisyyden arvoihin verrattuna eräversioon, mikä kuvastaa svi-algoritmin tehokkuutta.",
      "id": "task461-08c83fc1356a4d9c95e3a2e8ac813150",
      "output": [
        "Mitkä ovat ehdotetun mallin edut?"
      ]
    },
    {
      "input": "Rakennamme Twitter-tilien tietokannan, joka perustuu kahteen aiemmissa töissä kommentoituun luetteloon. Muiden kuin tosiasioihin perustuvien tilien osalta käytämme BIBREF1:n 180 Twitter-tilin luetteloa. Toisaalta faktatilien osalta käytämme BIBREF19:n luetteloa, jossa on 32 muuta Twitter-tiliä, joita riippumattomat kolmannet osapuolet pitävät luotettavina.",
      "id": "task461-56fb48d964ee4453ae4097758666f907",
      "output": [
        "Miten he hankkivat tietokokonaisuuden?"
      ]
    },
    {
      "input": "Arvioidaksemme ehdotettua mallia käyttäytymiseen liittyvillä tiedoilla käytämme pariterapiakorpusta (CoupTher) BIBREF21 ja syöpäparien vuorovaikutustietoaineistoa (Cancer) BIBREF22. Nämä ovat kohdennettuja olosuhteita, joissa käyttäytymisohjattu kielimalli voi tarjota paremman suorituskyvyn. Hyödynnämme Couple's Therapy Corpus -korpusta toimialan sisäisenä kokeellisena korpuksena, koska myös käyttäytymisen luokittelumallimme on koulutettu sillä. ",
      "id": "task461-e490c8be3eaa4314843adb7cbc3e2893",
      "output": [
        "Millä tietokokonaisuudella malli on koulutettu?"
      ]
    },
    {
      "input": "Tässä jaksossa kuvataan ensin perusmenetelmä, joka on saanut vaikutteita BIBREF12:n ja BIBREF13:n \"align to segment\" -menetelmästä. Sen jälkeen ehdotamme kahta laajennusta, jotka antavat mallille segmentointiprosessin kannalta merkityksellisen signaalin, jotta voidaan siirtyä segmentoinnin ja kohdistamisen yhteiseen oppimiseen.",
      "id": "task461-a2637049296941358273f12ca677365b",
      "output": [
        "Ilmoitetaanko asiakirjassa vain linjausta koskeva perustaso?"
      ]
    },
    {
      "input": "Aivan kuten sec:johdannossa esitettiin, samankaltaisuuden laskeminen täsmällisesti on hankalaa, koska siihen liittyy INLINEFORM0-laskenta. Näin ollen tarkastelemme monte-carlo-approksimaatiota: DISPLAYFORM0jossa INLINEFORM0 on luettelo INLINEFORM1:stä poimituista oliopareista. Käytämme peräkkäistä näytteenottoa saadaksemme INLINEFORM6 , mikä tarkoittaa, että otamme ensin INLINEFORM7:n INLINEFORM8:n perusteella INLINEFORM9:stä ja sitten INLINEFORM10:n INLINEFORM11:n ja INLINEFORM12:n perusteella INLINEFORM13:sta.",
      "id": "task461-4ed1082cbc1043f589c25c8a764cd831",
      "output": [
        "Mitä otantamenetelmää he käyttävät lähestyäkseen olioparien ehdollisten todennäköisyysjakaumien samankaltaisuutta?"
      ]
    },
    {
      "input": "Valitsimme seuraavat kolme mallia perusmalleiksi: K-means on tunnettu tietojen klusterointialgoritmi, toteutamme algoritmin sklearn-työkalupakilla ja edustamme dokumentit käyttämällä TF-IDF:llä painotettua sanasäkkiä (bag-of-words).LEM BIBREF13 on bayesiläinen mallinnusmenetelmä avoimen toimialueen tapahtumien louhintaan. Se käsittelee tapahtumaa latenttina muuttujana ja mallintaa tapahtuman syntymisen sen yksittäisten tapahtumaelementtien yhteisjakaumana. Toteutamme algoritmin oletuskonfiguraatiolla.DPEMM BIBREF14 on ei-parametrinen seosmalli tapahtumien louhintaan. Se korjaa LEM:n rajoituksen, jonka mukaan tapahtumien lukumäärä on tiedettävä etukäteen. Toteutamme mallin oletuskonfiguraatiolla.",
      "id": "task461-89e34d4290df4c7eaaa8a929341ec104",
      "output": [
        "Mitä peruslähestymistapoja tämä lähestymistapa päihittää?"
      ]
    },
    {
      "input": "Word2vec-esitys on paljon parempi, kehittyneempi ja uudempi tekniikka, joka toimii kartoittamalla sanat 300-ulotteiseen vektoriesitykseen.",
      "id": "task461-f0f946f6c7a244d9a1289fab0354be93",
      "output": [
        "Mikä on sulautumien ulottuvuus?"
      ]
    },
    {
      "input": "Käytämme kokeissamme kolmea tietokokonaisuutta: IWSLT14 saksa-englanti, turkki-englanti ja WMT14 englanti-saksa.",
      "id": "task461-024a010edb6d4b2091a2d38978554513",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?",
        "mitä kielipareja tutkitaan?"
      ]
    },
    {
      "input": "Tässä artikkelissa ehdotamme parannettua RNN-T-mallia, jossa on kielellinen ennakkoasenne, ongelman ratkaisemiseksi. Malli koulutetaan ennustamaan kielitunnuksia sekä alasanoja. Varmistaaksemme, että malli voi oppia CS-tietoa, lisäämme kielitunnukset CS-kohtaan transkriptiossa, kuten kuvassa 1 on esitetty.",
      "id": "task461-01eb7b075bd64078be082fcca4b3024b",
      "output": [
        "Miten he saavat kielelliset identiteetit?"
      ]
    },
    {
      "input": "Taulukon TABREF31 tulokset voivat antaa käsityksen siitä, että INLINEFORM0 on vain skaalattu INLINEFORM1 . Vaikka on totta, että ne osoittavat lineaarista korrelaatiota, INLINEFORM2 voi tuottaa erilaisen järjestelmäsijoituksen kuin INLINEFORM3, kun otetaan huomioon sen noudattama integraalinen moniviittausperiaate. Se, mitä pidämme INLINEFORM4:ssä kaikkein kannattavimpana, on kuitenkin sen suorittama kaikkien käytettävissä olevien viitteiden kaksinkertainen huomioon ottaminen. Ensinnäkin INLINEFORM5:n rakentaminen, jotta saadaan kattavampi viite, jota vasten arvioidaan, ja sitten INLINEFORM6:n laskeminen, joka skaalaa tuloksen riippuen viitteiden välisestä yhteisymmärryksestä. Osoitimme, että INLINEFORM0 on kattava mittari, joka ei ainoastaan arvioi järjestelmän suorituskykyä kaikkia viitteitä vastaan, vaan ottaa huomioon myös niiden välisen sopimuksen. ",
      "id": "task461-25de4816ccc54065bcfc3412eb1d2274",
      "output": [
        "Mikä tekee siitä luotettavamman mittarin?"
      ]
    },
    {
      "input": "Rakennamme kunkin asiakirjan upotukset käyttämällä MLDoc-ohjelmalla hienosäädettyjä BERT-malleja. Kunkin asiakirjan sulautuksen keskiarvot kerätään yhteen, jotta jokaisesta asiakirjasta saadaan yksi vektori. Tämän jälkeen lasketaan englanninkielisen asiakirjan ja sen käännöksen upotusten välinen kosinin samankaltaisuus. Taulukossa TABREF21 havaitaan, että kosinin samankaltaisuuden mediaani kasvaa dramaattisesti vastakohtaisen harjoittelun myötä, mikä viittaa siihen, että upotuksista tuli kielestä riippumattomampia.",
      "id": "task461-b3913aee51834ad7b3b1ec00c125b8b2",
      "output": [
        "Miten ne kvantifioivat asiakirjan upotusten ja käännöksen välisen vastaavuuden?"
      ]
    },
    {
      "input": "Sitten näytämme twiitin tekstin ja kuvan ja pyydämme heitä luokittelemaan sen johonkin kuudesta kategoriasta: Ei hyökkäyksiä mitään yhteisöä vastaan, rasistisia, seksistisiä, homofobisia, uskontoon perustuvia hyökkäyksiä tai hyökkäyksiä muita yhteisöjä vastaan.",
      "id": "task461-a59fc2e7126545bbbbab492fcd9888b7",
      "output": [
        "Mitä merkintöjä tietokokonaisuudessa on saatavilla - onko tweat käyttänyt vihapuheita vai ei?"
      ]
    },
    {
      "input": "Kohdetiedoissa koodi on kirjoitettu Python-ohjelmointikielellä.",
      "id": "task461-160fdee5fbec43e78b56eac05d50919a",
      "output": [
        "Mikä ohjelmointikieli on kohdekieli?"
      ]
    },
    {
      "input": "Vertaamme suorituskykyä toistuvien entiteettiverkkojen (EntNet) BIBREF17 -malliin.  RelNet-mallin keskimääräinen virhe on 0,285 % kaikissa tehtävissä, mikä on parempi kuin EntNet-mallin BIBREF17 tulokset. RelNet-malli pystyy saavuttamaan 0 prosentin testivirheen 11 tehtävässä, kun taas EntNet-malli saavuttaa 0 prosentin virheen 7 tehtävässä.",
      "id": "task461-a8360d10a299451f88b4088bb593a5e5",
      "output": [
        "Mihin menetelmiin RelNetiä verrataan?"
      ]
    },
    {
      "input": "Arvioimme mallejamme kolmella eri tietokokonaisuudella: CSAT-tietokokonaisuus CSAT-ennustusta varten, joka koostuu puhutuista transkripteistä (automaattinen ASR:n avulla).20 uutisryhmää aiheiden tunnistustehtävää varten, joka koostuu kirjoitetusta tekstistä;Fisher Phase 1 -korpus aiheiden tunnistustehtävää varten, joka koostuu puhutuista transkripteistä (manuaalinen);",
      "id": "task461-29c8a8e56c064f19bf46456b7aa46921",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät arvioinnissa?"
      ]
    },
    {
      "input": "Osoitimme kuitenkin myös, että tuotetuissa virheissä oli eroja kunkin menetelmän osalta ja että sanatasolla oli erilainen vaikutus lähestymistavasta tai yksiköistä riippuen. Tulevassa työssä keskitytäänkin analysoimaan näiden järjestelmien ortografisia tuotoksia kahdella tavalla: 1) tutkitaan päästä päähän -menetelmien tuottamia virheitä ja tutkitaan useita lähestymistapoja ranskan kielessä tehtyjen yleisten virheiden korjaamiseksi ja 2) verrataan päästä päähän -menetelmiä SLU-kontekstissa ja arvioidaan osittain oikein tuotettujen sanojen semanttista arvoa.",
      "id": "task461-96a185229c7b4b3ea58d4560a111bd44",
      "output": [
        "Mihin tulevassa työssä keskitytään?"
      ]
    },
    {
      "input": "Käytämme Nguyenin aiemmin käyttämiä laajamittaisia antonyymi- ja synonyymipareja:16. Alun perin aineistoparit kerättiin WordNet BIBREF9- ja Wordnik-tietokannoista.",
      "id": "task461-57474c825fd64ffb934388cc9ab416ad",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät menetelmänsä arvioinnissa?"
      ]
    },
    {
      "input": "Tietokanta: Kokeilemme kahta laajalti käytettyä tehtävää englannin ja japanin kieliparin välillä: KFTT BIBREF12 ja BTEC BIBREF13 . KFTT on kokoelma Kioton kaupunkia käsitteleviä Wikipedia-artikkeleita ja BTEC on matkakeskustelukorpus. BTEC on helpompi käännöstehtävä kuin KFTT, koska KFTT kattaa laajemman alan, siinä on enemmän harvinaisia sanoja ja suhteellisen pitkiä lauseita. ",
      "id": "task461-9d00f5d4d4034bc098b8e928e7e412a3",
      "output": [
        "Mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Alustava havaintomme osoittaa, että on mahdollista rakentaa geometrinen avaruusprojektio upotusavaruuksien välille, jotta voidaan oppia rajoitetuista annotoiduista kielellisistä resursseista ja auttaa kieltenvälisessä NE-tunnistuksessa.",
      "id": "task461-9220638e69354f8c9a877a3cb7288252",
      "output": [
        "Mikä on heidän mallinsa?"
      ]
    },
    {
      "input": "Tiedot ovat peräisin ADAPT:n ja Microsoftin yhteisestä hankkeesta. ",
      "id": "task461-ded0e7aa239b473ca2e3f43f346d4f42",
      "output": [
        "mitä tietokokonaisuutta käytettiin?"
      ]
    },
    {
      "input": "Ehdotettu järjestelmä koostuu kaksisuuntaisesta pitkäaikaisesta lyhytkestoisesta muistista (BiLSTM, Bi-directional Long Short-Term Memory) BIBREF16, kaksitasoisesta tarkkaavaisuusmekanismista BIBREF29, BIBREF30 ja jaetusta esityksestä tunteiden ja tunteiden analysointitehtäviä varten. BiLSTM koodaa kunkin sanan sanan edustuksen. Tämä esitys on yhteinen tunne- ja tunneanalyysin osajärjestelmien välillä. Kukin jaettu esitys syötetään sitten molempien osajärjestelmien ensisijaiseen huomiomekanismiin. Ensisijainen huomiomekanismi löytää kullekin sanalle parhaan edustuksen kutakin tehtävää varten. Toissijainen huomiomekanismi toimii ensisijaisen huomion lisäksi poimimalla parhaan lause-esityksen keskittymällä kuhunkin tehtävään sopivaan kontekstiin. Lopuksi molempien tehtävien representaatiot syötetään kahdelle eri feed-forward-neuraaliverkolle, jotka tuottavat kaksi tulosta - toisen tunneanalyysia ja toisen tunneanalyysia varten. Kukin komponentti selitetään seuraavissa alaluvuissa.",
      "id": "task461-5998396a8add4650a76a36a615ecce73",
      "output": [
        "Miten monitehtäväinen työskentely toteutetaan?"
      ]
    },
    {
      "input": "Ensimmäisessä skenaariossa dekooderi varustetaan ylimääräisellä morfologiataulukolla, joka sisältää kohdepuolen affiksit.",
      "id": "task461-2b50226580a8423aa76e8f48b2ce460f",
      "output": [
        "Minkälaista morfologista tietoa \"morfologinen taulukko\" sisältää?"
      ]
    },
    {
      "input": "Ensimmäisessä vaiheessa tarinasta poimitaan tietämysgraafi, joka kuvaa paikkoja, hahmoja, esineitä ja näiden kokonaisuuksien välisiä suhteita. Esittelemme kaksi tekniikkaa. Ensimmäisessä käytetään neuraalista kysymys-vastaus-tekniikkaa suhteiden poimimiseen tarinatekstistä. Toisessa menetelmässä, joka toimii perustasona, käytetään OpenIE5 -tekniikkaa, joka on yleisesti käytetty sääntöpohjainen tiedonlouhintatekniikka. Yksinkertaisuuden vuoksi tarkastelimme ensisijaisesti sijainti-sijainti- ja sijainti-hahmo/objekti-suhteita, joita kuvassa FIGREF4 edustavat \"next to\"- ja \"has\"-reunat. Sen sijaan ehdotamme uutta menetelmää, jossa hyödynnetään kontekstiin perustuviin kysymys-vastaus-tehtäviin koulutettuja malleja entiteettien louhintaan ilman tehtävästä riippuvia tietoja tai hienosäätöä. Menetelmämme, jonka nimi on AskBERT, hyödyntää kysymys-vastausmallia ALBERT BIBREF15. AskBERT koostuu kahdesta päävaiheesta, jotka on esitetty kuvassa KUVA 7: vertexien louhinta ja graafin rakentaminen. Ensimmäisessä vaiheessa tarinasta poimitaan joukko entiteettejä - graafin kärkipisteet. Tarkoituksena on poimia tietoa erityisesti hahmoista, paikoista ja esineistä. Tämä tehdään esittämällä QA-mallille kysymyksiä, kuten \"Kuka on tarinan hahmo?\". BIBREF16 on osoittanut, että QA-mallille annettujen kysymysten muotoilu on tärkeää, ja tämä muodostaa perustan sille, miten muotoilemme kysymyksemme - kysymykset esitetään niin, että ne todennäköisemmin antavat yhden vastauksen, esimerkiksi kysymällä \"Missä on tarinan paikka?\" eikä \"Missä ovat tarinan paikat?\". Huomasimme erityisesti, että pronominin valinta voi olla ratkaisevaa: \"Missä on tarinan paikka?\" tuotti johdonmukaisemman tuloksen kuin \"Mikä on tarinan paikka?\". ALBERT QA on koulutettu tuottamaan myös erityinen <$no$-$answer$>-merkki, kun se ei löydä vastausta kysymykseen tarinasta. Menetelmämme hyödyntää tätä pyytämällä iteratiivisesti QA-mallilta kysymyksen ja peittämällä pois edellisessä vaiheessa tulostetun todennäköisimmän vastauksen. Tämä prosessi jatkuu, kunnes <$no$-$answer$>-merkistä tulee todennäköisin vastaus. Ensimmäisessä vaiheessa tarinasta poimitaan joukko entiteettejä - graafin kärkipisteitä. Haluamme poimia tietoa erityisesti hahmoista, paikoista ja esineistä. Tämä tehdään esittämällä QA-mallille kysymyksiä, kuten \"Kuka on tarinan hahmo?\". BIBREF16 on osoittanut, että QA-mallille annettujen kysymysten muotoilu on tärkeää, ja tämä muodostaa perustan sille, miten muotoilemme kysymyksemme - kysymykset esitetään niin, että ne todennäköisemmin antavat yhden vastauksen, esimerkiksi kysymällä \"Missä on tarinan paikka?\" eikä \"Missä ovat tarinan paikat?\". Huomasimme erityisesti, että pronominin valinta voi olla ratkaisevaa: \"Missä on tarinan paikka?\" tuotti johdonmukaisemman tuloksen kuin \"Mikä on tarinan paikka?\". ALBERT QA on koulutettu tuottamaan myös erityinen <$no$-$answer$>-merkki, kun se ei löydä vastausta kysymykseen tarinasta. Menetelmämme hyödyntää tätä pyytämällä iteratiivisesti QA-mallilta kysymyksen ja peittämällä pois edellisessä vaiheessa tulostetun todennäköisimmän vastauksen. Tätä prosessia jatketaan, kunnes <$no$-$answer$>-merkistä tulee todennäköisin vastaus.Seuraava vaihe on graafin rakentaminen. Tyypilliset interaktiiviset fiktiomaailmat ovat yleensä rakenteeltaan puita, eli ei syklejä paitsi paikkojen välillä. Tätä tosiasiaa hyväksikäyttäen käytämme lähestymistapaa, jossa graafi rakennetaan kärkijoukosta yksi relaatio - tai reuna - kerrallaan. Jälleen kerran käytämme koko tarinan juonta kontekstina ja kysymme ALBERT-QA-mallilta satunnaista lähtöpaikkaa $x$ aiemmin poimitusta kärkipistejoukosta ja kysymme kysymykset \"Missä paikassa voin vierailla $x$:stä?\" ja \"Kuka/mikä on $x$:ssä?\". Menetelmä näiden kysymysten muotoilussa noudattaa samaa menetelmää, joka kuvattiin pisteiden poiminnan yhteydessä. QA-mallin antama vastaus sovitetaan verteksijoukkoon valitsemalla verteksi $u$, joka sisältää parhaan päällekkäisyyden vastauksen kanssa. Pisteiden väliset suhteet lisätään laskemalla suhteiden todennäköisyys QA-mallin antaman vastauksen tulostodennäköisyyksien perusteella. Vertailimme ehdotettua AskBERT-menetelmää ei-neuraaliseen, sääntöpohjaiseen lähestymistapaan. Tämä lähestymistapa perustuu OpenIE5:n poimimaan tietoon, jota seuraa jälkikäsittely, kuten nimettyjen yksiköiden tunnistaminen ja puheosien merkitseminen. OpenIE5:ssä yhdistetään useita huippuluokan ideoita useista olemassa olevista julkaisuista BIBREF17, BIBREF18 ja BIBREF19 tehokkaan tiedonlouhintatyökalun luomiseksi. OpenIE5 tuottaa tietystä lauseesta useita kolmioita muodossa $\\langle entity, relation, entity\\rangle $ tiiviinä esityksenä lauseesta, joista jokaiselle on annettu luottamuspisteet. Näihin kolmioihin merkitään toisinaan myös sijaintitietoja, jotka osoittavat, että kolmio on tapahtunut tietyssä paikassa.Kuten neuraalisessa AskBERT-mallissa, pyrimme poimimaan tietoa paikoista, hahmoista ja esineistä. Koko tarinan juoni siirretään OpenIE5 -malliin, ja saamme joukon kolmioita. Tripeleiden sijainti-merkintöjä käytetään luomaan joukko sijainteja. Merkitsemme, mitkä tarinan lauseet sisältävät nämä paikat. Tämän jälkeen käytetään POS-tunnistusta, joka perustuu substantiivilauseiden merkitsemiseen, yhdessä NER:n kanssa kolmoiskappaleiden joukon suodattamiseksi edelleen - tunnistetaan tarinan hahmojen ja esineiden joukko.Graafi rakennetaan yhdistämällä kolmoiskappaleiden joukko sen perusteella, mihin paikkaan ne kuuluvat. Vaikka jotkin lauseet sisältävät hyvin selkeää paikkatietoa, jonka OpenIE5 voi merkitä kolmioihin, suurin osa lauseista ei sisällä sitä. Sen vuoksi oletamme, että sijainti pysyy samana kaikissa kolmioissa, jotka on poimittu sellaisten lauseiden väliltä, joissa sijainti mainitaan nimenomaisesti. Jos esimerkiksi tarinan 1. lauseessa on $paikka A$ ja 5. lauseessa $paikka B$, kaikkien lauseissa 1-4 kuvattujen tapahtumien katsotaan tapahtuvan $paikassa A$. Näissä tapahtumissa mainitut entiteetit liittyvät graafissa paikkaan $paikka A$.",
      "id": "task461-0ce6da4156d44a27ac74b36e7f0bd91d",
      "output": [
        "Miten tiedot poimitaan?"
      ]
    },
    {
      "input": "Teimme kokeita Amazonin arvostelutietokannalla BIBREF9, joka on monialaisen tunneanalyysin vertailutietokanta. Tämä tietokokonaisuus sisältää Amazonin tuotearvosteluja neljältä eri tuotealueelta: Kirjat (B), DVD (D), elektroniikka (E) ja keittiökoneet (K). Jokaiseen arvosteluun on alun perin liitetty 1-5 tähden luokitus, ja se on koodattu 5 000-ulotteisiksi ominaisvektoreiksi, jotka koostuvat sanasäkkipohjaisista unigrammi- ja bigrammivektoreista.Koe ::: Dataset and Task Design :::: Tästä tietokokonaisuudesta muodostimme 12 binääriluokkaista, eri osa-alueiden välistä tunneanalyysitehtävää: B$\\rightarrow $D, B$\\rightarrow $E, B$\\rightarrow $K, D$\\rightarrow $B, D$\\rightarrow $E, D$\\rightarrow $K, D$\\rightarrow $K, E$\\rightarrow $B, E$\\rightarrow $D, E$\\rightarrow $K, K$\\rightarrow $B, K$\\rightarrow $D, K$\\rightarrow $E. Aiempien töiden asetusten mukaisesti käsittelimme arvostelua luokkana `1', jos se oli luokiteltu enintään 3 tähteen, ja luokkana `2', jos se oli luokiteltu 4 tai 5 tähteen. Kunkin tehtävän osalta $\\mathcal {D}_S$ koostui 1000 esimerkistä kustakin luokasta, ja $\\mathcal {D}_T$ koostui 1500 esimerkistä luokasta `1' ja 500 esimerkistä luokasta `2'. Koska on järkevää olettaa, että $\\mathcal {D}_T$ voi paljastaa kohdealueen tietojen jakauman, säädimme kohdealueen testitietokannan niin, että sen luokkasuhde on sama kuin $\\mathcal {D}_T$:n luokkasuhde. Käyttämällä samaa etiketinjakomekanismia tutkittiin myös mallin suorituskykyä eriasteisilla $\\rm {P}(\\rm {Y})$-siirtymillä, joita arvioitiin $\\rm {P}_S(\\rm {Y}=i)/\\rm {P}_T(\\rm {Y}=i), \\kaikkien i=1, \\cdots , L$ maksimiarvon perusteella. Lisätietoja tämän tutkimuksen tehtäväsuunnittelusta on liitteessä C. Koe ::: Dataset and Task Design ::: Rakensimme lisäksi 12 moniluokkaista, eri alojen välistä tunteiden luokittelutehtävää. Tehtävät suunniteltiin erottamaan 1 tai 2 tähteä (luokka 1) saaneet arvostelut 4 tähteä (luokka 2) ja 5 tähteä (luokka 3) saaneista arvosteluista. Kunkin tehtävän osalta $\\mathcal {D}_S$ sisälsi 1000 esimerkkiä kustakin luokasta, ja $\\mathcal {D}_T$ koostui 500 esimerkistä luokasta 1, 1500 esimerkistä luokasta 2 ja 1000 esimerkistä luokasta 3. Vastaavasti kontrolloimme myös kohdealueen testausaineistoa siten, että sillä oli sama luokkasuhde kuin $\\mathcal {D}_T$:lla.",
      "id": "task461-72389aed03204314a0829d89237e03df",
      "output": [
        "Mitä tunneanalyysitehtäviä käsitellään?"
      ]
    },
    {
      "input": "Mallimme tarkkuus on 7,8 % korkeampi kuin LSVM:n saavuttama paras tulos. Tulokset osoittavat, että tämä malli on 3,1 % parempi kuin uusimmat perusmallit, kuten hybridi-CNN BIBREF15 ja LSTM ja huomio BIBREF16, validointijoukossa ja 1 % testijoukossa.",
      "id": "task461-a739a46fb899481589a8212991a21bf7",
      "output": [
        "Mihin uusimpiin menetelmiin kirjoittajat vertaavat työtään? "
      ]
    },
    {
      "input": "Arvioinnissamme on 19 erilaista algoritmia, joilla suositellaan tunnisteita e-kirjoille. Ryhmittelimme ne i) suosioon perustuviin, ii) samankaltaisuuteen perustuviin (eli sisältötietoa hyödyntäviin) ja iii) hybridilähestymistapoihin.",
      "id": "task461-8242cf97eafb453fb4df8d1c6d8bfff3",
      "output": [
        "mitä algoritmeja he käyttivät?"
      ]
    },
    {
      "input": "uusi DMN+-malli ei edellytä, että tukevat tosiasiat Lisäksi otamme käyttöön uuden syöttömoduulin kuvien esittämistä varten.",
      "id": "task461-f6315ad402ad4287a3360494c4d71f8f",
      "output": [
        "Mitä parannuksia he tekivät DMN:lle?"
      ]
    },
    {
      "input": "LUWAK on toteutettu puhtaalla JavaScript-koodilla, ja se käyttää selaimen LocalStoragea.",
      "id": "task461-eb59faa895bb427dba9ceaa1f260aafd",
      "output": [
        "Millä ohjelmointikielellä työkalu on kirjoitettu?"
      ]
    },
    {
      "input": "Olemme arvioineet kehystämme käyttämällä DBpedia BIBREF0 -tietokannasta peräisin olevaa synteettistä kirjainjoukkoa (S-Lite) ja todellista kirjainjoukkoa (R-Lite). ",
      "id": "task461-1118a1c30b0742ed8bef02ea956a92c2",
      "output": [
        "Mitä KB:tä käytetään tässä työssä?"
      ]
    },
    {
      "input": "CoVoST perustuu tällä hetkellä tähän versioon ja kattaa seuraavat 11 kieltä: Ranska, saksa, hollanti, venäjä, espanja, italia, turkki, persia, ruotsi, mongoli ja kiina.",
      "id": "task461-ad04400f4fcc4cdeba40fea61a8414ba",
      "output": [
        "Onko arabia yksi CoVostin 11 kielestä?"
      ]
    },
    {
      "input": "Käyttämällä hienojakoista, leksikaalisiin piirteisiin perustuvaa porttimekanismia voimme tarkasti hallita sanatason ja merkkitason välisiä tietovirtoja. Intuitiivisesti muotoilu on seuraava: INLINEFORM0jossa INLINEFORM0 on elementtiviisas kertolaskuoperaattori. kun portilla on korkea arvo, enemmän tietoa virtaa sanatason esityksestä; muussa tapauksessa char-taso ottaa hallitsevan aseman. Se on käytännöllinen todellisissa skenaarioissa. Esimerkiksi tuntemattomien substantiiviyksiköiden kohdalla portit pyrkivät painottumaan char-tason esitykseen, jotta voidaan huolehtia rikkaammasta morfologisesta rakenteesta.",
      "id": "task461-d456f0bc378f47acbe52fcc9ac8bbc63",
      "output": [
        "Miten gatint-mekanismi yhdistää sana- ja merkkitiedot?"
      ]
    },
    {
      "input": "Seuraavaksi analysoimme, miksi ne eivät suoriudu hyvin tässä tehtävässä ja näillä tiedoilla:[noitemsep,leftmargin=*]Kohinainen data. Tämän tehtävän suurimpana haasteena on subjektiivisesta arvostelusta johtuva annotaatioiden välinen ristiriita. Vaikka tämä vaikuttaa myös pelkkää tekstiä käyttävään havaitsemiseen, sen vaikutukset ovat suuremmat monimutkaisemmissa tehtävissä, kuten kuvien tai multimodaalisen havaitsemisen yhteydessä. multimodaalisten suhteiden monimutkaisuus ja monimuotoisuus. Vihapuheen multimodaalisissa julkaisuissa käytetään paljon taustatietoa, minkä vuoksi niissä käytettyjen visuaalisten ja tekstuaalisten elementtien väliset suhteet ovat hyvin monimutkaisia ja monimuotoisia, minkä vuoksi neuraaliverkon on vaikea oppia niitä.Pieni joukko multimodaalisia esimerkkejä. Kuvassa FIGREF5 on esitetty joitakin haastavia multimodaalisia vihapuhe-esimerkkejä, jotka pyrimme havaitsemaan. Mutta vaikka olemme keränneet suuren 150 000 dollarin twiittien tietokokonaisuuden, siinä oleva multimodaalisen vihan osajoukko on edelleen liian pieni oppiaksemme monimutkaisia multimodaalisia suhteita, joita tarvitaan multimodaalisen vihan tunnistamiseen.",
      "id": "task461-9d838767dfe7485e878341c9b0556943",
      "output": [
        "Mikä on kirjoittajan mielipide siitä, miksi nykyiset multimodaaliset mallit eivät voi päihittää pelkkää tekstiä analysoivia malleja?"
      ]
    },
    {
      "input": "Erilaisten empiiristen tulosten tutkiminen voi auttaa meitä löytämään joitakin mielenkiintoisia ilmiöitä: Esikoulutuksen etu vähenee vähitellen merkityn datan määrän kasvaessa BIBREF14, BIBREF17, BIBREF18.Kiinteät esitykset tuottavat parempia tuloksia kuin hienosäätö joissakin tapauksissa BIBREF24.Kaiken kaikkiaan Seq2Seq-kooderin esikouluttaminen päihittää dekooderin esikouluttamisen BIBREF24, BIBREF17, BIBREF15, BIBREF16.",
      "id": "task461-258d5f773bc449798aa985e87c31771d",
      "output": [
        "Mitä kokeellisia ilmiöitä esitellään?"
      ]
    },
    {
      "input": "Tutkimme ensin kaikkien NMT-Fake-arvostelujen yleistä havaitsemista (1 006 väärennettyä arvostelua ja 994 aitoa arvostelua).",
      "id": "task461-2d6e59adbd084c91a98ab9d0026e9c49",
      "output": [
        "Kuinka monta arvostelua (sekä luotuja että oikeita) he arvioivat Amazon Mechanical Turkissa?"
      ]
    },
    {
      "input": "PERPLEXITY",
      "id": "task461-a733f25af567460cba3e523dfd899e0e",
      "output": [
        "Otetaanko asiakirjassa huomioon perpleksisyyden käyttö tekstin poikkeavuuksien tunnistamiseksi?"
      ]
    },
    {
      "input": "Menetelmiemme automaattiseen arviointiin ehdotamme, että käytämme laajalti käytettyä kuvan/videon tekstittämiseen tarkoitettua metriikkaa. Tämä johtuu siitä, että ehdotettua CommonGen-tehtävää voidaan pitää myös kuvatekstitehtävänä, jossa kontekstina ovat epätäydelliset kohtaukset, joissa on annetut käsitejoukot. Siksi valitsemme päämittareiksi BLEU-3/4 BIBREF28, ROUGE-2/L BIBREF29, CIDEr BIBREF30 ja SPICE BIBREF31. Näiden klassisten mittareiden lisäksi käytämme myös uutta sulauttamiseen perustuvaa mittaria nimeltä BERTScore BIBREF32. Vertailun selkeyttämiseksi näytämme BERTScore-tulosten delta-arvon vähentämällä tuloksen, joka saadaan, kun pelkkiä syöttökäsitejoukkoja käytetään kohdelauseina, nimellä $\\triangle $BERTS.",
      "id": "task461-942b6feb3cbd4be5949f4a9646512a64",
      "output": [
        "Mitä automaattisia mittareita käytetään tässä tehtävässä?"
      ]
    },
    {
      "input": "Syvät konvoluutiohermoverkot (CNN), joissa on 2D-konvoluutiot ja pienet ytimet BIBREF1, ovat saavuttaneet huippuluokan tuloksia useissa puheentunnistustehtävissä BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6. r Mallit: Perus-CNN-mallimme BIBREF21 koostuu 15 konvoluutiokerroksesta ja yhdestä täysin yhdistetystä kerroksesta.",
      "id": "task461-d91c960bc1c2460495906e0b1a7ab442",
      "output": [
        "Verrataanko mallia uusimpiin malleihin näillä tietokokonaisuuksilla?"
      ]
    },
    {
      "input": "Teemme suoran vertailun asiantuntijoiden ja joukko-osallistujien välillä 1000 termiryhmän osalta, jotka perustuvat annotaatioiden kokonaismäärään (200 termiryhmää, joissa on yhteensä 2 annotaatiota, 200 termiryhmää, joissa on yhteensä 3 annotaatiota, ja niin edelleen termiryhmiin, joissa on yhteensä 6 annotaatiota).  Arvioijille annettiin yhteenveto termiryhmälle saaduista annotaatioista seuraavassa muodossa: Termiryhmä \"epätasa-arvo epätasa-arvo\" sai annotaatioita seuraavasti: 50,0 % surua, 33,33 % inhoa, 16,67 % vihaa. Sitten heitä pyydettiin arvioimaan asteikolla 1-5, kuinka pätevinä näitä merkintöjä pidettiin.",
      "id": "task461-dc179cca8ab14d7e85635a664e0f233b",
      "output": [
        "Miten he vertailevat sanakirjoja?"
      ]
    },
    {
      "input": "Vertailemme kokeissamme kahdeksaa eri mallia. Neljässä niistä on projisoitu kerros (ks. kuva FIGREF2), kun taas muissa ei ole, ja tämä on ainoa ero näiden kahden malliryhmän välillä. Kokeissa on siis mukana neljä mallia (projisoitu kerros tai ei). LastStateRNN on klassinen RNN-malli, jossa viimeinen tila kulkee MLP:n läpi ja LR-kerros arvioi vastaavan todennäköisyyden. AvgRNN-mallissa sen sijaan tarkastelemme kaikkien soluista lähtevien tilojen keskimääräistä vektoria. AttentionRNN-malli on se, joka on esitetty BIBREF9:ssä. Lisäksi esitellään häirintäkielen havaitsemista varten MultiAttentionRNN-malli, joka sisältää yhden huomion sijasta neljä huomiota, yhden kutakin luokkaa varten.",
      "id": "task461-af03b9b3d99c4426aaad23adc363d017",
      "output": [
        "Mitä eri variaatioita tarkkaavaisuuteen perustuvasta lähestymistavasta tutkitaan?"
      ]
    },
    {
      "input": "Arvioimme malliamme sekä englannin- että kiinankielisellä segmentoinnilla. Molemmissa kielissä käytimme standarditietokantoja sanojen segmentointiin ja kielten mallintamiseen. EnglantiBrent-korpus on standardikorpus, jota käytetään lasten kielen omaksumisen tilastollisessa mallintamisessa BIBREF15 , BIBREF16 Käytämme yleisesti käytettyä versiota PTB:stä, jonka on laatinut BIBREF17 Koska kiinalainen ortografia ei merkitse sanojen välisiä välejä, sanojen rajoja on pyritty useaan otteeseen merkitsemään. Arvioinnissa käytetään kahta korpusta, jotka on segmentoitu manuaalisesti eri segmentointistandardien mukaisesti. Pekingin yliopiston korpus oli yksi korpuksista, joita käytettiin kansainvälisessä kiinalaisen sanan segmentointikilpailussa BIBREF18 . Käytämme Penn Chinese Treebank Version 5.1 BIBREF19 .",
      "id": "task461-0a29dfe8f14141f7be1bf898739ce5cd",
      "output": [
        "Mitä tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Jotta tällaisia olemassa olevia tietolähteitä voitaisiin hyödyntää paremmin, ehdotamme huomioiviin osoitinverkkoihin perustuvaa end-to-end (E2E) -mallia, joka voidaan kouluttaa end-to-end ihmisen IE-tehtävien tulo/lähtö -pareilla ilman, että tarvitaan merkkitason merkintöjä. Koska mallimme ei tarvitse token-tason merkintöjä, luomme jokaisesta aineistosta E2E-version ilman token-tason merkintöjä pilkkomalla BIO-merkityt sanat ja käyttämällä merkintöjä poimittavina kenttinä.",
      "id": "task461-e4ad0996ea514aae82ccaacb549051b0",
      "output": [
        "Olettavatko he rangaistustasoista valvontaa?"
      ]
    },
    {
      "input": "Ennen tämän NLP-työkalupaketin suunnittelua teimme kyselyn insinöörien keskuudessa ja määrittelimme kolme tyypillistä persoonaa.",
      "id": "task461-f037211239b74b8b9622f952d013a6c9",
      "output": [
        "Miten kirjoittajat todistavat väitteen, jonka mukaan monille insinööreille on suuri työläs valita useiden kehysten, mallien ja optimointitekniikoiden välillä?"
      ]
    },
    {
      "input": "Kaikki tutkimamme menetelmät parantavat sukupuolittuneiden sanojen prosenttiosuutta, miesten prosenttiosuutta ja F1:tä Transformer-sukupolven perusmalliin verrattuna, mutta kaikkien menetelmien yhdistäminen yhteen - ALL-malli - on mielestämme edullisin.",
      "id": "task461-451587e4428b44048ed133d7ce20dd2d",
      "output": [
        "Mihin perustasoon kokeellisia tuloksia verrataan?"
      ]
    },
    {
      "input": "Käsittelemme kahta keskeistä mallia sekvenssien merkintäongelmien ratkaisemiseksi ja kuvaamme kummankin mallin harjoittelua yhden mallin monikielisessä ympäristössä: (1) Meta-LSTM BIBREF0 , joka on erittäin vahva perusmalli tehtäviämme varten, ja (2) monikielinen BERT-pohjainen malli BIBREF1 .",
      "id": "task461-aeb5279c107c4c488326f4834070f0d6",
      "output": [
        "Mikä on monikielinen perustaso?"
      ]
    },
    {
      "input": "Keräsimme 14 vapaaehtoiselta, 5 italialaiselta ja 9 muulta kuin italialaiselta kuuntelijalta yhteensä 657 arviota, jotka jakautuivat 24 videoleikkeen ja kolmen testausolosuhteen kesken.",
      "id": "task461-0e9248f4ba7249fe84025efc5e9146d6",
      "output": [
        "Kuinka monta henkilöä työskentelee subjektiivisen arvioinnin parissa?"
      ]
    },
    {
      "input": "Arvioimme lähestymistapaamme harjoittelemalla automaattista täydennysjärjestelmää 500 000 satunnaisesti poimitulla lauseella Yelp-arvosteluista BIBREF6 (katso lisätietoja liitteestä). Mittaamme viestintäjärjestelmän $(q_{\\alpha },p_{\\beta })$ tehokkuutta merkkien säilymisasteella, jota mitataan avainsanoissa säilytettävien merkkien osuutena. Järjestelmän tarkkuutta mitataan ahnaasti dekoodaamalla mallin tuottamien lauseiden osuutena, joka vastaa täsmälleen kohdelausetta.",
      "id": "task461-c5d9c1f88d9249809471474cc3ad64a9",
      "output": [
        "Miten malleja arvioidaan tässä ihmisen ja koneen välisessä viestintäpelissä?"
      ]
    },
    {
      "input": "Arvioimme mallejamme kahdessa tyypillisessä tehtävässä: tekstin luokittelussa ja tekstin semanttisessa yhteensovittamisessa.",
      "id": "task461-5fdb35ce43d14deaa7474ec0a52c397e",
      "output": [
        "Mitä tehtäviä he kokeilevat?"
      ]
    },
    {
      "input": "Tässä julkaisussa keskitytään sellaisen tiedon esittämiseen, joka on arvokasta näissä tehtävissä, mutta joka on tähän asti jäänyt suurelta osin huomiotta yksinkertaistettuun kieleen keskittyvissä koneoppimismenetelmissä, erityisesti tekstin rakenteeseen (esim. kappaleet, rivit), typografiaan (esim. kirjasintyyppi, kirjasintyyli) ja kuvaan (sisältö, sijainti ja mitat) liittyvässä tiedossa. Tieto merkin kirjasintyypistä ja kirjasintyylistä (esim. kursivointi, lihavointi) ja sen sijainnista fyysisellä sivulla (vain PDF-tiedostojen osalta) määritettiin määritteinä merkkikerroksen merkkielementtien attribuuteiksi (ks. esimerkki kuvassa FIGREF34).",
      "id": "task461-dcfea739d64b4f5c8bc4024f14964b10",
      "output": [
        "Mitä typografiaa koskevia tietoja korpus sisältää?"
      ]
    },
    {
      "input": "Tässä työssä esittelemme menetelmän, jonka avulla VQA-algoritmit pystyvät tuottamaan ihmiselle tulkinnanvaraisia huomiokarttoja, jotka tehokkaasti maadoittavat vastauksen merkityksellisiin kuva-alueisiin. Saavutamme tämän hyödyntämällä Visual Genome -tietokannassa saatavilla olevia aluekuvauksia ja objektien annotaatioita ja käyttämällä niitä automaattisesti tarkkaavaisuuskarttojen rakentamiseen, joita voidaan käyttää tarkkaavaisuuden valvonnassa sen sijaan, että ihmisannotoijien olisi annettava manuaalisesti maadoitusmerkinnät.",
      "id": "task461-19e88e1519a1454dbaa838d3a392c33c",
      "output": [
        "Miten he saavat aluekuvaukset ja kohteiden merkinnät?"
      ]
    },
    {
      "input": "Upotusviisaan konvoluution tarkoituksena on soveltaa konvoluutiosuodatinta w $\\in \\mathbb {R}^{\\mathcal {\\\\\\}k*d}$ $k$ sanojen upotuksista koostuvaan ikkunaan uuden ominaisuuden tuottamiseksi, eli $k$ sanojen paikallisen kontekstin tiivistämiseksi. Soveltamalla konvoluutiosuodatinta kaikkiin lauseen mahdollisiin ikkunoihin luodaan ominaisuuskartta $c$.",
      "id": "task461-2444e4150cc049de85849f90d075c350",
      "output": [
        "Mikä tukee väitettä, jonka mukaan CNN:n lisääminen toistuviin yksiköihin parantaa mallin kykyä ottaa huomioon paikallinen konteksti ja vähentää epäselvyyksiä?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF12 käy ilmi, T-T-malli on huomattavasti parempi kuin LSTM-pohjainen RNN-T-perusversio.",
      "id": "task461-6acaffd9ddd943a7a3338f9c7cfb5230",
      "output": [
        "Mikä oli edellinen uusin malli?"
      ]
    },
    {
      "input": "Katsotaanpa tarkemmin, mitä tarkoitamme kahden jäsennyspuun välisellä yksimielisyydellä. Jos englanninkielisessä lauseessa on kaksi sanaa, joita merkitään i:llä ja i':llä ja jotka vastaavat sanoja j ja j' samansuuntaisessa hindinkielisessä lauseessa, englanninkielisen jäsennyspuun i:n ja i':n välisen riippuvuusreunan voidaan olettaa vastaavan j:n ja j':n välistä reunaa hindinkielisessä jäsennyspuussa ja päinvastoin. Englanninkielisen jäsennyspuun reunaa vastaavaa reunaa tai polkua hindinkielisessä jäsennyspuussa kutsutaan englanninkielisen reunan projisoinniksi tai projisoiduksi poluksi hindinkieliseen jäsennyspuuhun, ja vastaavasti on olemassa projisoituja polkuja hindistä englantiin. Kaksoispurkualgoritmi pyrkii tuomaan kahden kielen jäsennyspuut yhteen rajoitteidensa avulla.",
      "id": "task461-30fe92c8ed3841aa81ffe2284a419263",
      "output": [
        "Miten jäsennyspuiden välisen yhteisymmärryksen varmistaminen toimii eri kielillä?"
      ]
    },
    {
      "input": "Aloitamme tutkimalla muutaman merkittävän keskustelusivuston sisältöä: idebate.com, debatewise.org, procon.org.",
      "id": "task461-d76d8f458713423a9f103012f47e9220",
      "output": [
        "Mitä keskustelusivustoja he katsoivat?"
      ]
    },
    {
      "input": "Sen vuoksi käytimme tietojen keräämiseen CrowdFlower (CF) -joukkoistamisalustaa.",
      "id": "task461-9d210583784d4f71a117b67866440bf6",
      "output": [
        "Miten nämä tiedot kerättiin?"
      ]
    },
    {
      "input": "Yleisesti ottaen molemmat NN-mallit päihittävät CAEVO-perusmallin, ja BERT-sisällytystä sisältävä NN-malli on suorituskyvyltään paras.",
      "id": "task461-2e2153f3b60544b2b923ee3f8c05aeb8",
      "output": [
        "Parantavatko yhteistyöhön perustuvat sulautukset tuloksia?"
      ]
    },
    {
      "input": "LastStateRNN on klassinen RNN-malli, jossa viimeinen tila kulkee MLP:n läpi ja LR-kerros arvioi vastaavan todennäköisyyden. AvgRNN-mallissa sen sijaan tarkastellaan kaikkien soluista lähtevien tilojen keskimääräistä vektoria. AttentionRNN-malli on se, joka on esitetty BIBREF9:ssä. Lisäksi esitellään häirintäkielen havaitsemista varten MultiAttentionRNN-malli, joka sisältää yhden huomion sijasta neljä huomiota, yhden kutakin luokkaa varten.",
      "id": "task461-0b6fcae721944d5baf659b77312938fa",
      "output": [
        "Mitä perusmallia käytetään?"
      ]
    },
    {
      "input": "Siamilaisessa neuroverkossa on kaksi rinnakkaista konvoluutioverkkoa, INLINEFORM0 , joilla on sama painojen joukko, INLINEFORM1 , kuten kuvassa KUVA 5 (a) on esitetty.",
      "id": "task461-ed59cbf3fad844b680553f835ce6d2ef",
      "output": [
        "Mikä on siamilaisen neuroverkon arkkitehtuuri?"
      ]
    },
    {
      "input": "Meidän asetuksessamme lähtökohtana on perusmalli, joka on koulutettu NLI-tiedoilla. Sen sijaan, että käytettäisiin automatisoituja vastapuolimenetelmiä, tässä mallin \"vastapuolena\" on ihmisen kommentoija. Kun annetaan konteksti (jota kutsutaan NLI:ssä usein myös \"premissioksi\") ja haluttu kohdemerkintä, pyydämme ihmisen kirjoittajaa esittämään hypoteesin, joka huijaa mallia luokittelemaan merkinnän väärin. Kirjoittajaa voidaan pitää \"valkoisen hatun\" hakkerina, joka yrittää tunnistaa järjestelmän haavoittuvuuksia. Jokaisen väärin luokitellun ihmisen luoman esimerkin kohdalla pyydämme kirjoittajaa myös ilmoittamaan syyn, miksi hän uskoo, että se luokiteltiin väärin.",
      "id": "task461-51c127ccbd2f4f51b0afa2cfe1d3bb8a",
      "output": [
        "Käyttävätkö he aktiivista oppimista tietokokonaisuuksiensa luomiseen?"
      ]
    },
    {
      "input": "Tässä julkaisussa keskitytään sellaisten tietojen esittämiseen, jotka ovat arvokkaita näissä tehtävissä, mutta jotka on tähän asti jätetty suurelta osin huomiotta koneoppimisessa, joka keskittyy yksinkertaistettuun kieleen, erityisesti tekstin rakenteeseen (esim. kappaleet, rivit), typografiaan (esim. kirjasintyyppi, kirjasintyyli) ja kuviin (sisältö, sijainti ja mitat). Fyysistä sivun segmentointia (vain PDF-tiedostojen osalta), kappaleiden segmentointia ja rivien segmentointia koskevat tiedot lisättiin tekstin rakennekerroksen textspan-elementin osaksi.",
      "id": "task461-33223482d3404dc19c68deeab623ad84",
      "output": [
        "Mitä tietoja tekstin rakenteesta sisältyy korpukseen?"
      ]
    },
    {
      "input": "Suoritamme kokeita käyttämällä seuraavia uusimpia malleja: (1) SEQ2SEQ: sekvenssistä sekvenssiin -malli, jossa on huomiomekanismit BIBREF21, (2) CVAE: ehdollinen variaatiomalli, jossa on KL-annealing ja BOW-häviö BIBREF2, (3) Transformer: kooderi-dekooderiarkkitehtuuri, joka perustuu pelkästään huomiomekanismeihin BIBREF22, (4) HRED: yleistetty sekvenssistä sekvenssiin -malli hierarkkisen RNN-kooderin kanssa BIBREF23, (5) DialogWAE: ehdollinen Wassersteinin autokooderi, joka mallintaa datan jakaumaa kouluttamalla GAN:ia latenttien muuttujien tilassa BIBREF6.",
      "id": "task461-694c01b1dbc94eb6bc819bff64e7bfd6",
      "output": [
        "Mitä uusimpia malleja käytettiin kokeissa?"
      ]
    },
    {
      "input": "Asiakirjaluokittelijana käytämme Kimin kaltaista sanapohjaista CNN:ää, joka koostuu seuraavista kerroksista: $ \\texttt {Conv} \\xrightarrow{} \\texttt {ReLU} \\xrightarrow{} \\texttt {1-Max-Pool} \\xrightarrow{} \\texttt {FC} \\\\ $ Tulevaan työhön kuuluisi LRP:n soveltaminen muihin neuroverkkoarkkitehtuureihin (esim. merkkipohjaisiin tai rekursiivisiin malleihin) uusissa NLP-tehtävissä sekä sen tutkiminen, miten relevanssitieto voitaisiin ottaa huomioon luokittelijan koulutusmenettelyn tai ennustuskyvyn parantamiseksi.",
      "id": "task461-930f6a41493b498cade2145a21460875",
      "output": [
        "Tutkitaanko kokeiluissa, miten eri arkkitehtuurit ja kerrokset edistävät tiettyjen päätösten tekemistä?"
      ]
    },
    {
      "input": "Käytämme kilpailun tietokokonaisuutta, joka sisältää tekstiä twiiteistä, joilla on edellä mainitut kategoriat. ",
      "id": "task461-690195826edb4a5bbb957f42195cf32c",
      "output": [
        "Mitä tietokokonaisuutta tässä työssä käytetään?"
      ]
    },
    {
      "input": "BIBREF:ssä5 mainittujen luokkien mukaan ironia voidaan jakaa kolmeen luokkaan: sanallinen ironia polariteettikontrastin avulla eli lauseet, jotka sisältävät ilmaisun, jonka polariteetti on käänteinen tarkoitetun ja kirjaimellisen merkityksen välillä; muunlainen sanallinen ironia eli lauseet, joissa ei ole polariteettikontrastia kirjaimellisen ja tarkoitetun merkityksen välillä, mutta jotka ovat silti ironisia; ja tilannekohtainen ironia eli lauseet, joissa kuvataan tilanteita, jotka eivät täytä joitakin odotuksia. Koska kahteen jälkimmäiseen kategoriaan kuuluva ironia on epäselvää ja vaikeasti ymmärrettävää, päätämme keskittyä tässä työssä vain ensimmäiseen kategoriaan kuuluvaan ironiaan.   Koska aiempia ironian tuottamista koskevia töitä ja peruslinjoja ei ole, toteutamme mallin tyylinsiirtoon perustuen. ",
      "id": "task461-1b82e48072de48d681c7663e8829761c",
      "output": [
        "Mitä vaikeuksia ironisen kuvion mallintamisessa on?"
      ]
    },
    {
      "input": " Mallit sisältävät sekä neuroverkkoja (esim. RNN:t, CNN:t) että tavanomaisia koneoppimisvälineitä (esim. Naive Bayes ja Laplace Smoothing, k-klusterointi, SVM lineaarisella ytimellä). ",
      "id": "task461-167425881ec24ec6ae428b9e0598f150",
      "output": [
        "Mitä koneoppimismalleja käytetään?"
      ]
    },
    {
      "input": "Ensin työntekijöille annettiin alaan liittyvä kvalitatiivinen suhde q+/-( INLINEFORM0 ), joka ilmaistiin englanniksi (esim. \"Jos pinnalla on enemmän kitkaa, esine kulkee hitaammin\"), ja heitä pyydettiin syöttämään kaksi vertailtavaa esinettä, ihmistä tai tilannetta. Tämän jälkeen he loivat kysymyksen, jota ohjasivat lukuisat esimerkit, ja heitä rohkaistiin olemaan mielikuvituksellisia ja käyttämään omia sanojaan. Toiseksi, LF:t saatiin esiin käyttämällä uutta tekniikkaa, jossa ne muodostettiin käänteisesti seurantakysymysten joukosta ilman, että työntekijät joutuivat tutustumaan niiden taustalla olevaan formalismiin. Tämä on mahdollista, koska LF:t ovat rajallisia. Viitaten aiemmin esitettyihin LF-malleihin (1) ja (2) (jakso SECREF13 ), nämä kysymykset ovat seuraavat: Näistä tiedoista voimme päätellä kohde-LF:n ( INLINEFORM0 on INLINEFORM1:n komplementti, INLINEFORM2 , asetamme mielivaltaisesti INLINEFORM3 =maailma1, joten kaikki muut muuttujat voidaan päätellä).",
      "id": "task461-7bdaf75901c243c89da8f59923865b24",
      "output": [
        "Miten he saavat kysymystensä loogiset muodot aineistostaan?"
      ]
    },
    {
      "input": "Muistimekanismi on otettu käyttöön, jotta malli voi tarkastella paikallisia piirteitä laajemmin ja saada käyttöönsä koko sarjan.",
      "id": "task461-ecb9b05b73a34ef79df2b627fce00edd",
      "output": [
        "Mitä ominaisuuksia he käyttävät?"
      ]
    },
    {
      "input": "Jaoimme Dryhootchin valitsemat kyselyt 1 200 käyttäjälle (305 käyttäjää on itse ilmoittanut kärsivänsä PTSD:stä ja loput on valittu satunnaisesti edellisistä 2 423 käyttäjästä) ja saimme 210 onnistunutta vastausta.  Dryhootch määrittelee PTSD:n voimakkuuden neljään luokkaan kaikkien kolmen kliinisen kyselytyökalun (DOSPERT, BSSS ja VIAS ) viikoittaisten kyselytulosten perusteella.",
      "id": "task461-6cf7e49ee7f3480ca9a9b2c1c82645ac",
      "output": [
        "Mitä kliinisesti validoituja kyselytyökaluja käytetään?"
      ]
    },
    {
      "input": "Lähtökohtana käytimme DIP-korpusta BIBREF37 , joka koostuu 49:stä 100 verkkosivun klusterista, jotka käsittelevät koulutusaiheita (esim. kiusaaminen, kotiopetus, huumeet) ja sisältävät lyhyen kuvauksen kustakin aiheesta.",
      "id": "task461-c97f02fc073848db80bcf1d576ed667c",
      "output": [
        "Mitkä verkkoasiakirjojen kokoelmat sisältyvät korpukseen?"
      ]
    },
    {
      "input": "Etnisyys/rotuYksi mielenkiintoinen kuvio on, että vauvojen etnistä alkuperää/rotua ei näytä mainittavan, ellei vauva ole musta tai aasialainen. Toisin sanoen: valkoinen näyttää olevan oletusarvo, ja muut näyttävät olevan merkittyjä. Miten voimme sanoa, ovatko tiedot todella puolueellisia vai eivät? Taulukon TABREF22 luvut ovat silmiinpistäviä: etnisen alkuperän merkitsemisessä näyttää olevan todellinen, systemaattinen ero ryhmien välillä. Voimme mennä askeleen pidemmälle ja tarkastella kaikkia 697 kuvaa, joissa on sana \"vauva\". Jos valkoisia vauvoja on suhteettoman paljon, tämä vahvistaa päätelmää siitä, että aineisto on vääristynyt.",
      "id": "task461-f177626ede384ca8969452881c92f546",
      "output": [
        "Mitä vääristymiä aineistosta löytyy?"
      ]
    },
    {
      "input": "Kukin tietokokonaisuus koostuu tietueiden kokoelmasta, jossa on yksi laadunvarmistusongelma tietuetta kohti. Jokaiseen tietueeseen sisältyy kysymysteksti, kysymyksen kannalta merkityksellinen asiayhteysasiakirja, joukko ratkaisukandidaatteja ja oikea ratkaisu. Kunkin tietueen kontekstidokumentti koostuu luettelosta kysymyksen kannalta merkityksellisistä luokitelluista ja pisteytetyistä pseudodokumenteista. Useat perusmenetelmät perustuvat haettuun kontekstiin vastauksen saamiseksi kysymykseen. Näiden osalta viittaamme hakutarkkuuteen (Search Accuracy) niiden tapausten osuutta, joiden kohdalla oikea vastaus löytyy kontekstista. Luonnollisesti hakutarkkuus kasvaa kontekstin koon kasvaessa, mutta samalla lukusuorituskyky heikkenee, koska vastauksen poimiminen on vaikeampaa pidemmissä asiakirjoissa.",
      "id": "task461-4d7ca357f75a4399a149ae8f9f938324",
      "output": [
        "Mitä hakujärjestelmää käytettiin peruslinjoihin?"
      ]
    },
    {
      "input": "Olemme luoneet englanninkielisten kotiutusyhteenvetojen ja hoitajien muistiinpanojen tietokokonaisuuden, jossa keskitytään usein takaisin otettaviin potilaisiin, jotka on merkitty 15 kliinisellä potilasfenotyypillä, joiden uskotaan olevan yhteydessä toistuvan teho-osastolle takaisinottamisen riskiin, kuten asiantuntijamme (LAC, PAT, DAG) ja kirjallisuuslähteet ovat osoittaneet. BIBREF10 BIBREF11 BIBREF12",
      "id": "task461-140813266efc41258a796c2e5c1e2d8b",
      "output": [
        "Kuinka monta eri fenotyyppiä aineistossa on?"
      ]
    },
    {
      "input": "Kokeissamme RNN ottaa vastaan lausumien spektrogrammeja, jotka kulkevat kahden 2D-konvoluutiokerroksen läpi, minkä jälkeen ne kulkevat seitsemän kaksisuuntaisen rekursiivisen kerroksen ja täysin kytketyn kerroksen läpi, jossa on softmax-aktivointi. Kaikki rekursiiviset kerrokset on normalisoitu eräkohtaisesti. Jokaisella aikaportaalla softmax-aktivoinnit antavat todennäköisyysjakauman hahmoille. CTC-tappio BIBREF8 lasketaan sitten aikavaiheittaisten todennäköisyyksien perusteella.",
      "id": "task461-15552127b08b4d96859964e5fe3aa519",
      "output": [
        "Mitä mallia ne käyttävät päästä päähän -puheentunnistukseen?"
      ]
    },
    {
      "input": "Arvioimme malliamme kahdella julkisella tietokokonaisuudella, jotka ovat Penn Treebank (PTB) BIBREF9 ja End-to-end (E2E) -tekstintuottamiskorpus BIBREF10, joita on käytetty useissa aiemmissa teoksissa tekstintuottamiseen BIBREF0, BIBREF5, BIBREF11 ja BIBREF12. PTB koostuu yli 40 000 lauseesta Wall Street Journalin artikkeleista, kun taas E2E-tietokanta sisältää yli 50 000 lausetta ravintola-arvosteluista. Taulukossa TABREF11 on yhteenveto näiden kahden tietokokonaisuuden tilastoista.",
      "id": "task461-5b7804613d264708b913c084c39cdd15",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät tekstin mallintamiseen?"
      ]
    },
    {
      "input": "Jotta ihmisen edustaja voisi nopeasti määrittää eskaloitumisen syyn, luomme visualisoinnin käyttäjän käänteistä käyttämällä huomiopainoja korostamaan eskaloitumispäätökseen vaikuttavia käänteitä.",
      "id": "task461-de81cfc9eae141119c1a03806490bb39",
      "output": [
        "Selittävätkö ne mallin ennusteita pelkästään huomiopainoilla?"
      ]
    },
    {
      "input": "Näin ollen marcheggiani2017 esitti neuromallin, jossa syntaksi jätetään syrjään riippuvuuspohjaisen SRL:n osalta ja saadaan suotuisia tuloksia, mikä kumoaa luontaisen uskomuksen, että syntaksi on välttämätön SRL-tehtävässä BIBREF11 .",
      "id": "task461-052a693560c047f2b2feb63896fc5091",
      "output": [
        "Onko olemassa syntaksin suhteen tunnistamattomia SRL-malleja?"
      ]
    },
    {
      "input": "Kuten Sequicity-kehyksessä, raportoimme entiteettien vastaavuusprosentin, BLEU-pisteet ja menestyksen F1-pisteet. ",
      "id": "task461-eb14e884579f4e908494953cdd40ac86",
      "output": [
        "Mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Syväoppiminen on kiistatta edistänyt tekniikan tasoa monissa luonnollisen kielen käsittelytehtävissä, syntaktisten riippuvuuksien jäsennyksestä BIBREF0 nimettyjen yksiköiden tunnistamiseen BIBREF1 ja konekääntämiseen BIBREF2 . Sama pätee varmasti myös kielen mallintamiseen, jossa viimeaikaiset edistysaskeleet neuraalisissa kielimalleissa (NLM) ovat johtaneet huomattavasti parempiin lähestymistapoihin, kun niitä mitataan standardimittareilla, kuten perpleksisyydellä BIBREF3 , BIBREF4 .",
      "id": "task461-39137e1677c9488b98f03551bbff8742",
      "output": [
        "Mikä on yleisesti käytetty kielimallien arviointimittari?"
      ]
    },
    {
      "input": "Havaintomme mukaan, jos kansankielinen kappale sisältää enemmän klassisessa kirjallisuudessa käytettyjä runokuvia, sen tuottama runo saa yleensä korkeamman pistemäärän. Havaitsimme myös, että kuvailevista kappaleista luodut runot saavat korkeammat pisteet kuin loogisista tai filosofisista kappaleista luodut runot.",
      "id": "task461-b7a1ae7ff3694baab72db1e4c42a9226",
      "output": [
        "Mitkä ovat joitakin ohjeita kirjoitettaessa tulo kansankielellä niin malli voi tuottaa "
      ]
    },
    {
      "input": "Aloitamme harjoitteluprosessin soveltamalla sääntöä INLINEFORM4 luonnollisen kielen kysymyksiin INLINEFORM5 . Tuloksena saatua tietokokonaisuutta pidetään harjoitusaineistona, jolla alustetaan sekä semanttinen jäsentäjä että kysymysgeneraattori. Sen jälkeen molempia malleja parannetaan noudattaen takaisinkäännösprotokollaa, jonka mukaan kohdejaksojen pitäisi noudattaa todellisen datan jakaumaa, mutta lähdejaksot voidaan kuitenkin tuottaa kohinaa sisältäen.",
      "id": "task461-e718a69c83c04a1c8f6d640cfec150c9",
      "output": [
        "Miten takaisinkäännösmalli koulutetaan?"
      ]
    },
    {
      "input": "Lisäksi toteamme, että lähestymistapamme voi edelleen johtaa virheellisiin tosiseikkoihin tai jopa hallusinaatioihin. Mielenkiintoinen näkökulma voisi olla mallin rajoittaminen tietorakenteeseen, jotta vältettäisiin epätarkat tai jopa ristiriitaiset kuvaukset.",
      "id": "task461-761a3cdf86d74bb48a1439166e342f8f",
      "output": [
        "Mitä tulevia mahdollisia parannuksia on lueteltu?"
      ]
    },
    {
      "input": "Tämän hankkeen tiedot ovat kaksiosainen: ensimmäinen osa on historialliset S&P 500 -osakkeet, jotka on ladattu Yahoo Finance -palvelusta. Käytämme tietoja ajanjaksolta 12/07/2017 - 06/01/2018. Toinen osa on uutisartikkeli talousalalta, joka on kerätty samalla ajanjaksolla kuin varastotiedot. Näin ollen kerätään vain talousalan uutisartikkelit. Tiedot otetaan pääasiassa Webhose-arkistoidusta datasta, joka koostuu 306242 uutisartikkelista JSON-muodossa joulukuusta 2017 kesäkuun 2018 loppuun.",
      "id": "task461-9c132b60ac8c4629bd50943386826a07",
      "output": [
        "Mitä tietokokonaisuutta käytetään tutkimuksessa?"
      ]
    },
    {
      "input": "Pyysimme kustakin lauseesta kahta erillistä parafraasia, koska uskomme, että hyvän lauseen sulautuksen pitäisi asettaa parafraasit lähelle toisiaan vektoriavaruudessa.Useita muutostyyppejä valittiin erityisesti, jotta sulautuksia voitaisiin testata perusteellisesti. Erilaisessa merkityksessä annotoijien tulisi luoda lause, jolla on jokin muu merkitys, käyttäen samoja sanoja kuin alkuperäisessä lauseessa. Muita muunnoksia, joiden pitäisi olla vaikeita upotuksille, ovat minimaalinen muutos, jossa lauseen merkitys pitäisi muuttaa merkittävästi käyttämällä vain hyvin pientä muunnosta, tai hölynpöly, jossa lähdelauseen sanoja pitäisi sekoittaa niin, että se on kieliopillisesti oikein, mutta ilman mitään merkitystä.",
      "id": "task461-54f1ab850dac4c6d9bff77d3c3b14b0a",
      "output": [
        "Mitä merkintöjä tietokokonaisuudessa on saatavilla?"
      ]
    },
    {
      "input": "Kolme selkeää aluetta on havaittavissa $\\langle cc \\rangle $:n käyttäytymisessä suhteessa $\\wp $:hen $t_f$:n kohdalla, kuten kuvassa FIGREF15 on esitetty (siniset neliöt). Vaihe I: $\\langle cc \\rangle $ kasvaa tasaisesti, kun $\\wp < 0.4$, mikä osoittaa, että tällä alueella sanojen naapurustojen välillä on pieni korrelaatio. Täydet sanastot saavutetaan myös, kun $\\wp < 0.4$; Vaihe II: kriittisellä alueella $\\wp ^* \\ (0.4,0.6)$ tapahtuu jyrkkä siirtymä, jossa $\\langle cc \\rangle $ siirtyy jyrkästi kohti 1:tä. Myös $V(t_f)$:n äkillinen muutos $\\wp ^*$:n suhteen $\\wp ^* $:n suhteen on havaittavissa (kuva FIGREF16); vaihe III: yhden sanan kielet ovat vallitsevia, kun $\\wp > 0.6$. $\\langle cc \\rangle $:n maksimiarvo osoittaa, että sanojen naapurustot ovat täysin korreloituneita.",
      "id": "task461-6fa159c89da347e98c08d54631a44725",
      "output": [
        "Mitkä ovat kielen muodostumisen kolme mahdollista vaihetta?"
      ]
    },
    {
      "input": "Arvioimme havaintomallejamme kolmella vertailukohteella: FCE-testiaineisto (41 000 merkkiä) ja CoNLL 2014 Shared Task -tietokannan kaksi vaihtoehtoista merkintää (30 000 merkkiä) BIBREF3 . ",
      "id": "task461-68692a517770419cb25721250d3e49e8",
      "output": [
        "Mitä annotoitua korpusta he käyttivät?"
      ]
    },
    {
      "input": "Kuvassa FIGREF10 esitetään UTCNN-malli. Koska useampi kuin yksi käyttäjä voi olla vuorovaikutuksessa tietyn viestin kanssa, lisäämme ensin maksimipoolauskerroksen käyttäjämatriisin upotuskerroksen ja käyttäjävektorin upotuskerroksen jälkeen muodostaaksemme moderaattorimatriisin INLINEFORM0 ja moderaattorivektorin INLINEFORM1 moderaattorille INLINEFORM2, jossa INLINEFORM3:a käytetään asiakirjan koostamisprosessin semanttiseen muunnokseen, kuten edellisessä jaksossa mainittiin. Termi moderaattori tarkoittaa tässä yhteydessä pseudokäyttäjää, joka tarjoaa kaikkien sitoutuneiden käyttäjien yleisen semantiikan/sentimentin yhtä asiakirjaa varten. Upotus INLINEFORM4 mallintaa moderaattorin kannanottopreferenssiä, toisin sanoen paljastetun käyttäjän kannanoton mallia: haluaako käyttäjä osoittaa mieltymyksensä, haluaako käyttäjä osoittaa puolueettomuutta neutraaleilla lausunnoilla ja järkevillä argumenteilla vai haluaako hän vain osoittaa vahvaa tukea yhdelle kannalle. Ihannetapauksessa käyttäjän latentti kanta mallinnetaan INLINEFORM5 -ohjelmalla kunkin käyttäjän osalta. Vastaavasti aiheeseen liittyvää tietoa varten lisätään aihematriisin upotuskerroksen ja aihevektorin upotuskerroksen jälkeen maksimipoolauskerros, jotta muodostetaan yhteinen aihematriisin upotus INLINEFORM6 ja yhteinen aihevektorin upotus INLINEFORM7 aiheen INLINEFORM8 osalta, jossa INLINEFORM9 mallintaa aiheen INLINEFORM10 semanttista transformaatiota käyttäjissä ja INLINEFORM11 mallintaa aiheen kannan taipumusta. Latentti aiheen asenne mallinnetaan myös INLINEFORM12:lla kullekin aiheelle.Mitä tulee kommentteihin, pidämme niitä lyhyinä dokumentteina, joissa on vain kirjoittajat, mutta ei tykkääjiä eikä heidän omia kommenttejaan. Siksi sovellamme asiakirjojen koostumusta kommentteihin, vaikka tässä käyttäjät ovat kommentoijia (käyttäjät, jotka kommentoivat). Huomataan, että saman sanan INLINEFORM0-sanan upotukset viesteissä ja kommenteissa ovat samat, mutta sen jälkeen kun ne on muunnettu INLINEFORM1:ksi kuvassa KUVA 4 esitetyssä asiakirjojen koostamisprosessissa, ne saattavat muuttua erilaisiksi, koska niissä on eri sitoutuneita käyttäjiä. Lähtökommenttikuvaus yhdessä kommenttivektorin INLINEFORM2 ja aihevektorin INLINEFORM3 upotuksen kanssa ketjutetaan ja lisätään maksimipoolauskerros kommenttien tärkeimpien ominaisuuksien valitsemiseksi. Sen sijaan, että vaadittaisiin, että kommentin kannan on oltava samaa mieltä postauksen kanssa, UTCNN yksinkertaisesti poimii kommentin sisällöstä tärkeimmät piirteet; ne voivat olla hyödyllisiä riippumatta siitä, osoittavatko ne ilmeistä yhteisymmärrystä vai erimielisyyttä. Kun tässä yhdistetään kommenttitietoja, maksimipooling-kerros on siis sopivampi kuin muut pooling- tai yhdistämiskerrokset. Uskomme, että tämä on yksi syy UTCNN:n suorituskyvyn paranemiseen.Lopuksi yhdistetty kommenttiesitys yhdessä käyttäjävektorin INLINEFORM0 upottamisen, aihevektorin INLINEFORM1 upottamisen ja asiakirjan esityksen kanssa syötetään täysin kytkettyyn verkkoon, ja softmaxia sovelletaan lopullisen kannanottotarran ennusteen saamiseksi viestille.",
      "id": "task461-7de2ba4696f04c63bc64ebe054b88cff",
      "output": [
        "Kuinka monta kerrosta UTCNN-mallissa on?"
      ]
    },
    {
      "input": " Viime vuosina tutkijat ovat ehdottaneet erilaisia suodattimiin perustuvia ominaisuuksien valintamenetelmiä asiakirjojen tekstiluokittelun suorituskyvyn parantamiseksi BIBREF19.  Lisäksi käytämme suodattimiin perustuvaa ominaisuuksien valintamenetelmää nimeltä Normalized Difference Measure (NDM) BIBREF5, jotta termit voidaan asettaa paremmuusjärjestykseen niiden erottelukyvyn perusteella luokkien välillä. Rehman et al. BIBREF5 ehdottivat, että kaikki piirteet, jotka ovat piirteen vasemmassa yläkulmassa ja oikeassa alakulmassa, ovat erittäin merkittäviä verrattuna piirteisiin, jotka ovat lävistäjien ympärillä. Nykyaikaiset suodattimiin perustuvat piirteiden valinta-algoritmit, kuten ACC2, käsittelevät samalla tavalla kaikkia niitä piirteitä, jotka ovat diagonaalien ympärillä BIBREF5.",
      "id": "task461-11ad4da71ae34ed7ae1214169ca69417",
      "output": [
        "Onko suodattimiin perustuva ominaisuuksien valinta (FSE) eräänlainen regularisointi?"
      ]
    },
    {
      "input": "Määrittelimme aikomukset ohjaamalla kyselyitä, jotka kerättiin joukkoistamistehtävän avulla, jossa joukkoistajia kehotettiin esittämään aihealueisiin liittyviä kysymyksiä ja komentoja tavalla, jolla he olisivat vuorovaikutuksessa tekoälyavustajan kanssa. Ryhmittelimme käsin scoping-tehtävien tuottamat tiedot intenteiksi. ",
      "id": "task461-abe06c4a0e514cd6a79a69875a961901",
      "output": [
        "Miten tietokokonaisuutta kommentoitiin?"
      ]
    },
    {
      "input": "Ajoimme UTD:n kaikkiin 104 puhelinkeskusteluun, jotka yhdistävät 11 tuntia ääntä ja espanjankieliset transkriptiot sekä niiden englanninkieliset käännökset. Pöytäkirjat sisältävät 168 195 espanjankielistä sanamerkkiä (10 674 tyyppiä) ja käännökset 159 777 englanninkielistä sanamerkkiä (6 723 tyyppiä).",
      "id": "task461-998228d8b0bd4c5cad4f1b1ddf157e40",
      "output": [
        "Mikä on puhekorpuksen koko?"
      ]
    },
    {
      "input": "tämä vähentää merkittävästi tarvittavaa koulutusaikaa: SBERT voidaan virittää alle 20 minuutissa, ja samalla saadaan parempia tuloksia kuin vastaavilla lauseiden upottamismenetelmillä.",
      "id": "task461-8594437797c9447597df80bd3ec30923",
      "output": [
        "Kuinka kauan sen koulutus kestää?"
      ]
    },
    {
      "input": "Tulevaisuutta ajatellen tässä asiakirjassa tarkasteltujen töiden erinomainen laajennus olisi se, että tutkimuksiin osallistuville useille oppimismenetelmille annettaisiin enemmän riippumattomuutta (esim. vähemmän ihmisen väliintuloa) ja että tuloskuvien kokoa kasvatettaisiin.",
      "id": "task461-6028988c412949e5bf8d96539cb53c6f",
      "output": [
        "Mitä haasteita on vielä ratkaisematta?"
      ]
    },
    {
      "input": "Syvästi liikuttuneet lukijat vuodattavat kyyneleitä tai saavat kylmiä väreitä ja kananlihaa jopa laboratorio-olosuhteissa BIBREF4. Tällaisissa tapauksissa tunnereaktio merkitsee itse asiassa esteettistä arviointia: kertomukset, joilla on kyky liikuttaa lukijoita, arvioidaan juuri tästä syystä hyviksi ja voimakkaiksi teksteiksi. Vastaavasti kertomuksissa koettu jännityksen tunne ei ainoastaan reagoi juonen sisällön kulkuun, vaan se myös ennustaa suoraan esteettistä mieltymystä (tai vastenmielisyyttä). Tunteet, joilla on tämä kaksitahoinen kyky, on määritelty \"esteettisiksi tunteiksi\" BIBREF2.",
      "id": "task461-db7481797c1643299137b1abc4c3117c",
      "output": [
        "Mitä ovat esteettiset tunteet virallistettuina?"
      ]
    },
    {
      "input": "Bi-LSTM-malli koostuu Bi-LSTM-kerroksesta, jota seuraa lineaarinen kerros syötteen ominaisuuksien poimimiseksi. Bi-LSTM-kerroksessa on 300-ulotteinen piilotila kutakin suuntaa varten. Lopullista luokittelua varten lisätään lineaarinen lisäkerros ennustettujen luokkajakaumien tulostamiseksi. BERT-malli saadaan hienosäätämällä esivalmennettuja BERT-kuvioita NER-tietoihin ylimääräisellä kouluttamattomalla CRF-luokittelijalla. Hienosäädimme kaikkia BERT:n parametreja, myös CRF:n parametreja, päästä päähän.",
      "id": "task461-30d5ce3466c74dddb0c62f75983c2964",
      "output": [
        "Mitä luokittelijoita käytettiin kokeissa?"
      ]
    },
    {
      "input": "Pointer-Gen+ARL-SEN-mallimme saavuttaa parhaan tuloksen, 60,8 %. Tämä on 18,2 prosentin absoluuttinen parannus Pointer-Gen-perusmalliin verrattuna.",
      "id": "task461-9a3eb073df7e4cd187ee11e2431fa25c",
      "output": [
        "Mikä on tämän menetelmän parannus parhaaseen nykyaikaiseen menetelmään verrattuna?"
      ]
    },
    {
      "input": "Täydellinen tietokokonaisuutemme koostuu kaikista Redditissä tammikuusta 2013 joulukuuhun 2014 olleista alaryhmistä, joiden sanastossa on vähintään 500 sanaa, joita käytämme mittareidemme arvioinnissa, vähintään neljän kuukauden ajalta alaryhmän historiasta. Laskemme mittarimme yhteisön käyttäjien kirjoittamien kommenttien perusteella kuukausien aikaikkunoissa jokaiselle riittävän aktiiviselle kuukaudelle ja poistamme manuaalisesti yhteisöt, joissa suurin osa kommenteista on vieraskielisiä. ",
      "id": "task461-2e9b7373aefc4a6fbab102963ef52a89",
      "output": [
        "Miten vertailun kohteena olevat 300 Reddit-yhteisöä valittiin?"
      ]
    },
    {
      "input": "Tiedonkeruuasetelmamme käyttää dialogisimulaattoria, jolla luodaan ensin dialogin hahmotelmat ja sitten parafrasoidaan ne luonnollisten lausumien saamiseksi.",
      "id": "task461-f05933c2671c4319b1dacd0f89137b2d",
      "output": [
        "Mistä tietokokonaisuus on peräisin?"
      ]
    },
    {
      "input": "Kun kyseessä on uutistili Twitterissä, luemme sen twiitit tilin aikajanalta. Sitten lajittelemme twiitit julkaisupäivän mukaan nousevasti ja jaamme ne $N$-kappaleisiin. Kukin palanen koostuu lajitellusta twiittien sarjasta, joka on merkitty vastaavan tilin tunnisteella. Näin ollen tutkimme tapoja havaita epäilyttävät tilit tarkastelemalla niiden twiittejä ryhmissä (chunkeissa). Hypoteesimme on, että epäilyttävillä tileillä on ainutlaatuinen malli twiittien lähettämisessä. Koska heidän tarkoituksenaan on johtaa harhaan, heidän tapansa siirtyä twiittien sarjasta seuraavaan on piilotettu allekirjoitus, joka perustuu heidän aikomuksiinsa. Näin ollen näiden twiittien lukeminen kokonaisuuksina voi parantaa valeuutistilien havaitsemista.",
      "id": "task461-5cb61b7f21244e8bac8f34c74526d7a8",
      "output": [
        "Miten palaset määritellään?"
      ]
    },
    {
      "input": "Kun ultraääni- ja äänisegmenttipari on annettu, voimme laskea niiden välisen etäisyyden mallin avulla. Jotta voisimme ennustaa lausuman synkronointivirheen, tarkastelemme diskreettiä joukkoa ehdokkaita, laskemme kunkin etäisyyden keskiarvon lausuman segmenttien välillä ja valitsemme sen, jonka keskimääräinen etäisyys on pienin. ",
      "id": "task461-c47e483a9fa54c4dac2c41b8c2e1f224",
      "output": [
        "Ennustaako heidän neuroverkkonsa yksittäisen offsetin tallenteessa?"
      ]
    },
    {
      "input": "Käytimme Mikolovin 2013 julkaisemaa julkista word2vec-työkalua sanojen upotusten saamiseksi. Heidän neuroverkkomenetelmänsä on samanlainen kuin feed-forward-neuroverkot BIBREF5 , BIBREF6 . Käyttämässämme Skip-gram-malliarkkitehtuurissa valitsimme saatujen sanavektoreiden ulottuvuudeksi 200.",
      "id": "task461-b02e3d5f689a42dcb749165e1c23664d",
      "output": [
        "Minkä tyyppisiä ja kokoisia sanasulkeumia käytettiin?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme on muodostettu Twitterin etävalvonnan avulla.",
      "id": "task461-da1225742ab04332a19a626c208ce840",
      "output": [
        "Mistä he saivat tiedot tätä hanketta varten?"
      ]
    },
    {
      "input": "Tässä jaksossa arvioimme menetelmäämme ja vertaamme sen suorituskykyä kilpaileviin lähestymistapoihin. Käytämme INLINEFORM0 -kertaista arviointiprotokollaa INLINEFORM1:n kanssa satunnaisella tietokokonaisuuden jaolla. Mittaamme suorituskykyä käyttämällä vakiotarkkuusmittaria, jonka määrittelemme testidatajoukon oikein luokiteltujen tietonäytteiden ja kaikkien testinäytteiden väliseksi suhteeksi.",
      "id": "task461-7d8a40a2652f4dfca1c92df545624585",
      "output": [
        "Mitä arviointimittareita käytetään?"
      ]
    },
    {
      "input": "Neuraalisen g2p-järjestelmän kouluttamiseksi tarvitaan suuri määrä ääntämistietoja. G2p:n vakiotietoaineisto on Carnegie Mellon Pronouncing Dictionary BIBREF12 . Se on kuitenkin yksikielinen englanninkielinen resurssi, joten se ei sovellu monikieliseen tehtävään. Sen sijaan käytämme kaikissa kokeissa deri2016grapheme-ohjelmalla kerättyä monikielistä ääntämiskorpusta. Tämä korpus koostuu Wiktionarystä poimituista oikeinkirjoitus-äännevastaavuuspareista. Se on jo jaettu harjoitus- ja testijoukkoihin. Korpuksen tilastot on esitetty taulukossa TABREF10 Wiktionarystä poimittujen raakojen IPA-äännevastaavien lisäksi korpus tarjoaa automaattisesti puhdistetun version äännevastaavista. Puhdistus on välttämätön vaihe, koska verkosta poimitut tiedot ovat usein kohinaisia ja niiden transkriptiot saattavat olla epäjohdonmukaisen yksityiskohtaisia. Tässä käytetyllä tietojen puhdistuksella pyritään saamaan transkriptiot yhdenmukaisiksi Phoible BIBREFissä4 käytettyjen foneemisten luetteloiden kanssa. ",
      "id": "task461-1e31e28d74dd4449b648ecc61e38be15",
      "output": [
        "mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Tietokanta sisältää noin 30 miljoonaa lausumaa fiktiivisistä hahmoista.",
      "id": "task461-bad75196bcb94296aea85a4a394eed80",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "Hyödynnämme äskettäin julkaistua YK:n vuotuisen yleiskeskustelun aikana pidettyjen valtiollisten puheiden korpusta, joka on ensimmäinen valtioiden tekstimuotoista tuotosta sisältävä tietokokonaisuus, joka on tallennettu säännöllisin aikasarjavälein ja joka sisältää otoksen kaikista puheita pitävistä maista BIBREF11 . ",
      "id": "task461-c7ff20b1e09e4fb98d4b3fec48ec8695",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Korpuksen upottaminenEmme ole kiinnostuneita akustisen mallin optimoinnista paljon suuremmalla harjoituskorpusjoukolla INLINEFORM1 , jossa INLINEFORM2 on korpusten lukumäärä ja INLINEFORM3 . Jokainen korpus INLINEFORM4 on kokoelma INLINEFORM5-pareja, joissa INLINEFORM6 on tulo-ominaisuudet ja INLINEFORM7 on sen kohde. tarkoituksemme tässä on laskea sulautus INLINEFORM0 jokaiselle korpukselle INLINEFORM1, jossa INLINEFORM2 odotetaan koodaavan tietoa sen korpuksesta INLINEFORM3 . Nämä upotukset voidaan kouluttaa yhdessä monikielisen standardimallin BIBREF4 kanssa. Ensin alustetaan kaikkien korpusten upotusmatriisi INLINEFORM4 , jonka INLINEFORM5 -rivi INLINEFORM6 vastaa korpuksen INLINEFORM7 upotusta INLINEFORM8 . Seuraavaksi harjoitusvaiheessa INLINEFORM9 voidaan käyttää tulo-ominaisuuden INLINEFORM10 vinouttamiseen seuraavasti. DISPLAYFORM0 jossa INLINEFORM0 on lausuma, joka on poimittu satunnaisesti INLINEFORM1:stä, INLINEFORM2 on sen piilotetut piirteet, INLINEFORM3 on akustisen mallin parametri ja Encoder on pinottu kaksisuuntainen LSTM kuvan mukaisesti. KUVA5 . Seuraavaksi sovellamme kielikohtaista softmaxia logittien INLINEFORM4 laskemiseen ja optimoimme ne CTC-tavoitteella BIBREF29 . Upotusmatriisi INLINEFORM5 voidaan optimoida yhdessä mallin kanssa koulutusprosessin aikana.",
      "id": "task461-2a49817d0ae1475586656b948ce18444",
      "output": [
        "Miten ne laskevat korpustason sulautumat?"
      ]
    },
    {
      "input": "Tarkastelimme myös tapauksia, joissa kaikki kommentoijat olivat täysin yksimielisiä siitä, että kolmion poiminta oli virheellinen. Näitä kolmioita oli yhteensä 138 kappaletta, jotka olivat peräisin 76 eri lauseesta. ",
      "id": "task461-9a6caf27fe144e8aa1aa1a0f66842269",
      "output": [
        "Mikä on yleisin virhetyyppi?"
      ]
    },
    {
      "input": "Mathur et al. ehdottivat artikkelissaan loukkaavien twiittien havaitsemiseksi Ternary Trans-CNN -mallia, jossa he kouluttavat malliarkkitehtuurin, joka koostuu kolmesta konvoluution 1D-kerroksesta, joiden suodatinkoot ovat 15, 12 ja 10 ja ytimen koko 3, ja jota seuraa kaksi tiheää täysin kytkettyä kerrosta, joiden koko on 64 ja 3. Ensimmäisessä tiheässä FC-kerroksessa on ReLU-aktivointi ja viimeisessä tiheässä kerroksessa Softmax-aktivointi. He pystyivät kouluttamaan tämän verkon Davidsonin et al. toimittamalla rinnakkaisella englanninkielisellä tietokokonaisuudella. Kirjoittajat pystyivät saavuttamaan 83,9 %:n tarkkuuden, 80,2 %:n tarkkuuden ja 69,8 %:n palautuksen.Lähestymistapa näytti lupaavalta, kun otetaan huomioon, että tietokokonaisuus koostui vain 3189 lauseesta, jotka oli jaettu kolmeen luokkaan, ja näin ollen toistimme kokeen, mutta emme onnistuneet toistamaan tuloksia. Tulokset olivat heikompia kuin alkuperäisten tekijöiden saavuttamat tulokset. Suurin osa mallin hyperparametrien valinnoista oli kuitenkin peräisin tästä työstä.",
      "id": "task461-e5d6f22ba6d44570b6be62f699fc6d1f",
      "output": [
        "Mikä on edellisen työn malli?"
      ]
    },
    {
      "input": "Tässä käytän Informapin algoritmia BIBREF12. Vertailun vuoksi käytän tässä kokeessa myös CCM:ää ja SCA:ta etäisyyden mittaamiseen. UPGMA-algoritmia käytettäisiin vastaavasti näissä kahdessa tapauksessa.",
      "id": "task461-37b88fe81d28473286882a1b08712d56",
      "output": [
        "Verrataanko ehdotettua menetelmää aiempiin menetelmiin?"
      ]
    },
    {
      "input": "WikiTableQuestions sisältää 22 033 kysymystä, ja se on kertaluokkaa suurempi kuin aiemmat huipputason tietokokonaisuudet. Kysymyksiä ei ole suunniteltu ennalta määriteltyjen mallien mukaan, vaan käyttäjät ovat laatineet ne käsin, mikä osoittaa suurta kielellistä vaihtelua.",
      "id": "task461-bcd094d2585b4d0b97de51f58290107a",
      "output": [
        "Miten he keräävät tietoja kyselyn selitysongelmaa varten?"
      ]
    },
    {
      "input": "Tätä tarkoitusta varten valitsimme monipuolisen joukon kahdeksan eri kieliperheisiin kuuluvaa lähdekieltä - baskia, ranskaa, saksaa, unkaria, italiaa, navajoa, turkkia ja quechua - ja kolme kohdekieltä - englantia, espanjaa ja zulua. ",
      "id": "task461-ca5a6ba4d2254c809dcbf39d4835df14",
      "output": [
        "Mitä puun kohdekieliä tutkielmassa tarkastellaan?"
      ]
    },
    {
      "input": "Tässä asiakirjassa ehdotamme kolmea erityyppistä CRU-mallia: matala fuusio, syvä fuusio ja syväparannettu fuusio, perustavimmasta perustavimpaan ja ilmaisuvoimaisimpaan. Yksinkertaisin malli on soveltaa CNN-kerrosta suoraan upotuskerroksen jälkeen, jotta saadaan sekoitettuja kontekstuaalisia esityksiä. Sen jälkeen käytetään GRU-kerrosta.",
      "id": "task461-17044f16d2dc4974b537af0c53a1bf3b",
      "output": [
        "Miten CNN syötetään uusiin yksiköihin?"
      ]
    },
    {
      "input": "Takaisinottoriskiluokittimen syötteeksi poimittiin 45 kliinisesti tulkittavissa olevaa piirrettä ottoa kohti. Nämä piirteet voidaan ryhmitellä kolmeen ryhmään (täydellinen luettelo piirteistä on taulukossa TABREF5): Sosiodemografiset tiedot: sukupuoli, ikä, siviilisääty jne. Aikaisempi sairaushistoria: aiempien sairaalahoitojen määrä, itsetuhoisuus, keskimääräinen hoitojakson pituus (kyseiseen sairaalahoitoon asti) jne. Nykyisen sairaalahoidon tiedot: hoitojakson pituus, itsetuhoisuusriski, muistiinpanojen määrä ja pituus, kotiuttamisajankohta, arviointipisteet jne. Nämä piirteet voidaan jakaa edelleen kahteen ryhmään: \"strukturoidut\" kliiniset piirteet ja \"strukturoimattomat\" kliiniset piirteet. feature extraction ::: Strukturoidut piirteetSrukturoidut piirteet ovat piirteitä, jotka tunnistettiin EHR:stä säännöllisen lausekkeen täsmäytyksen avulla ja jotka sisältävät luokituspisteitä, joiden on raportoitu psykiatrisessa kirjallisuudessa korreloivan lisääntyneen takaisinottoriskin kanssa, kuten Global Assessment of Functioning, Insight and Compliance:Global Assessment of Functioning (GAF): Potilaan psykososiaalinen toimintakyky, joka vaihtelee 100:sta (erittäin hyvä toimintakyky) 1:een (vakavasti heikentynyt) BIBREF13.Insight: Se, missä määrin potilas tunnistaa ja hyväksyy sairautensa (joko hyvä, tyydyttävä tai huono): Potilaan kyky noudattaa lääkitystä ja noudattaa lääkärin ohjeita (joko Kyllä, Osittain tai Ei lainkaan).Näitä ominaisuuksia käytetään laajasti kliinisessä käytännössä, ja niillä arvioidaan potilaan yleistä tilaa ja ennustetta potilaan arvioinnin aikana.Feature Extraction ::: Strukturoimattomat piirteetSrukturoitujen piirteiden tarkoituksena on tallentaa potilaan tila suhteessa seitsemään riskitekijäalueeseen (ulkonäkö, ajatusprosessi, ajatusten sisältö, ihmissuhteet, päihteiden käyttö, ammatti ja mieliala) sähköisen potilastietojärjestelmän vapaan tekstin kertomuksista. Näiden seitsemän osa-alueen on todettu olevan yhteydessä takaisinottoriskiin aiemmassa BIBREF-työssä14 : 1) niiden lausekkeiden suhteellinen määrä vastaanottokertomuksissa, jotka liittyvät kuhunkin riskitekijäalueeseen (vastaanottokertomuksen lausekkeiden kokonaismäärästä) ja 2) kliiniset tunnepisteet jokaiselle näistä riskitekijäalueista, eli tunnepisteet, joilla arvioidaan potilaan psykososiaalisen toiminnan tasoa (positiivinen, negatiivinen tai neutraali) kunkin riskitekijäalueen osalta.",
      "id": "task461-db09f3f7a39a449d9667e43170f7f66b",
      "output": [
        "Mitä ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Uutuuksiamme ovat: Itsepelattavan oppimisen käyttäminen neuraalisessa vastausluokittelijassa (kuvattu yksityiskohtaisesti alla).Neuraalisten mallien optimointi tietyille metriikoille (esim. monimuotoisuus, johdonmukaisuus) ensemble-asetuksessamme.Erillisen dialogimallin kouluttaminen jokaiselle käyttäjälle, mikä personoi sosiaalista robottiamme ja tekee siitä johdonmukaisemman.Vastausluokittelun ennustajan ja vastausluokittelijan käyttäminen vastausten näkökohtien, kuten tunnelman, aiheen, loukkaavuuden, monimuotoisuuden jne., ennustamiseen ja hallintaan.Mallin ennustajan käyttäminen parhaan vastausmallin ennustamiseen ennen vastausehdokkaiden luomista, mikä vähentää laskentakustannuksia. entropiapohjaisen suodatustekniikan käyttäminen kaikkien dialogidatajoukkojen suodattamiseen, jolloin saadaan laadukkaampaa harjoitusdataa BIBREF3. suurten, valmiiksi koulutettujen hierarkkisten BERT- ja GPT-dialogimallien rakentaminen BIBREF6, BIBREF7, BIBREF8. käyttäjän syötteen jatkuva seuranta automaattisten mittareidemme avulla, mikä varmistaa, että käyttäjä pysyy mukana.",
      "id": "task461-33779bf5dc4d4f41ba1f206db7594dec",
      "output": [
        "Mikä on uutta kirjailijan lähestymistavassa?"
      ]
    },
    {
      "input": "Näiden seitsemän kielen merkistöissä on vain vähän päällekkäisyyksiä, paitsi että i) ne sisältävät kaikki yhteiset latinalaiset perusaakkoset ja ii) sekä hindi että marathi käyttävät devanagari-kirjoitusta. Otimme 7 merkkijoukon liiton monikieliseksi grafeemijoukoksi (SECREF2), joka sisälsi 432 merkkiä.",
      "id": "task461-ce4ece53d95c40c483780a5b286efdfa",
      "output": [
        "Kuinka suuri osa ASR-grafeemien joukosta on jaettu eri kielten välillä?"
      ]
    },
    {
      "input": "Hashtagien ennustamista sosiaalisessa mediassa on käsitelty aiemmin, esimerkiksi BIBREF15 , BIBREF16 . BIBREF15 käyttää myös neuraalista arkkitehtuuria, mutta muodostaa tekstin upotukset sanojen hakutaulukosta.",
      "id": "task461-463c66805a4a4ad79b598272c8d0947a",
      "output": [
        "Onko tämä hashtagien ennustamistehtävä vakiintunut tehtävä vai jotain uutta?"
      ]
    },
    {
      "input": "Suurin osa tunneanalyysin sanastoresursseista on englanninkielisiä. Jotta näitä lähteitä voitaisiin silti hyödyntää, AffectiveTweets-paketin leksikoni käännettiin espanjaksi käyttäen konekäännösalustaa Apertium BIBREF5. ",
      "id": "task461-476c9087d36248aab9f8c3356428828a",
      "output": [
        "Miten harjoitusaineisto käännettiin?"
      ]
    },
    {
      "input": "TextCat on tunnetuin Perl-toteutus out-of-place-menetelmästä, ja se sisältää mallit 76 kielelle valmiissa kokoonpanossaan; ohjelmaa ei ylläpidetä aktiivisesti. TextCat on tunnetuin Perl-toteutus out-of-place-menetelmästä, se luettelee mallit 76 kielelle valmiissa kokoonpanossaan; ohjelmaa ei ylläpidetä aktiivisesti. TextCat ei ole ainoa esimerkki out-of-place-menetelmän valmiista toteutuksesta: muita toteutuksia ovat muun muassa libtextcat, jossa on 76 kielimallia, JTCL, jossa on 15 kieltä, ja mguesser, jossa on 104 mallia eri kielikoodipareille. Tärkein ongelma, johon myöhemmät toteutukset puuttuvat, on luokittelun nopeus: TextCat on toteutettu Perl-kielellä eikä sitä ole optimoitu nopeuden kannalta, kun taas libtextcatin ja mguesserin kaltaiset toteutukset on kirjoitettu nimenomaan nopeiksi ja tehokkaiksi. whatlang-rs käyttää algoritmia, joka perustuu merkkitrigrammaan, ja se viittaa käyttäjälle BIBREF7-artikkeliin. Se on valmiiksi koulutettu 83 kielen kanssa. on Google Chrome -selaimeen upotettu kielitunniste. Se käyttää NB-luokittelijaa ja käsikirjoituskohtaisia luokittelustrategioita. olettaa, että kaikki syötteet ovat UTF-8-muodossa, ja antaa koodauksen tunnistamisen ja transkoodauksen käyttäjän tehtäväksi. käyttää Unicode-tietoa syötteen käsikirjoituksen määrittämiseen. toteuttaa myös useita esikäsittelyn heuristiikkoja, jotka auttavat parantamaan suorituskykyä kohdealueella (verkkosivut), kuten poistamaan merkkijaksot, kuten .jpg. Vakiototeutus tukee 83 kieltä, ja saatavilla on myös laajennettu malli, joka tukee 160 kieltä. on Java-kirjasto, joka toteuttaa kielitunnisteen, joka perustuu NB-luokittimeen, joka on koulutettu merkkien . Ohjelmiston mukana toimitetaan valmiiksi koulutetut mallit 53 kielelle käyttäen Wikipediasta saatuja tietoja. käyttää erilaisia normalisointiheuristiikkoja parantaakseen suorituskykyä tietyillä kielillä, mukaan lukien: (1) kiinalaisten/japanilaisten/korealaisten merkkien klusterointi harvojen merkkien vähentämiseksi; (2) \"kielestä riippumattomien\" merkkien poistaminen ja muu tekstin normalisointi; ja (3) arabialaisten merkkien normalisointi.on Python-toteutus BIBREF150 :n kuvaamasta menetelmästä, jossa hyödynnetään saman kielen harjoitteluaineistoa useista eri tekstilähteistä sellaisten merkkisarjojen tunnistamiseksi, jotka ennustavat vahvasti tiettyä kieltä tekstin lähteestä riippumatta. Tämä ominaisuusjoukko yhdistetään NB-luokittimeen, ja se jaetaan valmiiksi koulutetun mallin kanssa 97 kielelle, joka on laadittu käyttäen dataa viidestä eri tekstilähteestä. BIBREF151 vertailee empiirisesti mallia ja , ja toteaa, että se on hyvä sekä tarkkuuden että luokittelunopeuden suhteen. BIBREF153 käyttää vektoriavaruusmallia, jossa merkkisekvenssejä painotetaan ominaisuuksittain. Yksi sen erityispiirre on se, että se käyttää piirteiden valinnassa syrjivää koulutusta, eli se käyttää erityisesti sellaisia piirteitä, jotka ovat vahvoja todisteita tiettyä kieltä vastaan, mitä NB-mallit eivät yleensä huomioi. Toinen ominaisuus on se, että se käyttää merkkijonojen välistä tasoitusta hyödyntääkseen lausetason paikallisuutta kieliennusteiden tekemisessä olettaen, että vierekkäiset lauseet ovat todennäköisesti samaa kieltä. BIBREF153 raportoi, että tämä parantaa huomattavasti tunnisteen tarkkuutta. Whatthelang on Python-kielellä kirjoitettu tuore kielitunnistin, joka käyttää FastTextin NN-pohjaista tekstinluokittelualgoritmia. Se tukee 176 kieltä.implementoi valmiiksi koulutetun luokittelijan, joka on koulutettu Wikipedian datan avulla ja joka kattaa 122 kieltä. Vaikka sitä ei ole kuvattu sellaisenaan, varsinainen käytetty luokittelualgoritmi on lineaarinen malli ja siten läheistä sukua sekä NB:lle että kosinipohjaiselle vektoriavaruusmallille. edellä mainittujen yleiskäyttöisten kielitunnistimien lisäksi on pyritty tuottamaan valmiiksi koulutettuja kielitunnistimia, jotka on suunnattu erityisesti Twitter-viesteille. on Twitter-kohtainen työkalu, jossa on sisäänrakennetut mallit 19:lle kielelle. Se käyttää asiakirjan esitystapaa, joka perustuu tries BIBREF401 . Algoritmi on LR-luokittelija, joka käyttää datan kaikkia mahdollisia osajonoja, mikä on tärkeää, jotta suhteellisen lyhyistä Twitter-viesteistä saadaan mahdollisimman paljon tietoa.BIBREF152 vertailee kahdeksaa valmista kielitunnistinta, joita sovelletaan ilman uudelleenkoulutusta Twitter-viesteihin. Heidän mukaansa yksi ongelma on se, että valmiiden järjestelmien tarkkuuden vertailu on vaikeaa, koska kunkin järjestelmän tukema kielten osajoukko on erilainen, eikä se välttämättä myöskään kata kaikkia kohdedatassa esiintyviä kieliä. Kirjoittajat päättävät verrata tarkkuutta koko kielivalikoiman osalta, koska tämä kuvastaa parhaiten todennäköistä käyttötapaa, jossa valmisjärjestelmä sovelletaan uuteen dataan. He havaitsevat, että parhaat yksittäiset järjestelmät ovat , ja , mutta hieman korkeampaan tarkkuuteen päästään yksinkertaisella äänestykseen perustuvalla yhdistelmäluokittimella, jossa on mukana nämä kolme järjestelmää.Tämän lisäksi on olemassa kaupallisia tai muita suljetun lähdekoodin kielitunnistimia ja kielitunnistuspalveluja, joista mainitsemme muutamia. Polyglot 3000 ja Lextek Language Identifier ovat itsenäisiä kielitunnistimia Windowsille. Open Xerox Language Identifier on verkkopalvelu, jossa on saatavilla REST- ja SOAP API:t.",
      "id": "task461-67798e7e5d2549559470a2da300a4829",
      "output": [
        "Mitkä ovat asiakirjassa käsitellyt valmiit järjestelmät?"
      ]
    },
    {
      "input": "JESSI koulutetaan käyttämällä ainoastaan jaetussa tehtävässä annettuja tietokokonaisuuksia, eikä siinä käytetä mitään muita ulkoisia tietoja.",
      "id": "task461-4406b3c80a8d4bc2ae1e86878780be51",
      "output": [
        "Mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Arvioimme TN-teemamallia kvantitatiivisesti tavanomaisilla teemamallien mittareilla, kuten testijoukon perpleksisyydellä, todennäköisyyden konvergenssilla ja klusterointimittareilla. Laadullisesti arvioimme mallia visualisoimalla aiheyhteenvetoja, kirjoittajien aihejakaumia ja suorittamalla automaattisen merkintätehtävän.",
      "id": "task461-ee5f122fe6294746b24a341d2f96bec0",
      "output": [
        "Mitkä ovat tässä asiakirjassa käytetyt \"suorituskyvyn\" mittarit?"
      ]
    },
    {
      "input": "Tässä asiakirjassa ehdotetaan, että lähdetietokannan merkityksellisimpiä näytteitä käytetään kohdetietokannan harjoitteluun. Yksi tapa löytää samankaltaisimmat näytteet on löytää kohdetietokannan ja lähdetietokannan kehitysjoukon kaikkien näytteiden välinen pareittainen etäisyys. ehdotamme, että kehitysjoukkoon käytetään klusterointialgoritmia. Tässä käytetty klusterointialgoritmi on hierarkkinen klusterointialgoritmi. Kosinuksen samankaltaisuutta käytetään kriteerinä kunkin kysymyksen ja vastauksen klusterointiin. Näin ollen nämä klusterit edustavat kohdetietokannan kehitysjoukkoa, ja kunkin klusterin vastaava keskus edustaa kaikkia kyseiseen klusteriin kuuluvia näytteitä. Seuraavassa vaiheessa kunkin keskuksen etäisyyttä käytetään kosinin samankaltaisuuden laskemiseen. Lopuksi lähdetietokannan näytteet, jotka ovat kaukana näistä keskuksista, jätetään huomiotta. Toisin sanoen poikkeavat näytteet eivät osallistu siirto-oppimiseen.",
      "id": "task461-0bbea1829aee451abb5aa7231e4bb4b7",
      "output": [
        "Miten malli siirretään?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua lähestymistapaa kiinalaisen sosiaalisen median tekstin tiivistämistehtävässä, joka perustuu sekvenssistä sekvenssiin -malliin. Suuren mittakaavan kiinalaisen lyhyen tekstin tiivistämistietokanta (Large-Scale Chinese Short Text Summarization Dataset, LCSTS) on muodostettu BIBREF1 -tietokannan avulla. Tietokanta koostuu yhteensä yli 2,4 miljoonasta teksti-tiivistelmäparista, jotka on muodostettu kuuluisasta kiinalaisesta sosiaalisen median mikroblogipalvelusta Weibosta. ",
      "id": "task461-d5b9d4a95b9940b2b033df2f833f0d19",
      "output": [
        "Ilmoitetaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Kuten kohdassa \"sec:coalitionpolicy\" todettiin, Euroopan yhdentymisen kannattajat ja vastustajat jakautuvat voimakkaasti kahteen lohkoon, mikä näkyy vielä selvemmin kuviossa FIGREF42 B. Unionin valtio ja kehitys -alueella havaitaan jälleen voimakas jakautuminen kahteen lohkoon (ks. kuvio FIGREF42 E). Tämä eroaa kuitenkin talous- ja rahajärjestelmästä, jossa havaitaan äärivasemmiston ja äärioikeiston yhteistyötä, jossa jako on perinteisen vasemmisto-oikeistoakselin suuntainen.Twitterissä muodostuvien koalitioiden mallit muistuttavat läheisesti Euroopan parlamentin malleja.",
      "id": "task461-97d78c63adf6486d9a916c3f0d9d2ca2",
      "output": [
        "Havaitaanko analyysissä, että koalitiot muodostuvat samalla tavalla eri politiikan aloilla?"
      ]
    },
    {
      "input": " Yleisemmin ottaen tiedämme vain vähän siitä, millaisia kehityskysymyksiä eri maat pitävät ensisijaisina tai ovatko maakohtaiset tekijät, kuten vauraus tai demokratia, syynä siihen, että maat ajavat todennäköisemmin tiettyjen kehityskysymysten ottamista maailmanpoliittiselle asialistalle.  Huomasimme, että maakohtaiset tekijät, kuten vauraus, väestö, demokratia, julkisen kehitysavun määrä ja konfliktit, eivät vaikuta merkittävästi aihealueesta 2 käytävään keskusteluun (joskin alueellisia vaikutuksia on havaittavissa). ",
      "id": "task461-d4525514ca0440c6834d3e2b5f85c3b8",
      "output": [
        "Mitkä ovat kansainvälisen kehitysretoriikan maakohtaiset ajurit?"
      ]
    },
    {
      "input": "Ternaarinen ja hienojakoinen tunteiden luokittelu olivat osa SemEval-2016 \"Sentiment Analysis in Twitter\" -tehtävää BIBREF16 . Käytämme haasteen järjestäjien julkaisemia korkealaatuisia tietokokonaisuuksia.",
      "id": "task461-9725256176d94c1d87ab4e0f941fceaa",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": "Tavoitteenamme on antaa NMT-järjestelmälle tietoa ensimmäisen persoonan lauseiden puhujasta ja keskustelukumppanista, jotta se voi tuottaa halutun kohdepuolen morfologian, kun tietoa ei ole saatavilla lähdelauseesta. Lähestymistapamme tässä työssä on mustan laatikon injektio, jossa yritämme syöttää tietoa syötteeseen vaikuttaaksemme koulutetun NMT-järjestelmän tulosteeseen ilman, että meillä on pääsyä sen sisäisiin osiin tai sen koulutusmenettelyyn, kuten vanmassenhove-hardmeier-way:2018:EMNLP:ssä ehdotetaan. Tämän todentamiseksi kokeilemme lauseiden kääntämistä seuraavilla variaatioilla: Ei etuliitettä - GMT-järjestelmän palauttama peruskäännös. \"He said:\"-merkki miespuolisesta puhujasta. Odotamme järjestelmän vinoutuvan entisestään kohti maskuliinisia muotoja. \"She said:\"-merkki naispuolisesta puhujasta ja tuntemattomasta yleisöstä. Koska tämä vastaa puhujan todellista sukupuolta, odotamme, että ensimmäisen persoonan pronominien ja verbien, joiden subjektina on ensimmäisen persoonan pronomini, käännös paranee. \"I said to them:\"-merkki tuntemattomasta puhujasta ja monikossa olevasta yleisöstä. \"He said to them:\"-Maskuliininen puhuja ja monikossa oleva yleisö. \"She said to them:\"-Nainen puhuja ja monikossa oleva yleisö - täydellinen, oikea tila. Odotamme parasta käännöstarkkuutta tässä asetelmassa. \"He/she said to him/her\"- Tässä asetamme (virheellisen) yksikön sukupuoleen merkityn yleisön tutkiaksemme kykyämme hallita yleisön morfologiaa.",
      "id": "task461-d395bbe86c184e629af26437acd0606e",
      "output": [
        "Mitkä ovat black-box-kontekstin injektiojärjestelmän osat?"
      ]
    },
    {
      "input": "Tässä artikkelissa ehdotamme kahta neuraalista upotusmallia, joiden avulla voidaan oppia jatkuvia käsitevektoreita, jotka perustuvat BIBREF11 -hyppygrammimalliin. Ensimmäinen mallimme on Concept Raw Context -malli (CRC), joka hyödyntää käsitteiden mainintoja laajamittaisessa tietokannassa oppiakseen yhdessä sekä sanojen että käsitteiden upotukset. Toinen mallimme on Concept-Concept Context -malli (3C), joka oppii käsitteiden upotukset niiden käsitteellisistä konteksteista (eli konteksteista, jotka sisältävät vain ympäröiviä käsitteitä). ",
      "id": "task461-7a527c82c3ab4d8f9d399338b7b7360c",
      "output": [
        "Mitkä ovat kaksi neuraalista upotusmallia?"
      ]
    },
    {
      "input": "Käytämme kahta erilaista valvomatonta lähestymistapaa sanojen merkityksen erotteluun.  Toinen, nimeltään \"tiheä malli\", edustaa synsetit ja kontekstit tiheässä, matalaulotteisessa avaruudessa keskiarvoistamalla sanojen upotukset. Synsettien sulautusmallia käytettäessä noudatamme SenseGram BIBREF14 -mallia ja sovellamme sitä synonyymien graafista indusoituihin synsetteihin.  Havaitsemme, että SenseGram-pohjainen lähestymistapa sanojen merkitysten erotteluun tuottaa huomattavasti parempia tuloksia kaikissa tapauksissa (taulukko TABREF25 ). Pääsyy tähän on samankaltaisten sanojen implisiittinen käsittely, joka johtuu semanttisesti toisiinsa liittyvien sanojen tiheiden sanavektoreiden keskiarvoistamisesta. ",
      "id": "task461-489703bec714400a8f8c165297f3319a",
      "output": [
        "Esittävätkö kirjoittajat hypoteeseja siitä, miksi tiheä tila oli parempi kuin harva tila?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa tutkimme harhojen vähentämisen tehokkuutta harjoittelun aikana ottamalla käyttöön uuden tappiofunktion, joka kannustaa kielimallia tasoittamaan sukupuolittuneiden sanaparien, kuten hän ja nainen, ennustamisen todennäköisyyksiä. ",
      "id": "task461-38738696beee41439c8408c24f5d0ff6",
      "output": [
        "millaisia mies- ja naissanoja tarkastellaan?"
      ]
    },
    {
      "input": "Käytämme MedWeb-tietokokonaisuutta BIBREF4 (\"Medical Natural Language Processing for Web Document\"), joka toimitettiin osana NTCIR-13-konferenssin BIBREF5 osatehtävää. Tietojen yhteenveto on taulukossa TABREF1. Pseudotwiittejä on yhteensä 2560 kappaletta kolmella eri kielellä: Japani (ja), englanti (en) ja kiina (zh).",
      "id": "task461-8411dd87f4a84bc9be89ed1c1b4170f7",
      "output": [
        "Kuinka suuri on tietokokonaisuus, jota käytetään mallin hienosäätöön punaisen lipun lääketieteellisten oireiden havaitsemiseksi yksittäisissä lausunnoissa?"
      ]
    },
    {
      "input": "Opetussuunnitelman yleismaailmallisuuden ja yleisen sovellettavuuden varmistamiseksi suoritamme perusteellisen tutkimuksen kolmella julkisesti saatavilla olevalla keskustelukorpuksella, jotka ovat PersonaChat BIBREF12, DailyDialog BIBREF13 ja OpenSubtitles BIBREF7 ja jotka koostuvat 140 248, 66 594 ja 358 668 todellisesta keskustelunäytteestä.",
      "id": "task461-e02c38c4165849318cc720617458be13",
      "output": [
        "Mitä kolmea julkisesti saatavilla olevaa coroporaa käytetään?"
      ]
    },
    {
      "input": "DNN-pohjaiset mallit yhdistettynä siirto-oppimiseen päihittävät parhaat tunnetut tulokset kaikissa kolmessa tietokokonaisuudessa. Aiemmat parhaat F1-tulokset Wikipedia BIBREF4- ja Twitter BIBREF8 -tietokannoille olivat 0,68 ja 0,93. Saavutamme molemmille tietokokonaisuuksille F1-pisteet 0,94 käyttämällä BLSTM-malleja, joissa on huomio- ja ominaisuustason siirto-oppiminen (taulukko TABREF25 ). Formspring-tietokannan tekijät eivät ole ilmoittaneet F1-tulosta. Heidän menetelmänsä tarkkuus on 78,5 % BIBREF2 . Meidän F1-tuloksemme on 0,95 ja tarkkuus 98 % samasta tietokokonaisuudesta.",
      "id": "task461-5ea06c19fa3941b2aa80639eeb4027b7",
      "output": [
        "Millaisia tuloksia he saavuttivat?"
      ]
    },
    {
      "input": "Poistamme käyttäjän iän soveltamalla säännöllisten lausekkeiden malleja profiilin kuvauksiin (kuten \"17-vuotias, itsensä vahingoittaminen, ahdistus, masennus\") BIBREF41 . Kootaan \"ikäprefiksit\" ja \"ikäsuffiksit\" ja käytetään kolmea iän poimintasääntöä: 1. Olen X vuotta vanha 2. Syntynyt vuonna X 3. X vuotta vanha, jossa X on \"päivämäärä\" tai ikä (esim. 1994). Valitsimme INLINEFORM1:stä 1464 käyttäjän INLINEFORM0 osajoukon, jotka paljastavat sukupuolensa profiilikuvauksessaan.",
      "id": "task461-b5490ee0240443b49eaf42a61cabe392",
      "output": [
        "Mistä yksilötason demografisia tietoja saadaan?"
      ]
    },
    {
      "input": "Teemme kokeilumme 8,7 miljoonan annotoidun ja anonymisoidun käyttäjän lausumilla. Ne on annotoitu ja johdettu 23 toimialueen pyynnöistä.",
      "id": "task461-c2f779322952418aa8840fa229401b16",
      "output": [
        "Minkä tietokokonaisuuksien/korporaatioiden perusteella tätä työtä arvioidaan?"
      ]
    },
    {
      "input": "Profiilien todentamisprosessissa havaitsimme, että useimmat jengiläisten profiilit kuvaavat jengikulttuuria edustavaa kontekstia. Esimerkkejä tällaisista profiilikuvista on esitetty kuvassa KUVA32 , jossa käyttäjällä on kädessään tai osoittamassa aseita, hänet nähdään jengikulttuuria ilmentävässä ryhmäkuvassa tai hän esittelee graffiteja, käsimerkkejä, tatuointeja ja suuria määriä käteistä rahaa.",
      "id": "task461-a1ce1e79386040fbb1cb62c0069e9542",
      "output": [
        "Mitä eroja kuvien käytössä on jengiläisten ja muun Twitter-väestön välillä?"
      ]
    },
    {
      "input": "Pääkirjat: 9) Klassiset teostyypit (\"sinfonia\", \"ouvertuuri\" jne.); 9) Klassiset teostyypit (\"sinfonia\", \"ouvertuuri\" jne.).); 10)Soittimet; 11)Opus-muodot (\"op\", \"opus\"); 12)Teoksen numeromuodot (\"no\", \"number\"); 13)Teoksen avaimet (\"C\", \"D\", \"E\", \"F\", \"G\", \"A\", \"B\", \"tasa\", \"terävä\"); 14)Teoksen moodit (\"duuri\", \"molli\", \"m\").",
      "id": "task461-8353c3d375ab4c9bab4488b5b29e0a05",
      "output": [
        "Mitä tehtäväkohtaisia ominaisuuksia käytetään?"
      ]
    },
    {
      "input": "Hienosäätöön käytämme seuraavaa GLUE-tehtävien osajoukkoa BIBREF4: MRPC: Microsoft Research Paraphrase Corpus BIBREF13STS-B: Semantic Textual Similarity Benchmark BIBREF14SST-2: Stanford Sentiment Treebank, kaksisuuntainen luokittelu BIBREF15QQP: Quora Question Pairs datasetRTE: Recognizing Textual Entailment datasetsQNLI: Stanford Question Answering Dataset -tietokantaan perustuva Question-answering NLI BIBREF3MNLI: Multi-Genre Natural Language Inference Corpus, täsmäytetty osa BIBREF16",
      "id": "task461-33156bb923fb429ebbdbbc9d60841b62",
      "output": [
        "Mitä GLUE-tehtävien osajoukkoa käytetään?"
      ]
    },
    {
      "input": "GE-FL vähentää instanssien annotaation aiheuttamaa raskasta kuormitusta ja toimii hyvin, kun annamme ennakkotietoa ilman ennakkoasenteita. Kokeissamme havaitsimme, että kullekin luokalle on toimitettava vertailukelpoinen määrä merkittyjä piirteitä. Valitsemme satunnaisesti $t \\ in [1, 20]$ piirteitä piirrejoukosta yhdelle luokalle ja vain yhden piirteen toiselle luokalle. Menetelmiämme arvioidaan myös tietokokonaisuuksilla, joissa on erilaisia epätasapainoisia luokkajakaumia. Rakennamme manuaalisesti useita elokuvatietoaineistoja, joiden luokkajakaumat ovat 1:2, 1:3 ja 1:4, poistamalla satunnaisesti 50 %, 67 % ja 75 % positiivisia asiakirjoja. KL-divergenssin sisällyttäminen on riittävän vankka keino hallita epätasapainoa sekä tietokannassa että merkityissä ominaisuuksissa, kun taas kolme muuta menetelmää eivät ole yhtä kilpailukykyisiä.",
      "id": "task461-20aacdd5b81743dfbe6150cedee26eb4",
      "output": [
        "Miten ne määrittelevät mallin kestävyyden?"
      ]
    },
    {
      "input": "Tulokset ::: Tässä asetelmassa vertaamme ympäristössä suoritettujen toimintojen määrää (kehykset) ja agentin saavuttamaa pistemäärää (eli +1 palkkio, jos kolikko on kerätty). Go-Exploressa laskemme myös toiminnot, joita käytettiin ympäristön palauttamiseen valittuun soluun, eli agentin saattamiseen valitun solun edustamaan tilaan. Tämä mahdollistaa Go-Exploren ja algoritmien, jotka käyttävät laskentaan perustuvaa palkitsemista tekstipohjaisissa peleissä, välisen tutkimustehokkuuden yksiselitteisen vertailun. Tärkeää on, että BIBREF8 osoitti, että DQN ja DRQN eivät ilman tällaisia laskentapalkkioita koskaan pysty löytämään onnistunutta rataa vaikeissa peleissä, kuten kokeissamme käytetyissä peleissä. Kuvassa FIGREF17 esitetään vuorovaikutusten määrä ympäristön kanssa (kehykset) suhteessa saavutettuun maksimipistemäärään keskiarvona 10:stä saman vaikeusasteen pelistä. Kuten BIBREF8 osoittaa, DRQN++ löytää radan, jolla saavutetaan maksimipisteet, nopeammin kuin DQN++. Toisaalta Go-Exploren vaihe 1 löytää optimaalisen radan noin puolet harvemmalla vuorovaikutuksella ympäristön kanssa. Lisäksi Go-Exploren löytämän liikeradan pituus on aina optimaalinen (30 askelta), kun taas DQN++:n keskimääräinen pituus on 38 ja DRQN++:n 42 askelta. CookingWorld-pelin CoinCollector tapauksessa vertailimme malleja kolmessa aiemmin mainitussa asetelmassa, jotka olivat yksittäinen, yhteinen ja nollalaukaus. Kaikissa kokeissa mittasimme kaikkien pelien loppupisteiden summan ja niiden liikeradan pituuden (askelten määrä). Taulukossa TABREF26 on yhteenveto tuloksista näissä kolmessa asetelmassa. Go-Exploren vaiheessa 1 yksittäisillä peleillä saavutetaan kokonaispisteet 19 530 (kaikkien pelien summa), joka on hyvin lähellä suurinta mahdollista pistemäärää (eli 19 882 pistettä), 47 562 askeleella. Voittorata löytyi 4 279 pelissä 4 440 pelistä. Tämä tulos vahvistaa jälleen kerran, että Go-Exploren tutkimusstrategia on tehokas tekstipohjaisissa peleissä. Seuraavaksi arvioimme Go-Exploren vaiheessa 1 poimittujen liikeratojen avulla koulutetun yksinkertaisen jäljittely-oppimiskäytännön tehokkuutta ja yleistettävyyttä edellä mainituissa kolmessa ympäristössä. Tässä asetelmassa kukin malli koulutetaan tyhjästä jokaisessa 4440 pelissä Go-Exploren vaiheessa 1 (edellinen vaihe) löydetyn liikeradan perusteella. Kuten taulukosta TABREF26 käy ilmi, LSTM-DQN BIBREF7, BIBREF8 -lähestymistapa, jossa ei käytetä sallittuja toimintoja, toimii huonosti. Yksi selitys tälle voi olla se, että tämän mallin on vaikea tutkia sekä kieltä että pelistrategiaa samanaikaisesti; mallin on vaikea löytää palkintosignaalia ennen kuin se on oppinut mallintamaan kieltä, koska lähes yksikään sen toimista ei ole sallittu, ja juuri nämä palkintosignaalit ovat välttämättömiä kielimallin oppimiseksi. Kuten taulukosta TABREF26 nähdään, LSTM-DQN:n saavuttama pistemäärä kasvaa kuitenkin dramaattisesti käyttämällä sallittuja toimintoja $\\epsilon $-greedy-vaiheessa (+ADM-rivi taulukossa TABREF26). DRRN BIBREF10 saavuttaa erittäin korkean pistemäärän, koska se oppii nimenomaisesti asettamaan hyväksyttävät toiminnot paremmuusjärjestykseen (eli paljon yksinkertaisempi tehtävä kuin tekstin tuottaminen). Lopuksi, lähestymistapamme, jossa käytetään Seq2Seq-mallia, joka on koulutettu Go-Exploren vaiheen 1 antamalla yksittäisellä liikeradalla, saa kaikista menetelmistä korkeimman pistemäärän, vaikka emme käytä sallittuja toimintoja tässä vaiheessa. Tässä kokeessa Seq2Seq-malli ei kuitenkaan pysty täydellisesti jäljittelemään annettua liikerataa, ja sen saavuttama kokonaispistemäärä on itse asiassa 9,4 prosenttia pienempi kuin Go-Exploren vaiheessa 1 saavutettu kokonaispistemäärä. Kuvassa FIGREF61 (liitteessä SECREF60) esitetään pisteiden jakautuminen kunkin tason ja mallin osalta, ja siinä näkyy, että mallimme ja muiden menetelmien välinen ero kasvaa, kun pelit vaikeutuvat tarvittavien taitojen osalta. Tässä asetelmassa 4440 peliä on jaettu harjoitus-, validointi- ja testipeleihin. Jako tehdään satunnaisesti, mutta siten, että eri vaikeustasot (reseptit 1, 2 ja 3) ovat edustettuina yhtä suurella osuudella kaikissa kolmessa jaossa eli vaikeusasteen mukaan jaoteltuina. Kuten taulukosta TABREF26 käy ilmi, RL-perusratkaisujen suorituskyky nollapisteissä on heikko, mikä voi johtua samoista syistä, joiden vuoksi RL-perusratkaisut alisuoriutuvat Joint-tapauksessa. Erityisen mielenkiintoista on se, että DRRN-mallin suorituskyky on huomattavasti heikompi kuin Go-Explore Seq2Seq -mallin, vaikka DRRN-mallilla on pääsy sallittuihin toimintoihin testiajankohtana, kun taas Seq2Seq-malli (samoin kuin LSTM-DQN-malli) joutuu rakentamaan toimintoja merkki kerrallaan koko 20 000 merkin sanastosta. Toisaalta Go-Explore Seq2Seq osoittaa lupaavia tuloksia, sillä se ratkaisee melkein puolet näkemättömistä peleistä. Kuva FIGREF62 (liitteessä SECREF60) osoittaa, että suurin osa hävityistä peleistä kuuluu vaikeimpaan joukkoon, jossa pelin voittaminen edellyttää hyvin pitkää toimintasarjaa. Nämä tulokset osoittavat sekä Seq2Seq-mallin kouluttamisen suhteellisen tehokkuuden Go-Explore-pelien liikeradoilla että sen, että tarvitaan lisäponnistuksia sellaisten vahvistusoppimisalgoritmien suunnittelemiseksi, jotka yleistyvät tehokkaasti näkymättömiin peleihin.",
      "id": "task461-b5f323f30ceb462eae65505b0767865a",
      "output": [
        "Kuinka paremmin uusi lähestymistapa toimii kuin nykyiset ratkaisut?"
      ]
    },
    {
      "input": "Ehdotetussa mallissa yhdistetään kaksi solmua (sanaa) toisiinsa esiintymisreunojen lisäksi, jos vastaava sanan upotuskuvaus on samanlainen.",
      "id": "task461-cf55c8ad2ab849a5ba5897c9e239e1bd",
      "output": [
        "Käyttävätkö ne pelkkiä sanojen upotuksia vai korvaavatko ne jotkin mallin aiemmat piirteet sanojen upotuksilla?"
      ]
    },
    {
      "input": "Otokseen valittiin kaikki julkaisut, jotka julkaistiin seuraavissa tietotekniikan alaluokissa: Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Social and Information Networks (cs.SI), Computational Linguistics (cs.CL), Computers and Society (cs.CY), Information Retrieval (cs.IR) ja Computer Vision (CS.CV), Computer Science (stat.ML) ja Social Physics (physics.soc-ph). Suodatimme artikkelit, joiden otsikossa tai tiivistelmässä oli vähintään yksi sanoista \"machine learning\", \"classif*\" tai \"supervi*\" (isoja ja pieniä kirjaimia ei huomioida). Tämän jälkeen suodatimme paperit, joiden otsikossa tai tiivistelmässä oli vähintään sana \"twitter\" tai \"tweet\" (isoja ja pieniä kirjaimia ei huomioida), jolloin tulokseksi saatiin 494 paperia. Käytimme samaa kyselyä Elsevierin vertaisarvioituja artikkeleita sisältävään Scopus-tietokantaan ja valitsimme 30 satunnaisotannalla poimittua artikkelia, jotka oli valittu enimmäkseen konferenssijulkaisuista. Yksi Scopus-otoksen artikkeli oli vioittunut, joten tarkasteltiin vain 29 artikkelia.",
      "id": "task461-c5ea4a2bacd44872a59c43f323199cbd",
      "output": [
        "Miten ArXivin koneoppimisjulkaisut poimittiin?"
      ]
    },
    {
      "input": "Käytämme seuraavia halpoja tapoja luoda pseudolähdetekstejä: copy: tässä asetelmassa lähdepuoli on pelkkä kopio kohdepuolen tiedoista. copy-marked: toinen tapa integroida kopioita ilman OOV:ien käsittelyä on täydentää lähdesanastoa kohdesanaston kopiolla. copy-dummies: varsinaisten kopioiden sijasta korvaamme jokaisen sanan \"dummy\"-tavuilla. ",
      "id": "task461-22af3187b05748318a07600f801eda1f",
      "output": [
        "mitä tietojen simulointitekniikoita otettiin käyttöön?"
      ]
    },
    {
      "input": "Useita kierroksia: Keskimääräinen lausumien määrä vuoropuhelua kohden on noin 23, mikä takaa kontekstirikkaan kielenkäyttäytymisen.",
      "id": "task461-70652b07687542c79f92159effb20425",
      "output": [
        "Kuinka monta kierrosta keskimäärin tehdään vuoropuhelua kohden?"
      ]
    },
    {
      "input": "On kaksi näkökohtaa, jotka siirretään tulevaan työhön. Ensinnäkin tässä suunnitelluissa järjestelmissä oletettiin, että syötteet ovat kelvollisia väitelauseita. Jotta tällaisia järjestelmiä voitaisiin käyttää, on kehitettävä mekanismeja, joilla voidaan tunnistaa kelvollisia argumenttirakenteita. Lisäksi jätämme huomiotta luotettavuuteen ja uskottavuuteen liittyvät kysymykset, jotka ovat tärkeitä tutkimuskysymyksiä ja joita käsitellään muissa töissä.",
      "id": "task461-0e9b19f3767d442899ba34de0ab7e0bc",
      "output": [
        "Mitä haasteita korostetaan?"
      ]
    },
    {
      "input": "MT-tehtävässä käytämme WMT 2014 En $\\leftrightarrow $ Fr -rinnakkaiskorpusta. Tietokokonaisuus sisältää 36 miljoonaa En $\\rightarrow $ Fr-lauseparia. Vaihdoimme lähde- ja kohdelauseet saadaksemme rinnakkaisdataa Fr $\\rightarrow $ En -käännöstehtävää varten. Käytämme näitä kahta tietokokonaisuutta (72 miljoonaa lauseparia) kouluttaaksemme yhden monikielisen NMT-mallin oppimaan molemmat käännössuunnat samanaikaisesti. ",
      "id": "task461-15e87633b5f44e09ae4a09dfc29a9bae",
      "output": [
        "Mitä tietoja käytettiin monikielisen koodaimen kouluttamiseen?"
      ]
    },
    {
      "input": "BIBREF6 esittelee KG-A2C:n, joka käyttää tietämysgraafiin perustuvaa tilojen esittämistä apuna toimintojen osion määrittämisessä kombinatorisesti mitoitetussa toiminta-avaruudessa - erityisesti he käyttävät tietämysgraafia rajoittaakseen, millaisia entiteettejä voidaan täyttää tyhjät kohdat mallitoiminta-avaruudessa. He testaavat lähestymistapaansa Zork1:llä ja osoittavat, että tietämysgraafin ja mallitoimintojen valinnan yhdistelmä parantaa nykyisiä menetelmiä. He huomauttavat, että heidän lähestymistapansa saavuttaa 40 pisteen tuloksen, joka vastaa Zork1:n pullonkaulaa, jossa \"grue\" syö pelaajan (mikä johtaa negatiiviseen palkintoon), jos pelaaja ei ole ensin sytyttänyt lamppua.",
      "id": "task461-e641f0eea7624899a7cdf986105f4d26",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Tässä työssä analysoidaan, miten esivalmennetut kielimallit ymmärtävät kieltäviin lausumiin tallennettua fakta- ja maalaisjärjen tietoa. Tätä varten esitellään negaatioita sisältävä LAMA-tietokanta. Rakennamme sen yksinkertaisesti lisäämällä negaatioelementtejä (esim. \"ei\") LAMA-lausekkeisiin (esim. \"Suhteellisuusteoriaa ei kehittänyt [MASK].\").",
      "id": "task461-84980666d80b4cdcbb867acb4f972a6d",
      "output": [
        "Miten he laajensivat LAMA-arviointikehystä keskittymällä negaatioon?"
      ]
    },
    {
      "input": "Siksi analyysissämme keskitymme ketjun piirteisiin, jotka liittyvät läpivalaisun ja selittämisen ilmiöihin.",
      "id": "task461-91392223769449fd9d9572f27d69f256",
      "output": [
        "Mitä coreference-ilmiöitä analysoidaan?"
      ]
    },
    {
      "input": "Kielimalli (LM): Koulutamme kaksikerroksisen rekursiivisen neuraalisen kielimallin, jonka GRU-solujen piilokoko on 512. Sequence-to-Sequence Attention Model (S2S): Koulutetaan kaksikerroksinen neurologinen sekvenssistä sekvenssiin -malli, joka on varustettu bilineaarisella huomiofunktiolla ja jossa on piilotetun koon 512 GRU-soluja.  Lineaarinen dynaaminen järjestelmä (LDS): Koulutamme myös jaksossa SECREF1 käsitellyn lineaarisen dynaamisen järjestelmän, joka on yksi vertailulinjoistamme oikeudenmukaista vertailua varten. Puolivalvottu SLDS (SLDS-X%): Koulutamme puolivalvonnan käytettävyyden arvioimiseksi myös puolivalvottuja SLDS-malleja, joissa on vaihteleva määrä tunnetunnisteita, toisin kuin alkuperäisessä mallissa, joka käyttää 100-prosenttisesti tunnisteilla varustettua dataa. ",
      "id": "task461-340a9086db4d4195adbbde8175ed1041",
      "output": [
        "Mitä perustasoja käytetään?"
      ]
    },
    {
      "input": "Tämän ongelman ratkaisemiseksi BIBREF1 esitteli semanttisesti ehdollistetun sukupolvimallin, jossa käytetään hierarkkista epäyhtenäistä itsehuomiota (HDSA) .",
      "id": "task461-067b4e90d9dd4801b05bd6b6dd9095cf",
      "output": [
        "mihin semanttisesti ehdollistettuihin malleihin niitä verrattiin?"
      ]
    },
    {
      "input": " Kompensoidaksemme aukkokohtaisten parametrien poissulkemisen otamme käyttöön paremman ominaisuuksien esityksen käyttäjän lausumasta ja dialogin tiloista käyttämällä syntaktista tietoa ja konvoluutio-neuraaliverkkoja (CNN, convolutional neural networks).",
      "id": "task461-4d9930e9cb0d4237a32f7f48b5cd5bd0",
      "output": [
        "Mitä verkkoarkkitehtuuria he käyttävät SIM-kortissa?"
      ]
    },
    {
      "input": "Vertaamme HR-VAE-malliamme kolmeen vahvaan perusmalliin, jotka käyttävät VAE:tä tekstin mallintamiseen: VAE-LSTM-pohja: Variationaalinen automaattinen koodausmalli, joka käyttää LSTM:ää sekä koodauksessa että dekoodauksessa. KL-hehkutusta käytetään latenttien muuttujien romahdusongelman ratkaisemiseen BIBREF0;VAE-CNN: Variationaalinen autokooderimalli, jossa on LSTM-kooderi ja laajennettu CNN-dekooderi BIBREF7;vMF-VAE: Variationaalinen autokooderimalli, jossa käytetään LSTM:ää sekä kooderissa että dekooderissa ja jossa ennakkojakauma on von Mises-Fisher (vMF) -jakauma Gaussin jakauman sijasta BIBREF5.",
      "id": "task461-46015377c26f443a8c0b442f78c06d36",
      "output": [
        "Verrataanko niitä uusimpaan tekstin tuottamiseen?"
      ]
    },
    {
      "input": "Täydellinen aineisto koostuu sekä edellä mainitusta otoksesta että alustavan työn 819 parista, eli yhteensä 2677 parista. Jaoimme vSTS-tietokannan harjoittelu-, validointi- ja testiosioihin satunnaisotannalla ja säilytimme kokonaispistejakaumat. Käytämme yhteensä 1338 paria harjoitteluun, 669 validointiin ja loput 670 paria lopulliseen testaukseen.",
      "id": "task461-f7ce3de03a414b91b5b551280711d7ca",
      "output": [
        "Kuinka suuri vSTS-koulutusdata on?"
      ]
    },
    {
      "input": "Testaamme myös olemassa olevia debiasing-menetelmiä, CDA:ta ja REG:ää, mutta koska BIBREF5 raportoi, että tulokset vaihtelevat huomattavasti REG:n eri regularisointikertoimilla, suoritamme hyperparametrin virityksen ja ilmoitamme parhaat tulokset taulukossa TABREF12 .",
      "id": "task461-b4cacb27bdc04ad6923880ad16058bfd",
      "output": [
        "mitä nykyisiä strategioita verrataan?"
      ]
    },
    {
      "input": "Health Level Seven Fast Healthcare Interoperability Resources (HL7 FHIR)FHIR BIBREF5 on uusi avoin standardi terveydenhuollon tiedoille, jonka on kehittänyt sama yritys, joka kehitti HL7v2:n. Resource Description Framework (RDF)RDF on semanttisen webin selkärankaBIBREF8.",
      "id": "task461-117e93a3d5474cc1a3d1e599e0b3f372",
      "output": [
        "Mitä FHIR ja RDF tarkoittavat?"
      ]
    },
    {
      "input": "Jotta suurta datakokonaisuutta $\\mathcal {A}$ ja $\\mathcal {M}$ voidaan hyödyntää riittävästi, malli on esiharjoitteluvaiheessa esikoulutettu CTC-pohjaisella ASR-tehtävällä ja MT-tehtävällä.",
      "id": "task461-e27051c5f964496597661cacc7ef5785",
      "output": [
        "Mihin huomiomoduuli on esivalmennettu?"
      ]
    },
    {
      "input": "Vaikka suunnitelman luomisvaihe on taatusti uskollinen syötteelle, käännösprosessi suunnitelmista tekstiksi perustuu neuraaliseen seq2seq-malliin, ja se voi kärsiä tällaisten mallien tunnetuista ongelmista: se voi harhailla tosiasioita, joita ei ole syötteessä, toistaa tosiasioita tai jättää pois tosiasioita. Vaikka suunnitelmien ja tekstin selkeä yhdistäminen auttaa vähentämään näitä ongelmia huomattavasti, BIBREF0-järjestelmässä on edelleen 2 % tällaisia virheitä. Viimeaikaiset työt neuraalisen tekstin tuottamisen ja tiivistämisen alalla pyrkivät puuttumaan näihin ongelmiin pyrkimällä kartoittamaan tekstin tuotokset takaisin strukturoituihin predikaatteihin ja vertaamalla näitä predikaatteja syöttötietoihin.",
      "id": "task461-1819a140d09346b4b830cc968257eaf0",
      "output": [
        "Mikä on suunnitelman tehokkuus?"
      ]
    },
    {
      "input": " Huomaa, että noudatamme mallintamisessa säästäväistä suunnitteluperiaatetta: sekä Centroid että Naïve Bayes ovat parametrittomia malleja, $k$NN riippuu vain $k$:n valinnasta, ja KDE käyttää yhtä kaistanleveysparametria $h$. Centroid-malli tiivistää jokaisen siemensanojen joukon sen odotetun vektorin mukaan upotusavaruudessa ja luokittelee käsitteet luokkaan, jonka odotettu upotus on lähimpänä euklidista etäisyyttä softmax-säännön mukaisesti; Naïve Bayes -malli ottaa huomioon sekä keskiarvon että varianssin olettaen, että upotusulottuvuudet ovat riippumattomia, sovittamalla normaalijakauma, jolla on keskivektori ja diagonaalinen kovarianssimatriisi, kunkin luokan siemensanojen joukkoon;",
      "id": "task461-9bc7edf4bf594274bd67d8302fafd8e4",
      "output": [
        "Miten parametriton malli toimii?"
      ]
    },
    {
      "input": "Lataamme 210 käyttäjän kaikki Twitter-viestit, jotka ovat sotaveteraaneja ja kliinisesti diagnosoituja PTSD-oireyhtymästä kärsiviä henkilöitä, ja saimme yhteensä 12 385 twiittiä. ",
      "id": "task461-459c4254d1814440918e7dd6ace279cd",
      "output": [
        "Kuinka monta Twitterin käyttäjää tutkitaan kliinisesti validoidulla kyselyllä?"
      ]
    },
    {
      "input": "Perusmalli anglikaanien automaattista uuttamista varten luotiin käyttämällä äsken esittelemäämme annotoitua korpusta harjoitusmateriaalina. Kuten luvussa 3 mainittiin, anglikaanien havaitsemistehtävää voidaan lähestyä sekvenssien merkintäongelmana, jossa vain tietyt tekstikatkelmat merkitään anglikaanisiksi (samaan tapaan kuin NER-tehtävässä). Malliksi valittiin ehdollinen satunnaiskenttämalli (CRF), joka oli myös suosituin malli molemmissa Shared Tasks on Language Identification for Code-Switched Data -tehtävissä BIBREF23 ja BIBREF24.",
      "id": "task461-f7671e02cae14cb1b036eeab7d4de145",
      "output": [
        "Perustellaanko asiakirjassa CRF:n käyttöä perusmallina?"
      ]
    },
    {
      "input": "Lähtötilanteen tulokset ::: Aiemmassa työssämme BIBREF7, jossa rakensimme puhejärjestelmiä 700 kielestä löydettyyn aineistoon, käsittelimme yhdenmukaistamisongelmia (kun ääntä ei ole segmentoitu vuoron/lauseen kokoisiin kappaleisiin) ja oikeellisuusongelmia (kun ääni ei vastaa transkriptiota). Käytimme tässä samoja tekniikoita kuin edellä on kuvattu.Parhaanlaatuista puhesynteesiä varten tarvitsemme muutaman tunnin foneettisesti tasapainotetun, yhden puhujan luetun puheen. Ensimmäisenä askeleenamme käytimme dialogien kunkin vuoron alku- ja loppupisteitä ja valitsimme useimmin esiintyvän puhujan, nmlch, alku- ja loppupisteet. Näin saimme noin 18250 segmenttiä. Lisäksi poistimme automaattisesti liiallisen hiljaisuuden näiden vuorojen alusta, keskeltä ja lopusta (F0:n esiintymisen perusteella). Näin saimme 13 tuntia ja 48 minuuttia puhetta.Tasasimme tämän datan foneettisesti ja rakensimme puheklusteringen tilastollisen puhesyntetisaattorin BIBREF9 kaikesta tästä datasta. Puheentunnistukseen (ASR) käytimme Kaldi BIBREF11 -ohjelmistoa. Rakensimme neuraalisia päästä päähän -koneellisia käännösjärjestelmiä Mapudungunin ja espanjan välille molempiin suuntiin käyttäen uusinta Transformer-arkkitehtuuria BIBREF14 ja BIBREF15-työkalupakettia.",
      "id": "task461-edfd60a38ce54276a4ffb019845fd5a8",
      "output": [
        "Mitä malleja käytetään kolmen NLP-tehtävän perustasolla?"
      ]
    },
    {
      "input": "Akustinen sanan upotus on funktio, joka ottaa syötteenä sanaa vastaavan puhesegmentin, INLINEFORM0 , jossa jokainen INLINEFORM1 on kehystason akustisten piirteiden vektori, ja antaa tuloksena segmenttiä kuvaavan kiinteäulotteisen vektorin, INLINEFORM2 .",
      "id": "task461-d3b8719a7d214c2798b4ab52efa38515",
      "output": [
        "Miten he esittävät mallinsa syöttöominaisuudet upotusten kouluttamiseksi?"
      ]
    },
    {
      "input": "W2V:n kouluttamiseen tarvittava tietokokonaisuus saatiin käyttämällä tietoja, jotka oli poimittu italialaisen Wikipedian dumppausdatasta (päivätty 2019.04.01), italialaisen Google Newsin pääluokista (MAAILMA, KANSAT, LIIKETOIMINTA, TEKNOLOGIA, VIIHDE, URHEILU, TIETO, TERVEYS) ja joistakin anonymisoiduista keskusteluista, jotka käytiin käyttäjien ja asiakaspalvelukeskustelurobotin (Laila) välillä.",
      "id": "task461-ab9caf5eb013455aab52688840e34a85",
      "output": [
        "Mitä tietokokonaisuutta käytetään Word2Vecin harjoitteluun italiankielellä?"
      ]
    },
    {
      "input": "Kooderi on konvoluutiohermoverkko (Convolutional Neural Network, CNN) ja dekooderi on LSTM-verkko (Long Short-Term Memory, LSTM), kuten kuvassa 2 on esitetty. Kuva kulkee koodaajan läpi ja tuottaa kuvan esityksen, jota dekooderi käyttää kuvan sisällön tuntemiseen ja kuvauksen tuottamiseen sana sanalta.",
      "id": "task461-f9507e19669345dc9c98901ceb80a673",
      "output": [
        "Mitä mallia käytetään kuvien koodaamiseen?"
      ]
    },
    {
      "input": "Sovellamme adaptiivisesti harvoja Transformers-ohjelmia neljään konekäännöstehtävään.  IWSLT 2017 saksa $\\rightarrow $ englanti BIBREF27: 200K lauseparia.KFTT japani $\\rightarrow $ englanti BIBREF28: 300K lauseparia.WMT 2016 romania $\\rightarrow $ englanti BIBREF29: 600K lauseparia.WMT 2014 englanti $\\rightarrow $ englanti BIBREF30: 4,5M lauseparia.",
      "id": "task461-bb6fa961d7894c41a53d12ffbfca71a6",
      "output": [
        "Mitä tehtäviä käytetään arvioinnissa?"
      ]
    },
    {
      "input": "EmotionLines BIBREF6 on dialogitietoaineisto, joka koostuu kahdesta osajoukosta, Friends ja EmotionPush, dialogien lähteen mukaan.",
      "id": "task461-ccf000947d6c49f6a2536a46f929b5b0",
      "output": [
        "mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Korjaamattomat merkintöjen ristiriitaisuudet Jotkin muistamisen puutteet johtuvat korjaamattomista merkintöjen ristiriitaisuuksista. Suurelta osin meitä haittaavat erot annotoitavien attribuuttien valinnassa. Kun yksi resurssi merkitsee sukupuolen ja toinen tavun, emme voi päätellä sanan sukupuolta pelkästään sen pintamuodosta. Itse resursseja pitäisi päivittää, jotta ne koodaisivat asiaankuuluvan morfosyntaktisen tiedon. Joissakin kielissä päällekkäisiä muotoja oli hyvin vähän, eikä niiden välillä ollut yhtään tunnistetapausta tai lähes yhtäläisyyttä: Arabia, hindi, liettuan kieli, persia ja venäjä. Täydellinen luettelo havaituista, korjaamattomista ristiriidoista esitetään koodipohjan ohella. Pystyimme löytämään tiettyjä tapauksia, joissa UniMorph-merkintöjä oli sovellettu väärin, sekä erityisiä tapauksia, joissa molemmissa resursseissa oli kieltenvälisiä epäjohdonmukaisuuksia. ",
      "id": "task461-1d18a4b100dc4e978024f72851f8974c",
      "output": [
        "Mitkä ovat kartoituksessa esiintyvien muistivirheiden pääasialliset lähteet?"
      ]
    },
    {
      "input": "Kysymyksiä: BIBREF-korpuksen31 7 787 luonnontieteiden tenttikysymystä Aristo Reasoning Challenge (ARC) -korpuksesta, joka sisältää standardoituja 3.-9. luokan luonnontieteiden tenttikysymyksiä 12 yhdysvaltalaisesta osavaltiosta viime vuosikymmeneltä. ",
      "id": "task461-d8f60ce0b9014355be7d75432ce59387",
      "output": [
        "Miten aineisto kerättiin?"
      ]
    },
    {
      "input": "Jotta moraaliset tunteet voidaan perustaa tekstiin, käytämme Moral Foundations Dictionary BIBREF27 - sanakirjaa. MFD on psykolingvistinen resurssi, joka liittää kuhunkin MFT-kategoriaan joukon alkusanoja, jotka ovat sanoja, jotka tarjoavat todisteita vastaavasta moraalikategoriasta tekstissä. Toteuttaaksemme kehyksemme ensimmäisen tason ja havaitakseen moraalisen relevanssin, täydennämme moraalisesti relevantteja siemensanoja vastaavalla joukolla siemensanoja, jotka lähentelevät moraalista epärelevanssia, joka perustuu valenssin käsitteeseen eli ärsykkeen miellyttävyyden tai epämiellyttävyyden asteeseen. Viittaamme BIBREF-tietokannan28 keräämiin noin 14 000 englanninkielisen sanan emotionaaliseen valenssiluokitukseen ja valitsemme moraalisesti merkityksettömien siemensanojen joukkoon sanat, joilla on neutraalimmat valenssiluokitukset ja jotka eivät esiinny MFD:ssä, jotta moraalisesti merkityksellisten ja moraalisesti merkityksettömien sanojen kokonaismäärä olisi yhtä suuri. Jaamme historiallisen ajan vuosikymmenen mittaisiin jaksoihin ja käytämme kahta BIBREF30:n tarjoamaa upotussarjaa, jotka on koulutettu eri englannin kielen historiallisella korpuksella: Google N-grams BIBREF31: korpus $8.5 \\times 10^{11}$ merkkejä, jotka on kerätty englanninkielisestä kirjallisuudesta (Google Books, kaikki genret) ajanjaksolta 1800-1999.COHA BIBREF32: pienempi korpus, jossa on 4,1 \\times 10^8$ merkkejä teoksista, jotka on valittu siten, että ne ovat genreiltään tasapainoisia ja edustavat amerikanenglantia vuosina 1810-2009.",
      "id": "task461-2ae2b37092b2410bbdc61aa0f843e21b",
      "output": [
        "Mitä tietokokonaisuuksia käytetään asiakirjassa?"
      ]
    },
    {
      "input": "Rakensimme siemenleksikon, joka koostuu 15 positiivisesta sanasta ja 15 negatiivisesta sanasta, kuten kohdassa SECREF27 esitetään. ",
      "id": "task461-689b419c9a394b0fb8ee6bf6ec8c638f",
      "output": [
        "Kuinka suuri on koulutuksessa käytettävä siemenleksikko?"
      ]
    },
    {
      "input": "Käytimme neljää luokittelualgoritmia: 1) Logistinen regressio, jota käytetään perinteisesti tunnetilaluokittelussa. Kolme muuta algoritmia, jotka ovat suhteellisen uusia ja jotka ovat osoittaneet hyviä tuloksia tunteiden luokittelun tyyppisissä ongelmissa, ovat seuraavat: 2) Naïve Bayes ja SVM (NBSVM), 3) Extreme Gradient Boosting (XGBoost) ja 4) FastText-algoritmi ja kaksisuuntainen LSTM (FastText-BiLSTM).",
      "id": "task461-cdb763a93a954b5f82b3ed27276dcb52",
      "output": [
        "Mitä uusimpia malleja kokeissa käytetään?"
      ]
    },
    {
      "input": "Parantaaksemme mallimme suorituskykyä entisestään otamme käyttöön sisäisesti merkittyjä tietoja, joita käytämme BERT:n hienosäätöön. Sukupuolen luokittelutehtävää varten merkitsemme manuaalisesti 1 100 käyttäjää käsittävän sisäisen tietokokonaisuuden, johon kuuluu 550 naiskäyttäjää ja 550 mieskäyttäjää. Saamme 162 829 twiittiä indeksoimalla 1 100 käyttäjän aikajanat. Murteiden tunnistustehtävää varten otamme satunnaisesti 20 000 twiittiä kutakin luokkaa varten sisäisestä tietokokonaisuudesta, joka on merkitty kultaisesti samoilla 15 luokalla kuin jaettu tehtävä.",
      "id": "task461-a1f71c5b29f041debcbe945687fe042d",
      "output": [
        "Mitä sisäisiä tietoja käytetään?"
      ]
    },
    {
      "input": "Lisäksi voidaksemme hyödyntää useita vastaustyylejä samassa järjestelmässä, mallimme ottaa käyttöön vastauksen alkuun keinotekoisen merkin, joka vastaa kohdetyyliä ( $y_1$ ), kuten BIBREF14 . Testaushetkellä käyttäjä voi määritellä ensimmäisen merkin, joka ohjaa vastaustyylejä.",
      "id": "task461-058ef31a01dd4d42a35cce573d631eed",
      "output": [
        "Ottaako heidän mallinsa syötteenä myös odotetun vastaustyylin?"
      ]
    },
    {
      "input": "Ensinnäkin tarkastelemme WeedsPrec BIBREF8, joka kuvaa INLINEFORM0:n piirteitä, jotka sisältyvät laajemman termin piirteiden INLINEFORM1 : DISPLAYFORM0joukkoon. Toiseksi tarkastelemme invCL BIBREF11, joka ottaa käyttöön distributiivisen poissulkemisen käsitteen mittaamalla myös sitä, missä määrin laajempi termi sisältää konteksteja, joita suppeampi termi ei käytä. Vaikka useimmat valvomattomat distributiiviset lähestymistavat perustuvat DIH:hen, tarkastelemme myös distributiivista SLQS-mallia, joka perustuu vaihtoehtoiseen informatiivisuushypoteesiin BIBREF10 , BIBREF4 . Täydellisyyden vuoksi otamme myös kosinin samankaltaisuuden perustasona mukaan arviointiimme.",
      "id": "task461-12e1b799060d49af92b0890af298a764",
      "output": [
        "Mitä jakomenetelmiä he harkitsivat?"
      ]
    },
    {
      "input": "Ensimmäinen tehtävämme on hiljattain käyttöön otettu visuaalisen kysymysten vastaamisen haaste (VQA) BIBREF22 . Seuraavat kokeet keskittyvät GeoQA:han, joka on maantieteellinen kysymysvastaustehtävä, jonka Krish2013Grounded esitteli ensimmäisen kerran.",
      "id": "task461-8007e89e40c34887aaad802e1a0e5505",
      "output": [
        "Mitä vertailutietoaineistoja he käyttävät?"
      ]
    },
    {
      "input": "Vertailemme seuraaviin perustasoihin:(1) Naive: 2) mSDA BIBREF7 : Tämä on uusin menetelmä, joka perustuu diskreetteihin syöttöominaisuuksiin. 1000 parasta sanasäkkiominaisuutta pidetään pivot-ominaisuuksina. Asetamme pinottujen kerrosten lukumääräksi 3 ja korruptoitumistodennäköisyydeksi 0,5. (3) NaiveNN: Tämä on lähdealueelle koulutettu ei-domain-adaptiivinen CNN, joka on muunnelma mallistamme asettamalla INLINEFORM0 , INLINEFORM1 ja INLINEFORM2 nollaksi. 4) AuxNN BIBREF4 : Tämä on aputehtäviä hyödyntävä neuraalimalli, jolla on saavutettu huipputason tuloksia toimialueiden välisessä tunteiden luokittelussa. Tässä mallissa käytetty lauseenkooderi on sama kuin meidän.(5) ADAN BIBREF16 : Tässä menetelmässä hyödynnetään adversarial training -harjoittelua toimialueiden välisten representaatioerojen vähentämiseksi. Alkuperäisessä artikkelissa käytetään kooderina yksinkertaista feedforward-verkkoa. Oikeudenmukaisen vertailun vuoksi korvaamme sen CNN-pohjaisella koodaajallamme. Koulutamme 5 iteraatiota diskriminaattorille kutakin kooderin ja tunneluokittelijan iteraatiota kohden, kuten heidän artikkelissaan ehdotetaan. 6) MMD: MMD:tä on käytetty laajalti kuvien toimialue-erojen minimoimiseen. Näissä töissä BIBREF9 , BIBREF13 , syvien CNN:ien muunnelmia käytetään kuvien koodaamiseen ja useiden kerrosten MMD:t minimoidaan yhdessä. NLP:ssä useampien CNN-kerrosten lisääminen ei välttämättä ole kovin hyödyllistä, joten näitä kuviin liittyvistä tehtävistä peräisin olevia malleja ei voida suoraan soveltaa ongelmaamme. Vertaillaksemme MMD-pohjaiseen menetelmään koulutamme mallin, joka yhdessä minimoi luokitteluhäviön INLINEFORM0 lähdealueella ja MMD:n INLINEFORM1:n ja INLINEFORM2:n välillä. MMD:n laskemiseen käytämme Gaussin RBF:ää, joka on yleinen valinta ominaistaitojen ytimeksi.",
      "id": "task461-4eb248cfc6944c1a9f8fd501cd08c98e",
      "output": [
        "Mitkä ovat perusmenetelmät?"
      ]
    },
    {
      "input": "Macaw tukee myös Wizard of Oz -tutkimuksia tai välittäjiin perustuvia tiedonhakututkimuksia. Macaw'n arkkitehtuuri tällaista asetelmaa varten on esitetty kuvassa FIGREF16. Kuten kuvassa näkyy, etsijä on vuorovaikutuksessa todellisen keskustelukäyttöliittymän kanssa, joka tukee multimodaalista ja sekamuotoista vuorovaikutusta useilla laitteilla. Välittäjä (tai ohjattava) vastaanottaa etsijän viestin ja suorittaa Macaw'n avulla erilaisia tiedonhakutoimia. Kaikki hakijan ja välittäjän sekä välittäjäjärjestelmän vuorovaikutukset kirjataan ylös lisäanalyysiä varten.",
      "id": "task461-7ce61215c31946f0aa08a4254ee773d2",
      "output": [
        "Mikä on Wizard of Oz -asetelma?"
      ]
    },
    {
      "input": "Arviointimittarit. Strategian muotoilukyvyn arvioimiseksi otamme käyttöön mittarin nimeltä Coverage( INLINEFORM0 ), joka määritellään osuutena kaikista kyselydatatapauksista, joille LiLi on onnistuneesti muotoillut strategioita, jotka johtavat voittoon. Jos LiLi voittaa kaikissa tietyn tietokokonaisuuden jaksoissa, INLINEFORM1 on 1,0. Arvioidaksemme ennustuskykyä käytämme Avg. MCC:tä ja keskimääräistä +ve F1-pistemäärää.",
      "id": "task461-0b3ba18417fa4be28469cc59c1f8ad9b",
      "output": [
        "Mitä mittareita käytetään sen toteamiseksi, että tämä tekee chat-roboteista asiantuntevampia ja parempia oppimaan ja keskustelemaan? "
      ]
    },
    {
      "input": "BIBREF-ohjelmassa14 arvioidaan useita sanojen upottamismalleja, jotka on koulutettu suurella portugalinkielisellä korpuksella.  Ehdotuksessa käytetään julkisessa BIBREF-tietokannassa14 saatavilla olevaa word2vec-mallia, ja siinä analysoidaan samankaltaisimmat analogiat, jotka on luotu ennen ja jälkeen BIBREF3 :n soveltamisen. ",
      "id": "task461-98ced8ea36d34f9eabd712b97e408daa",
      "output": [
        "Mihin sanojen upotukset koulutettiin?"
      ]
    },
    {
      "input": "Menetelmässämme otamme kuvan syötteenä ja luomme luonnollisen kysymyksen tulosteena.",
      "id": "task461-9329337580c54a979e69507d30538ff4",
      "output": [
        "Mikä on differentiaaliverkon tulo?"
      ]
    },
    {
      "input": "Pidämme arabian eri variantteja eri aloina, ja siksi otamme käyttöön yksinkertaisen mutta tehokkaan \"alaan kuuluvan\" harjoittelutoimenpiteen, jossa esiharjoittelemme BERT:n tietosarjalla, joka on lähempänä tehtäväaluetta (koska se sisältää murteellista twiittidataa).",
      "id": "task461-14ff4af27e8f4768ac465f0485b9004e",
      "output": [
        "Mitä toimialueen sisäisiä tietoja käytetään esivalmennuksen jatkamiseen?"
      ]
    },
    {
      "input": "Tässä jaksossa keskustelemme keskustelujärjestelmien nykytilasta kolmesta näkökulmasta: vuorovaikutustyypit, arkkitehtuurityypit ja konteksti päättelyn tyypit. ELIZA BIBREF11 oli yksi ensimmäisistä luonnollisen kielen käsittelyä varten luoduista ohjelmistoista.  Heti ELIZAn jälkeen tuli PARRY, jonka kehitti Kenneth Colby, joka on psykiatri Stanfordin yliopistossa 1970-luvun alussa. A.L.I.C.E. (Artificial Linguistic Internet Computer Entity) BIBREF12 ilmestyi vuonna 1995, mutta nykyisessä versiossa käytetään AIML:ää, XML-kieltä, joka on suunniteltu ärsyke-vastaus-keskustelurobottien luomiseen BIBREF13 . Cleverbot (1997-2014) on brittiläisen tekoälytutkijan Rollo Carpenterin kehittämä chatrobotti. ",
      "id": "task461-70d2a1aa6458457db806f9dabe464a76",
      "output": [
        "Mikä on asiakirjassa kuvatun tekniikan taso?"
      ]
    },
    {
      "input": "Saimme hytissä olevasta aineistostamme 1260 yksilöllistä lausetta, joissa oli AMIE-komentoja. Laajensimme tätä aineistoa Amazon Mechanical Turkin kautta ja saimme 3347 lausumaa, joissa oli aikomuksia. Tarkoitusten ja lähtöaikojen merkinnät saadaan transkriptoiduista lausahduksista kolmen merkitsijän enemmistöäänestyksellä.",
      "id": "task461-b81bf6d850de492a8dc7578ad4243302",
      "output": [
        "Mikä on niiden keräämän aineiston koko?"
      ]
    },
    {
      "input": "Olemme myös sisällyttäneet järjestelmän harjoitteluun NIST:n tarjoaman 2472 puhelun merkitsemättömän joukon sekä pienistä (cebuano ja mandariini) että suurista (tagalog ja kantoninkiina) kielistä.",
      "id": "task461-8a9cd324fb4341189728905fb99fd2d7",
      "output": [
        "Mitkä ovat ne uudet kielet, joita SRE painottaa?"
      ]
    },
    {
      "input": "Tutkimuksemme vahvisti BT:n tehokkuuden, mutta ehdotti myös huomattavasti halvempia tapoja parantaa perustason suorituskykyä käyttämällä kohteen hieman muunneltua kopiota sen täyden BT:n sijasta. ",
      "id": "task461-8fecd73e563a45b3ad4963b71d8234e2",
      "output": [
        "miksi heidän tekniikkansa ovat halvempia toteuttaa?"
      ]
    },
    {
      "input": "Arvioinnin tulokset esitetään taulukossa TABREF42, jossa ne on esitetty [0,1] välille normalisoituina promedioina ja niiden estimaattisena poistona $\\sigma $.",
      "id": "task461-4dec88a11ca44d1f83b75c45f60aeb39",
      "output": [
        "Mitä arviointimittareita he tarkastelivat?"
      ]
    },
    {
      "input": " TransE-malli Upotusmallit Rakenteeton malli BIBREF22 TransH-malli BIBREF26 DISTMULT BIBREF45 ConvE BIBREF51 ja ConvKB BIBREF52 Polkujen järjestysalgoritmi (PRA) BIBREF21",
      "id": "task461-b649a104b8c54a538d8a24bbfc70e0f3",
      "output": [
        "Mitä malleja tämä yleiskatsaus kattaa?"
      ]
    },
    {
      "input": "Piirsimme häirintätapausten jakautumisen kunkin luokitteluulottuvuuden mukaan (kuvio KUVIO 19). Kuvassa esitetään tilastoja, jotka tarjoavat tärkeää näyttöä häirinnän laajuudesta ja jotka voivat toimia perustana tehokkaammille toimenpiteille, joita viranomaiset aina edunvalvontajärjestöistä poliittisiin päättäjiin asti voivat kehittää. Se tarjoaa näyttöä joidenkin yleisesti oletettujen häirintää koskevien tekijöiden tueksi: Ensinnäkin osoitamme, että häirintää esiintyy useammin yöaikaan kuin päiväsaikaan. Toiseksi se osoittaa, että tuntemattomien tuntemattomien henkilöiden (joita ei ole esitetty kuvassa) lisäksi konduktöörit ja kuljettajat ovat ahdistelijoiden listan kärjessä, ja seuraavina tulevat ystävät ja sukulaiset. Lisäksi havaittiin, että häiritsijöiden iän ja häirintäpaikan, yhden tai useamman häiritsijän ja paikan sekä iän ja yhden tai useamman häiritsijän välillä on vahva korrelaatio (kuvio FIGREF20).  Havaitsimme myös, että suurin osa nuorista tekijöistä harjoitti häirintää kaduilla. Nämä havainnot viittaavat siihen, että nuoriin miehiin ja poikiin, joihin ikätoverit helposti vaikuttavat, kohdistuvat toimet saattavat olla tehokkaimpia, kun koulutus toteutetaan vertaisilta toisille. Ne osoittavat myös, missä tällaisia toimia voitaisiin toteuttaa, kuten kouluissa ja kaduilla.  Sitä vastoin havaitsimme, että aikuiset seksuaalisen häirinnän tekijät toimivat todennäköisemmin yksin. Suurin osa aikuisista häiritsijöistä harjoitti häirintää julkisissa liikennevälineissä. Nämä erot aikuisten häirintätoimissa ja -paikoissa tarkoittavat, että toimenpiteissä olisi otettava huomioon nämä tekijät. Esimerkiksi lisäämällä turvatoimia liikennevälineissä keskeisinä aikoina ja paikoissa. Lisäksi havaitsimme, että häirinnän muotojen ja iän, yhden tai useamman häiritsijän, häiritsijätyypin ja sijainnin välillä oli korrelaatioita (kuvio KUVIO 21). Esimerkiksi nuoret häiritsijät syyllistyvät aikuisiin verrattuna todennäköisemmin sanalliseen häirintään kuin fyysiseen häirintään. Koskettelua tai näpistelyä harjoitti useammin yksittäinen häiritsijä kuin häiritsijöiden ryhmät. Sen sijaan kommentointia tapahtui useammin, kun häiritsijät olivat ryhmissä. Lopuksi todettakoon, että julkisissa liikennevälineissä ihmiset joutuivat useimmin siveettömien kosketusten kohteeksi sekä kanssamatkustajien että konduktöörien ja kuljettajien toimesta. Häirinnän luonne ja tapahtumapaikka ovat erityisen merkittäviä, kun kehitetään strategioita, joiden avulla häirinnän kohteeksi joutuneet tai häirinnän todistajat voivat reagoida ja hallita häirinnän jokapäiväistä uhkaa. Jotkin strategiat toimivat parhaiten esimerkiksi julkisissa liikennevälineissä, jotka ovat suljettuja ja jaettuja tiloja, kun taas toiset strategiat saattavat olla tehokkaampia avoimessa katutilassa.",
      "id": "task461-3fef45c5bc5844bb9ed2cd5833d9cdb2",
      "output": [
        "Mitä malleja tarinoista löytyi?"
      ]
    },
    {
      "input": "Pyrimme siis poistamaan kielikohtaisen informaation representaatioista keskittämällä kunkin kielen lauseiden representaatiot siten, että niiden keskiarvo on vektoriavaruuden alkupisteessä.",
      "id": "task461-a2bef82d10a84b5e9783a2ceadad3707",
      "output": [
        "Ovatko kielikohtaiset ja kielineutraalit osat epäjohdonmukaisia?"
      ]
    },
    {
      "input": "Tässä työssä kehitämme tekniikan, jolla olemassa oleva esivalmennettu malli voidaan nopeasti siirtää englannista muille kielille energiatehokkaasti BIBREF8. ",
      "id": "task461-daa1187719c54e57a062d9de06c2717e",
      "output": [
        "Kuinka paljon muuta kuin englanninkielistä harjoitusdataa järjestelmä käyttää?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa keskitytään Switchboard-300:een, joka on 300 tunnin mittainen englanninkielinen puheentunnistustehtävä.",
      "id": "task461-046ff87be6774bc18079c7607acfd39a",
      "output": [
        "Kuinka suuri Switchboard-300-tietokanta on?"
      ]
    },
    {
      "input": "Koska menetelmämme ei käytä loukkaavien sanojen siemenluetteloa, se ei ole aiheen, kohteen tai murteen mukaan puolueellinen. Menetelmämme avulla merkitsimme 10 000 arabiankielisen twiitin aineiston loukkaavuuden perusteella, ja loukkaavien twiittien osuus oli noin 19 prosenttia twiiteistä. Lisäksi merkitsimme twiitit mauttomiksi tai vihapuheiksi. Tämä on toistaiseksi suurin saatavilla oleva tietokokonaisuus, jonka aiomme asettaa julkisesti saataville yhdessä annotaatio-ohjeiden kanssa. Käytämme tätä tietokokonaisuutta arabialaisen loukkaavan kielen luonnehtimiseen selvittääksemme, mitkä aiheet, murteet ja käyttäjien sukupuoli ovat eniten yhteydessä loukkaavan kielen käyttöön. ",
      "id": "task461-1ca7224246214b16b5fe912c01150985",
      "output": [
        "Millä tavoin hyökkäävä aineisto ei ole aiheen, murteen tai kohteen mukaan puolueellinen?"
      ]
    },
    {
      "input": "Meillä on kaksi pääkäyttöliittymää, jotka mahdollistavat ihmisen ja tietokoneen välisen vuorovaikutuksen. Ristikkäismallien välinen vuorovaikutus, jossa kone tekee kaiken sävellystyön ja näyttää kolme erilaista versiota tarinasta, jotka on kirjoitettu kolmella eri mallilla, jotta ihminen voi vertailla niitä keskenään. Käyttäjä ohjaa luomista antamalla aiheen tarinan kirjoittamiselle ja säätämällä dekoodausparametreja uutuuden eli monimuotoisuuden hallitsemiseksi. Toinen käyttöliittymä on mallin sisäinen vuorovaikutus, jossa ihminen voi valita mallin, jonka kanssa hän haluaa olla vuorovaikutuksessa (mahdollisesti valittuaan sen ristikkäismallin kautta), ja tehdä yhteistyötä kaikissa vaiheissa parempien tarinoiden luomiseksi yhdessä.",
      "id": "task461-536ec17284cd43e9829815ebf1a1371c",
      "output": [
        "Miten ihmisen vuorovaikutus kuluu mallissa?"
      ]
    },
    {
      "input": "Korpuksemme käsittää yhteensä 6 127 tieteellistä kokonaisuutta, joista 2 112 on prosessi-, 258 menetelmä-, 2 099 materiaali- ja 1 658 datayksikköä. ",
      "id": "task461-d0b5f781ec8f4f6ea294507f04e73890",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "DQA:ssa neljä osallistujaa vastasi kuhunkin kysymykseen, joten otimme kysymyskohtaiseksi tulokseksi INLINEFORM0-, INLINEFORM1- ja INLINEFORM2-arvojen keskiarvon neljältä arvioijalta. Osallistujien yksityiskohtaiset vastaukset ovat saatavilla verkossa. Arvioidaksemme sekä DQA-kokeiden osallistujien että QALD-järjestelmän antamien vastausten oikeellisuutta käytämme klassisia tiedonhaun mittareita tarkkuus (P), palautus (R) ja F1. INLINEFORM0 mittaa annettujen relevanttien (oikeiden) vastausten (kohteiden) osuutta kaikista annetuista vastauksista (vastauskohteista).",
      "id": "task461-4de0c5854e724eaba319a2da10cb9161",
      "output": [
        "Testaavatko ne lähestymistapojensa toimivuutta ihmisten tekemien arvioiden avulla?"
      ]
    },
    {
      "input": "Title-to-Story-järjestelmä on perustaso, joka syntyy suoraan aiheesta.",
      "id": "task461-dbd9c1ac5e044622a5069f677e699c9b",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Kuten E. Tongin ym. työssä ( BIBREF9 ), me esivalmennamme sanojen upotukset käyttämällä skip-gram-mallia BIBREF4, jota sovelletaan escort-mainoksista saatuihin merkitsemättömiin tietoihin, mutta menemme kuitenkin pidemmälle analysoimalla emojien upotuksia ja laajennamme näin ihmiskaupan sanastoa.",
      "id": "task461-d47b2639e8dd43ec99c432660eed3ef4",
      "output": [
        "Käytetäänkö niissä esivalmisteltuja sanasulkeumia?"
      ]
    },
    {
      "input": "Käytämme tietokokonaisuuksissa Karpathyn ja Fei-Fein jakoa MS-COCO-tietokokonaisuudelle BIBREF10 .",
      "id": "task461-780c7cc33f05419faf7baf542b90a9d5",
      "output": [
        "Minkä tietokokonaisuuden/korpuksen perusteella tätä työtä arvioidaan?"
      ]
    },
    {
      "input": "Monitehtäväiset BERT-mallimme sisältävät kuusi erilaista arabian kielen luokittelutehtävää. Tekijän profilointi ja petoksen havaitseminen arabiaksi (APDA). LAMA+DINA Tunteiden havaitseminen. Arabian kielisten twiittien tunneanalyysi.",
      "id": "task461-1fc5545596e44a4bbf6b860fd8892970",
      "output": [
        "Mitä tehtäviä käytetään monitehtäväisessä oppimisasetelmassa?"
      ]
    },
    {
      "input": "Tavoitteenamme oli luoda kysymyksiä ilman malleja ja mahdollisimman vähällä ihmisen osallistumisella käyttämällä koneoppimismuuntajia, joiden on osoitettu kouluttautuvan nopeammin ja paremmin kuin RNN:t. Tällaisesta järjestelmästä olisi hyötyä opettajille, sillä se säästäisi aikaa tietokilpailujen ja testien tuottamiseen.",
      "id": "task461-1f9f24133772422599d0f3e2366b77b4",
      "output": [
        "Mikä on työn motivaatio? Miksi kysymysten laatiminen on tärkeä tehtävä?"
      ]
    },
    {
      "input": "Sememit ovat sanojen merkitysten semanttisia minimiyksiköitä, ja kunkin sanan merkityksen merkitys koostuu tyypillisesti useista sememeistä, kuten kuvassa 1 on esitetty.",
      "id": "task461-64731f9065aa415c91d0c48e195f1cdd",
      "output": [
        "Mikä on sememi?"
      ]
    },
    {
      "input": "Tässä artikkelissa ehdotamme yksinkertaista ja tehokasta menetelmää affektiivisten tapahtumien oppimiseen, joka vaatii vain hyvin pienen siemenleksikon ja suuren raakakorpuksen. Kuten kuvassa KUVIO 1 havainnollistetaan, keskeinen ajatuksemme on, että voimme hyödyntää diskurssisuhteita BIBREF4 levittääksemme polariteettia tehokkaasti siemenpredikaateista, jotka ilmoittavat suoraan henkilön tunteista (esim. \"olla iloinen\" on positiivinen).",
      "id": "task461-1225c1e8346f4f1aae082c2c67c13aaa",
      "output": [
        "Miten heidän mallinsa oppii käyttämällä lähinnä raakadataa?"
      ]
    },
    {
      "input": "Saatujen tietojen perusteella olemme parantaneet huomattavasti XNLI:n huipputasoa Translate-Test- ja Zero-Shot-menetelmien osalta.",
      "id": "task461-2a548d30dc344d6d939789d9e02cfa54",
      "output": [
        "Onko parannus uusimpaan tekniikkaan verrattuna tilastollisesti merkittävä?"
      ]
    },
    {
      "input": "Lähtötilanteessa arvioimme syötemerkit yksinkertaisesti IOC:ksi BIBREF12 -julkaisussa kuvattujen oikeinkirjoitusominaisuuksien perusteella.",
      "id": "task461-3271c44943324c9cbae2907fa66a91b2",
      "output": [
        "Mitä käytetään perustasona?"
      ]
    },
    {
      "input": ". Vastaamme useisiin eri haasteisiin: Twitterin asiakaspalvelusta ei ole saatavilla dialogitekojen annotoitua dataa, dialogitekojen annotointi on subjektiivinen tehtävä, olemassa olevat taksonomiat eivät kaappaa hienojakoista tietoa, jonka uskomme olevan arvokasta tehtävämme kannalta, ja vaikka twiitit ovatkin luonteeltaan tiiviitä, ne koostuvat usein päällekkäisistä dialogitekoista, jotka kuvaavat niiden koko tarkoitusta.",
      "id": "task461-db0ec2bc63124cfaa1d560fcaeada1b5",
      "output": [
        "Mitkä dialogitekstit sopivat paremmin Twitter-verkkoon?"
      ]
    },
    {
      "input": "Taulukossa TABREF19 esitetään ehdotetun järjestelmämme vertailu SemEval 2016 Task 6:n nykyiseen huippuluokan järjestelmään sentimenttitietokannan osalta. BIBREF7 käytti ominaisuuksiin perustuvaa SVM:ää, BIBREF39 käytti avainsanasääntöjä, LitisMind luotti ulkoisen datan hashtag-sääntöihin, BIBREF38 hyödynsi sentimenttiluokittelijoiden ja -sääntöjen yhdistelmää, kun taas BIBREF37 käytti maksimieentropialuokittelijaa, jossa oli toimialuekohtaisia ominaisuuksia. Vertaamme järjestelmäämme myös BIBREF15:n ehdottamiin uusimpiin järjestelmiin tunneaineistossa. Vertailu on esitetty taulukossa TABREF22. BIBREF15:n käyttämät viisi yksittäistä järjestelmää olivat Maximum Entropy, SVM, LSTM, Bi-LSTM ja CNN.",
      "id": "task461-9df99e38daca4519a166409d5d22cae2",
      "output": [
        "Mikä on edellinen uusin malli?"
      ]
    },
    {
      "input": "Käytämme Ultrax Typically Developing -tietokokonaisuutta (UXTD) julkisesti saatavilla olevasta UltraSuite-tietokannasta BIBREF19 . Tämä tietokokonaisuus sisältää synkronoituja akustisia ja ultraäänitietoja 58 tyypillisesti kehittyvältä 5-12-vuotiaalta lapselta (31 naista, 27 miestä). Tiedot linjattiin puhelintasolla BIBREF19 , BIBREF25 -julkaisuissa kuvattujen menetelmien mukaisesti. Tiedot tallennettiin Ultrasonix SonixRP -laitteella käyttäen Articulate Assistant Advanced (AAA) -ohjelmistoa INLINEFORM0 121 kuvaa sekunnissa 135 näkökentän alueella. Yksi ultraäänikehys koostuu 412 kaikupalautteesta jokaiselta 63 skannauslinjalta (63x412 raakakehystä).",
      "id": "task461-81ee4480a2f642dfbc67000c3b4f1657",
      "output": [
        "Mitkä ovat tietokokonaisuuden ominaisuudet?"
      ]
    },
    {
      "input": "Tässä artikkelissa kuvaamme ja arvioimme Nefnir BIBREF0 , uuden avoimen lähdekoodin lemmatizer-ohjelman islannin kielelle. Nefnir käyttää suffiksien korvaussääntöjä, jotka on johdettu (opittu) Database of Modern Icelandic Inflection (DMII) BIBREF1 -tietokannasta, joka sisältää yli 5,8 miljoonaa taivutusmuotoa.",
      "id": "task461-92880997ee2c402783fd91acf22aa7b1",
      "output": [
        "Miten korvaussäännöt on rakennettu?"
      ]
    },
    {
      "input": "Jos sana kuuluu johonkin näitä käsitteitä edustavaan sanaryhmään, muutettu kustannustermi suosii kyseisen sanan upotusvektorin ulottuvuuden arvon kasvattamista sen käsitteen mukaan, johon kyseinen sana kuuluu. ",
      "id": "task461-93a7b2bb0c354e98961fa2c24e371265",
      "output": [
        "Millä ulottuvuudella semanttisesti toisiinsa liittyvät sanat saavat suurempia arvoja?"
      ]
    },
    {
      "input": "Tarkemmin tarkasteltuna suorituskyvyn heikkeneminen käännetyn ja alkuperäisen japanin kielen välillä johtui usein käännöksistä, jotka olivat kohtuullisia, mutta eivät olleet johdonmukaisia merkintöjen kanssa. Esimerkiksi käännettäessä ensimmäistä esimerkkiä kuvassa FIGREF2 molemmat konekäännökset kuvaavat \"UTF8min風邪\", joka tarkoittaa kylmää (sairautta), muotoon \"UTF8min寒さ\", joka tarkoittaa kylmää (alhainen lämpötila). Toinen esimerkki on, jossa japaninkielinen pseudotwiitti \"UTF8min花粉症の時期はすごい疲れる。\" annettiin englanninkielisen pseudotwiitin \"Allergy season is so exhausting.\" rinnalla. Tässä japaninkielinen sana heinänuhasta \"UTF8min花粉症。\" on manuaalisesti yhdistetty englanninkieliseen vähemmän täsmälliseen sanaan \"allergies\"; konekäännös yhdistetään takaisin japaninkieliseksi käyttämällä sanaa \"allergies\" i.\"UTF8minアレルギー\" katakana-aakkosilla (katakanaa käytetään ilmaisemaan vieraista kielistä johdettuja sanoja), koska käsitteelle \"allergiat\" ei ole olemassa kanji-merkkiä.",
      "id": "task461-2d6bede300ef4a629a832eb6a0ed21f0",
      "output": [
        "Onko olemassa mitään selitystä sille, miksi jokin kieliparin valinta on parempi kuin toinen?"
      ]
    },
    {
      "input": "Perusarvot. Käytämme yhtä vahvaa ei-DNN-perusversiota, NBSVM:ää (unigrammi- tai bigrammiominaisuuksilla) BIBREF23 ja kuutta DNN-perusversiota. Ensimmäinen DNN-perustapaus on CNN BIBREF25, joka ei käsittele meluisia merkintöjä. Muut viisi baselinea on suunniteltu käsittelemään meluisia merkintöjä.Vertailutulokset esitetään taulukossa TABREF12. Tuloksista voidaan tehdä seuraavat havainnot. (1) NetAb-mallimme saavuttaa parhaat ACC- ja F1-arvot kaikissa tietokokonaisuuksissa paitsi negatiivisen luokan F1-arvossa Laptopissa.",
      "id": "task461-bd150def376e49a2a98e58f0866d17d1",
      "output": [
        "Arvioidaanko mallia CNN-perustason perusteella?"
      ]
    },
    {
      "input": "Malliamme voidaan pitää koodaaja-dekooderi-rakenteen avulla laajennuksena BIBREF18:n ainesosien jäsennysmallista, kuten kuvassa KUVA 4 on esitetty. Erona on se, että meidän mallissamme sekä konstituentti- että riippuvuusjäsennys käyttävät samaa merkkien esitystä ja yhteisiä itsehuomautuskerroksia, ja kummallakin on omat yksilölliset itsehuomautuskerroksensa ja myöhemmät käsittelykerroksensa. Malliimme kuuluu neljä moduulia: merkkien esitys, itsehuomion koodaaja, konstituentti- ja riippuvuusjäsennyksen purkukooderi. Constituent Parsing Decoder Dependency Parsing Decoder (riippuvuusjäsennyksen jäsennyksen dekooderi).",
      "id": "task461-8ba4217d28d640a5bfa9a685622faf3c",
      "output": [
        "Mitä malleja käytetään vaalipiiri- ja riippuvuusanalyysin suorittamiseen?"
      ]
    },
    {
      "input": " Annotoinnissa käytettiin portugalin kielen vapaasti saatavilla olevia työkaluja.",
      "id": "task461-edc15fefb01d425db825eec3971c3428",
      "output": [
        "Ovatko merkinnät automaattisia vai manuaalisesti luotuja?"
      ]
    },
    {
      "input": ". Voidaan havaita, että perusmalliin verrattuna tarkkuus parani 7,36 % ja F1-pistemäärä 9,69 %. ",
      "id": "task461-41301cdd138e4a7d968b1d0488ecbbdb",
      "output": [
        "Kuinka suuria parannuksia saadaan aikaan pienissä epätasapainoisissa tietokokonaisuuksissa, kun lauseiden esitystapaa parannetaan aihekohtaisella tiedolla?"
      ]
    },
    {
      "input": "Esikoulutus. Keräämme kolmen vuoden verkkouutisartikkelit kesäkuusta 2016 kesäkuuhun 2019. Suodatamme pois artikkelit, jotka ovat päällekkäisiä arviointitietojen kanssa media-alan ja aikavälien osalta. Tämän jälkeen suoritamme useita tietojen puhdistusstrategioita.",
      "id": "task461-5e2b5408415f491aadbc5c0251064f54",
      "output": [
        "Millä he esivalmensivat mallin?"
      ]
    },
    {
      "input": "Käytämme neljää järjestelmää arvioidaksemme tämän tietokokonaisuuden vaikeusastetta.  Kaksi ensimmäistä ovat tiedonhakujärjestelmä ja sanojen yhdistämismenetelmä, jotka noudattavat BIBREF26 Clark2016CombiningRS:n malleja. Nämä ovat naiiveja perusjärjestelmiä, jotka eivät analysoi kysymystä, mutta saattavat kuitenkin löytää suuresta tekstikorpuksesta jonkin signaalin, joka auttaa arvaamaan oikean vastauksen. Kolmas on CCG-tyylinen sääntöpohjainen semanttinen jäsentäjä, joka on kirjoitettu nimenomaan kitkakysymyksiä varten (QuaRel INLINEFORM0 -osajoukko), mutta ennen tietojen keräämistä. Viimeinen on uusinta tekniikkaa edustava neuraalinen semanttinen jäsentäjä. Kuvaamme lyhyesti kutakin vuorollaan.",
      "id": "task461-d73bdf9eeb3d423ab53a5eace38c0f21",
      "output": [
        "Mitä valmiita työkaluja he käyttävät QuaRelissa?"
      ]
    },
    {
      "input": "Esittelemme uuden mallin vaikeuksien ennustamista varten, jossa yhdistyvät oppimamme representaatiot, jotka on saatu valmiiksi koulutetun \"universaalin\" lauseenkoodaajan BIBREF6 avulla, ja lauseenkoodaaja, joka on opetettu alusta alkaen tätä tehtävää varten. Yhteensä tämä johti 57 505 lauseen ja 2 428 lauseen muodostamiseen harjoitus- ja testijoukon tiivistelmissä.",
      "id": "task461-247598aa03224bb1a27fed388406774f",
      "output": [
        "Kuinka paljon dataa tarvitaan tehtäväkohtaisen koodaimen kouluttamiseen?"
      ]
    },
    {
      "input": "UTD:n haasteiden analyysiJärjestelmämme perustuu ZRToolsin (ainoa tietojemme mukaan vapaasti saatavilla oleva UTD-järjestelmä) tuottamaan pseudotekstiin, joka asettaa useita haasteita MT:lle.  Väärien sanojen osoittaminen klusteriinSen vuoksi, että UTD on valvomaton, löydetyt klusterit ovat kohinaisia.  Sanojen jakaminen eri klustereihinVaikka suurin osa UTD-tapauksista on eri puhujien välisiä, puhujien välisten tapausten muistaminen on heikompaa kuin saman puhujan tapausten. Tämän seurauksena sama sana eri puhujilta esiintyy usein useissa klustereissa, mikä estää mallia oppimasta hyviä käännöksiä. UTD on harva, joten sen kattavuus on heikko Havaitsimme, että ZRToolsin löytämät mallit vastaavat vain 28 prosenttia äänitteistä. Tämä alhainen kattavuus pienentää harjoitusaineiston kokoa, vaikuttaa kohdistuksen laatuun ja vaikuttaa haitallisesti käännökseen, joka on mahdollista vain silloin, kun pseudotermit ovat läsnä.",
      "id": "task461-273617640d99401583fd93b6ab27fd03",
      "output": [
        "mitä haasteita on havaittu?"
      ]
    },
    {
      "input": "Ensimmäisessä NLI-tehtävien kanssa suoritettavassa karkeasuuntautumisvaiheessa käytämme MultiNLI BIBREF15- ja SNLI BIBREF16 -tietokantoja toimialueen ulkopuolisina lähtötietoaineistoina. ",
      "id": "task461-32c548a1c0c144f4a0bb8cb713eca481",
      "output": [
        "Mitä toimialueen ulkopuolisia tietokokonaisuuksia kirjoittajat käyttivät karkeasuuntausvaiheessa?"
      ]
    },
    {
      "input": "Arvioimme LAN-mallimme tehokkuutta kahdessa tyypillisessä tietämysgraafin täydennystehtävässä eli linkkien ennustamisessa ja triplettien luokittelussa.",
      "id": "task461-e9e0a64eca294dc3b571cbbf0f5de744",
      "output": [
        "Mitä tietämysgraafin täydennystehtäviä he kokeilevat?"
      ]
    },
    {
      "input": "Tehtävässä 1 on kaksi yläluokkaa, nimittäin rupattelu ja tehtäväkeskeinen vuoropuhelu.",
      "id": "task461-4bd90473ebc64d2caf151a7624e8b202",
      "output": [
        "Kuinka monta aikomusta oli luokiteltu?"
      ]
    },
    {
      "input": "Tietokokonaisuutemme sisältää Yhdysvalloissa maaliskuussa 2010 kerättyjä tviittejä \"ObamaCare\"-ohjelmasta. ",
      "id": "task461-47ea82e3b90f4d82b891c1bc844cb885",
      "output": [
        "Mitä twiittaustietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "FEVER-tietokannan BIBREF0 (FEVER fact extraction and verification dataset) julkaiseminen tarjoaa laajamittaisen haasteen, jossa testataan tiedonhaku- ja tekstuaalisten päättelyvalmiuksien yhdistelmää. Varmistaakseen tietokokonaisuuteen sisältyvän väittämän tuetuksi, kumotuksi tai päättämättömäksi järjestelmän on haettava asiaankuuluvat artikkelit ja lauseet Wikipediasta. Sitten sen on päätettävä, sisältääkö kukin näistä lauseista tai jokin niiden yhdistelmä väitteen vai kumoaa sen, mikä on seuraamusongelma. Järjestelmät arvioidaan väitteiden ennustamisen tarkkuuden perusteella, ja pisteitä annetaan vain silloin, kun oikeat todisteet on toimitettu. FEVER-tiedoissa olevat premissiot eroavat olennaisesti Stanford Natural Language Inference (SNLI) BIBREF1 -tietokannan pohjana käytetyn kuvatekstitiedoston premisseistä. Lauseet ovat pidempiä (keskimäärin 31 sanaa verrattuna 14 sanaan), sanasto on abstraktimpaa ja nimettyjen entiteettien ja sanaston ulkopuolisten termien esiintyvyys on suurempi. Myöskään FEVERin haku ei ole yksinkertaista. Väitteellä voi olla pieni sanojen päällekkäisyys asiaankuuluvan todistusaineiston kanssa, varsinkin jos todistusaineisto kumoaa väitteen.",
      "id": "task461-601245431760439f8709158bc84fc44c",
      "output": [
        "Mikä on FEVER-tehtävä?"
      ]
    },
    {
      "input": "Tässä artikkelissa hyödynnetään kahta tietokokonaisuutta. Molemmat tietokokonaisuudet koostuvat tavallisesta tekstistä, joka sisältää espanjankielisen kliinisen kertomuksen, ja niiden manuaalisista arkaluonteisten tietojen merkinnöistä BRAT BIBREF13 -muodossa. NUBes BIBREF4 on korpus, joka koostuu noin 7 000 espanjaksi kirjoitetusta todellisesta lääketieteellisestä raportista, jotka on annotoitu negaatio- ja epävarmuustiedoilla. Välttääksemme sekaannuksia näiden kahden korpuksen välillä, kutsumme tässä asiakirjassa merkityksellistä versiota jatkossa nimellä NUBes-PHI (sanoista `NUBes with Personal Health Information'). MEDDOCANin jaetun tehtävän BIBREF3 järjestäjät kuratoivat synteettisen korpuksen kliinisistä tapauksista, jotka terveydenhuollon dokumentoijat ovat rikastaneet arkaluonteisilla tiedoilla.",
      "id": "task461-930a8666c8ce4ba9b4df1d46567f3680",
      "output": [
        "Mitä kliinisiä tietokokonaisuuksia tutkimuksessa on käytetty?"
      ]
    },
    {
      "input": "Sanojen ja POS-tunnisteiden upotukset harjoitteltiin valmiiksi suurella kommentoimattomalla korpuksella, joka koostui Wikipedian ensimmäisestä miljardista merkistä.",
      "id": "task461-81c7b170c1ca4e608ab49f57fcc0c6d4",
      "output": [
        "Käyttävätkö ne esivalmennettuja malleja osana jäsentäjäänsä?"
      ]
    },
    {
      "input": "Luonnollisen kielen prosessoinnin ja laskennallisen yhteiskuntatieteen alalla on tutkittu, miten NLP-järjestelmät voivat havaita moraalisia tunteita verkkotekstissä. Esimerkiksi moraalinen retoriikka sosiaalisessa mediassa ja poliittisessa keskustelussa BIBREF19, BIBREF20, BIBREF21, sosiaalisessa mediassa esiintyvän moralisoinnin ja väkivaltaisten mielenosoitusten välinen suhde BIBREF22 sekä pakolaisiin kohdistuvat ennakkoluulot keskusteluradio-ohjelmissa BIBREF23 ovat olleet eräitä tällä tutkimuslinjalla tutkittuja aiheita. Toisin kuin tällä tutkimuslinjalla, moraalisten tunnetilojen muutosta koskevan muodollisen kehyksen kehittäminen on vielä vähän tutkittu, eikä tätä aihetta ole käsitelty systemaattisesti ja muodollisesti BIBREF16.",
      "id": "task461-52100d99bcab45cfbb211ec0e534034c",
      "output": [
        "Käsitelläänkö asiakirjassa aiempia malleja, joita on sovellettu samaan tehtävään?"
      ]
    },
    {
      "input": "Yksinkertainen, mutta toistuva tekstimalli on tunnettu sanojen yhteisesiintymisverkko. Valinnaisten tekstin esikäsittelyvaiheiden jälkeen yhteisesiintymisverkossa jokaisesta eri sanasta tulee solmu, ja särmät muodostetaan yhteisesiintymisen avulla halutussa ikkunassa. Yleinen strategia yhdistää vain vierekkäiset sanat niin sanotuissa sanojen vierekkäisyysverkoissa.",
      "id": "task461-f7fc57f8a8a94f7493b20355a88c10f7",
      "output": [
        "Mihin malliarkkitehtuureihin aiemmat yhteenkuuluvuusverkot perustuvat?"
      ]
    },
    {
      "input": "Toiseksi analysoimme laajasti NLI-tehtävän uusinta mallia ja osoitamme, että menetelmämme paljastavat mielenkiintoisia oivalluksia, joita ei ole saatavissa perinteisistä huomion ja sanojen erottuvuuden tarkastusmenetelmistä.",
      "id": "task461-8a1106f4ab4b4a58840bc5860e9025e3",
      "output": [
        "Käytettiinkö huomion analysoinnissa uusinta mallia?"
      ]
    },
    {
      "input": "Arvioimme kolme mallia kuvan huomiomekanismista INLINEFORM0 yhtälön EQREF11 mukaisesti. Pehmeä huomio Kova Stokastinen huomio Paikallinen huomio",
      "id": "task461-467d30b8ba30488a8745cba310934efc",
      "output": [
        "Mitä huomiomekanismeja ne vertailevat?"
      ]
    },
    {
      "input": "Yhteistä kaikille lähestymistavoille on ollut se, että niissä on käytetty ainoastaan tietokannassa saatavilla olevia tekstiominaisuuksia. Meidän mallissamme ei käytetä ainoastaan tekstuaalisia piirteitä, jotka on mallinnettu BiLSTM:llä ja joita on täydennetty huomiomekanismilla, vaan siinä otetaan huomioon myös tehtävään liittyvät kuvat.",
      "id": "task461-cd1cb17788fe40ddb15d7b1dff199a26",
      "output": [
        "Mitä eroja on neuroverkkojen aiempiin sovelluksiin tässä tehtävässä?"
      ]
    },
    {
      "input": "Harjoittelu- ja testidata on jaettu 70-30-suhteella, ja saimme taulukossa TABREF17 esitetyt tulokset yksittäiselle tietokokonaisuudelle ja molempien yhdistelmälle. Esikoulutettu verkko oli jo koulutettu, ja käytimme kohdetietoja Queenslandin tulvasta, joka antoi 96 prosentin tarkkuuden 0,118 testihäviöllä vain 11 sekunnissa, jos käytimme vain 70 prosenttia koulutuksesta merkityistä tiedoista. Toinen kohdedata on Albertan tulva, jossa käytettiin samaa koulutus- ja testijakoa, jonka avulla saatiin 95 prosentin tarkkuus ja 0,118 testitappio vain 19 sekunnissa.",
      "id": "task461-964e67acea354194bde0026994563a9a",
      "output": [
        "Mitkä olivat mallin tulokset tulvien havaitsemisessa?"
      ]
    },
    {
      "input": "Monissa NLP-tehtävissä käytetään POS-merkintöjä ominaisuuksina, mutta ihmisten kommentoimia POS-sekvenssejä on vaikea ja kallis saada. Näin ollen on tärkeää tietää, voimmeko oppia lausetason syntaktisia upotuksia matalalähteisille kielille ilman puupankkeja.Suoritimme syntaktisten upotusten siirtämisen nollapisteellä ranskan, portugalin ja indonesian kielille. Ranska ja portugali ovat simuloituja matalalähteisiä kieliä, kun taas indonesia on todellinen matalalähteinen kieli.",
      "id": "task461-6744fe90c6dc4e3b9a666a639bd39106",
      "output": [
        "Arvioivatko he jatkojalostustehtäviä?"
      ]
    },
    {
      "input": "Gallupin tutkimuksessa kysyttiin mielipiteitä \"homoseksuaalisten suhteiden\" laillisuudesta vuoteen 2008 asti, mutta sitten sanamuoto muutettiin \"homo- ja lesbosuhteiksi\". Tämä johtui todennäköisesti siitä, että monet homoseksuaaleiksi ja lesboiksi identifioituvat ihmiset pitävät sanaa homoseksuaali vanhentuneena ja halventavana.",
      "id": "task461-6f7620b64ae94368a166ca8ef1909f75",
      "output": [
        "Analysoidaanko tiettyjä halventavia sanoja?"
      ]
    },
    {
      "input": "Word2Vec-arkkitehtuuri on innoittanut paljon tutkimusta bio- ja kemianinformatiikan aloilla. Word2Vec-algoritmia on sovellettu menestyksekkäästi proteiiniluokkien BIBREF44 ja proteiini-proteiini-interaktioiden (PPI) BIBREF56 määrittämiseen.",
      "id": "task461-5d9e4ed232d2454a8ef59c71cc0bfb65",
      "output": [
        "Onko artikkelissa jokin konkreettinen esimerkki, joka osoittaa, että tällä lähestymistavalla on ollut valtava vaikutus lääkekehitykseen?"
      ]
    },
    {
      "input": "Ymmärtääksemme näiden #MeToo-twiittien latentteja aiheita korkeakoulujen seuraajille, käytämme ensin Latent Dirichlet Allocation (LDA) -menetelmää käyttäjien osoittamien yleisten aiheiden merkitsemiseen. Koska tietyt sanat esiintyvät usein näissä #MeToo-twiiteissä (esim. seksuaalinen häirintä, miehet, naiset, tarina jne.), muutamme korpuksemme käyttämällä TF-IDF:ää, termipainotusjärjestelmää, joka vähentää yhteisten termien vaikutusta.",
      "id": "task461-170a17fc7d254b01902253bf1e954e71",
      "output": [
        "Miten #MeToo-twiitteihin upotetut aiheet poimitaan?"
      ]
    },
    {
      "input": "Intuitiivisin tapa arvioida tekstivastausta on laskea suoraan tarkan vastaavuuden (EM) ja makrokeskiarvoiset F1-pisteet (F1) ennustetun tekstivastauksen ja todellisen tekstivastauksen välillä.",
      "id": "task461-66f80df8e42642d7abacd152fd01141a",
      "output": [
        "Mitä arviointimittareita käytettiin?"
      ]
    },
    {
      "input": "Harjoittelun aikana käytämme suunnitelman ja DFS:n välistä kartoitusta oikean kulkemisjärjestyksen suorittamiseen ja koulutamme neuraalisen luokittelijan toimimaan ohjaimena, joka valitsee, mikä toiminto kussakin vaiheessa suoritetaan.",
      "id": "task461-7b706852c5fe42aca206e91579a28246",
      "output": [
        "Miten neuraalinen suunnittelukomponentti koulutetaan?"
      ]
    },
    {
      "input": "Yli 2 100 tekstiä paritettiin 15 kysymyksen kanssa, ja näin saatiin yhteensä noin 32 000 kommentoitua kysymystä. Kysymyksistä 13 %:n osalta työntekijät eivät olleet samaa mieltä yhdestä neljästä kategoriasta enemmistön ollessa 3 viidestä, joten emme sisällyttäneet näitä kysymyksiä tietokantaamme. 87 %:n jäljelle jääneiden kysymysten kategoriamerkintöjen jakautuminen on esitetty taulukossa TABREF10 . 14 074 kysymykseen (52 %) voitiin vastata. Vastattavista kysymyksistä 10 160:een voitiin vastata suoraan tekstistä (tekstipohjainen) ja 3 914 kysymystä vaati maalaisjärjen käyttöä (käsikirjoituspohjainen). Kun validoinnin aikana poistettiin 135 kysymystä, lopulliseen tietokokonaisuuteen kuuluu 13 939 kysymystä, joista 3 827 kysymystä edellyttää maalaisjärjen käyttöä (eli 27,4 %). Tämä suhde tarkistettiin manuaalisesti satunnaisotoksen perusteella.",
      "id": "task461-507517f813404d07b164e341d0fe6303",
      "output": [
        "mitä tietokokonaisuuksia koskevia tilastoja tarjotaan?"
      ]
    },
    {
      "input": "Mittarit. Käytämme mittarina toleranssitarkkuutta BIBREF16 , joka mittaa, kuinka kaukana ennustettu jänneväli on kultaisesta standardista. Metriikka perustuu siihen, että käytännössä riittää, että suositellaan vastauksen sisältävää karkeaa välimatkaa - muutaman sekunnin erolla ei ole käyttäjälle suurta merkitystä. Mittarit. Käytimme mittareina tarkkuutta ja MRR:ää (Mean Reciprocal Ranking).  Mittarit. Arvioidaksemme putkilinjamalliamme käytämme kokonaistarkkuutta suodatuksen jälkeen ja tarkkuutta, kun otetaan huomioon, että segmentti on 10 parhaan videon joukossa. ",
      "id": "task461-566e116a8bdf432a8fc86425ce69b382",
      "output": [
        "Mitä arviointimittareita kokeilussa käytettiin?"
      ]
    },
    {
      "input": "korvataan tämä yksi GRU kahdella eri komponentilla ensimmäinen komponentti on lauseenlukija toinen komponentti on tulon fuusiokerros.",
      "id": "task461-f26845c4d90a461597f5896a587302a1",
      "output": [
        "Mitä muutoksia he tekivät tulomoduuliin?"
      ]
    },
    {
      "input": "Arvioidaksemme annotaatioiden johdonmukaisuutta ja poistaaksemme myös sattumanvaraiset annotaatiot käytimme yhteisymmärrysprosenttia, joka lasketaan jakamalla niiden aistien lukumäärä kussakin kategoriassa, joihin annotaattorit tekevät johdonmukaisia annotaatioita, kunkin aistityypin kokonaismäärällä. Ottaen huomioon aistien epätasapainoisen jakautumisen mahdollisen vaikutuksen käytimme myös Kappa-arvoa.",
      "id": "task461-396ecba630204977bce3da3a449cbf42",
      "output": [
        "Minkälaista metriikkaa he käyttävät eri merkitsijöiden välillä?"
      ]
    },
    {
      "input": "Vertailukohtana käytämme Burckhardt et al. BIBREF22 , Liu et al. BIBREF18 , Dernoncourt et al. BIBREF9 ja Yang et al. BIBREF10 järjestelmien tuloksia i2b2-tietokannassa sekä Burckhardt et al. suorituskykyä hoitotyön korpuksessa.",
      "id": "task461-07ab75cc1cb14e4b9984390bace66f10",
      "output": [
        "Mikä on heidän perustasonsa?"
      ]
    },
    {
      "input": "Analyysin ensisijaiseen syötteeseen kerättiin INLINEFORM0 miljoonaa twiittiä, jotka sisälsivät avainsanat \"rinta\" JA \"syöpä\". ",
      "id": "task461-5fdd8f8188a64670b0b492efcd8bbbd9",
      "output": [
        "Miten rintasyöpään liittyvät viestit koottiin Twitterin suoratoistopalvelun API:sta?"
      ]
    },
    {
      "input": "Kaaviosta käy selvästi ilmi, että väärennettyjen uutisten todennäköisyys on suurempi, kun ne tulevat vahvistamattomilta tileiltä. Huomaa, että väärennettyjä uutisia sisältäviä virustwiittejä levittävillä tileillä on keskimäärin suurempi ystävien/seuraajien suhde.  Kuvio FIGREF24 osoittaa, että toisin kuin muunlaiset virustwiitit, valeuutisia sisältävät twiitit on luotu hiljattain.",
      "id": "task461-9050803ca9794d5f8975ed864b8ad1f6",
      "output": [
        "Mitkä ovat valeuutisia levittävien tilien ominaisuudet?"
      ]
    },
    {
      "input": " Mallimme parantaa F1-pistemäärää lähes 2 %, mikä vastaa 12,3 %:n virhemäärän vähenemistä.",
      "id": "task461-5775734a64174e99b5ad3f2d587ed72d",
      "output": [
        "Kuinka parempi ehdotettu malli on perusmalliin verrattuna?"
      ]
    },
    {
      "input": "Kuten voidaan nähdä, ehdotettu DSC-häviö on huomattavasti parempi kuin parhaat perustulokset, eli se ylittää BERT-taggerin +1,86:lla F1-pistemäärällä CTB5:ssä, +1,80:lla CTB6:ssa ja +2,19:llä UD1.4:ssä.",
      "id": "task461-ee12e4f225f1443bb23d0cfbc404de7c",
      "output": [
        "Mitkä ovat menetelmän F1-parannukset verrattuna perus-BERT-taggeriin kiinalaisissa POS-tietoaineistoissa?"
      ]
    },
    {
      "input": "Visuaalinen mallimme perustuu Inception V3 -mallin BIBREF1 hienosäätöön asiakirjojen visuaalisten esitysten avulla, kun taas tekstuaalinen mallimme perustuu hierarkkiseen biLSTM-malliin. Yhdistämme nämä kaksi edelleen yhteiseksi malliksi.  Sovelsimme neuroverkkomalleja visuaalisten piirteiden tallentamiseen asiakirjojen visuaalisten esitysten perusteella. Kokeelliset tulokset osoittavat, että saavutamme 2,9 % korkeamman tarkkuuden kuin uusimmat tekstuaalisiin ominaisuuksiin perustuvat lähestymistavat Wikipediassa ja että suorituskyky on kilpailukykyinen tai jopa parempi kuin uusimmilla lähestymistavoilla arXivissa. Lisäksi ehdotimme yhteistä mallia, jossa yhdistetään tekstuaaliset ja visuaaliset esitykset, asiakirjan laadun ennustamiseksi. ",
      "id": "task461-5168f4de7d534626b1af0ccb92495162",
      "output": [
        "Millaista mallia he käyttävät?"
      ]
    },
    {
      "input": " Ne lisäävät tietoja kääntämällä tietoja englannin ja kiinan välillä, mikä näyttää olevan yksi erottelevista tekijöistä, jotka johtavat paljon korkeampaan tarkkuuteen.",
      "id": "task461-ebcc649c65154d0fb24f46f32d8d1576",
      "output": [
        "Mitä tietojen lisäämiseen liittyviä tekniikoita käytetään?"
      ]
    },
    {
      "input": "Lisäksi tässä teoksessa käsitellään myös yksikön ja monikon, subjektipronominin ja objektipronominin jne. tapauksia. Esimerkiksi pronominia \"hän\" käytetään subjektista \"hän\", mutta objektista \"hän\".",
      "id": "task461-dbe806cf42704113b7c074dbb9afb182",
      "output": [
        "Mitä muuta yritetään ratkaista kuin 12 aikamuotoa, malliverbejä ja kielteinen muoto?"
      ]
    },
    {
      "input": "Tutkimuskysymyksemme ohjaavat siis käyttämiämme lähestymistapoja ja sitä, mitä tarkoitamme \"onnistumisella\".Alan asiantuntijat ja tutkijatoverit voivat antaa palautetta kysymyksistä ja auttaa niiden dynaamisessa tarkistamisessa. Joskus toivomme myös voivamme olla yhteydessä useisiin tieteenaloihin. Myös mahdolliseen \"kaksoiskäyttöön\" liittyviä kysymyksiä voi nousta esiin.",
      "id": "task461-f709a526665643d19c8c7a37d6958761",
      "output": [
        "Mitä lähestymistapoja he käyttävät tekstianalyysissä?"
      ]
    },
    {
      "input": "Ehdollisia satunnaiskenttiä (CRF, Conditional Random Fields) BIBREF15 on käytetty laajalti peräkkäisiin tehtäviin. Tässä asiakirjassa ehdotamme yhdeksi kilpailukykyiseksi perusversioksi CRF-luokittelijaa, joka on koulutettu sklearn-crfsuite-ohjelmalla Python 3.5:lle ja seuraavalla kokoonpanolla: algoritmi = lbfgs; maksimi iteraatiot = 100; c1 = c2 = 0,1; kaikki siirtymät = true; optimoida = false. spaCy on laajalti käytetty NLP-kirjasto, joka toteuttaa nykyaikaisia tekstinkäsittelyputkia, mukaan lukien strubell2017fastin kuvaaman kaltainen sekvenssien merkintäputki. spaCy tarjoaa useita valmiiksi koulutettuja espanjankielisiä malleja, jotka suorittavat NLP:n perustehtäviä, kuten nimettyjen entiteettien tunnistusta (NER). Tässä artikkelissa olemme kouluttaneet uuden NER-mallin NUBes-PHI-merkintöjen tunnistamiseen. Yksinkertaisimpana perustasona on kehitetty arkaluonteisen tiedon tunnistin ja luokittelija, joka koostuu säännöllisistä lausekkeista ja sanakirjanäkymästä. Jokaista tunnistettavaa luokkaa varten on toteutettu erityinen menetelmä. Esimerkiksi päivämäärän, iän, kellonajan ja lääkärin tunnistimet perustuvat säännöllisiin lausekkeisiin; sairaala, sukupuoli, sukulaisuus, sijainti, potilas ja työpaikka etsitään sanakirjoista. Sanakirjat on laadittu käsin käytettävissä olevasta harjoitusaineistosta lukuun ottamatta potilaan tapausta, jossa mahdollisina ehdokkaina on käytetty Espanjan 100 yleisintä nais- ja miehenimeä Instituto Nacional de Estadístican (INE; Espanjan tilastokeskus) mukaan.",
      "id": "task461-71588527a4d04586bc212da803d42c58",
      "output": [
        "Mitä muita algoritmeja testataan?"
      ]
    },
    {
      "input": "Otamme käyttöön Amazonin Mechanical Turk -palvelun avulla toteutetun BIBREF-annotaatiokoneiston5 ja annotoimme jokaisen predikaatin kahdella koulutetulla työntekijällä itsenäisesti, kun taas kolmas yhdistelee heidän annotaationsa lopulliseksi rooli- ja argumenttikokonaisuudeksi. ",
      "id": "task461-aba770e4e7fd4ad0bc2af8401b6c3c02",
      "output": [
        "Miten edellinen tietokokonaisuus annotoitiin?"
      ]
    },
    {
      "input": "Koko MSD-dekooderin (aputehtävän) parametrit ovat yhteiset kaikille kielille.Koska kielten ryhmittely kieliperheen perusteella olisi jättänyt useita kieliä yksijäsenisiin ryhmiin (esim. venäjä on ainoa slaavilaisen kieliperheen edustaja), kokeilemme satunnaisia ryhmittelyjä, joissa on kahdesta kolmeen kieltä. Monikielinen harjoittelu suoritetaan vaihtelemalla kieliä satunnaisesti jokaisessa uudessa minierässä.",
      "id": "task461-23c12718697343a1829c8d473573ec1c",
      "output": [
        "Miten he suorittavat monikielisen koulutuksen?"
      ]
    },
    {
      "input": "Taulukossa TABREF10 esitetään tärkeimmät tulokset. Mallimme perustuvat aiempiin töihin, ja niihin on lisätty huomionvalvontamoduuli, kuten kohdassa SECREF3 on kuvattu. Tarkemmin sanottuna merkitsemme Attn-*:llä kyseisen mallin mukauttamista sisällyttämällä siihen Attention Supervision Module -moduulimme. Korostamme, että MCB-malli on VQA-haasteen 2016 voittaja ja MFH-malli on VQA-haasteen 2017 paras yksittäinen malli. Taulukosta TABREF10 voidaan havaita, että ehdotettu mallimme parantaa merkittävästi sijoituskorrelaatiota suhteessa ihmisen huomiokykyyn. Lisäksi mallimme päihittää vaihtoehtoiset uusimmat tekniikat vastausten ennustamisen tarkkuudessa. MFH-mallin sijoituskorrelaatio kasvaa 36,4 %, kun sitä arvioidaan VQA-HAT-tietokannassa, ja 7,7 %, kun sitä arvioidaan VQA-X-tietokannassa. Tämä osoittaa, että ehdotetut menetelmät mahdollistavat sen, että VQA-mallit tuottavat merkityksellisempiä ja tulkittavampia tuloksia tuottamalla tarkemman visuaalisen perustan.",
      "id": "task461-98c403a1c3f14489bdfa94d29b7da31b",
      "output": [
        "Kuinka paljon ne ovat nykyisiä nykyaikaisia VQA-malleja suorituskykyisempiä?"
      ]
    },
    {
      "input": "Koska portugalinkielisiä taloudellisia aikomuksia sisältäviä julkisia tietokokonaisuuksia ei ole saatavilla, olemme käyttäneet inkrementaalista lähestymistapaa luodaksemme oman harjoitusjoukon aikomusluokittelijalle. Olemme luoneet alaan liittyviä sanavektoreita tarkastelemalla 246 945 asiakirjaa, jotka vastaavat 184 001 Twitter-viestiä ja 62 949 uutisartikkelia, jotka kaikki liittyvät rahoitukseen.",
      "id": "task461-2a8ea13967d74dcc8ecf6e6805ffefac",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "Vertailemme seuraavien mallien suorituskykyä: - Vain IMG: Tämä on yksinkertainen perusmalli, jossa kuva vain ohjataan VGG19:n läpi ja käytetään kuvan upotusta vastauksen ennustamiseen kiinteästä sanastosta.- QUES-only: Tämä on yksinkertainen perusmalli, jossa kuva vain ohjataan VGG19:n läpi ja käytetään kuvan upotusta vastauksen ennustamiseen kiinteästä sanastosta: SANBIBREF2: Tämä on uusin VQA-malli, joka on koodaaja-dekooderimalli, jossa on monikerroksinen pinottu huomio BIBREF26 -mekanismi. Se saa kuvan esityksen käyttämällä syvää CNN:ää ja kyselyn esityksen käyttämällä LSTM:ää. Sen jälkeen se käyttää kyselyn esitystä löytääkseen relevantteja alueita kuvasta ja valitsee sen perusteella vastauksen kiinteästä sanastosta.- SANDYBIBREF1: Tämä on DVQA-aineistossa parhaiten suoriutunut malli, ja se on SAN:n muunnos. Valitettavasti tämän mallin koodia ei ole saatavilla, eikä sen kuvaus artikkelissa ollut riittävän yksityiskohtainen, jotta olisimme voineet toteuttaa sen uudelleen. Näin ollen ilmoitamme tämän mallin luvut vain DVQA:n osalta (alkuperäisestä artikkelista). - VOES: Tämä on kohdassa SECREF3 kuvattu mallimme, joka on suunniteltu erityisesti kysymyksille, joihin ei ole vastauksia kiinteästä sanastosta.- VOES-Oracle: mustaTämä on mallimme, jossa VOES:n kolme ensimmäistä vaihetta korvataan Oracle:lla, eli QA-malli vastaa kysymyksiin taulukossa, joka on luotu käyttäen juonen ground truth -merkintöjä. Tämän avulla voimme arvioida WikiTableQA-mallin suorituskykyä, kun VED-mallin virheet eivät vaikuta siihen.- SAN-VOES: Ottaen huomioon SAN-VQA:n ja VOES:n toisiaan täydentävät vahvuudet koulutamme hybridimallin, jossa on binäärinen luokittelija, joka päättää kysymyksen perusteella, käytetäänkö SAN- vai VOES-mallia. Tämän binääriluokittelijan kouluttamiseen tarvittavat tiedot saadaan vertaamalla koulutetun SAN-mallin ja koulutetun VOES-mallin ennusteita koulutustietokannassa. Tietyn kysymyksen merkinnäksi asetetaan 1 (valitse SAN), jos SAN-mallin suorituskyky oli parempi kuin VOES-mallin. Jätämme huomiotta kysymykset, joissa on tasapeli. Luokittelija on yksinkertainen LSTM-pohjainen malli, joka laskee kysymyksen esityksen LSTM:n avulla ja käyttää tätä esitystä ennustamaan 1/0. Testihetkellä kysymys ohjataan ensin tämän mallin läpi, ja mallin tuloksesta riippuen käytetään SAN- tai VOES-luokitusta.",
      "id": "task461-18a959165c864f73a6789be5a23f4994",
      "output": [
        "Mitä muita malleja kuin SAN-VOES on koulutettu uudella PlotQA-aineistolla?"
      ]
    },
    {
      "input": "Käytämme perustasona GraphParseria ilman parafraaseja. Näin saadaan käsitys parafraasien käytön vaikutuksesta Vertaamme parafraasimalliamme yksikieliseen konekääntämiseen perustuvaan parafraasien tuottamiseen tarkoitettuun malliin BIBREF24 , BIBREF36 . Käytämme erityisesti Mosesin BIBREF37 -mallia kouluttaaksemme yksikielisen fraasipohjaisen MT-järjestelmän Paralex-korpuksen avulla. Lopuksi käytämme Moses-dekooderia tuottamaan 10 parasta erillistä parafraasia testikysymyksiä varten.",
      "id": "task461-ecd76c281609466a843a546cc25d377a",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Annotoitujen korporaatioiden ja merkkipohjaisten piirteiden perusteella tehdyissä tutkimuksissa on käytetty koneoppimismenetelmiä sanojen segmentointijärjestelmien rakentamiseen, joiden tarkkuus on noin 94-97 prosenttia.",
      "id": "task461-b985fc04b99b459a89e09f4f9e0c83da",
      "output": [
        "Kuinka onnistuneita ovat lähestymistavat, joita käytetään sanojen segmentoinnin ratkaisemiseen vietnamiksi?"
      ]
    },
    {
      "input": "WAS: BIBREF3:ssa käytetty arkkitehtuuri ilman äänituloa. Dekooderi tuottaa kiinalaisen merkin kullakin aika-askeleella. Muut osat säilyvät muuttumattomina alkuperäiseen toteutukseen verrattuna. LipCH-Net-seq: Oikeudenmukaisen vertailun vuoksi käytämme sekvenssistä sekvenssiin -periaatetta, jossa on huomiokehys, korvataksemme Connectionist temporal classification (CTC) -menetyksen BIBREF14 , jota käytetään LipCH-Net BIBREF5:ssä, kun kuva muunnetaan pinyiniksi. CSSMCM-w/o video: Jotta voidaan arvioida videon tarpeellisuutta äänensävyn ennustamisessa, videovirta poistetaan äänensävyä ja kiinalaisia merkkejä ennustettaessa. Toisin sanoen videokuvaa käytetään vain pinyin-sekvenssiä ennustettaessa. Äänensävy ennustetaan pinyin-sekvenssin perusteella. Sävytieto ja pinyin-informaatio toimivat yhdessä kiinalaisen merkin ennustamisessa.",
      "id": "task461-356c7f0800aa46f8b06d8e64fb172860",
      "output": [
        "Mikä oli tämän tehtävän aiempi nykytilamalli?"
      ]
    },
    {
      "input": "Tutkiaksemme, missä määrin Yahoo! Answersin ja Twitterin kahdesta alustasta saatu teksti kuvastaa naapurustojen todellisia ominaisuuksia, tutkimme ensin, onko kummassakin korpuksessa esiintyvien termien ja monien naapuruston ominaisuuksien välillä merkittäviä, vahvoja ja merkityksellisiä korrelaatioita Pearsonin korrelaatiokertoimen $\\rho $ avulla.",
      "id": "task461-11c9e06e4d47431980f11f3557b84792",
      "output": [
        "Mitä korrelaatio osoittaa? "
      ]
    },
    {
      "input": "Multimodaalista tunneanalyysia varten voimme yksinkertaisesti jakaa kuvan kahteen osaan. Toinen tekstin syöttöä varten ja toinen taulukkomuotoista dataa varten.",
      "id": "task461-2a49f7e34f02432a984d95f6e5fcd9ad",
      "output": [
        "Miten Super Character -menetelmää muutetaan siten, että se voi käsitellä myös taulukkomuotoisia tietoja?"
      ]
    },
    {
      "input": "Kagglen StackLite-tunnisteiden suosittelutehtävän innoittamana luomme uuden vertailutehtävän, joka perustuu julkiseen StackExchange-tietoon. Käytämme kysymysten otsikoita lähteenä ja käyttäjän antamia tunnisteita kohde-avainlauseina.Koska StackExchange-kysymykset sisältävät usein vähemmän tietoa kuin tieteelliset julkaisut, StackExissä on vähemmän avainsanoja per datapiste. Lisäksi StackExchange käyttää tunnisteiden suosittelujärjestelmää, joka ehdottaa aiheeseen liittyviä tunnisteita käyttäjille, kun he lähettävät kysymyksiä; siksi näemme todennäköisemmin yleistä terminologiaa, kuten Linux ja Java. Tämä ominaisuus haastaa mallit siihen, että ne pystyvät erottelemaan kysymyksen tärkeimmät aiheet sen sijaan, että ne valitsisivat tekstistä tiettyjä pätkiä.",
      "id": "task461-4e056d71f1304ed5979f63c9d670c751",
      "output": [
        "Miten StackExchange-tietokanta kerättiin?"
      ]
    },
    {
      "input": "Otamme aineistomme uutisjulkaisuista, viinikritiikeistä ja Redditistä, joiden suuren volyymin lisäksi voimme myös luonnehtia binomeja uusilla tavoilla ja analysoida eroja binomijärjestelyissä eri yhteisöissä ja ajan kuluessa.",
      "id": "task461-9ff6962c990b40f6a91630aaa5aea580",
      "output": [
        "Minkälaisia erilaisia yhteisötekstejä on tutkittu binomien globaalirakenteen tutkimiseksi?"
      ]
    },
    {
      "input": "Koska TextWorld-pelien tehtävien pituus on suhteellisen pieni - pelit voidaan suorittaa vain viidessä vaiheessa - luomme 50 tällaista peliä ja jaamme ne harjoittelu- ja testijoukkoihin suhteessa 4:1. Valitsemme pelin 9:05 kohdetehtäväpeliksi, koska sanaston päällekkäisyyden lisäksi sen rakenne on samankaltainen.  Kauhualueeksi valitsemme Lurking Horror -pelin, jolla kysymys-vastausjärjestelmää koulutetaan. Lähde- ja kohdetehtäväpeleiksi valitaan Afflicted ja Anchorhead.",
      "id": "task461-ab470b07787042c69675ec2cde52028f",
      "output": [
        "Mitä pelejä käytetään tekijän menetelmien testaamiseen?"
      ]
    },
    {
      "input": "Tässä osassa esitämme ehdotettujen mallien - HAKE ja ModE - suorituskyvyn verrattuna nykyisiin uusimpiin menetelmiin, kuten TransE BIBREF8, DistMult BIBREF9, ComplEx BIBREF17, ConvE BIBREF18 ja RotatE BIBREF7.",
      "id": "task461-e79ad2341e1b4f74bebaa53f53b855ca",
      "output": [
        "Mitkä ovat nykyaikaiset mallit tätä tehtävää varten?"
      ]
    },
    {
      "input": "Ensimmäinen tietokokonaisuus (WIKI) oli sama 200 lauseen joukko Wikipediasta, jota käytettiin BIBREFissä7 .  Toinen tietokokonaisuus (SCI) koostui 220 lauseesta tieteellisestä kirjallisuudesta. Lauseet saatiin OA-STM-korpuksesta. Kaikkiaan poimittiin 2247 kolmikkoa. Annotointiprosessin suorittamisen jälkeen saatiin yhteensä 11262 tuomiota.",
      "id": "task461-63409bc6ae1c42778aca853ff528fdf0",
      "output": [
        "Mikä on julkaistun tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Konteksti on ylöspäin päättyvä (osoitetaan [... $\\leavevmode {\\color {red!80!black}\\uparrow }$ ]), joka sallii päättelyn (\"Johdanto\" ) ja (\"Johdanto\" ) välillä, jossa ranskankielinen illallinen korvataan yleisemmällä käsitteellä illallinen.  Toisaalta alaspäin johtava konteksti (esitetty [... $\\leavevmode {\\color {blue!80!black}\\downarrow }$ ]) sallii päätelmän (\"Johdanto\" ) ja (\"Johdanto\" ) välillä, jossa työntekijät korvataan tarkemmalla käsitteellä uudet työntekijät. Kaikki [ työntekijät $\\leavevmode {\\color {blue!80!black}\\downarrow }$ ] [liittyivät ranskalaiseen illalliseen $\\leavevmode {\\color {\\color {red!80!black}\\uparrow }$ ] Kaikki työntekijät liittyivät illalliselle Kaikki uudet työntekijät liittyivät ranskalaiseen illalliseen Eivät kaikki [uudet työntekijät $\\leavevmode {\\color {\\color {red!80!black}\\uparrow }$ ] liittyneet illalliselle Eivät kaikki työntekijät liittyneet illalliselle.",
      "id": "task461-cd60219423a64e1690f7f82800263a5f",
      "output": [
        "Miten he määrittelevät ylös- ja alaspäin suuntautuvan päättelyn?"
      ]
    },
    {
      "input": "Kun analysoimme raakadataa manuaalisesti, huomasimme, että kun tarkastelemme twiittejä, joihin on vastattu tai joita on siteerattu, saamme merkittävää taustatietoa. Kutsumme näitä twiittejä \"kontekstitwiiteiksi\". Koska ihmiset ymmärtävät twiitin paremmin sen kontekstin avulla, oletamme, että myös tietokoneet hyötyvät kontekstitwiittien huomioon ottamisesta havaitessaan loukkaavaa kieltä.Kuten alla olevista esimerkeistä käy ilmi, (2) leimataan loukkaavaksi mauttoman kielenkäytön vuoksi. Käyttäjän aikomus voidaan kuitenkin ymmärtää paremmin sen kontekstitwiitin (1) avulla. 1) Inhoan sitä, kun istun bussin edessä ja joku pyörätuolilla istuva nousee kyytiin. INLINEFORM0 (2) Inhoan sitä, kun yritän nousta bussiin ja siinä on jo as**ole.Vastaavasti kontekstin twiitti (3) on tärkeä loukkaavan twiitin (4) ymmärtämisessä, erityisesti pahansuopaisuuden kohteen tunnistamisessa. 3) Survivors of #Syria Gas Attack Recount `a Cruel Scene'.INLINEFORM0 (4) Who the HELL is \"LIKE\" ING this post? Sick people....Huang et al. huang2016mallinnuksessa käytettiin useita kontekstin twiittien attribuutteja sentimenttianalyysiin perus-LSTM-mallin parantamiseksi. Heidän lähestymistapansa oli kuitenkin rajallinen, koska metatiedot, joihin he keskittyivät - kirjoittajan tiedot, keskustelun tyyppi, samojen hashtagien tai emojien käyttö - ovat kaikki hyvin riippuvaisia datasta. datariippuvuuden välttämiseksi kontekstitwiittien tekstijaksoja käytetään suoraan neuroverkkomallien lisäominaisuutena. Käytämme samaa perusmallia muuntamaan kontekstitwiitit vektoreiksi ja sitten ketjuttamaan nämä vektorit vastaavien merkittyjen twiittien ulostulojen kanssa. Tarkemmin sanottuna yhdistämme CNN-perusmalliin kontekstin ja merkittyjen twiittien maksimikerrokset. RNN:n osalta kontekstin ja merkittyjen twiittien viimeiset piilotetut kerrokset yhdistetään.",
      "id": "task461-31319abc65ac41149d7ff93c8ef6e1fd",
      "output": [
        "Mitä lisäominaisuuksia ja -yhteyksiä ehdotetaan?"
      ]
    },
    {
      "input": "SLC-tehtävän perusjärjestelmä on hyvin yksinkertainen logistinen regressioluokittelija, jossa on oletusparametrit ja jossa edustamme syötetapauksia yhdellä ominaisuudella: lauseen pituudella.  FLC-tehtävän perustasolla luodaan jaksoja ja valitaan yksi 18 tekniikasta satunnaisesti. ",
      "id": "task461-8fac478d43b8429bba3b07c1ac1c2c95",
      "output": [
        "Mikä oli tämän tehtävän lähtötaso?"
      ]
    },
    {
      "input": "Kunkin arvioinnin aikana kohdetermejä peitetään, ennustetaan ja verrataan sitten peitettyyn (tunnettuun) arvoon.",
      "id": "task461-818cf898d2fb476baf25ca5b774dac75",
      "output": [
        "Ovatko muuntajat naamioituneita?"
      ]
    },
    {
      "input": "Kokeemme tavoitteellisella dialogikorpuksella, personoidulla bAbI-dialogitietokannalla, osoittavat, että henkilökohtaisten tietojen hyödyntäminen voi parantaa merkittävästi dialogijärjestelmien suorituskykyä. ",
      "id": "task461-d2ca00c60868428f921d389deede2c57",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Englannin ja saksan kieliparin osalta käytämme koko WMT 2019 -rinnakkaistietokokonaisuutta. Englannin ja ranskan kieliparin osalta käytämme rajoitettua tietokokonaisuutta, joka sisältää täyden TED-korpuksen MUST-C BIBREF10:stä ja otoksen lauseita WMT 2019 -tietokokonaisuudesta. ",
      "id": "task461-675d2f919a624ae191fdb3d2a7575d69",
      "output": [
        "Mitä tietokokonaisuuksia käytettiin kokeessa?"
      ]
    },
    {
      "input": "Keräsimme Twitterin sovellusrajapinnan avulla reaaliaikaisia twiittejä syyskuusta 2018 helmikuuhun 2019 ja valitsimme ne, jotka sisälsivät jonkin 51 Hatebase-termistä, jotka ovat yleisempiä vihapuheviestien twiiteissä, kuten BIBREF9:ssä tutkittiin.",
      "id": "task461-d6e76573269b4c009914133877a98a8c",
      "output": [
        "Miten tiedot kerätään, manuaalinen keruu vai Twitter api?"
      ]
    },
    {
      "input": "Optimoimme yhden tehtävän perustason saadaksemme vahvan perustason, jotta voimme sulkea pois paremmat tulokset monitehtäväoppimisessa verrattuna pelkkään yhden tehtävän oppimiseen näiden kahden seuraavan seikan vuoksi: verkkoparametrit sopivat paremmin monitehtäväoppimismenetelmään ja parempi satunnaisuus monitehtäväoppimisen harjoittelun aikana. Ensimmäisen seikan poissulkemiseksi testasimme erilaisia hyperparametreja yhden tehtävän perustasoa varten. Testasimme kaikkien seuraavien hyperparametrien yhdistelmiä: 256, 512 tai 1024 LSTM:ien piilotettujen tilojen kokoja, 256, 512 tai 1024 sanojen upotuskokoja ja 30 %, 40 % tai 50 %:n pudotusta. Mallimme syötteenä käytimme tavuparikoodauksen (BPE) BIBREF16:n tuottamia alasanayksiköitä. Synteettisten tietokokonaisuuksien huonon alasanojen tuottamisen välttämiseksi otimme koulutustietokokonaisuuden lisäksi huomioon validointi- ja testitietokokonaisuudet BPE:n yhdistämistoimintaluettelon tuottamista varten. Koulutimme kokoonpanoja 14 epookin ajan ja koulutimme jokaisen kokoonpanon kolme kertaa. Valitsimme koulutuksen, jonka laatu oli paras validoinnin F1-pistemäärän suhteen, jotta huonosta satunnaisuudesta aiheutuvat haitat voitaisiin sulkea pois. Saimme parhaan laadun F1-pistemäärän suhteen, kun LSTM:ien piilotettujen tilojen koko oli 256, sanojen upotuskoko 1024 ja pudotus 30 prosenttia. Eräkokona käytimme 64:ää.",
      "id": "task461-e9cb8d363bc74bb8920fb9ebfe4c73cc",
      "output": [
        "Mitkä ovat vahvat lähtökohtanne?"
      ]
    },
    {
      "input": "Testasimme luonnollisen kielen esitystä visuaalista esitystä ja ominaisuuksien esitystä vastaan useissa tehtävissä, joiden vaikeusaste vaihteli. Tehtäviin kuuluivat perusskenaario, terveyden keräämistä koskeva skenaario, skenaario, jossa agentin on suojauduttava tulipalloja vastaan, skenaario, jossa agentin on puolustettava itseään hyökkääviltä vihollisilta, ja superskenaario, jossa agentti haastettiin edellä mainittujen skenaarioiden yhdistelmällä.",
      "id": "task461-682136536ee94773968a523a39f684e2",
      "output": [
        "Mitä kokeita kirjoittajat tekevät?"
      ]
    },
    {
      "input": "Testaamme ehdotettua lähestymistapaamme sarkasmin tai ironian binääriseen luokitteluun seitsemällä vertailutietoaineistolla, jotka on haettu eri medialähteistä. Seuraavassa kuvataan kukin tietokokonaisuus, ja taulukossa TABREF1 on yhteenveto. Reddit: BIBREF21 keräsi SARC-korpuksen, joka koostuu 600 000 sarkastisesta kommentista Redditissä. Käytämme pääjoukkoa SARC 2.0 ja poliittista osajoukkoa SARC 2.0 pol. Twitter: Käytämme SemEval 2018 Task 3, Irony Detection in English Tweets BIBREF18 -tehtävää varten toimitettua Twitter-tietokokonaisuutta. Tietokokonaisuus annotoitiin manuaalisesti käyttämällä binäärisiä merkintöjä. Käytämme myös BIBREF4 -tietokokonaisuutta, joka on manuaalisesti annotoitu sarkasmia varten. Lopuksi käytämme BIBREF20 -tietokokonaisuutta, joka keräsi käyttäjän itsensä kommentoiman korpuksen twiittejä, joissa oli #sarcasm-hashtag. Verkkodialogit: Käytämme sarkasmikorpusta V1 (SC-V1) ja sarkasmikorpusta V2 (SC-V2), jotka ovat Internet Argument Corpusin (IAC) osajoukkoja. Verrattuna muihin valikoimassamme oleviin tietokokonaisuuksiin nämä eroavat lähinnä tekstin pituuden ja rakenteen monimutkaisuuden BIBREF22 osalta.",
      "id": "task461-8bc8d76fa9244f15b9415cfd57cb80d0",
      "output": [
        "Mitkä ovat kolme eri tietolähdettä?"
      ]
    },
    {
      "input": " Tietylle kyselylle $q = \\langle s, r, ? \\rangle $ tunnistetaan $S_q$:ssa olevat maininnat $C_q \\cup \\lbrace s\\rbrace $:n olioista ja luodaan yksi solmu jokaista mainintaa kohti. Prosessi perustuu seuraavaan heuristiikkaan: katsomme, että $S_q$:n maininnat, jotka täsmälleen vastaavat $C_q \\cup \\lbrace s\\rbrace $:n elementtiä, ovat $S_q$:ssa. Tämä on tosin melko yksinkertainen strategia, joka saattaa kärsiä alhaisesta muistijäljestä.Käytämme coreference resolution -järjestelmän ennusteita lisätäksemme mainintoja elementeistä $C_q \\cup \\lbrace s\\rbrace $:ssa, jotka eivät ole täsmällisesti yhteensopivia (mukaan lukien sekä substantiivilauseet että anaforiset pronominit). Käytämme erityisesti BIBREF:in16 käyttämää end-to-end coreference resolution -ratkaisua. Hylkäämme maininnat, jotka on epäselvästi ratkaistu useisiin coreference-ketjuihin; tämä saattaa heikentää muistijälkeä, mutta välttää epäselvyyksien leviämisen.",
      "id": "task461-634f3ab6c92848338fc8cf70f5c1b18d",
      "output": [
        "Miten he havaitsivat kokonaisuuksien maininnat?"
      ]
    },
    {
      "input": "Vaikka WSD:tä arvioidaan pääasiassa englanniksi, olemme kiinnostuneita arvioimaan lähestymistapaamme myös kiinaksi, jotta voimme arvioida lähestymistapamme tehokkuutta eri kielellä.",
      "id": "task461-c712a990bba6467ba26af3d48684b8dd",
      "output": [
        "Mitä kieltä (kieliä) WSD-tietoaineistoissa on?"
      ]
    },
    {
      "input": "MTMSN BIBREF4 on ensimmäinen ja toistaiseksi ainoa malli, jossa on erityisesti pyritty käsittelemään DROPin monialaisia kysymyksiä. Heidän lähestymistapansa koostui kahdesta osasta. Ensimmäisessä koulutettiin erityinen kategorinen muuttuja, jolla ennustettiin poimittavien jännevälien määrä. Toisessa mallissa yleistettiin yhden jännevälien päähän perustuvaa menetelmää jännevälien poimimiseksi käyttämällä NMS-algoritmia (non-maximum suppression) BIBREF7 löytääkseen todennäköisimmän joukon päällekkäisiä jännevälejä. Poistettavien jännevälien lukumäärä määritettiin edellä mainitun kategorisen muuttujan avulla.",
      "id": "task461-1d014828326d4bd386f99eb25888de62",
      "output": [
        "Millaista lähestymistapaa aiemmat mallit ovat käyttäneet usean aikavälin kysymyksiin?"
      ]
    },
    {
      "input": "Päätimme käyttää lauseita, joissa oli vähintään yksi rotuun tai sukupuoleen liittyvä sana. Lauseiden oli tarkoitus olla lyhyitä ja kieliopillisesti yksinkertaisia. Halusimme myös, että joihinkin lauseisiin sisältyisi tunne- ja tunneilmaisuja, koska tavoitteena on testata tunne- ja tunnejärjestelmiä.",
      "id": "task461-36ef7a4ddb8b4c888fa05d3daa242721",
      "output": [
        "Millä kriteereillä 8 640 englanninkielistä lausetta on valittu?"
      ]
    },
    {
      "input": "SIGHAN Bakeoff määrittelee kahdenlaisia arviointiasetuksia, suljettu testi rajoittaa kaikki oppimiseen käytettävät tiedot eivät saisi ylittää annettua koulutusjoukkoa, kun taas avoin testi ei ota tätä rajoitusta BIBREF21.",
      "id": "task461-9940dfd831ab41c18c31463542732663",
      "output": [
        "Mitä tarkoitetaan suljetulla testiasetuksella?"
      ]
    },
    {
      "input": "Roget's Thesaurus BIBREF38 , BIBREF39 -teesaurusta johdetaan käsitteet ja sanaryhmät, joita käytetään ehdotetun menetelmän ulkoisena leksikaalisena resurssina. Käsite-sanaryhmien avulla olemme kouluttaneet GloVe-algoritmin, johon on tehty SECREF4-jaksossa ehdotettu muutos, englanninkielisen Wikipedian 8 Gt:n kokoisella tilannekuvalla, josta on suodatettu stop-sanat pois.",
      "id": "task461-54e75ae163644b64acf6009b10c0a8ce",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Tarkastelemme kolmea tehtävää, jotka edustavat laajaa valikoimaa luonnollisen kielen ymmärtämisen skenaarioita: paperin hyväksynnän ennustaminen PeerRead-tietoaineiston BIBREF2 perusteella, nimettyjen entiteettien tunnistaminen (NER) Broad Twitter Corpus BIBREF3 perusteella ja kirjoittajan kannan ennustaminen RumEval-19-tietoaineiston BIBREF6 perusteella. ",
      "id": "task461-a06e95b7e7b141079d0c531e44098d5a",
      "output": [
        "Mitkä ovat kolme haastavaa tehtävää, joiden tekijät arvioivat niiden peräkkäin kohdistettuja esityksiä?"
      ]
    },
    {
      "input": "Luokittelijoiden rakentamiseen käytimme kolmea erilaista oppimisalgoritmia, nimittäin logistista regressiota (LR), satunnaismetsää (RF) ja tukivektorikoneita (SVM).",
      "id": "task461-3336d7a702254305b738cee714459008",
      "output": [
        "Mitä valvotun oppimisen algoritmeja kokeissa käytetään?"
      ]
    },
    {
      "input": "Jotta kommentoidut tiedot olisivat julkisesti saatavilla, valitsimme 70 uutisartikkelia arabialaisesta WikiNews-sivustosta. Nämä artikkelit kattavat viimeaikaisia uutisia vuodesta 2013 vuoteen 2015 useista eri genreistä (politiikka, talous, terveys, tiede ja teknologia, urheilu, taide ja kulttuuri). Artikkelit sisältävät 18 300 sanaa, ja ne jakautuvat tasaisesti näiden 7 genren kesken, 10 artikkelia kutakin genreä kohden.",
      "id": "task461-d593c3db05d74dc1b54c692069062de7",
      "output": [
        "Mikä on tietokokonaisuuden koko?",
        "Mistä he keräsivät tietonsa?"
      ]
    },
    {
      "input": "GTD:n käytännön arviointi on tällä hetkellä mahdollista vain synteettisillä tiedoilla. Rakennamme erilaisia tietokokonaisuuksia, jotka on suunniteltu kuvatekstien arviointia varten. Kutsumme tätä diagnostista arviointivertailua ShapeWorldICE:ksi (ShapeWorld for Image Captioning Evaluation). Havainnollistamme tiettyjen kuvatekstitysmallien arviointia ShapeWorldICE:llä.",
      "id": "task461-6ab6f159fd0c48b88a8b4a054712147d",
      "output": [
        "Ovatko kuvat tietystä verkkotunnuksesta?"
      ]
    },
    {
      "input": "Naisten osuus puhujista on 33,16 prosenttia, mikä vahvistaa GMMP:n raportissa BIBREF0 esitetyt luvut.",
      "id": "task461-ecb1e1b0aeb243258f09821fc8fe9056",
      "output": [
        "Kuinka suuri epätasapaino on analysoiduissa korpuksissa?"
      ]
    },
    {
      "input": "Suosituksen monimuotoisuus. Kuten BIBREF:ssä18 on määritelty, laskemme suositusten monimuotoisuuden kaikkien suositeltujen tunnisteiden luettelossa olevien tunnisteiden parien keskimääräisenä eroavaisuutena.",
      "id": "task461-a27f2b5b2d1544d6b5fd4010d6eab5b6",
      "output": [
        "miten monimuotoisuutta mitataan?"
      ]
    },
    {
      "input": "Tätä tietoa varten luomme tietopohjan laskemalla, kuinka monta kertaa predikaatti-argumenttitupli esiintyy korpuksessa, ja käytämme tuloksena saatua lukua edustamaan preferenssin voimakkuutta. Käytämme erityisesti englanninkielistä Wikipediaa perusjoukkona tällaista laskentaa varten.",
      "id": "task461-e9d0d54e1f9d4333856cd3f57d71a67c",
      "output": [
        "Mikä on ulkoisen tiedon lähde?"
      ]
    },
    {
      "input": "Vertaamme kiinalaisten sanojen upotusvektoriemme suorituskykyä synonyymien löytämistehtävässä toiseen upotusvektorijoukkoon, joka on muodostettu BIBREF1 -toistuvuusmallin avulla. Myös meidän upotuksemme osoittautuivat paremmiksi kuin vertailutietokantamme.",
      "id": "task461-e71e15f581964c43a3fcbe26fe321b4e",
      "output": [
        "Suoriutuuko tämä lähestymistapa paremmin kuin kontekstiin perustuvat sanojen upotukset?"
      ]
    },
    {
      "input": "BIBREF3:n mukaisesti oletamme, että mBERT:ssä lauseen esitys koostuu kielikohtaisesta komponentista, joka tunnistaa lauseen kielen, ja kielineutraalista komponentista, joka kuvaa lauseen merkityksen kielestä riippumattomalla tavalla. Oletamme, että kielikohtainen komponentti on samankaltainen kaikissa kyseisen kielen lauseissa, joten pyrimme poistamaan kielikohtaisen informaation representaatioista keskittämällä kunkin kielen lauseiden representaatiot siten, että niiden keskiarvo on vektoriavaruuden alkupisteessä. Tämän jälkeen analysoimme sekä alkuperäisten että keskitettyjen representaatioiden semanttisia ominaisuuksia erilaisten koetehtävien avulla.",
      "id": "task461-57fbdd91f23c420984c8a264d4e143d4",
      "output": [
        "Miten he osoittavat, että mBERT-edustukset voidaan jakaa kielikohtaiseen ja kielineutraaliin osaan?"
      ]
    },
    {
      "input": "Kokeissamme käytimme ulkoisena tietopohjana WordNet 3.0 BIBREF9 -tietokantana INLINEFORM0 . Sanojen upotuksia varten kokeilimme kahta suosittua mallia: (1) BIBREF10:n Wikipediaan ja Gigaword 5:een (vocab: 400K, dim: 300) kouluttamat GloVe- upotukset ja (2) Google News -tietokantaan (vocab: 3M, dim: 300) kouluttama w2v-gn, Word2vec BIBREF5. Kattavuuden parantaminen aloitetaan muuntamalla tietopohja INLINEFORM0 vektoriavaruusesitykseksi, joka on verrattavissa korpuspohjaisen INLINEFORM1 -avaruuden esitykseen. Tätä varten käytämme kahta tekniikkaa matalaulotteisten ominaisuusavaruuksien oppimiseen tietämysgraafeista: DeepWalk ja node2vec. DeepWalk käyttää lyhyiden satunnaiskävelyjen virtaa poimiakseen graafista solmun paikallista tietoa. Käsittelemällä näitä kävelyjä lyhyinä lauseina ja lausekkeina erityisellä kielellä lähestymistapa oppii latentteja representaatioita kullekin solmulle. Vastaavasti node2vec oppii solmujen kuvauksen jatkuviin vektoreihin, joka maksimoi todennäköisyyden säilyttää solmujen verkkoympäristöt. Joustavan tavoitteen ansiosta, joka ei ole sidottu tiettyyn näytteenottostrategiaan, node2vec raportoi parannuksia DeepWalkiin verrattuna useissa luokittelu- ja linkkien ennustamista koskevissa tietokokonaisuuksissa. Molemmissa järjestelmissä käytimme oletusparametreja ja asetimme tulostusrepresentaation dimensioksi 100. Huomaa myös, että WordNetin semanttisen graafin solmut edustavat synsettejä. Näin ollen monimerkityksinen sana vastaa useita solmuja. Kokeissamme käytämme BIBREF11:n MaxSim-oletusta sanojen kartoittamiseksi synseteiksi.",
      "id": "task461-ff4b1c2294a74432825c7801f2d5e6aa",
      "output": [
        "Mitä muita upotusmalleja testataan?"
      ]
    },
    {
      "input": "Toisaalta sovellamme formalisointiamme arvioidaksemme monikielisen $\\textsc {bert} $:n syntaksitietämystä kuuden typologisesti erilaisen kielen joukossa. Vaikka se koodaa suuren määrän tietoa syntaksista (yli $81\\%$ kaikilla kielillä), se koodaa vain korkeintaan $5\\%$ enemmän tietoa kuin jokin triviaali perustieto (tyyppitason esitys). Tämä osoittaa, että POS-merkintä (sanatason POS-taggaus) ei ole ihanteellinen tehtävä kontekstuaalisten sanasulkeumien syntaktisen ymmärryksen pohtimiseksi. Näemme, että kaikissa analysoiduissa kielissä tyyppitason upotukset voivat jo nyt kattaa suurimman osan POS-merkinnän epävarmuudesta. Näemme myös, että BERT jakaa vain vähän lisätietoa tehtävän kanssa, ja sen hyöty on pieni (tai jopa negatiivinen) kaikilla kielillä. Lopuksi voidaan todeta, että monikieliset $\\textsc {bert} $:n representaatiot eivät näytä koodaavan paljon enempää tietoa syntaksista kuin triviaali perustaso. $\\textsc {bert} $ parantaa fastTextiä vain kolmessa kuudesta analysoidusta kielestä - ja näissäkin se koodaa (englanniksi) korkeintaan 5 \\% $ lisätietoa.",
      "id": "task461-945e13c8a0eb4720bf8655b59a5c41ac",
      "output": [
        "Oliko tuloksissa havaittavissa kielityypologiaan perustuvaa vaihtelua?"
      ]
    },
    {
      "input": ". Kieliopillisesti oikeaa tekstiä tarvitaan lähtökohdaksi keinotekoisten virheiden lisäämiselle, ja käytimme kahta eri lähdettä: 1) korjatun version samasta FCE-harjoitusjoukosta, johon järjestelmä on koulutettu (450 000 merkkiä), ja 2) esimerkkilauseet, jotka on poimittu English Vocabulary Profile -ohjelmasta (270 000 merkkiä).",
      "id": "task461-c001f76c4beb4089ae4cff3d3d8e91ab",
      "output": [
        "Mitä kieliä tässä asiakirjassa tutkitaan?"
      ]
    },
    {
      "input": "Kuten edellä olevassa esimerkissä, esikäsittelemme asiakirjat poistamalla kaikki numerot ja välimerkit.",
      "id": "task461-da197e40506a453a8b5c09714f6ce9c0",
      "output": [
        "mitä käsittelyä puheille tehtiin ennen niiden jäsentämistä?"
      ]
    },
    {
      "input": "Lähestyimme ensimmäistä ja toista haastetta käyttämällä bayesiläistä lähestymistapaa oppiaksemme, mitkä termit liittyivät tapahtumiin riippumatta siitä, olivatko ne vakiokieliä, lyhenteitä vai jopa keksittyjä sanoja, kunhan ne sopivat kiinnostaviin tapahtumiin. Kolmatta ja neljättä haastetta lähestytään käyttämällä sanapareja, joista poimitaan kaikki kussakin twiitissä esiintyvät sanaparit. Löytääksemme sanat, jotka liittyvät eniten tapahtumiin, etsimme sanoja, jotka saavuttavat suurimman määrän tapahtumapäiviin sopivia piikkejä. ",
      "id": "task461-692b66c2cbe24a1881a6b254b41a5c0e",
      "output": [
        "Miten mielenosoitusten kaltaisiin tapahtumiin liittyvät avainsanat valitaan?"
      ]
    },
    {
      "input": "Luonnollisessa kielessä subjektiivisuudella viitataan niihin viestinnän osa-alueisiin, joita käytetään mielipiteiden, arvioiden ja spekulaatioiden ilmaisemiseenBIBREF0 ja joihin usein vaikuttavat henkilön tunnetila ja näkemykset. Tässä työssä tutkimme BERT-pohjaisten mallien soveltamista subjektiivisen kielen tunnistamiseen. Kokeet ::: Tietoaineisto ja koeasetuksetToteutamme kokeilumme WNC-tietoaineistolla, jonka BIBREF2:n kirjoittajat ovat avoimeen käyttöön luovuttaneet. Se koostuu kohdistetuista neutraalista näkökulmasta tehdyistä Wikipedian toimittajien tekemistä neutraalista näkökulmasta tehdyistä ennen ja jälkeen neutralisoitujen lauseista. Se sisältää $180k$ puolueellisia lauseita ja niiden neutraaleja vastineita, jotka on poimittu $423,823$ Wikipedian tarkistuksista vuosina 2004-2019.",
      "id": "task461-f95590b25cda4ea3907f8e5d12b7b277",
      "output": [
        "Mitä kokeita tehdään?"
      ]
    },
    {
      "input": "EmotionLines BIBREF6 on dialogitietoaineisto, joka koostuu kahdesta osajoukosta, Friends ja EmotionPush, dialogien lähteen mukaan. Ensimmäinen on peräisin Friends-tv-sarjakuvan käsikirjoituksista. Toinen koostuu Facebookin messenger-keskusteluista. ",
      "id": "task461-8ad98e6e99574523b9b77c4f09b94a04",
      "output": [
        "Mitkä ovat tietokokonaisuuksien lähteet?"
      ]
    },
    {
      "input": "Tuloksena saatujen 1,8 miljoonan luettelon perusteella, joissa on noin 169 000 erillistä käyttäjätunnusta, laskemme INLINEFORM0-aiheita sisältävän aihepiirimallin käyttämällä Latent Dirichlet Allocation BIBREF3 -ohjelmaa. Kullekin käyttäjän tunnukselle poimimme todennäköisimmän aiheen päätellystä käyttäjätunnuksen ja aiheen välisestä jakaumasta klusterin id:nä. Tämän tuloksena useimmille taustakorpuksemme käyttäjätunnuksille saadaan temaattinen klusterin id, joka ryhmittää yhteen esimerkiksi amerikkalaisia tai saksalaisia poliittisia toimijoita, muusikoita, mediasivustoja tai urheiluseuroja koskevia tilejä (ks. taulukko TABREF17 ). ",
      "id": "task461-a988b694cafa4217992dd9755388100d",
      "output": [
        "Mitä aiheklustereita LDA tunnistaa?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua arkkitehtuuria kahdella julkisesti saatavilla olevalla tietokokonaisuudella: BIBREF6-tietokokonaisuudella (Adverse Drug Events, ADE) ja BIBREF7-tietokokonaisuudella (CoNLL04). Osoitamme, että arkkitehtuurimme kykenee ADE-tietokannan tapauksessa ylittämään nykyiset huipputason (SOTA) tulokset sekä NER- että RE-tehtävissä. CoNLL04-tietokannan tapauksessa ehdotettu arkkitehtuurimme saavuttaa SOTA-tuloksen NER-tehtävässä ja lähes SOTA-tuloksen RE-tehtävässä. Molemmissa tietokokonaisuuksissa tuloksemme ovat SOTA-tasoa, kun keskiarvo lasketaan molempien tehtävien suorituskyvystä.",
      "id": "task461-3ab6846db2ad4c8c8fe40a3a104a1569",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Tšekin ylimpien tuomioistuinten viittaustietojen saamiseksi oli tarpeen tunnistaa ja poimia viittaukset CzCDC 1.0 -tietokannasta. Koska sekä viitteiden tunnistamismallin BIBREF13, BIBREF34 että tekstin segmentointimallin BIBREF33 harjoitusaineisto on julkisesti saatavilla, pystyimme tekemään kattavan virheanalyysin ja kokoamaan putken, jonka avulla tehtävässä saavutetaan mahdollisimman suuri tehokkuus. Tässä osassa kuvattu putki on esitetty graafisesti kuvassa FIGREF10. Tässä vaiheessa on tarpeen arvioida edellä mainitun putken osan suorituskykyä ennen kuin jatketaan eteenpäin. Suorituskyvyn arviointi esitetään yhteenvetona taulukossa TAULUKKO TABREF11. Siitä käy ilmi, että kahden mallin järjestäminen putkistoon paransi viitetunnistusmallin suorituskykyä, mikä johti korkeampaan F1-arvoon tekstivälien alkutunnistuksessa ja niiden luokittelussa.",
      "id": "task461-1c380e65e27440059bed2943cbd8a760",
      "output": [
        "Miten viittauksen laatua mitataan?"
      ]
    },
    {
      "input": "Käytämme mallien harjoitteluun VisDial v1.0 BIBREF0 -tietokokonaisuutta, jossa yksi esimerkki sisältää kuvan ja sen kuvatekstin, 9 kysymys-vastausparia sekä jatkokysymykset ja vastausehdokkaat jokaisella kierroksella. Kierroksella $r$ kuvatekstistä ja edellisistä kysymys-vastauspareista tulee keskustelukonteksti. Koko tietokokonaisuus on jaettu 123 287/2 000/8 000 kuvaan harjoittelua, validointia ja testausta varten. Toisin kuin harjoitus- ja validointijoukon kuvissa, testijoukon kuvissa on vain yksi jatkokysymys ja vastausehdokkaat sekä niitä vastaava keskustelukonteksti.",
      "id": "task461-8bd9fa9dfad6433f901c8a82c26e4bfb",
      "output": [
        "Kuinka suuri on tämän haasteen tietokanta?"
      ]
    },
    {
      "input": "Toisin kuin SQuAD-tietokannassa, jossa on vain yksi kohta kysymystä kohden, MS-MARCO-tietokannassa on useita toisiinsa liittyviä kohtia kutakin kysymystä kohden. Vastauksen merkitsemisen lisäksi MS-MARCO-tietokannassa merkitään myös, mikä kohta on oikea. ",
      "id": "task461-f011eaf97d344c31aba7e53c70609ba5",
      "output": [
        "Miksi MS-MARCO eroaa SQuADista?"
      ]
    },
    {
      "input": "Keräsimme runojen korpuksen ja kansankielisen kirjallisuuden korpuksen verkkolähteistä. Runokorpus sisältää 163K nelisäkeistä runoa Tang-runoista ja Song-runoista, kansankielisen kirjallisuuden korpus sisältää 337K lyhyttä kappaletta 281 kuuluisasta kirjasta, korpus kattaa eri kirjallisuuden muodot, kuten proosan, fiktion ja esseen. Huomaa, että runokorpuksemme ja kansankielinen korpus eivät ole linjassa keskenään. Jaoimme nämä kaksi korpusta harjoitusjoukkoon ja validointijoukkoon.",
      "id": "task461-7711f45076c546248218b4ab4325e9f4",
      "output": [
        "Mitä tietokokonaisuutta käytetään harjoittelussa?"
      ]
    },
    {
      "input": " Tämän perustason F1-arvo on 41,59 % ja tarkkuus 71,22 %.",
      "id": "task461-02ef3df1fca14b2f8de193cec350e91f",
      "output": [
        "mitkä ovat niiden arviointimittarit?"
      ]
    },
    {
      "input": "Viime aikoina useat tutkijat ovat pyrkineet tutkimaan simultaanikäännösmenetelmiä NMT:n yhteydessä BIBREF6, BIBREF7, BIBREF8, BIBREF9. Jotkut heistä ehdottavat kehittyneitä harjoituskehyksiä, jotka on suunniteltu nimenomaan simultaanikääntämistä varten BIBREF5, BIBREF10. ",
      "id": "task461-ffc92a5586aa4bb88ac60bea45f0dc99",
      "output": [
        "Onko SNMT:tä käsitelty aiemmin?"
      ]
    },
    {
      "input": "Kieli on kiinaa, mikä ei ole helppoa muille kuin kiinaa puhuville tutkijoille.",
      "id": "task461-773ecb70207e424ea64d7e1a9e6f40db",
      "output": [
        "Millä kielellä keskustelut käydään?"
      ]
    },
    {
      "input": "Selitämme mallimme merkittävän suorituskyvyn kasvun perusmalliin verrattuna useiden tekijöiden yhdistelmällä, joita kuvataan jäljempänä:",
      "id": "task461-17eaaa16663f40d6ac7d16ec890e16a2",
      "output": [
        "Kouluttautuvatko he muulla koulutusmenetelmällä kuin suunnitellulla otannalla?"
      ]
    },
    {
      "input": "DQA:ssa neljä osallistujaa vastasi kuhunkin kysymykseen, joten otimme kysymyskohtaiseksi tulokseksi INLINEFORM0-, INLINEFORM1- ja INLINEFORM2-arvojen keskiarvon neljältä arvioijalta.",
      "id": "task461-af00d896523241049d862181e0bcb161",
      "output": [
        "Miten ne mittaavat suorituskykyä?"
      ]
    },
    {
      "input": "NLG-mallien kehittämisen ja arvioinnin helpottamiseksi on ehdotettu erilaisia automaattisia arviointimenetelmiä. Seuraavassa esitetään yhteenveto näistä arviointimenetelmistä. Tekstin päällekkäisyysmittarit, kuten BLEU BIBREF5, METEOR BIBREF6 ja ROUGE BIBREF7, ovat suosituimpia NLG-mallien arvioinnissa käytettyjä mittareita. Perpleksisyyttä käytetään yleisesti kielimallin laadun arviointiin. Parametrisoidut metriikat oppivat parametrisoidun mallin tuotetun tekstin arvioimiseksi.",
      "id": "task461-26f07fd8568547db956ab2d2f68f0ab7",
      "output": [
        "Mitä aiempia automatisoituja arviointimenetelmiä kirjoittajat mainitsevat?"
      ]
    },
    {
      "input": "Termi \"propaganda\" tulee klassisen ajan jälkeisen latinan sanasta propagare, kuten \"uskon levittäminen\" BIBREF1, ja se on siten alusta alkaen liitetty tarkoitukselliseen ja mahdollisesti monilähetysviestintään; vasta myöhemmin siitä tuli halventava termi. Toisen maailmansodan aikakaudella se määriteltiin pragmaattisesti seuraavasti: \"yksilöiden tai ryhmien mielipiteen ilmaiseminen tai toiminta, jonka tarkoituksena on tarkoituksellisesti vaikuttaa toisten yksilöiden tai ryhmien mielipiteisiin tai toimintaan ennalta määrättyihin päämääriin viitaten\" BIBREF2.",
      "id": "task461-1f3ff6d88cb3441b86827ab35e62136f",
      "output": [
        "Miten \"propaganda\" määritellään tässä tutkimuksessa?"
      ]
    },
    {
      "input": "Perustasomme on GRU-verkko kutakin kolmea tehtävää varten.",
      "id": "task461-cdd05ded7d2341c5a67d64ba65357e76",
      "output": [
        "Verrataanko malleja joihinkin perusmalleihin?"
      ]
    },
    {
      "input": "Diskurssipiirteiden johtamiseksi rakennetaan entiteettiruudukko syöttämällä asiakirja NLP-putken läpi, jotta voidaan tunnistaa erottuvat entiteetit. Kaksi erilaista diskurssipiirrettä luodaan täyttämällä olioruudukko joko i) kieliopillisilla suhteilla (GR) tai ii) RST-diskurssisuhteilla (RST). ",
      "id": "task461-2e3c4956dd604910ba50b22287e9ab35",
      "output": [
        "Mitä diskurssipiirteitä käytetään?"
      ]
    },
    {
      "input": "Regressorina käytettiin tukivektoriregressiota (SVR) ja luokittelijana tukivektoriluokitusta (SVC). Taulukon TABREF26 alaosassa esitetään neuroarkkitehtuurin eri vaihtoehtojen tulokset. Taulukko sisältää neuraalisen regressorin (NNR) ja neuraalisen luokittelijan (NNC). ",
      "id": "task461-d7ee0d3325c340cdb30ef5a911aab244",
      "output": [
        "Mitä lähestymistapoja ilman vahvistusoppimista on kokeiltu?"
      ]
    },
    {
      "input": "Tutkimuksessamme valitsemme uusimman merkkibigrammaattisen CNN-luokittimen BIBREF4 ja tutkimme eri tapoja, joilla diskurssitieto voidaan featurisoida ja integroida CNN:ään. ",
      "id": "task461-ecf8b91f291e4b428962ff78dfb9c647",
      "output": [
        "Mikä oli edellinen huipputekniikka?"
      ]
    },
    {
      "input": "Tässä artikkelissa esitellään automaattinen \"rötöstelytekstien ennustaminen\" laskennallisena tehtävänä. Tavoitteena on tunnistaa automaattisesti, onko twiitti humalaisen käyttäjän kirjoittama. ",
      "id": "task461-de28be7596b34207b31598a2f59d986e",
      "output": [
        "Asettavatko kirjoittajat humalaisen twiittaamisen ja humalaisen tekstiviestittelyn samalle viivalle? "
      ]
    },
    {
      "input": "Kaiken kaikkiaan MMM on saavuttanut uuden SOTA- eli testitarkkuuden 88,9 %, joka ylittää aiemman parhaan tuloksen 16,9 %:lla.",
      "id": "task461-c70c72a9d3f6417ebfc9ba75ba1deeaa",
      "output": [
        "Kuinka suuria ovat MMM:n parannukset nykyiseen tekniikkaan verrattuna?"
      ]
    },
    {
      "input": "He voivat vastata kuhunkin kysymykseen joko \"kyllä\", \"pikemminkin kyllä\", \"pikemminkin ei\" tai \"ei\". He voivat täydentää jokaista vastausta enintään 500 merkin mittaisella kommentilla.",
      "id": "task461-559e8795c5754e6fbd210aa21d1f8472",
      "output": [
        "Mitä merkintöjä aineistossa on?"
      ]
    },
    {
      "input": "Mallimme sai ensimmäisen sijan saksankielisessä osatehtävässä makro-F1-pistemäärällä 0,62.",
      "id": "task461-2b9d7ca35f9b4f6483efd9508b4bcc38",
      "output": [
        "Mikä on mallin suorituskyky saksalaisen osatehtävän A osalta?"
      ]
    },
    {
      "input": "Arvioimme osoitingeneraattorimme suorituskykyä BLEU-pisteiden avulla. Peruskielimalli on koulutettu käyttämällä RNNLM BIBREF23 -ohjelmaa. Arvioinnissa käytetään perpleksisyysmittaa.",
      "id": "task461-dffa725c9a614cc0b386af6de809671c",
      "output": [
        "Käytettiinkö muita arviointimittareita?"
      ]
    },
    {
      "input": "Tämän hypoteesin testaamiseksi koulutimme ensin UG-WGANin englanniksi, kiinaksi ja saksaksi kohdassa \"UG-WGAN\" kuvatun menettelyn mukaisesti. Tätä kokeilua varten koulutimme UG-WGANin englannin ja venäjän kielelle kohdassa \"UG-WGAN\" kuvatun menettelyn mukaisesti.  Tätä varten koulutimme 6 UG-WGAN-mallia seuraavilla kielillä: Englanti, venäjä, arabia, kiina, saksa, espanja ja ranska.",
      "id": "task461-a62a385fbef84abeae4bc510184b611a",
      "output": [
        "Mitä kieliä he tarkastelevat tässä asiakirjassa?"
      ]
    },
    {
      "input": "Mallin tislausta varten BIBREF6 poimitaan Wikipediasta lauseita kielillä, joita varten julkinen monikielinen on esivalmennettu. Kunkin lauseen osalta käytämme avoimen lähdekoodin BERT-sanakappaleiden tokenisoijaa BIBREF4 , BIBREF1 ja laskemme ristiinentropiahäviön kullekin sanakappaleelle: INLINEFORM0jossa INLINEFORM0 on risti-entropiafunktio, INLINEFORM1 on softmax-funktio, INLINEFORM2 on BERT-mallin logit nykyiselle sanakappaleelle, INLINEFORM3 on pienen BERT-mallin logit ja INLINEFORM4 on lämpötilahyperparametri, joka selitetään luvussa SECREF11. Tislattua monikielistä mallia mMiniBERT harjoitellaksemme käytämme ensin edellä mainittua tislaustappiota kouluttaaksemme oppilaan tyhjästä käyttäen opettajan logituksia merkitsemättömällä datalla. Sen jälkeen hienosäädämme oppilaan mallia opettajan koulutetulla merkityllä datalla.",
      "id": "task461-e3c86bef9fad486f9122f6661fe1c2ed",
      "output": [
        "Miten malli tiivistetään?"
      ]
    },
    {
      "input": "Monivalintakysymyksissä, jotka ovat kysymys-vastaus -tapaus, johon keskitymme tässä artikkelissa, optimaalisten vastausvaihtoehtojen valintaan liittyy myös pragmaattista päättelyä (esim. vaikka kasvihuoneilmiö saattaisi jossakin muussa yhteydessä olla järkevä vastaus kuvassa FIGREF1 esitettyyn toiseen kysymykseen, ilmaston lämpeneminen on suositeltavampi vaihtoehto).",
      "id": "task461-285d1c77ca3149c6b1d97a51e5debe03",
      "output": [
        "Keskitytäänkö niissä luetun ymmärtämiseen vai monivalintakysymyksiin vastaamiseen?"
      ]
    },
    {
      "input": "Kaikissa kokeissamme käytimme valmiita BERT-malleja ilman tehtäväkohtaista hienosäätöä.",
      "id": "task461-651f9f8bc0534f1e85a5a56087313da5",
      "output": [
        "Miten heidän mallinsa eroaa yhteistyöelimen mallista?"
      ]
    },
    {
      "input": "Kouluttaaksemme parhaan mallin valitsimme parhaan verkon kokeiluistamme (6-kerroksinen bLSTM, jossa on 1024 piilotettua yksikköä), koulutimme sen Adam-optimointilaitteella ja hienosäädimme sen SGD:llä, jossa käytetään eksponentiaalista oppimisnopeuden hidastumista.",
      "id": "task461-0bf995734ccd4ad29eeea52e154566b2",
      "output": [
        "Mikä arkkitehtuuri on heidän paras mallinsa?"
      ]
    },
    {
      "input": "Myös muiden esimerkkien manuaalinen tarkastelu tukee väitettämme.",
      "id": "task461-64fccdcf0c5944cf833da232fe9a0dde",
      "output": [
        "Suorittavatko ne manuaalisen arvioinnin?"
      ]
    },
    {
      "input": "Tunnelma: Kunkin klusterin yleinen sentimenttipistemäärä määritetään kaikkien twiittien sentimenttipisteiden keskiarvona.",
      "id": "task461-8307f7622b814aad8404a74c3dde45ff",
      "output": [
        "Miten tunteiden napaisuus mitataan?"
      ]
    },
    {
      "input": "Aiemmista töistä poiketen teemme mallistamme käsitteellisesti yksinkertaisen ja modulaarisen, jotta tärkein alamoduuli, nimittäin viiden merkin ikkunakonteksti, voidaan esivalmentaa ulkoisten tietojen avulla. ",
      "id": "task461-e46cb071e0c1486c9d908bd3a4e4cd20",
      "output": [
        "Mistä alamoduuleista malli koostuu?"
      ]
    },
    {
      "input": "IDEABIBREF9 Kehitettiin kaksi erilaista BERT-mallia. Friends-mallia varten tehtiin esiharjoittelu käyttäen kahden lausuman liukuvaa ikkunaa, jotta saatiin dialogin konteksti. Molemmissa Next Sentence Prediction (NSP) -vaiheessa käytettiin täydellisiä merkitsemättömiä käsikirjoituksia kaikista Friends-sarjan kymmenestä tuotantokaudesta, jotka ovat ladattavissa. Lisäksi malli oppi kunkin Friendsin kuuden päähenkilön (Rachel, Monica, Phoebe, Joey, Chandler ja Ross) tunnetason lisäämällä puhujaa kuvaavan merkin. EmotionPushia varten esiharjoittelu suoritettiin Twitter-datalla, koska se on luonteeltaan samanlainen kuin chat-pohjaiset dialogit. Molemmissa tapauksissa kiinnitettiin erityistä huomiota luokkien epätasapainoon soveltamalla \"painotettua tasapainoista lämpenemistä\" tappiofunktioon.",
      "id": "task461-bc37e8c38d014185aa526da5a4d6f273",
      "output": [
        "Mitä mallia huipputiimi käytti?"
      ]
    },
    {
      "input": "Keräämme tietoja käyttämällä Twitterin API:ta tallennettuja tietoja varten, jotka ovat julkisessa käytössä. Kokeilujamme varten keräämme 3200 twiittiä, jotka on suodatettu avainsanoilla kuten \"tulipalo\", \"maanjäristys\", \"varkaus\", \"ryöstö\", \"rattijuopumus\", \"rattijuopumusonnettomuus\" jne. ",
      "id": "task461-557894b3a18e46a4a46fd30d674bca61",
      "output": [
        "Ovatko twiitit peräisin keneltäkään yksittäiseltä henkilöltä?"
      ]
    },
    {
      "input": "Annotointia varten loimme esimerkissä 1 ja 2 esitettyjen keskustelujen kaltaisia katkelmia, jotka koostuivat epäillyn trollaustapahtuman vanhemmasta osapuolesta, epäillyn trollaustapahtuman kommentista ja kaikista epäiltyyn trollaustapahtumaan annetuista suorista vastauksista. Tämänkaltaiset pätkät mahdollistavat kuitenkin sen, että voimme hyödyntää Amazon Mechanical Turk (AMT) -palvelua tietokokonaisuuden annotoinnissa, koska \"turkkilaiselle\" ei ole suuri taakka työskennellä yksittäisen pätkän parissa pientä palkkaa vastaan ja koska annotointiprosessi nopeutuu, kun se jaetaan kymmenille ihmisille. Pyysimme kolmea annotoijaa merkitsemään kutakin katkelmaa varten neljä aiemmin kuvattua näkökohtaa.",
      "id": "task461-83f05edbc72b424883f4c19c2957194c",
      "output": [
        "miten merkinnät tehtiin?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa keskitymme arvioimaan uudelleen avainsanojen louhinnan suorituskykyä kolmella yhä kehittyneemmällä asiakirjojen esikäsittelyn tasolla, jotka kuvataan jäljempänä.",
      "id": "task461-472967b10d874beea6807775205d7927",
      "output": [
        "mitä avainsanojen louhintamalleja arvioitiin uudelleen?"
      ]
    },
    {
      "input": "Koska meillä ei ole koko aineistoa, luotu englanninkielinen runo ei välttämättä toimi hyvin Shakespearen tyylinsiirron kanssa, kuten kuvassa FIGREF12 näkyy \"Starry Night\" -runon kohdalla, jonka keskimääräinen sisältöpistemäärä on alhainen. Näin käy, kun tyylinsiirtotietokannassa ei ole samanlaisia sanoja harjoituslausejoukossa. Ratkaisu olisi laajentaa tyylinsiirtotietokokonaisuutta, jotta se edustaisi paremmin runoaineistoa.",
      "id": "task461-5713065247a344deaf3b7f51aa1f7e43",
      "output": [
        "Millaisia rajoituksia kirjoittajat osoittavat mallissaan?"
      ]
    },
    {
      "input": "Kuvassa FIGREF23 esitetään ehdotettu ontologia, joka arviointimenettelyssämme täytettiin 3121 tapahtumamerkinnällä 51 asiakirjasta.",
      "id": "task461-8e65d51778154c31b50c9728966f7946",
      "output": [
        "Miten tämän putkilinjaisen lähestymistavan tehokkuutta arvioidaan?"
      ]
    },
    {
      "input": "Tässä asiakirjassa esitämme lyhyen katsauksen olemassa oleviin tietokokonaisuuksiin ja kuvaamme CRWIZ-kehyksen, jonka avulla voidaan yhdistää joukko-osallistujia ja saada puolet heistä toimimaan velhoina rajoittamalla heidän vuoropuheluvaihtoehtonsa vain asiaankuuluviin ja uskottaviin vaihtoehtoihin vuorovaikutuksen kussakin vaiheessa Dialogin rakenne: otimme käyttöön strukturoidut vuoropuhelut äärellisen tilakoneen (FSM) avulla, joka ohjaa vuoropuhelun nykyistä tilaa ja tarjoaa velholle useita sopivia ja asiaankuuluvia tilasiirtymiä (toimia) vuorovaikutuksen kohdasta, maailman tilasta ja historiasta riippuen. Dialogitilojen, siirtymien ja lausumien graafi ladataan, kun järjestelmä käynnistetään, ja jokaisella keskusteluhuoneella on oma dialogitilansa, joka muuttuu toimintojen kautta.",
      "id": "task461-d58a5cf85f20413ca49c32cc5b7b8a1d",
      "output": [
        "Miten vuoropuhelua ohjataan siten, että vältetään vuorovaikutusta, joka rikkoo menettelyjä ja prosesseja, jotka ovat vain asiantuntijoiden tiedossa?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa tutkimme ehdotettujen mallien suorituskykyä WSJ BIBREF5 -tietokannassa. ",
      "id": "task461-bd81340c1e504d148f00e94c9c334485",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "on tavanomainen sanojen laskentamenetelmä, jossa ominaisvektori edustaa lauseen sanojen termifrekvenssiä. on samanlainen kuin BoW, paitsi että se on johdettu laskemalla lauseen sanat painotettuna yksittäisen sanan termifrekvenssillä ja käänteisellä dokumenttitaajuudella BIBREF31 . on johdettu k-means-menetelmällä tehdystä sanojen yhdistelmien klusteroinnista 5000 klusteriin, ja sen jälkeen BoW-edustus 5000 klusterin sanoista.",
      "id": "task461-957efcdfbe69468591fd230a4930ebb0",
      "output": [
        "Mihin muihin ei-neuraalisiin perusjoukkoihin kirjoittajat vertaavat? "
      ]
    },
    {
      "input": " 2) Vastaukset ovat oikeudellisen koulutuksen saaneiden asiantuntijoiden laatimia. ",
      "id": "task461-ea6ba31f79c143fd92c28184e745e172",
      "output": [
        "Ovatko asiantuntijat verrattavissa reaalimaailman käyttäjiin?"
      ]
    },
    {
      "input": " Tietojemme mukaan tämä on ensimmäinen laajamittainen uudelleenkäytettävissä oleva lauseiden esitysmalli, joka on saatu yhdistämällä joukko harjoitustavoitteita, jotka ovat yhtä monipuolisia kuin tässä tutkitut, eli monikielinen NMT, luonnollisen kielen päättely, konstituutiojäsennys ja ohitusajatusvektorit.",
      "id": "task461-08748b7407064bb9b3543485e5f3a86b",
      "output": [
        "Mitä koulutustavoitteita ne yhdistävät?"
      ]
    },
    {
      "input": "Etsimme porttien ohjaamaa funktiota, joka voi sekoittaa tiloja eri aika-askeleissa mutta joka vaikuttaa itsenäisesti tilavektorin jokaiseen kanavaan. Yksinkertaisin vaihtoehto, jota BIBREF12 kutsuu nimellä \"dynamic average pooling\", käyttää vain unohdusporttia: DISPLAYFORM0",
      "id": "task461-c828ae947d034c83a1039c133a61f1e5",
      "output": [
        "Mitä pooling-funktiota käytetään?"
      ]
    },
    {
      "input": "Lopuksi verrattiin 50. epookissa saatua Skip-gram-mallia W10N20 kahteen muuhun kirjallisuudessa esiintyvään italian kielen W2V-malliin (BIBREF9 ja BIBREF10). Ensimmäinen testi (taulukko TABREF15) suoritettiin ottaen huomioon kaikki analogiat ja arvioimalla näin ollen virheeksi kaikki analogiat, jotka eivät olleet toteutettavissa (koska ne liittyivät yhteen tai useampaan sanaan, jotka puuttuivat sanastosta) Kuten voidaan nähdä, käytetystä mittarista riippumatta mallimme saavutti huomattavasti parempia tuloksia kuin kaksi muuta mallia sekä kokonaisuutena että kahdella makroalueella.",
      "id": "task461-eacbf57699574ab28e7ba1722d5294e6",
      "output": [
        "Arvioidaanko sanojen upotuksia?"
      ]
    },
    {
      "input": "Baturo et al. UNGAspeeches -tietokokonaisuus UNGAspeeches sisältää tekstin 7 507 puheesta, jotka on pidetty vuosina 1970-2015.",
      "id": "task461-25a13ee7a5e540e180eeabeb9b9f07b9",
      "output": [
        "kuinka monta puhetta aineistossa on?"
      ]
    },
    {
      "input": "Tietokanta: Ainoassa saatavilla olevassa merkityssä tietokokonaisuudessa oli 3189 riviä tekstiviestejä, joiden keskipituus oli 116 sanaa ja vaihteluväli 1 1295 sanaa.",
      "id": "task461-b71cc731e3af44998a3a693019ad6883",
      "output": [
        "Kuinka suuri tietokokonaisuus on?"
      ]
    },
    {
      "input": "Englanninkielistä tietokokonaisuutta varten poimimme 687 kyberturvallisuusartikkelia APT-raporttien (Advanced Persistent Threats, kehittyneet pysyvät uhkat) kokoelmasta, joka on julkaistu vuosina 2008-2018. ",
      "id": "task461-61a424a9ab144daf96c3990f759f7535",
      "output": [
        "Mistä mallissa käytetyt kyberturvallisuusartikkelit ovat peräisin?"
      ]
    },
    {
      "input": "DeepMine-tietokanta koostuu kolmesta osasta. Ensimmäinen osa sisältää kiinteitä yleisiä lauseita tekstiriippuvaista puhujan todentamista varten. Toinen osa koostuu satunnaisista sanasarjoista, joita voidaan käyttää tekstin avulla tapahtuvaan puhujan todentamiseen, ja viimeinen osa sisältää lauseita, joissa on sana- ja foneemitason transkriptio ja joita voidaan käyttää tekstistä riippumattomaan puhujan todentamiseen satunnaisen lausekkeen avulla (kuten RedDotsin osa 4). DeepMine-tietokannan osat ::: Osa1 - Tekstiriippuvainen (TD)Tämä osa sisältää joukon kiinteitä lauseita, joita käytetään puhujien todentamiseen tekstiriippuvaisessa tilassa. Kukin puhuja lausuu 5 persialaista lausetta, ja jos puhuja osaa lukea englantia, tallennetaan myös 5 RedDots-tietokannan osasta1 valittua lausetta.Olemme luoneet kolme koeasetelmaa, joissa on eri määrä puhujia arviointijoukossa. Samoin kuin tekstiriippuvaisessa tapauksessa, on määritelty kolme koeasetelmaa, joissa on eri määrä puhujia arviointijoukossa (vastaa taulukon TABREF16 rivejä). Kokeiden määrittelyssä käytetään kuitenkin erilaista strategiaa: Riippuen ilmoittautumisehdosta (1- tai 3-sessio), kokeet ilmoitetaan kaikkien sanojen lausumilla 1 - 3 eri istunnosta (eli 3 - 9 lausumaa). Lisäksi tarkastelemme kahta testi-ilmaisuja koskevaa ehtoa: seq-testi-ilmaisu, jossa on vain 3 tai 4 sanaa, ja täydelliset testi-ilmaisut, joissa on kaikki sanat (eli samat sanat kuin ilmoittautumisessa, mutta eri järjestyksessä). Luimme nauhoitussessioiden perusteella kaksi koeasetelmaa puhujan todentamista varten. Ensimmäisessä niistä vastaajat, joilla on vähintään 17 nauhoitussessiota, sisältyvät arviointijoukkoon, vastaajat, joilla on 16 nauhoitussessiota, kehitykseen ja loput vastaajista taustajoukkoon (voidaan käyttää harjoitusaineistona). Toisessa asetelmassa vastaajat, joilla on vähintään 8 istuntoa, sisällytetään arviointijoukkoon, vastaajat, joilla on 6 tai 7 istuntoa, kehitykseen ja loput vastaajista tausta-aineistoon. kaksi kokeellista asetelmaa puhujan todentamiseksi.",
      "id": "task461-398fc894b2c448069988a94ded6a3a6e",
      "output": [
        "mitä arviointiprotokollia tarjotaan?"
      ]
    },
    {
      "input": "Keskusteluagenttimme käyttää kahta arkkitehtuuria simuloidakseen erikoistunutta muistiterapeuttia. Kysymysten luomisesta vastaava lohko perustuu teokseen Show, Attend and Tell BIBREF13. Tämä työ tuottaa kuvista kuvauksia, joita kutsutaan myös kuvateksteiksi.",
      "id": "task461-b710db67339f49cda3d03bef2939ba0b",
      "output": [
        "Onko koneoppimisjärjestelmä alla samanlainen kuin kuvatekstien ML-järjestelmät?"
      ]
    },
    {
      "input": "Sen vuoksi päätimme koota omat korpuksemme englanninkielisistä asiakirjoista, jotka keräsimme eri julkisista lähteistä.",
      "id": "task461-a94f5b61a40c40f69bc6e1914221fe5a",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tiedoista?"
      ]
    },
    {
      "input": "Sisällytämme tyypitystiedot yhdistämällä kunkin syötesymbolin upotusvektoriin yhden kolmesta upotusvektorista, S, E tai R, jossa S on yhdistetty rakenteellisiin elementteihin (avaavat ja sulkeutuvat sulkeet), E entiteettisymboleihin ja R relaatiosymboliin.",
      "id": "task461-c934d0b2686749858defd99ba9ebef63",
      "output": [
        "Miten kirjoitusvihjeitä ehdotetaan?"
      ]
    },
    {
      "input": "Taulukossa TABREF18 esitetään tulokset loukkaavien (OFF) ja ei-loukkaavien (NOT) viestien erottelussa. Kaikkien järjestelmien suorituskyky on huomattavasti parempi kuin sattumanvarainen, ja neuraaliset mallit ovat huomattavasti parempia kuin SVM. CNN päihittää RNN-mallin, ja sen makro-F1-pistemäärä on 0,80. CNN-järjestelmä saavutti tässä kokeessa paremman suorituskyvyn kuin BiLSTM, jonka makro-F1-pistemäärä oli 0,69. Kaikki järjestelmät suoriutuivat paremmin kohteiden ja uhkien (TIN) kuin kohdentamattomien rikosten (UNT) tunnistamisessa.",
      "id": "task461-571c64baf0c545228b2803a3f3f2bd77",
      "output": [
        "Mikä on parhaiten toimiva malli?"
      ]
    },
    {
      "input": "ICSI:n kokouskorpus BIBREF11 on kokoelma kokoustallenteita, jotka on annotoitu perusteellisesti, mukaan lukien annotaatiot osallistumisen hot spots BIBREF12 -kohtiin, kielelliset lausumayksiköt ja sanojen aikarajat, jotka perustuvat pakotettuun kohdistamiseen. Aineisto koostuu 75 kokouksesta ja noin 70 tunnin reaaliaikaisesta äänitiedostosta, jossa on keskimäärin 6 puhujaa kokousta kohden. Suurin osa osallistujista on hyvin tuttuja ja ystävällisiä keskenään. Kuumat kohdat annotoitiin alun perin kahdeksalla tasolla ja asteella, jotka vaihtelivat tasoista \"ei kuuma\" ja \"lämmin\" tasoihin \"kuuma +\". Yksi annotoija merkitsi jokaisen lausuman yhdellä näistä erillisistä merkinnöistä. Korostunut osallistuminen on harvinaista, sillä se on merkitty vain 1 prosenttiin lausumista.",
      "id": "task461-787ce91df6854bd0b397a5be578bea9f",
      "output": [
        "Kuinka suuri on ICSI-kokouskorpus?"
      ]
    },
    {
      "input": "Aukkotäyttömallit ovat hyödyllinen menetelmä yksinkertaisissa luonnollisen kielen ymmärtämistehtävissä, joissa lauseesta voidaan poimia tietoa ja käyttää sitä jonkin strukturoidun toiminnon suorittamiseen. Ehdokkaina tehtäviksi katsotaan toimet, joita käyttäjä voi suorittaa puhelimensa sovellusten avulla. Kerättiin joukkoresurssi-dataa, jossa simuloitiin neljän eri sovelluksen yleisiä käyttötapauksia: United Airlines, Airbnb, Greyhound-bussipalvelu ja OpenTable. Vastaavat toiminnot ovat lennon varaaminen, asunnon vuokraaminen, bussilippujen ostaminen ja ravintolavarauksen tekeminen.",
      "id": "task461-dddda91082dc4eb08f8321f69ef86955",
      "output": [
        "Mitä tehtäviä he kokeilevat tässä asiakirjassa?"
      ]
    },
    {
      "input": "TweetLID-työpajan yhteisessä tehtävässä vaaditaan järjestelmiä tunnistamaan espanjaksi (es), portugaliksi (pt), katalaaniksi (ca), englanniksi (en), galegoiksi (gl) ja baskiksi (eu) kirjoitettujen twiittien kieli. ",
      "id": "task461-7479887c02334edc9df86d781eb35106",
      "output": [
        "Missä yhteisessä tehtävässä tämä järjestelmä saavuttaa SOTA:n?"
      ]
    },
    {
      "input": "Keräämme kolmen vuoden verkkouutisartikkelit kesäkuusta 2016 kesäkuuhun 2019.",
      "id": "task461-a117dd78233b4691a12348d7e3bd1f5a",
      "output": [
        "Mitä merkitsemätöntä korpusta he käyttivät?"
      ]
    },
    {
      "input": "Käytämme monialueen polariteettiluokituskokeissa monialueen aistimustietoaineiston (Multi-Domain Sentiment Dataset BIBREF0) toista versiota. Aineisto sisältää Amazonin tuotearvosteluja neljältä eri toimialueelta: Kirjat (B), DVD:t (D), elektroniikka (E) ja keittiökoneet (K). Arvostelut sisältävät tähtiluokituksia (1-5), jotka muunnetaan binäärimerkinnöiksi seuraavasti: yli 3 tähteä saaneet arvostelut merkitään positiivisiksi ja alle 3 tähteä saaneet negatiivisiksi. Kullakin alueella on 1000 positiivista ja 1000 negatiivista arviota.",
      "id": "task461-84f80dd1bb9845faaac039dcda6d6b9c",
      "output": [
        "Kuinka pitkä tietokokonaisuus on?"
      ]
    },
    {
      "input": "Kunkin skenaarion tarinat jaettiin neljän eri kommentoijan kesken. ",
      "id": "task461-eca20efcc33d48b99e97c7403a801f55",
      "output": [
        "Kuinka monta aihetta on käytetty huomautusten laatimiseen?"
      ]
    },
    {
      "input": "Arvioidaksemme mallimme kykyä käsitellä kiinan kieltä testasimme LCF-ATEPC:n suorituskykyä myös neljällä kiinalaisella kommenttikokoelmalla BIBREF35, BIBREF36 ja BIBREF29 (auto, puhelin, kannettava tietokone, kamera).",
      "id": "task461-8aa0252916c84eafa4120430c8bdeb89",
      "output": [
        "Missä neljässä kiinalaisessa katsaustietoaineistossa LCF-ATEPC saavuttaa huipputason?"
      ]
    },
    {
      "input": "WikiSmall koostuu tavallisista ja yksinkertaistetuista lauseista tavallisista ja yksinkertaisista englanninkielisistä Wikipedioista, joita on käytetty vertailukohtana tekstin yksinkertaistamisen arvioinnissa BIBREF17 , BIBREF18 , BIBREF8 . Harjoitusjoukossa on 89 042 lauseparia, ja testijoukossa on 100 lauseparia. WikiLarge on myös Wikipedian korpuksesta, jonka harjoitusjoukko sisältää 296 402 lauseparia BIBREF19 , BIBREF20 . WikiLarge sisältää 8 (viite)yksinkertaistusta 2 359 lauseelle, jotka on jaettu 2 000:een kehitettävään ja 359:ään testattavaan lauseeseen.",
      "id": "task461-cac755bbc949465e85ebb98d9cfc7ddc",
      "output": [
        "Mikä on molempien tietokokonaisuuksien koko?"
      ]
    },
    {
      "input": "Kuvassa FIGREF4 esitetään seitsemän kysymystyypin jakaumat, jotka on ryhmitelty deterministisesti sanakirjojen perusteella.",
      "id": "task461-2afc6cbe927e40a1906f479e8bad0b1f",
      "output": [
        "Kuinka monta kysymystyyppiä he löytävät analysoiduista tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Käytämme Universal Dependencies (UD) -puistopankkien (tiedostomuodon $4^\\text{th}$ ja $6^\\text{th}$ sarakkeiden yhteenliittäminen) BIBREF13 tarjoamia morfologisia merkintätietokantoja.",
      "id": "task461-5558cb8e7d124d659e78b7883b10c54c",
      "output": [
        "Millä aineistolla koe suoritetaan?"
      ]
    },
    {
      "input": "Havaitsimme kuitenkin, että näiden upotusten alustaminen vektoreilla, jotka oli koulutettu etukäteen suurella kokoelmalla merkitsemätöntä dataa, paransi suorituskykyä merkittävästi (ks. kohta \"Alustettujen upotusten ja korruptoituneiden näytteenottojärjestelmien vaikutukset\" ).",
      "id": "task461-2d43e5b7f9c84bbbb902e0b81fc02c7d",
      "output": [
        "Mikä on tässä asiakirjassa ehdotettu uusi alustamismenetelmä?"
      ]
    },
    {
      "input": "Kohdeaineistomme koostuu kotiutusyhteenvedoista, sisäänpääsymuistiinpanoista, yksittäisten tapaamisten muistiinpanoista ja muista kliinisistä muistiinpanoista, jotka ovat peräisin 220:ltä McLean Hospitalin OnTrackTM-ohjelmaan kuuluvalta potilaalta. OnTrackTM on avohoito-ohjelma, jossa keskitytään hoitamaan 18-30-vuotiaita aikuisia, joilla on ensimmäiset psykoosijaksot. Ohjelman kesto vaihtelee potilaan voinnin paranemisen ja vakuutusturvan mukaan, ja se on keskimäärin kahdesta kolmeen vuotta. Ohjelmassa keskitytään ensisijaisesti varhaiseen puuttumiseen yksilöterapian, ryhmäterapian, lääkityksen arvioinnin ja lääkehoidon avulla. Katso taulukko TABREF2, jossa on 220 potilaan demografinen jaottelu, joista olemme tähän mennessä poimineet yhteensä noin 240 000 EHR-kohtaa vuosilta 2011-2014 käyttämällä Meditech-ohjelmistoa, jota McLean käyttää EHR-tietojen tallentamiseen ja järjestämiseen.Nämä potilaat ovat osa laajempaa, noin 1800 psykoosipotilaan tutkimuskohorttia, jonka avulla voimme yhdistää tämän EHR-tutkimuksen tulokset muihin meneillään oleviin tutkimuksiin, joissa otetaan huomioon geneettisiä, kognitiivisia, neurobiologisia ja toiminnallisia tuloksia koskevat tiedot tästä kohortista.Käytämme vektoriavaruusmallimme kouluttamiseen myös lisätietoaineistoa, joka koostuu EHR-teksteistä, jotka on haettu Research Patient Data Registrystä (RPDR), joka on keskitetty alueellinen tietovarasto, johon on koottu kliinisiä tietoja kaikista Partners HealthCare -verkoston laitoksista. Nämä tietueet ovat tyyliltään ja sanastoltaan hyvin vertailukelpoisia kohdetietoaineistomme kanssa. Korpus koostuu kotiutusyhteenvedoista, kohtaamismuistiinpanoista ja käyntimuistiinpanoista noin 30 000 potilaasta, jotka on otettu järjestelmän sairaaloihin psykiatristen diagnoosien ja oireiden perusteella. Tämä laaja aineisto kattaa monenlaisia kliinisiä kertomuksia, mikä luo kattavan perustan aiheiden poimimiselle.",
      "id": "task461-1e3daec1362e41c58bc76d00c8cafd4d",
      "output": [
        "Mitä tietokokonaisuuksia kirjoittajat käyttivät?"
      ]
    },
    {
      "input": "Sen jälkeen ehdotamme ryhmää uusia mielenkiintoisia tehtäviä, kuten analogiakyselyä ja analogian selausta, ja keskustelemme siitä, miten niitä voidaan käyttää nykyaikaisissa digitaalisissa kirjastoissa.",
      "id": "task461-37885c803a9e4bf58653ccd3ed25c135",
      "output": [
        "Millaisia uusia mielenkiintoisia tehtäviä voidaan ratkaista upotusavaruuden kummallisten semanttisten rakenteiden perusteella?"
      ]
    },
    {
      "input": "Arvioimme sitten kohdeyksiköiden $t$:n sijat yleisesti käytetyillä keskiarvolla (mean rank, MR), keskimääräisellä vastavuoroisella sijalla (mean reciprocal rank, MRR) sekä osumilla Hits@1, Hits@3 ja Hits@10.",
      "id": "task461-a651ad3108b245ddaf46910bd822d02d",
      "output": [
        "mitä arviointimittareita tässä työssä tutkittiin?"
      ]
    },
    {
      "input": "CoinCollector BIBREF8 on tekstipohjaisten pelien luokka, jossa tavoitteena on löytää ja kerätä kolikko tietystä paikasta tietyssä yhdistettyjen huoneiden joukossa. Agentti voittaa pelin kerättyään kolikon, jolloin (ensimmäisen ja ainoan kerran) agentti saa palkkioksi +1. Ympäristö jäsentää vain viisi sallittua käskyä (mene pohjoiseen, mene itään, mene etelään, mene länteen ja ota kolikko), jotka on tehty kahdesta maailmasta; CookingWorld BIBREF14 tässä haasteessa on 4440 peliä, joissa on 222 erilaista vaikeustasoa ja 20 peliä vaikeustasoa kohden, joissa jokaisessa on erilaisia entiteettejä ja karttoja. Kunkin pelin tavoitteena on valmistaa ja syödä ruokaa annetusta reseptistä, mikä sisältää tehtävän kerätä ainesosia (esim. tomaatti, peruna jne.), esineitä (esim. veitsi) ja käsitellä niitä reseptin mukaisesti (esim. keittää perunaa, viipaloida tomaattia jne.). Kunkin pelin jäsentäjä hyväksyy 18 verbiä ja 51 oliota ennalta määritellyllä kieliopilla, mutta havaintojen sanaston kokonaiskoko on 20 000. Liitteessä SECREF36 annetaan lisätietoja tasoista ja pelien kieliopista.",
      "id": "task461-c8e29548e81a4b7faab39e061fd6fc34",
      "output": [
        "Millä tekstipohjaisilla peleillä tehdään kokeita?"
      ]
    },
    {
      "input": "Nykyaikaisessa arabian kielen standardissa (MSA) ja klassisessa arabian kielessä (CA) on kahdenlaisia vokaaleja: pitkät vokaalit, jotka on kirjoitettu selvästi, ja lyhyet vokaalit eli diakriittiset merkit, jotka tyypillisesti jätetään pois kirjoitettaessa, mutta jotka lukijat ottavat uudelleen käyttöön, jotta sanat lausuttaisiin oikein. Osoitamme, että mallimme saavuttaa 3,7 prosentin virheprosentin (CEER) MSA:n osalta ja 2,5 prosentin virheprosentin CA:n osalta. MSA:n osalta tämä CEER on yli 60 prosenttia pienempi kuin muilla uusimmilla järjestelmillä, kuten Farasalla ja RDI-diacritizerilla, jotka on koulutettu samalla aineistolla ja joiden CEER on 10,7 prosenttia ja 14,4 prosenttia. ",
      "id": "task461-029f016b8d5f4f2aae7639bd7f4f4726",
      "output": [
        "mikä on aiempi tekniikan taso?"
      ]
    },
    {
      "input": "Sovellamme toimialueen mukauttamismenetelmäämme neuraaliseen tekstitysmalliin ja osoitamme suorituskyvyn parantuneen muihin vakiomenetelmiin verrattuna useilla tietokokonaisuuksilla ja mittareilla. ",
      "id": "task461-e95afb322e8b471499783fa44b17575e",
      "output": [
        "Kokeilivatko he vain tekstitystehtävää?"
      ]
    },
    {
      "input": "Koska lähestymistapamme tarkoituksena on nimenomaan tuottaa kieliopillisia lauseita, otamme lisäksi huomioon seuraavan log-suhteen (eli kieliopillisten lauseiden ja epäkieliopillisten lauseiden suhde):",
      "id": "task461-6dbbb76c1002405eb9c005b6a2c8c570",
      "output": [
        "Miten he mittaavat kieliopillisuutta?"
      ]
    },
    {
      "input": "Lauseen tason luokittelua varten meidän on saatava lauseen esitys sanavektoreista INLINEFORM0 . Saavutimme tämän käyttämällä BiLSTM:ää, jossa on maksimipoolaus, joka osoittautui hyväksi universaaliksi lauseen koodausmekanismiksi BIBREF13 .",
      "id": "task461-337c73d1e5074bbea65da19ef529ca4a",
      "output": [
        "Mitä malliarkkitehtuuria ne käyttävät esitysten saamiseksi?"
      ]
    },
    {
      "input": "Keräsimme twiittejä, jotka liittyivät viiteen eri DDoS-hyökkäykseen kolmeen eri amerikkalaiseen pankkiin. Kunkin hyökkäyksen osalta kerättiin kaikki pankin nimen sisältävät twiitit, jotka lähetettiin viikkoa ennen hyökkäystä hyökkäyspäivään asti. Aineistossa on yhteensä 35214 twiittiä. Tässä kokeessa käytettiin vain 19.9.2012 tapahtuneen Bank of America -hyökkäyksen twiittejä. Tässä alaluvussa arvioidaan, kuinka hyvin malli yleistyy. Tätä varten tietokokonaisuus jaetaan kahteen ryhmään, joista toinen koskee Bank of Americaan kohdistuneita hyökkäyksiä ja toinen PNC:tä ja Wells Fargoa. Ainoa ero tämän kokeen ja kohdassa 4.4 esitetyn kokeen välillä on tietokokonaisuus. Tässä kokeessa asetelma $D_a$ sisältää vain PNC:hen ja Wells Fargoon kohdistuneiden hyökkäysten päivinä kerätyt twiitit. $D_b$ sisältää vain ennen Bank of America -hyökkäystä kerätyt twiitit.",
      "id": "task461-ce931e30d9954ef8b8db2f2256630e04",
      "output": [
        "Mitä koulutus- ja testidataa käytetään?"
      ]
    },
    {
      "input": " Valintamalli valitsee parhaan vastauksen vuorovaikutuksen aikana havaitusta joukosta $\\lbrace a_i\\rbrace _{i=1}^N$ ennustamalla F1-tuloksen eron kaikkien vaihtoehtojen keskimääräiseen F1-tulokseen. Koulutamme toisen neuroverkon valitsemaan parhaan vastauksen ehdokkaiden joukosta. Kehitämme tehtävän binääriseksi luokitteluksi, jossa erotetaan keskimääräistä parempi ja huonompi suorituskyky. Koulutuksessa laskemme vastauksen F1-pistemäärän jokaiselle tapaukselle. Jos uudelleenkirjoitus tuottaa vastauksen, jonka F1-pistemäärä on suurempi kuin muiden uudelleenkirjoitusten keskimääräinen pistemäärä, tapaukselle annetaan positiivinen merkintä.",
      "id": "task461-1a095a74e8574759af437ae0079c4728",
      "output": [
        "miten useiden uudelleen muotoiltujen kysymysten vastaukset kootaan yhteen?"
      ]
    },
    {
      "input": "Venäjän kielessä, jossa on rikas morfologia, harjoitus- ja testiaineiston lemmatointi ELMo-esityksiä varten tuottaa pieniä mutta johdonmukaisia parannuksia WSD-tehtävässä. ",
      "id": "task461-990384d79adc4a1c83590d0a6194943c",
      "output": [
        "Mitä muita esimerkkejä morfologisesti rikkaista kielistä kirjoittajat antavat?"
      ]
    },
    {
      "input": "Koska olimme kiinnostuneita myös siitä, onko argumentointi erilaista eri rekistereissä, otimme mukaan neljä eri rekisteriä: (1) käyttäjien kommentit uutislehtiartikkeleihin tai blogikirjoituksiin, (2) viestit keskustelufoorumeilla (foorumiviestit), (3) blogikirjoitukset ja (4) uutislehtiartikkelit. ",
      "id": "task461-e45117d4ad9e4efb88f6a75800be804d",
      "output": [
        "Miten uuden korpuksen tiedot on hankittu?"
      ]
    },
    {
      "input": "Toisin sanoen sulautumisavaruudessa on muutamia suuntia, jotka selittävät suhteettoman paljon varianssia. On selvää, että How2-tietokannan visuaalisia ominaisuuksia hallitsevat paljon enemmän \"yhteiset\" ulottuvuudet verrattuna Multi30k-aineistoon. Lisäksi tämä analyysi on edelleen lausetasolla, eli visuaaliset piirteet ovat paljon vähemmän erottelevia yksittäisten lauseiden välillä, mikä pahentaa ongelmaa entisestään token-tasolla. Tämä viittaa siihen, että nykyiset visuaaliset piirteet eivät ole riittävän riittäviä, jotta visuaalisesta modaliteetista voitaisiin odottaa hyötyjä NMT:ssä, koska ne eivät tarjoa sanaston elementtien välistä erottelukykyä token-tasolla ennusteen aikana.",
      "id": "task461-ba4057a9b5764a1788e2fdfe18b4be3f",
      "output": [
        "Mikä on niiden pääkomponenttianalyysin tulos?"
      ]
    },
    {
      "input": "Matkustamon AV-tietoaineistomme sisältää 30 tuntia multimodaalista dataa, joka on kerätty 30 matkustajalta (15 naiselta ja 15 mieheltä) 20 kyydissä/sessiossa. Matkustajien 10 erilaista aikomusta on tunnistettu ja kommentoitu seuraavasti: Muun muassa seuraavat: Aseta/muuta määränpäätä, Aseta/muuta reittiä (mukaan luettuna käännöksen mukaan annetut ohjeet), Aja nopeammin, Aja hitaammin, Pysähdy, Pysäköi, Pysähdy sivuun, Pysähdy pois, Avaa ovi ja Muut (musiikin/radion kytkeminen päälle/pois, ikkunan/ tavaratilan avaaminen/sulkeminen, ilmastointilaitteen/lämpötilan muuttaminen, kartan näyttäminen jne.). Asiaankuuluvat lähtö- ja saapumisajat yksilöidään ja merkitään seuraavasti: Sijainti, sijainti/suunta, kohde, aikaohjaus, henkilö, ele/katse (tämä, tuo, tuolla jne.) ja ei mitään. Lausetason aikomustyyppien ja niiden paikkojen lisäksi myös sanatason aikomusavainsanat merkitään aikomukseksi. Saimme hytissä olevasta aineistostamme 1260 yksilöllistä lausumaa, joissa oli komentoja AMIE:lle. Laajensimme tätä aineistoa Amazon Mechanical Turkin kautta ja saimme lopulta 3347 lausumaa, joissa oli aikomuksia. Intenttien ja lähtöaikojen merkinnät saadaan transkriptoiduista lausumista kolmen merkitsijän enemmistöäänestyksellä.",
      "id": "task461-e949c4ca3f0b48b3965ab6429f433ea6",
      "output": [
        "Mitkä ovat tuetut luonnolliset komennot?"
      ]
    },
    {
      "input": "Vertaamme SBERT-lauseen upotuksia muihin lauseen upotusmenetelmiin seuraavissa seitsemässä SentEval-siirtotehtävässä: MR: Elokuva-arvostelukatkelmien tunteiden ennustaminen viiden alun asteikolla BIBREF25.CR: Asiakkaiden tuotearvostelujen tunteiden ennustaminen BIBREF26.SUBJ: Elokuva-arvostelujen ja juonitiivistelmien lauseiden subjektiivisuuden ennustaminen BIBREF27.MPQA: Lauseen tason mielipiteiden polariteettiluokitus uutislehdistä BIBREF28.SST: Stanfordin tunnetietopankki binäärisillä merkinnöillä BIBREF29.TREC: Hienojakoinen kysymystyyppiluokitus TREC:stä BIBREF30.MRPC: Microsoft Research Paraphrase Corpus rinnakkaisista uutislähteistä BIBREF31.",
      "id": "task461-f55f5941542f4a379cc6268582c6da3d",
      "output": [
        "Mitä siirto-oppimistehtäviä arvioidaan?"
      ]
    },
    {
      "input": "Harjoitusaineistomme koostuu 2,09 miljoonasta lauseparista, jotka on poimittu LDC-korpuksesta. Testataksemme eri lähestymistapoja kiinasta englanniksi kääntämistehtävässä käytämme validointijoukkona NIST 2003 (MT03) -tietokokonaisuutta ja testijoukkoina NIST 2004 (MT04), NIST 2005 (MT05) ja NIST 2006 (MT06) -tietokokonaisuuksia. Englannista kiinaan -käännöstehtävässä käytämme validointijoukkona myös NIST 2003(MT03)-tietokokonaisuutta ja testijoukkona NIST 2008(MT08)-tietokokonaisuutta.",
      "id": "task461-a940d4298ad8486883d95e93611b7779",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": "Tässä jaksossa esitellään tämän taskCorpus-tehtävän koeasetelma: SEAME (South East Asia Mandarin-English), keskustelunomainen mandariini-englanti-koodinvaihtopuhekorpus koostuu spontaanisti puhutuista haastatteluista ja keskusteluista BIBREF8 . ",
      "id": "task461-a1853c1d5e084ca085dffca69eb77d2b",
      "output": [
        "Mitä kieliä teoksessa tutkitaan?"
      ]
    },
    {
      "input": "Testaamme ehdotettua lähestymistapaa kolmella julkisella lyhyellä tekstiaineistolla.  SearchSnippets. Tämä tietokokonaisuus valittiin Phan et al. BIBREF41 -tietokannasta, jossa käytettiin ennalta määriteltyjä lauseita kahdeksalta eri toimialueelta. StackOverflow. Käytämme Kaggle.com-sivustolla julkaistuja haastetietoja.  Biolääketiede. Käytämme BioASQ:n virallisella verkkosivustolla julkaistua haastedataa. ",
      "id": "task461-ed15104c80ee48f39347450bb57a57e9",
      "output": [
        "Mitä tietokokonaisuuksia he käyttivät?"
      ]
    },
    {
      "input": "Ajatuksemme on BQ:n tuottaminen MQ:lle, ja samalla haluamme vain pienimmän määrän BQ:tä edustamaan MQ:ta, joten ongelman mallintaminen $LASSO$-optimointiongelmaksi on sopiva tapa.",
      "id": "task461-c62de3c35e5049789f2409e8995e9ef4",
      "output": [
        "Mitä he muotoilevat kysymyksen sukupolvi kuin?"
      ]
    },
    {
      "input": "Malli on luonteeltaan peräkkäinen, ja se koostuu seuraavista vaiheista: teksti luetaan, se käsitellään dynaamiseen relaatiomuistiin, ja sen jälkeen kysymykseen perustuva huomio tuottaa vastauksen. Mallinnamme dynaamisen muistin samalla tavalla kuin Recurrent Entity Networks BIBREF17 ja varustamme sen sitten ylimääräisellä relaatiomuistilla.",
      "id": "task461-b39721d088aa4dde9d2043fd19f5384c",
      "output": [
        "Mikä on neuroverkon arkkitehtuuri?"
      ]
    },
    {
      "input": "Merkkien upotusten yli käytetään porttiohjattua neuroverkkoa luomaan hajautettuja esityksiä ehdolla olevista sanoista, jotka lähetetään LSTM-malliin.",
      "id": "task461-29a33da816944dc7a2bd6eb49ab52512",
      "output": [
        "Mitä neuroverkkoarkkitehtuureja käytetään?"
      ]
    },
    {
      "input": " Tässä työssä olemme rajoittuneet samoihin tietokokonaisuuksiin kuin BIBREF7 . Näihin kuuluu yhdeksän (reaaliarvoista) numeerista ominaisuutta, jotka ovat leveysaste, pituusaste, korkeus, väestö ja viisi ilmastoon liittyvää ominaisuutta (keskilämpötila, keskimääräinen sademäärä, keskimääräinen auringonsäteily, keskimääräinen tuulennopeus ja keskimääräinen vesihöyrynpaine). Lisäksi käytettiin 180 kategorista ominaisuutta, jotka ovat CORINE-maapeiteluokat tasolla 1 (5 luokkaa), tasolla 2 (15 luokkaa) ja tasolla 3 (44 luokkaa) sekä 116 maalajia (SoilGrids). Huomattakoon, että kunkin sijainnin on kuuluttava täsmälleen neljään luokkaan: yksi CORINE-luokka kullakin kolmella tasolla ja yksi maalaji.",
      "id": "task461-edd36362e69e44ee8e4b15d3f1d83041",
      "output": [
        "mitä tietokokonaisuutta tässä asiakirjassa käytetään?"
      ]
    },
    {
      "input": "Englanninkielisen version osalta suoritimme sekä perusteellisen manuaalisen analyysin että automaattisen arvioinnin kolmella yleisesti käytetyllä TS-tietoaineistolla kahdelta eri alalta Englanninkielisen version osalta suoritimme sekä perusteellisen manuaalisen analyysin että automaattisen arvioinnin kolmella yleisesti käytetyllä TS-tietoaineistolla kahdelta eri alalta Saksankielisen version arviointi on käynnissä.",
      "id": "task461-451d193e1a464b89926cf4035208bf26",
      "output": [
        "Mitä korporaatioita tehtävässä käytetään?"
      ]
    },
    {
      "input": "OntoNotes-tietokannan F-1-kokonaispistemäärä on 88 %, ja 112-luokkaisen Wiki(gold)-tietokannan F-1-ristiinvalidoinnin kokonaispistemäärä on 53 %. ",
      "id": "task461-0e6f08bc23684d59ac2fe65a0555701d",
      "output": [
        "Millaisia tuloksia he saavuttavat ehdotetulla lähestymistavalla?"
      ]
    },
    {
      "input": "Etenkin Davidson-aineistossa on ylinäytteistetty joitakin twiittejä, joiden kieli (kirjoitettu afroamerikkalaisella kansankielellä) ja maantieteellinen rajoitus (Yhdysvallat) on liian suuri, kuten twiitit, jotka sisältävät halventavia sanoja \"nigga\", \"faggot\", \"coon\" tai \"queer\", mikä johtaa korkeaan virheellisen luokittelun määrään. Nämä virheelliset luokittelut eivät kuitenkaan vahvista luokittelijamme heikkoa suorituskykyä, koska annotoijilla oli taipumus annotoida monet halventavia sanoja sisältävät näytteet vihaksi tai loukkaavaksi ilman mitään oletuksia twiittaajien sosiaalisesta kontekstista, kuten puhujan identiteetistä tai murteesta, vaikka ne olivat vain loukkaavia twiittejä tai jopa eivät kumpaakaan. ",
      "id": "task461-99213c6d465e417d85656ee77aa33cf0",
      "output": [
        "Mitä ennakkoluuloja heidän mallinsa tallentaa?"
      ]
    },
    {
      "input": "Koska meillä ei ollut julkisesti saatavilla olevaa nepalilaista NER-standarditietokokonaisuutta, emmekä saaneet aiemmilta tutkijoilta mitään tietokokonaisuutta, meidän oli luotava oma tietokokonaisuutemme. Tämä tietokokonaisuus sisältää lauseita, jotka on kerätty vuoden 2015-2016 päivälehdistä. ",
      "id": "task461-b766fb3e87274af28a3772bac621afc7",
      "output": [
        "Mikä on heidän tietokantansa lähde?"
      ]
    },
    {
      "input": "Oletetaan, että kerroksia on yhteensä $M$, ja määritetään näiden kerrosten osajoukko, johon tappiofunktiota sovelletaan: $K = \\lbrace k_1, k_2, ..., k_L\\rbrace \\subseteq \\lbrace 1,...,M-1\\rbrace $. Kokonaiskohdefunktio määritellään seuraavasti: $Z_{k_l}$ on $k_l$:nnen muuntajakerroksen aktivoinnit, $Y$ on CTC:n osalta perustotuuden transkriptio ja hybridi-ASR:n osalta kontekstista riippuvaiset tilat, ja $Loss(P, Y)$ voidaan määritellä CTC:n tavoitteeksi BIBREF11 tai hybridi-ASR:n osalta ristikkäisentropiaksi. T",
      "id": "task461-194932457f434b15ab093914af2214fa",
      "output": [
        "Lasketaanko kaikki tappiot yhteen, jotta saadaan yksi ainoa tappio?"
      ]
    },
    {
      "input": "Tarkastelemme syväoppimislähestymistapaa sekvenssien merkitsemiseen käyttäen vaniljaista toistuvaa neuroverkkoa (RNN), jossa on sanojen upotuksia, sekä yhteistä päättelyä ja strukturoitua ennustamista käyttäen Stanfordin tietopohjan rakentamisjärjestelmää DeepDive BIBREF1 .",
      "id": "task461-6d63d1056ca74e38858f6e54a0c94502",
      "output": [
        "Minkä strukturoidun ennustusmenetelmän ne ottavat käyttöön ajallisten entiteettien poimimiseksi?"
      ]
    },
    {
      "input": "Huomaa, että ESIM-malleissa on kaksi LSTM-kerrosta, joista ensimmäinen (syöttö) LSTM suorittaa syötteen koodauksen ja toinen (päättely) LSTM luo esityksen päättelyä varten.",
      "id": "task461-86c26a57f0934c21bc3ccd768fa1d9c9",
      "output": [
        "Kuinka monta kerrosta heidän mallissaan on?"
      ]
    },
    {
      "input": "Saavutamme huomattavia parannuksia vahvaan perustasoon nähden hyödyntämällä parhaan hajotemallimme hajotteita, jotka on koulutettu USeq2Seq-ohjelmalla FastTextin pseudopalautteilla; saamme 3,1 F1-hyötyä alkuperäisessä dev-joukossa, 11 F1-hyötyä multi-hop dev-joukossa ja 10 F1-hyötyä toimialueen ulkopuolisessa dev-joukossa. ",
      "id": "task461-f2c173fe180e40d78c77c97877a10e68",
      "output": [
        "Kuinka suuri on parannus perustasoon verrattuna?"
      ]
    },
    {
      "input": "MonaLog käyttää kahta apujoukkoa. Ensinnäkin tietämyskanta ${K}$, johon tallennetaan päättelyyn tarvittava maailman tietämys, esim, semantikko $\\le $ kielitieteilijä ja uida $\\le $ liikkua, mikä kattaa tosiasiat, että $[\\![\\mbox{\\em semantikko}]\\!]$ tarkoittaa osajoukkoa $[\\![\\mbox{\\em kielitieteilijä}]\\!]$ ja että $[\\![\\mbox{\\em uida}]\\!]$ tarkoittaa osajoukkoa $[\\![\\mbox{\\em liikkua}]\\!]$, vastaavasti. Tällainen maailmantuntemus voidaan luoda käsin käsillä olevaa ongelmaa varten tai johtaa helposti olemassa olevista resursseista, kuten WordNet BIBREF22. Huomattakoon, että emme lisää sokeasti kaikkia WordNetin suhteita tietopohjaamme, koska tämä riippuisi suuresti sanan merkityksen disambiguoinnista (meidän on tiedettävä, onko \"pankki\" rahoituslaitos vai jokipankki, jotta voimme poimia sen suhteet oikein). Nykyisessä toteutuksessa vältämme tämän lisäämällä x $\\le $ y- tai x $\\perp $ y-suhteet vain, jos sekä x että y ovat sanoja premissi-hypoteesiparissa. Lisäksi jotkin suhteet, joihin liittyy kvanttoreita ja prepositioita, on koodattava kovakoodilla, koska WordNet ei sisällä niitä: every $=$ all $=$ each $\\le $ most $\\le $ many $\\le $ a few $=$ several $\\le $ some $=$ a; the $\\le $ some $=$ a; on $\\perp $ off; up $\\perp $ down; jne.",
      "id": "task461-ef53ee24c3aa442bb0ba5ab54e3e2d05",
      "output": [
        "Miten ne valitsevat monotonisuusfaktat?"
      ]
    },
    {
      "input": "Menetelmät ::: Lisäksi ehdotamme, että näitä kahta menetelmää käytetään yhdessä niiden vahvuuksien yhdistämiseksi. Vaikka pituusmerkki toimii pehmeänä rajoitteena, joka ohjaa NMT:tä tuottamaan lyhyen tai pitkän käännöksen suhteessa lähteeseen, verkolle ei itse asiassa anneta mitään tietoa pituudesta. Toisaalta pituuden koodauksessa hyödynnetään tietoa kohdepituudesta, mutta se on riippumaton lähteen pituudesta.",
      "id": "task461-6e35539070d24a6ba2722b226143ce9d",
      "output": [
        "Kokeilevatko he molempien menetelmien yhdistämistä?"
      ]
    },
    {
      "input": "Morfeemien segmentoinnin ongelmana on, että kantasanastojen sanavarasto on edelleen hyvin suuri, mikä johtaa siihen, että harjoittelun aikana on paljon harvinaisia ja tuntemattomia sanoja.  Tämän vuoksi opimme BPE-mallin harjoituskorpuksen kantayksiköille sanojen sijaan ja sovellamme sitä sitten kunkin sanan kantayksikköön morfeemin segmentoinnin jälkeen.",
      "id": "task461-4b0128b1c82b440d8171dea7a2fb8f6f",
      "output": [
        "Miten morfologian tuntemus on toteutettu menetelmässä?"
      ]
    },
    {
      "input": "Arvioimme RNN-mallia, joka käyttää kaksisuuntaisesti summattuja GRU-muistisoluja BIBREF18 ja joka käyttää lopputiloja sulautumina; CNN-mallia, joka käyttää lauseen maksimipoolistettuja konvoluutiosuodattimia sulautumina BIBREF19 ; RNN-CNN-malli, joka asettaa CNN:n sanakohtaisten GRU-tulosten päälle sanakohtaisten upotusten sijaan BIBREF20 ; ja BIBREF20:n innoittama attn1511-malli, joka yhdistää RNN-CNN-mallin sanakohtaisen huomion kanssa hypoteesikohtaisten todisteiden upotusten rakentamiseksi. Raportoimme myös perustulokset sanojen upotusten keskimääräisestä keskiarvosta lauseessa projektiomatriisilla ja DAN Deep Averaging Network -mallilla, joka käyttää sanatason pudotusta ja lisää useita epälineaarisia muunnoksia keskiarvoistettujen upotusten päälle BIBREF21 .",
      "id": "task461-6ba0c1e570f14447abfc021988d5f2dc",
      "output": [
        "mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Sentimenttianalyysissä käytetty korpus on BIBREF11:n elokuva-arvosteluja sisältävä IMDb-tietokanta, kun taas NER-korpus on BIBREF12:n Groningenin merkityspankki (GMB), joka sisältää 47 959 lausenäytettä.",
      "id": "task461-0be0326f2f92414fa24040b01495e7fa",
      "output": [
        "Mitä sentimenttianalyysin tietokokonaisuutta käytetään?"
      ]
    },
    {
      "input": "Intuitiivisesti ajateltuna, kun Ranker tekee tarkempia valintoja, Reasoner työskentelee vähemmän kohinaisen datan kanssa ja onnistuu siten helpommin. Tarkemmin sanottuna Reasoner oppii poimimaan yhdistävän entiteetin hyvin koulutetun Rankerin valitsemista ketjuista, ja se hyödyttää Rankerin koulutusta tarjoamalla lisäpalkkioita.",
      "id": "task461-e773d787bc2f42bea12beb9e359f2d77",
      "output": [
        "Miten kaksi mallia tekevät yhteistyötä, jotta voidaan valita varmimmat ketjut?"
      ]
    },
    {
      "input": "Harjoittelussa, validoinnissa ja testauksessa käytetyt tietokokonaisuudet sisältävät lauseita, jotka on poimittu Europarl-korpuksesta BIBREF1 ja SoNaR-korpuksesta BIBREF2. Europarl-korpus on avoimen lähdekoodin rinnakkaiskorpus, joka sisältää Euroopan parlamentin istuntoja. Hollantilainen osa koostuu 2 333 816 lauseesta ja 53 487 257 sanasta. SoNaR-korpus koostuu kahdesta korpuksesta: SONAR500 ja SONAR1. SONAR500-korpus koostuu yli 500 miljoonasta sanasta, jotka on saatu eri aloilta.",
      "id": "task461-a9ac86be49524485b7df51511c3ee201",
      "output": [
        "Mitkä ovat molempien tietokokonaisuuksien koot?"
      ]
    },
    {
      "input": "Vertaamme malliamme useisiin perusmalleihin, mukaan lukien: Attn seq2seq BIBREF22: Malli, jossa on yksinkertainen huomio tulokontekstissa jokaisella aikavaiheella dekoodauksen aikana.Ptr-UNK BIBREF23: Ptr-UNK on malli, joka täydentää sekvenssistä sekvenssiin -arkkitehtuuria huomioon perustuvalla kopiointimekanismilla koodaajan kontekstissa.KV Net BIBREF6: Malli on hyväksytty ja argumentoitu dekooderi, joka dekoodaa sanaston ja KB-olioiden ketjuttamisen yli, mikä mahdollistaa mallin luoda olioita.Mem2Seq BIBREF7: Mem2Seq on malli, joka ottaa syötteenä dialogihistorian ja KB-oliot ja käyttää osoitinporttia ohjaamaan joko sanaston sanan tuottamista tai syötteen valitsemista tulosteeksi.DSR BIBREF9: DSR hyödynsi dialogin tilan esitystä hakeakseen KB:n implisiittisesti ja sovelsi kopiointimekanismia hakeakseen olioita tietämyskannasta dekoodauksen aikana.",
      "id": "task461-b071b3e3fa854c32a2f319c09f8176b8",
      "output": [
        "Mitkä olivat perusjärjestelmät?"
      ]
    },
    {
      "input": "Molemmat järjestelmät optimoitiin tst2014-ohjelmalla käyttäen minimivirheprosentin koulutusta BIBREF20 . Järjestelmien yksityiskohtainen kuvaus on BIBREF21 .",
      "id": "task461-4e6ab4ea6e4a4b6ea4ca865e235471e5",
      "output": [
        "Miten PBMT-järjestelmää koulutetaan?"
      ]
    },
    {
      "input": "Vanilla ST:n perustaso: Vanilla ST BIBREF9:ssä on vain puheen kooderi ja dekooderi. Se on koulutettu tyhjästä ST-TED-korpuksella: Teemme kolme esivalmennuksen perustason kokeilua: 1) kooderin esivalmennus, jossa ST-kooderi alustetaan ASR-mallista; 2) dekooderin esivalmennus, jossa ST-dekooderi alustetaan MT-mallista; ja 3) kooderin ja dekooderin esivalmennus, jossa sekä kooderi että dekooderi on esivalmennettu. ASR-mallilla on sama arkkitehtuuri kuin vanilla ST-mallilla, joka on koulutettu ST-TED- ja TED-LIUM2-korpusten sekoituksella. MT-mallissa on tekstin kooderi ja dekooderi, joiden arkkitehtuuri on sama kuin TCEN-mallissa. Se koulutetaan ensin WMT-datalla (toimialueen ulkopuolella) ja hienosäädetään sitten toimialueen sisäisellä datalla: Suoritamme myös kolme monitehtäväperuskokeilua, mukaan lukien yksi-moneen-asetelma, moni-yhdelle-asetelma ja moni-moneen-asetelma. Kahdessa ensimmäisessä vaihtoehdossa koulutamme mallin arvolla $\\alpha _{st}=0.75$ ja arvolla $\\alpha _{asr}=0.25$ tai $\\alpha _{mt}=0.25$. Monesta moneen -asetuksessa käytetään $\\alpha _{st}=0.6, \\alpha _{asr}=0.2$ ja $\\alpha _{mt}=0.2$. MT-tehtävässä käytämme vain toimialueen sisäistä dataa.Many-to-many+esikoulutus: Koulutamme monesta moniin -monitehtäväisen mallin, jossa koodaajat ja dekooderit johdetaan esikoulutetuista ASR- ja MT-malleista. Kolmio+esikoulutus: BIBREF18 DBLP:conf/naacl/AnastasopoulosC18 ehdotti kolmiomuotoista monitehtävästrategiaa puheen kääntämiseen. Heidän mallinsa ratkaisee aliverkkohävikkiongelman ketjuttamalla ST-dekooderin ASR-kooderi-dekooderimalliin. Heidän ST-dekooderinsa voi käyttää sekä puheen enkooderin että ASR-dekooderin representaatioita. Oikeudenmukaisen vertailun vuoksi puheen kooderi ja ASR-dekooderi alustetaan valmiiksi koulutetusta ASR-mallista. Triangle-mallia hienosäädetään niiden monitehtäväisellä tavalla.",
      "id": "task461-40d71e60a19245f9a016c9b7bfea90aa",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Kuten kuvassa KUVA7 on esitetty, KAR on alusta loppuun ulottuva MRC-malli, joka koostuu viidestä kerroksesta: Lexicon Embedding Layer. Tämä kerros kuvaa sanat leksikon upotuksiin. Kontekstin upotuskerros. Tämä kerros kartoittaa leksikon upotukset kontekstin upotuksiin. Karkean muistin kerros. Tämä kerros kartoittaa kontekstin upotukset karkeisiin muisteihin. Hienostunut muistikerros. Tämä kerros kartoittaa karkeat muistit tarkennetuiksi muisteiksi. Answer Span Prediction Layer. Tämä kerros ennustaa vastauksen alku- ja loppupisteen edellä mainittujen kerrosten perusteella.",
      "id": "task461-1cc5e6f0fcaf47c8be82899dc400a18b",
      "output": [
        "Millainen malli on KAR?"
      ]
    },
    {
      "input": " Mallinsimme sanamäärän ja kahden käyttäjän sitoutumista kuvaavan mittarin (kokonaisarvosana, keskimääräinen kierrosten määrä) välistä suhdetta erillisillä lineaarisilla regressioilla.",
      "id": "task461-3943b6a7d1e745f0826dbffd1e322e3a",
      "output": [
        "Mitkä ovat kaikki mittarit, joilla mitataan käyttäjien sitoutumista?"
      ]
    },
    {
      "input": "Saimme 9 892 tarinaa seksuaalisesta häirinnästä, joista oli raportoitu Safecityssä. Nämä tarinat sisältävät tekstikuvauksen sekä häirinnän muotojen, kuten kommentoinnin, tuijottelun ja kähmimisen, tunnisteet. Karlekar ja Bansal karlekar2018safecity julkaisivat näistä tarinoista koostuvan tietokokonaisuuden. Häirinnän muotojen lisäksi merkitsimme jokaiseen tarinaan manuaalisesti keskeiset elementit (esim. \"häiritsijä\", \"aika\", \"paikka\", \"laukaisija\"), koska ne ovat olennaisia häirintämallien paljastamiseksi. Esimerkki on esitetty kuvassa FIGREF3. Lisäksi annoimme kullekin tarinalle luokittelutarrat viidellä ulottuvuudella (taulukko TABREF4). Kaikkien ulottuvuuksien luokitusten yksityiskohtaiset määritelmät selitetään jäljempänä.",
      "id": "task461-649dc82bf75d40dca6e217b2e9c97681",
      "output": [
        "Mikä on tietokokonaisuuden koko?"
      ]
    },
    {
      "input": "Keräämme tietoja käyttämällä Twitterin API:ta tallennettuja tietoja varten, jotka ovat julkisessa käytössä. Kokeilujamme varten keräämme 3200 twiittiä, jotka on suodatettu avainsanoilla kuten \"tulipalo\", \"maanjäristys\", \"varkaus\", \"ryöstö\", \"rattijuopumus\", \"rattijuopumusonnettomuus\" jne. Myöhemmin merkitsemme twiitit manuaalisesti ja merkinnät luokittelua varten ensimmäisenä vaiheena. Aineistossamme on 1313 twiittiä, joilla on positiivinen merkintä, ja 1887 twiittiä, joilla on negatiivinen merkintä. Luomme toisen tietokokonaisuuden positiivisesti merkityistä twiiteistä ja annamme niille luokkatunnisteet, kuten \"tulipalo\", \"onnettomuus\", \"maanjäristys\" jne.",
      "id": "task461-01c3ea147efb42778de6d3f254b31f32",
      "output": [
        "Ovatko twiitit aluekohtaisia?"
      ]
    },
    {
      "input": "Vertailemme malliamme seuraaviin perusmalleihin: 1) SVM unigram-, bigram- ja trigram-ominaisuuksilla, joka on tavallinen mutta melko vahva luokittelija tekstiominaisuuksille; 2) SVM keskimääräisellä sanojen upotuksella, jossa dokumentti esitetään jatkuvana esityksenä laskemalla yhdistettyjen sanojen upotusten keskiarvo; 3) SVM keskimääräisillä muunnetuilla sanojen upotuksilla (INLINEFORM0 yhtälössä EQREF6 ), jossa asiakirja esitetään jatkuvana esityksenä keskiarvoistamalla yhdistettyjen sanojen muunnetut upotukset; 4) kaksi kypsää tekstiluokittelun syväoppimismallia, CNN BIBREF3 ja Recurrent Convolutional Neural Networks (RCNN) BIBREF0 , joiden hyperparametrit perustuvat niiden työhön; 5) edellä mainitut SVM- ja syväoppimismallit kommentti-informaatiolla; ",
      "id": "task461-f49b5e215a3c4bf5a960c65e759d44e7",
      "output": [
        "Mitkä ovat perustasot?"
      ]
    },
    {
      "input": "Tutkimme erilaisia normalisointitekniikoita. FB-pankit, joissa on käytetty cepstral mean -normalisointia (CMN), toimivat paremmin kuin raa'at FB-pankit. Koimme, että varianssin ja keskiarvon normalisoinnin (CMVN) käyttäminen ei ole tarpeellista tehtävän kannalta. Deltojen ja delta-deltojen käyttö parantaa mallia, joten käytimme niitä muissa kokeissa. Spektrogrammiominaisuuksilla koulutetut mallit konvergoituvat hitaammin ja huonompaan minimiin, mutta ero CMN:ää käytettäessä ei ole kovin suuri FBanksiin verrattuna.",
      "id": "task461-dbb4573e97a94759863ad7884f10e0f6",
      "output": [
        "Mitä normalisointitekniikoita mainitaan?"
      ]
    },
    {
      "input": "Saadaksemme arvion ihmisen suorituskyvystä kullakin mittarilla käsittelemme iteratiivisesti jokaista referenssilauseen dev/testidatassa ennusteena, jota verrataan kaikkiin referensseihin (mukaan lukien itsensä). Toisin sanoen, jos mallilla on sama päättelykyky kuin väkijoukon työntekijöiden keskimääräisellä suorituskyvyllä, sen tulosten pitäisi ylittää tämä \"inhimillinen raja\".",
      "id": "task461-3aeb2b113c954240ace507edaf952068",
      "output": [
        "Mitä toimenpiteitä käytettiin ihmisten arvioinnissa?"
      ]
    },
    {
      "input": "Koulutustietokanta UM Inventory BIBREF5 on Minnesotan yliopiston tutkijoiden luoma julkinen tietokanta, joka sisältää noin 37 500 harjoitusnäytettä, joissa on 75 lyhennettä. Olemassa olevassa työssä raportoidaan lyhenteiden disambiguointituloksia 50 lyhenteestä BIBREF6, BIBREF5, BIBREF17. Tutkittuamme huolellisesti tämän tietokokonaisuuden havaitsimme kuitenkin, että se sisältää monia näytteitä, joista lääketieteen ammattilaiset ovat eri mieltä: vääriä näytteitä ja luokittelemattomia näytteitä. Näiden virheiden ja puutteiden vuoksi poistimme virheelliset näytteet ja valitsimme lopulta 30 lyhenne-termiä harjoitusaineistoksi, joka voidaan julkaista.",
      "id": "task461-7e5a6f422eb04842a43d354fcd22e58b",
      "output": [
        "Mitä olemassa olevaa tietokokonaisuutta tarkastellaan uudelleen ja korjataan koulutusta varten?"
      ]
    },
    {
      "input": "Käytimme kahta strategiaa kahden mallityypin ennustustulosten yhdistämisessä. Max Score Ensemble -malli teki lopulliset päätökset kahden erillisen mallin antamien pisteiden maksimipisteiden perusteella, kun taas Average Score Ensemble -malli käytti keskimääräistä pistemäärää lopullisten päätösten tekemiseen.",
      "id": "task461-ec67ca1cafa84bc4abed2267d1c16c3a",
      "output": [
        "Miten he yhdistävät mallit?"
      ]
    },
    {
      "input": "Ensinnäkin ehdotamme, että näkymättömien suhteiden käsittelemiseksi suhteiden nimet jaetaan sanasarjoiksi kysymys-suhde-vertailua varten. Toiseksi, koska alkuperäiset relaationimet voivat joskus auttaa pitempien kysymysyhteyksien yhteensovittamisessa, ehdotamme sekä relaatio- että sanatason relaatioesitysten luomista. Kolmanneksi käytämme syviä kaksisuuntaisia LSTM-malleja (BiLSTM) oppiaksemme eritasoisia kysymysrepresentaatioita, jotta voimme sovittaa yhteen eritasoisia relaatiotietoja. Lopuksi ehdotamme sekvenssien yhteensovittamista varten jäännösoppimismenetelmää, joka helpottaa mallin kouluttamista ja johtaa abstraktimpiin (syvempiin) kysymysrepresentaatioihin, jolloin hierarkkinen yhteensovittaminen paranee.",
      "id": "task461-9cc6712d10d04322b48a79d6580b7d9c",
      "output": [
        "Mitä he käyttävät propsoed-kehyksessään?"
      ]
    },
    {
      "input": "Monitehtäväinen pareittainen neuraalinen luokitteluEhdotamme monitehtäväistä pareittaista neuraalista luokittelumenetelmää, jonka avulla voidaan paremmin sisällyttää ja erottaa tietyn hashtagin ehdokkaiden segmentointien välinen suhteellinen järjestys. Mallimme mukautuu käsittelemään yhden ja usean merkin hashtageja eri tavoin monitehtäväisen oppimisstrategian avulla ilman, että se vaatii ylimääräisiä merkintöjä. Tässä jaksossa kuvaamme tehtäväasetelman ja kolme vaihtoehtoa pareittaisen neuraalisen luokittelun malleista (kuva FIGREF11 ). Pareittainen neuraalinen ranking-malli Margin Ranking (MR) Loss Adaptive Multi-task Learning (mukautuva monitehtäväoppiminen)",
      "id": "task461-4538539057f54b3881477706d3276f36",
      "output": [
        "Mitä lähestymistapoja hashtagien segmentointiin ehdotetaan?"
      ]
    },
    {
      "input": "Näemme, että porttiarkkitehtuurit ovat lähes aina suorituskykyisempiä kuin toistuvat, huomio- ja lineaariset mallit BoW, TFIDF ja PV. Tämä johtuu pitkälti siitä, että kun näitä malleja harjoitellaan ja testataan samoilla aloilla, erityisesti toistuvat ja huomioperusteiset mallit voivat toimia paremmin. Koska niistä kuitenkin puuttuu porttirakenne, jota koulutetaan rinnakkain tärkeyden oppimiseksi, niiden suorituskyky kohdealueella on huono verrattuna porttiarkkitehtuureihin. Koska gated-arkkitehtuurit perustuvat konvoluutioihin, ne hyödyntävät rinnakkaistamista ja lisäävät huomattavasti aikakompleksisuutta muihin malleihin verrattuna. Porttiarkkitehtuurien tehokkuus perustuu ajatukseen, että portti koulutetaan vain painotuksen tunnistamiseksi. Tunneanalyysin tehtävässä tämä painotus vastaa sitä, mitkä painot johtavat lopullisen tappion pienenemiseen tai toisin sanoen tarkimpaan tunteen ennustamiseen. Näin tehdessään porttiarkkitehtuuri oppii, mitkä sanat tai n-grammit vaikuttavat eniten sentimenttiin, ja nämä sanat tai n-grammit ovat usein yhteydessä toimialasta riippumattomiin sanoihin. Toisaalta portti antaa vähemmän painoarvoa n-grammeille, jotka ovat suurelta osin joko alalle ominaisia tai funktiona toimivia sanakokonaisuuksia, joiden osuus yleiseen sentimenttiin on vähäinen. Tämä tekee porttiarkkitehtuurista tehokkaan toimialueen mukauttamisessa.",
      "id": "task461-aa67e750db3947f89ede91d68c77c994",
      "output": [
        "Kertooko se, että GCN:t pystyvät suoriutumaan tästä hyvin, että tehtävä on yksinkertaisempi kuin aiemmin luultiin?"
      ]
    },
    {
      "input": "Kunkin pelin video on 30-50 minuutin mittainen ja sisältää kuva- ja keskustelutietoja, jotka on liitetty pelin tiettyyn aikaleimaan.",
      "id": "task461-3506af1022794681913e8c12890b294f",
      "output": [
        "Mikä on nauhoitusten keskimääräinen pituus?"
      ]
    },
    {
      "input": "Vaikka tehtäväsuuntautuneille järjestelmille on olemassa joitakin objektiivisia arviointimittareita, kuten dialogin vuorojen määrä, tehtävän suorittamisen osuus jne., ei ole olemassa kultaista standardia kahden (tai useamman) dialogijärjestelmän automaattiseen arviointiin, kun otetaan huomioon ihmisen tyytyväisyys ja luodun dialogin sujuvuus.",
      "id": "task461-2b1513ddc0a24a41b089ac6e1ede623b",
      "output": [
        "Mitä ongelmia arviointijärjestelmässä on havaittu?"
      ]
    },
    {
      "input": "BIBREF0 (BIBREF0) kehittämä Moral Choice Machine laskee kysymys-vastauspareihin upotetun mielivaltaisen toiminnan kosinusarvoista samankaltaisuutta lauseen upotusavaruudessa.",
      "id": "task461-42b0d3912c0d4391bb15253785596ea6",
      "output": [
        "Mikä on moraalinen valintakone?"
      ]
    },
    {
      "input": "Uskollisuuden määrittely ::: Kaksi mallia tekee samat ennusteet, jos ja vain jos ne käyttävät samaa päättelyprosessia. Uskollisuuden määrittely :::: Oletus 2 (Ennuste-oletus): Malli tekee samanlaisilla syötteillä samanlaisia päätöksiä, jos ja vain jos sen päättelytapa on samanlainen. Uskollisuuden määrittely ::: Oletus 3 (Lineaarisuusoletus): Tietyt syötteen osat ovat mallin päättelyssä tärkeämpiä kuin toiset. Lisäksi syötteen eri osien osuudet ovat toisistaan riippumattomia.",
      "id": "task461-e02649ac707e4089a49b69455505cc22",
      "output": [
        "Mitkä ovat kolme oletusta nykyisissä uskollisuuden määrittelyä koskevissa lähestymistavoissa?"
      ]
    },
    {
      "input": "Osallistujia pyydetään arvioimaan kutakin tiivistelmää kolmella indikaattorilla: merkityksellisyys, tiiviys ja luettavuus asteikolla 1-5 ja asettamaan tiivistelmäpari paremmuusjärjestykseen (tasapisteet sallitaan). Havaitaan, että SPNet saa korkeimman pistemäärän sekä ROUGE- että CIC-vertailussa.",
      "id": "task461-7e193850fe5847b887dd7cc6d956c5b6",
      "output": [
        "Mitä automaattisia ja inhimillisiä arviointimittareita käytetään SPNetin ja vastaavien verkkojen vertailussa?"
      ]
    },
    {
      "input": "Arvioidaksemme sanan INLINEFORM0 merkityksen lauseessa, etsimme sellaisen synsetin INLINEFORM1, joka maksimoi kosinin samankaltaisuuden lauseen vektorin kanssa: DISPLAYFORM0",
      "id": "task461-3a0f077aee7e4fa58c879e1768b60a6f",
      "output": [
        "Mitä semanttisen samankaltaisuuden mittaria käytetään?"
      ]
    },
    {
      "input": "Päällekkäisen puheentunnistusongelman osalta oletetaan edelleen, että ulostulon etikettivirrat ovat ehdollisesti riippumattomia, kuten yhtälössä ( 5 ). Tällöin ristiinentropiaan perustuva PIT voidaan muuttaa sekvenssidiskriminointikriteeriin perustuvaksi PIT:ksi seuraavasti,$$\\begin{split} \\mathcal {J}_{\\text{SEQ-PIT}}=\\sum _u \\min _{s^{\\prime }\\in \\mathbf {S}} \\frac{1}{N} \\sum _{n\\in [1,N]}-\\mathcal {J}_{\\text{SEQ}}(\\mathbf {L}_{un}^{(s^{\\prime })},\\mathbf {L}_{un}^{(r)})) \\end{split}$$ (Yht. 44)Yhtälöstä ( 7 ) poiketen paras permutaatio päätetään $\\mathcal {J}_{\\text{SEQ}}(\\mathbf {L}_{un}^{(s^{\\prime })},\\mathbf {L}_{un}^{(r)})$ , joka on sekvenssidiskriminointikriteeri, jonka mukaan otetaan $s^{\\prime }$ -loppuinen permutaatio $n$ -loppuisessa ulostulon päättelyvirrassa lausuman $u$ kohdalla. CE-PIT:n tapaan kaikkien permutaatioiden $\\mathcal {J}_{\\text{SEQ}}$ lasketaan ja optimointia varten otetaan pienin permutaatio.",
      "id": "task461-c9739fb8a33c48f2b6524369b6aa0042",
      "output": [
        "Miten erottelukoulutuksen muotoilu eroaa tavanomaisesta?"
      ]
    },
    {
      "input": "Kokeessa 1 testattiin suoraan hypoteesia, jonka mukaan puhujat lisäävät spesifisyyttään tilanteissa, joissa näköyhteys on epäsymmetrinen. Havaitsimme, että puhujat eivät ole ainoastaan kontekstin suhteen herkkiä valitsemaan viittaavia ilmaisuja, jotka erottavat kohteen häiriötekijöistä jaetussa kontekstissa, vaan ovat myös okkluusioherkkiä kompensoiden adaptiivisesti epävarmuutta. Nämä tulokset viittaavat vahvasti siihen, että puhujan informatiivisuus vaikuttaa kuuntelutarkkuuteen. Tämän hypoteesin tueksi havaitsimme vahvan negatiivisen korrelaation informatiivisuuden ja virhemäärien välillä kaikissa kohteissa ja olosuhteissa: kuuntelijat tekevät vähemmän virheitä, kun lausumat sopivat paremmin kohteeseen suhteessa häiritsevään tekijään ( $\\rho = -0.81$ , bootstrapped 95 % CI $= [-0.9, -0.7]$ ; Kuva 6 B). Tämä tulos viittaa siihen, että kuuntelijoiden käyttäytymistä ohjaa odotus puhujan informatiivisuudesta: kuuntelijat tulkitsevat lausumia suhteessa siihen, kuinka hyvin ne sopivat kohteisiin kontekstissa. Rational Speech Act (RSA) -formalisointimme yhteistoiminnallisesta päättelystä tässä kontekstissa ennustaa, että puhujat (johtajat) luonnollisesti lisäävät viittaavien ilmaisujensa informatiivisuutta suojautuakseen lisääntyneeltä väärinymmärryksen riskiltä; kokeilu 1 esittää suoraa näyttöä tämän hypoteesin tueksi. Eksp. 2 on johdonmukainen tämän hypoteesin kanssa; kun ohjaajat käyttivät ali-informatiivisia käsikirjoitettuja ohjeita (jotka oli otettu aiemmasta työstä), kuuntelijat tekivät huomattavasti enemmän virheitä kuin silloin, kun puhujien annettiin käyttää viittaavia ilmaisuja niiden luonnollisella informatiivisuustasolla, ja puhujan informatiivisuus muokkasi voimakkaasti kuuntelijoiden virhemääriä.",
      "id": "task461-d053f201aa1f485fab7853bd165be309",
      "output": [
        "Käyttäytyivätkö osallistujat odottamattomasti?"
      ]
    },
    {
      "input": "Ensimmäisessä vaiheessa rakennamme kolme perus-LID-järjestelmää, joista yksi perustuu i-vektorimalliin ja kaksi muuta LSTM-RNN-malliin, käyttäen kahden kielen puheaineistoa Babelista: Assamin ja georgian kieli (AG). Kaksi RNN-LID-perusjärjestelmää ovat: tavallinen RNN-LID-järjestelmä (AG-RNN-LID), joka erottelee tuloksessaan kaksi kieltä toisistaan, ja monitehtäväjärjestelmä (AG-RNN-MLT), joka koulutettiin erottelemaan kaksi kieltä sekä puhelimet toisistaan.",
      "id": "task461-1ce18cbb9a654b379e95a141f16312a4",
      "output": [
        "Mikä on perusmalli?"
      ]
    },
    {
      "input": "Koska ShapeWorldin referenssikuvatekstit ovat satunnaisotannalla poimittuja, otamme testikuviin liitetyt kuvatekstit optimaalisen kuvatekstien moninaisuuden vertailuarvona ja vertaamme sitä arvioitujen mallien empiiriseen tuotosmoninaisuuteen näissä testikuvissa. Käytännössä tarkastelemme käytettyjä kielikonstruktioita ja laskemme vastaavan monimuotoisuuspistemäärän havaitun määrän ja optimaalisen määrän suhteena.",
      "id": "task461-bce6343141b5464e87d06688c29bc8c3",
      "output": [
        "Miten monimuotoisuutta mitataan?"
      ]
    },
    {
      "input": "Käytämme kolmea koodaaja-dekooderi-neuraalista arkkitehtuuria perusratkaisuna: (1) LSTM+attention LSTM BIBREF19 ja huomiomekanismi BIBREF20; (2) Transformer BIBREF21 ja (3) Universal Transformer BIBREF22.",
      "id": "task461-4acdb61036f74212b87d1842c2a76711",
      "output": [
        "Mitä kolmea konearkkitehtuuria analysoidaan?"
      ]
    },
    {
      "input": "Bossa-nova- ja jovem-guarda -genret, joita on aineistossa vähän, ovat vaikeimpia luokitella mallin avulla.",
      "id": "task461-6e802776319c4317b7fd1c6a888af356",
      "output": [
        "mitä genreä oli vaikeinta luokitella?"
      ]
    },
    {
      "input": "Mediaani-ikä on 17 vuotta masentuneiden luokassa ja 19 vuotta vertailuluokassa, mikä viittaa siihen, että joko masentuneiden käyttäjien todennäköinen populaatio on nuorempaa tai masentuneet nuoret paljastavat todennäköisemmin ikänsä saadakseen yhteyden ikätovereihinsa (sosiaalinen homofilia). Tuloksemme ovat johdonmukaisia lääketieteellisen kirjallisuuden BIBREF10 kanssa, sillä BIBREF52:n mukaan useammalle naiselle kuin miehelle annettiin masennusdiagnoosi.",
      "id": "task461-366a4bb7f1d043ada325576a4ceed0fd",
      "output": [
        "Millaisia näkemyksiä väestörakenteen ja mielenterveyden välisestä suhteesta saadaan?"
      ]
    },
    {
      "input": "Transformer Transducer -malliarkkitehtuurissamme on 18 ääni- ja 2 etikettikooderikerrosta. Jokainen kerros on identtinen sekä ääni- että etikettikoodereissa. Kerroksen laskutoimitusten yksityiskohdat on esitetty kuvassa FIGREF10 ja taulukossa TABREF11. Kaikki tässä asiakirjassa esitettyjen kokeiden mallit on koulutettu 8x8 TPU:lla, jonka ydinkohtainen eräkoko on 16 (tehokas eräkoko 2048).",
      "id": "task461-09a6a6becc854161ae9c00cdbc0db699",
      "output": [
        "Käyttääkö malli esivalmennettuja Transformer-koodaajia?"
      ]
    },
    {
      "input": "Tässä tarkastelemme viittä perusversiota, joita voimme verrata GraLapiin: (i) Yhtenäinen: kaikille viitteille annetaan 3 ja oletetaan, että niiden intensiteetti on sama, (ii) SVR+W: äskettäin ehdotettu tukivektoriregressio (SVR) BIBREF4:ssä mainituilla ominaisuuksilla, (iii) SVR+O: SVR-malli meidän ominaisuuksillamme, (iv) C4.5SSL: C4.5-puolivalvottu algoritmi BIBREF23:ssa mainituilla ominaisuuksillamme ja (v) GLM: perinteinen graafipohjainen LP-malli BIBREF9:ssä mainituilla ominaisuuksilla.",
      "id": "task461-7ce024cb72564ff3993949f49a2049e8",
      "output": [
        "Mikä on perusmalli?"
      ]
    },
    {
      "input": "Tuloksena saatu tietokokonaisuus on lähes tasapainoinen, sillä 52,3 % datasta (1 857 tapausta) on merkitty stressiä aiheuttavaksi.",
      "id": "task461-ba6cc88e1315431182e36d37c1a187f5",
      "output": [
        "Onko tietokokonaisuus tasapainossa eri luokkien välillä?"
      ]
    },
    {
      "input": "Oletimme, että kysymyksiin vastaaminen voi hyötyä näiden kahden tehtävän synergisestä vuorovaikutuksesta, joka perustuu parametrien jakamiseen ja yhteiseen harjoitteluun tässä monitehtäväympäristössä.",
      "id": "task461-873fa212ecb542ba8209f30e28dfba12",
      "output": [
        "Mitkä QA- ja QG-mallien osat jaetaan koulutuksen aikana?"
      ]
    },
    {
      "input": "Saadaan sanavektorit, joiden koko on 300, opituista sanojen upotuksista. Twitter-profiilin esittämistä varten haemme sanavektorit kaikille tietyssä profiilissa esiintyville sanoille, mukaan lukien twiiteissä esiintyvät sanat, profiilin kuvaus, emojista poimitut sanat, tekstimuotoon muunnetut kansi- ja profiilikuvat sekä YouTube-videoiden kommenteista ja kuvauksista poimitut sanat kaikkien käyttäjän aikajanalla jaettujen YouTube-videoiden osalta. Nämä sanavektorit yhdistetään Twitter-profiilin lopullisen ominaisuusvektorin laskemiseksi.",
      "id": "task461-3000ff60216f4961bbd96b94baf46f04",
      "output": [
        "Miten YouTube-sisältö käännetään vektorimuotoon?"
      ]
    },
    {
      "input": "Tässä työssä ehdotetaan jäljempänä esitettyjä mittareita, ja niiden laatua arvioidaan ihmisen suorittaman arvioinnin avulla SECREF32-alajaksossa. Automaattisten mittareiden lisäksi suoritimme myös inhimillisen arvioinnin. Päätimme käyttää SQuAD-pohjaisten kokeilujemme tietoja, jotta voimme myös mitata ehdotetun lähestymistavan tehokkuutta Curiosity-lähtöisten QG-tietojen johtamisessa tavallisesta, ei-keskustelullisesta QA-aineistosta. Otimme satunnaisesti 50 näytettä testijoukosta. Kolmea englantia ammattimaisesti puhuvaa henkilöä pyydettiin arvioimaan kysymykset, jotka oli luotu: ihmisillä (eli vertailukysymykset) ja malleilla, jotka oli koulutettu käyttämällä esivalmennusta (PT) tai (RL), sekä näiden menetelmien yhdistelmillä.Ennen kuin näytteet lähetettiin ihmisten arvioitavaksi, kysymykset sekoitettiin. Arviot kerättiin 1-5 likert-asteikolla, jotta voitiin mitata, missä määrin luodut kysymykset olivat: vastattavissa kontekstia tarkastelemalla; kieliopillisesti oikeita; kuinka paljon ulkoista tietoa vastaaminen vaatii; asiaankuuluvia kontekstin kannalta; ja semanttisesti järkeviä. Ihmisten suorittaman arvioinnin tulokset esitetään taulukossa TABREF33.",
      "id": "task461-cb72a88f94cf4356a9a9c0881f35523d",
      "output": [
        "Miten he arvioivat tuotoksen laatua?"
      ]
    },
    {
      "input": "Jotta ehdotettua mallia voitaisiin verrata suosittuun kuvanluokittelun huipputason lähestymistapaan, LabelMe-tietokokonaisuuden osalta otettiin käyttöön seuraava perustaso: Bosch 2006 (mv): Tämä perustaso on samankaltainen kuin BIBREFissä33 . Kirjoittajat ehdottavat pLSA:n käyttöä latenttien aiheiden poimimiseen ja k-nearest neighbor (kNN) -luokittimen käyttöä asiakirjojen aihejakaumien avulla. Tässä perustasossa käytetään pLSA:n sijasta valvomatonta LDA:ta, ja kNN:n (INLINEFORM0 ) eri merkitsijöiden merkinnät yhdistetään enemmistöpäätöksellä (mv). eri lähestymistavoilla LabelMe-aineistosta saadut tulokset on esitetty kuvassa. Analysoimalla tuloksia Reuters-21578- ja LabelMe-tiedoista voidaan havaita, että MA-sLDAc päihittää kaikki perusmenetelmät, mutta eräversion tarkkuus on hieman parempi, erityisesti Reuters-tiedoissa. Mielenkiintoista on, että toiseksi parhaat tulokset saavutetaan johdonmukaisesti usean annotoijan lähestymistavoilla, mikä korostaa tarvetta ottaa huomioon eri annotoijien vastausten kohina ja vääristymät. Sekä ehdotetun mallin (MA-sLDAc) eräversiota että stokastisen variationaalisen päättelyn (svi) versiota verrataan seuraaviin perusversioihin: [itemsep=0.02cm]LDA + LogReg (mv): Tämä lähtötilanne vastaa sitä, että aineistoon sovelletaan valvomatonta LDA:ta ja opetetaan logistinen regressioluokittelija asiakirjojen pääteltyjen aihejakaumien perusteella. Eri kommentoijien merkinnät yhdistettiin käyttämällä enemmistöpäätöstä (mv). Huomattakoon, että kun kutakin instanssia kohden on vain yksi merkintä, enemmistöäänestys vastaa kyseisen merkinnän käyttämistä koulutuksessa. Näin on 20-Newsgroupsin simuloitujen annotaattoreiden tapauksessa, mutta sama ei päde jakson UID89 kokeiluihin. .LDA + Raykar: Tätä perustasoa varten sovellettiin BIBREF21:n mallia käyttäen ominaisuuksina LDA:n avulla pääteltyjä asiakirjojen aihejakaumia. .LDA + Rodrigues: Blei 2003 (mv): Tämä perusskenaario on samanlainen kuin edellinen, mutta sen sijaan käytetään BIBREF9-mallia: BLEI: Tämän perustason ideana on jäljitellä dokumenttien luokittelussa suosittua viimeisintä tekniikkaa. Näin ollen käytettiin BIBREF0:n lähestymistapaa. Siinä sovelletaan LDA:ta asiakirjojen aihepiirijakaumien poimimiseen, minkä jälkeen käytetään SVM:n kouluttamiseen. Samoin kuin edellisessä lähestymistavassa, eri kommentoijien merkinnät yhdistettiin käyttämällä enemmistöpäätöstä (mv).sLDA (mv): Tämä vastaa sLDA BIBREF2:n luokitteluversiota, jossa käytetään merkintöjä, jotka on saatu suorittamalla enemmistöäänestys (mv) annotoijien vastauksista.",
      "id": "task461-9a189cbbbc364080988f303062b8b4d3",
      "output": [
        "mitkä ovat uusimmat lähestymistavat?"
      ]
    },
    {
      "input": "Lisäksi WER:n parannukset perusasetelmaan verrattuna ovat huomattavasti suuremmat Density Ratio -menetelmällä kuin Shallow Fusion -menetelmällä: WER:n suhteellinen vähennys on jopa 28 % (17,5 % $\\rightarrow $ 12,5 %) verrattuna Shallow Fusion -menetelmän suhteelliseen vähennykseen, joka on jopa 17 % (17,5 % $\\rightarrow $ 14,5 %) skenaariossa, jossa ei ole hienosäätöä.",
      "id": "task461-14acec4e25104ab69e0f2c7a65595d26",
      "output": [
        "Mitä mittareita käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Tämän luettelon avulla voimme etsiä käyttäjän profiilisivun ja poimia siitä lisätietoja, kuten nimi, sähköpostiosoite, ammatti, toimiala ja niin edelleen. Luomme myös kaksi karttaa, jotka kuvaavat aineiston sukupuolijakaumaa. Tietoaineistomme tarjoaa sijainnin, profiilitietojen ja kielenkäytön välisiä yhdistelmiä, joita voimme hyödyntää luodaksemme karttoja, jotka heijastavat aineistossa edustetun väestön demografisia, kielellisiä ja psykolingvistisiä ominaisuuksia.",
      "id": "task461-53911af5a23a4ea69aaa28c166b07b73",
      "output": [
        "Mitä väestörakenteellisia ulottuvuuksia ne saavat ihmisistä?"
      ]
    },
    {
      "input": "Arvioimme mallien suorituskykyä SQUAD BIBREF16 -tietokannassa (merkitään $\\mathcal {S}$ ). Käytämme samaa jaottelua kuin BIBREF4:ssä, jossa 70 484 tapauksen satunnaista osajoukkoa $\\mathcal {S}\\ $:sta käytetään koulutukseen ( ${\\mathcal {S}}^{tr}$ ), 10 570 tapausta validointiin ( ${\\mathcal {S}}^{val}$ ) ja 11 877 tapausta testaukseen ( ${\\mathcal {S}}^{te}$ ).",
      "id": "task461-10ae73d850b74671bfafe832e2ed2e94",
      "output": [
        "Mitä tietokokonaisuuksia käytetään tämän mallin kouluttamiseen?"
      ]
    },
    {
      "input": "Ehdotimme, että asiakirjojen visuaalisia esityksiä käytettäisiin asiakirjojen implisiittisten laatuindikaattoreiden, kuten fonttivalintojen, kuvien ja visuaalisen ulkoasun, tallentamiseen, sillä tekstisisältöä ei ole otettu huomioon. Sovelsimme neuroverkkomalleja visuaalisten ominaisuuksien tallentamiseen asiakirjojen visuaalisten esitysten perusteella. Kokeelliset tulokset osoittavat, että saavutamme 2,9 % paremman tarkkuuden kuin uusimmat tekstuaalisiin ominaisuuksiin perustuvat lähestymistavat Wikipediassa ja että suorituskyky on kilpailukykyinen tai jopa parempi kuin uusimmilla lähestymistavoilla arXivissa. Lisäksi ehdotimme yhteistä mallia, jossa yhdistetään tekstuaaliset ja visuaaliset esitykset, asiakirjan laadun ennustamiseksi. Kokeelliset tulokset osoittavat, että yhteinen mallimme päihittää pelkän visuaalisen mallin kaikissa tapauksissa ja pelkän tekstin mallin Wikipediassa ja kahdessa arXivin osajoukossa. Nämä tulokset osoittavat, että asiakirjan laatua voidaan arvioida visuaalisten piirteiden avulla ja että visuaaliset ja tekstimuotoiset asiakirjan esitykset täydentävät toisiaan laadun arvioinnissa.",
      "id": "task461-4317b4aed82e4ad1aca27c33aadc6832",
      "output": [
        "Kumpi on hyödyllisempää, visuaaliset vai tekstuaaliset ominaisuudet?"
      ]
    },
    {
      "input": "perusmalli tuottaa hyvän tuloksen myös eksplisiittisten diskurssisuhteiden tunnistamisessa, mikä on verrattavissa aiempaan parhaaseen tulokseen (92,05 % makro F1-tulos ja 93,09 % tarkkuus, kuten BIBREF11 raportoi). Kun softmax-ennustuskerroksen parametrit poistettiin, implisiittisten diskurssisuhteiden luokittelun suorituskyky parani kaikissa neljässä suhteessa, ja samalla myös eksplisiittisten diskurssisuhteiden luokittelun suorituskyky parani. Tämän jälkeen luotiin myös ensemble-malleja soveltamalla enemmistöpäätöstä kymmenen ajokerran tulosten yhdistämiseen. Taulukon 5 mukaan kunkin ensemble-mallin suorituskyky parani yksittäiseen malliin verrattuna. Täydellinen malli parantaa suorituskykyä (51,84 - 48,82 = 3,02) ja (94,17 - 93,21 = 0,96) makro-F1-pistemäärissä implisiittisten ja eksplisiittisten diskurssisuhteiden ennustamisessa. ",
      "id": "task461-c50cd23823074762a035a351734d3e8f",
      "output": [
        "Missä diskurssisuhteissa se toimii parhaiten/huonoimmin?"
      ]
    },
    {
      "input": "Kuten taulukosta TABREF3 käy ilmi, keräämme Amazonin arvostelujen avainsanoja 2 896 e-kirjasta (kustantajat: Kiwi, Rowohlt, Fischer ja Droemer), mikä johtaa 33 663 erilliseen arvostelujen avainsanaan ja keskimäärin 30 avainsanamääritykseen e-kirjaa kohti.",
      "id": "task461-9c636e3987784892a6c737e634a970f7",
      "output": [
        "kuinka suuri on sanavarasto?"
      ]
    },
    {
      "input": "Vietnamin kielen ja puheen käsittelyä käsittelevässä kuudennessa kansainvälisessä seminaarissa (VLSP 2019) ehdotetaan Hate Speech Detection (HSD) -tehtävää yhdeksi jaetuista tehtävistä, joilla voidaan käsitellä SNS-verkkojen sisällön valvontaan liittyvää ongelmaa. Tämän järjestelmän perusajatus on, miten tehdä järjestelmä, jolla on monipuolisuus tarkastella syötettä. Tämä johtuu vietnamilaisen kielen merkityksen moninaisuudesta erityisesti akronyymin, teini-koodin tyypin kanssa.",
      "id": "task461-7bb57b0fcb1943a3b864caee727158c0",
      "output": [
        "Ovatko kaikki tiedot vietnamiksi?"
      ]
    },
    {
      "input": "On totta, että edellä mainitut kuhunkin käsitejoukkoon liittyvät kuvatekstilauseet ovat ihmisen kirjoittamia ja kuvaavat kohtauksia, jotka kattavat kaikki annetut käsitteet. Ne on kuitenkin luotu tietyissä konteksteissa (esim. kuva tai video), joten ne eivät ehkä ole yhtä edustavia yleisen järjen kannalta. Jotta voimme mitata paremmin generatiivisten päättelijöiden laatua ja tulkittavuutta, meidän on arvioitava niitä kohtausten ja perustelujen avulla, jotka on luotu käyttämällä annotoijien signaaleina vain käsitejoukkoja.Keräämme lisää ihmisten kirjoittamia kohtauksia kullekin käsitejoukolle dev- ja testijoukkoon Amazon Mechanical Turk -alustan kautta tapahtuvan joukkoistamisen avulla. Kutakin syötettyä käsitejoukkoa on kommentoinut vähintään kolme eri ihmistä. Annotoijien on myös annettava lauseet perusteluina, mikä edelleen kannustaa heitä käyttämään tervettä järkeä kohtauksia luodessaan.",
      "id": "task461-bac8f25f135b46fcb409e148d0bd1bab",
      "output": [
        "Ovatko tietokannan lauseet ihmisten kirjoittamia, joille käsitejoukkoja näytettiin?"
      ]
    },
    {
      "input": "Valitsemalla englannin (En) kääntökieleksi, suoritamme identtisten englanninkielisten segmenttien kääntökohdistukset Europarl Fr-En- ja En-De-rinnakkaiskorpuksissa BIBREF18 , jolloin muodostuu moniparalleelinen Fr-En-De-korpus. Tämän jälkeen kukin Fr*-De- ja Fr-De*-pseudorinnakkaiskorpuksista muodostetaan moniparalleeliaineistosta soveltamalla edellisessä jaksossa kuvattua pivot-kielipohjaista käännöstä.",
      "id": "task461-19789cb4cb874073be8b6419cbbdca5b",
      "output": [
        "Miten synteettiset tiedot sovitetaan yhteen?"
      ]
    },
    {
      "input": "Koulutuksessa käytetään kolmea erilaista rekursiivisen neuroverkon (Recurrent Neural Network, RNN) kerrosta: koodauskerrosta, dekooderikerrosta ja ulostulokerrosta. Nämä kerrokset muodostavat yhdessä LSTM-mallin. LSTM-mallia käytetään tyypillisesti seq2seq-kääntämisessä.",
      "id": "task461-287c4dcb40324cb08c0d299b30df6094",
      "output": [
        "Mikä on järjestelmän arkkitehtuuri?"
      ]
    },
    {
      "input": "Tulevaisuudessa voidaan parantaa sensationalismipisteytystä ja tutkia dynaamisten tasapainotusmenetelmien soveltamista RL:n ja MLE:n välillä textGANBIBREF23:ssa. Työmme herättää myös eettisiä kysymyksiä sensaatiohakuisten otsikoiden tuottamisesta, joita voidaan tutkia edelleen.",
      "id": "task461-2ffb1f97ef8a4315b03047a95a0d2232",
      "output": [
        "Millaisia tulevia toimia on suunniteltu?"
      ]
    },
    {
      "input": "Luomme uuden manuaalisesti annotoidun multimodaalisen vihapuheaineiston, joka koostuu 150 000 dollarin twiiteistä, joista jokainen sisältää tekstiä ja kuvan. Kutsumme tietokokonaisuutta MMHS150K:ksi ja asetamme sen saataville verkkoon. Tässä jaksossa selvitetään tietokokonaisuuden luomisen vaiheet.",
      "id": "task461-81545ba7f9864c77b153aa778a902259",
      "output": [
        "Kuinka monta tweattia MMHS150k sisältää, 150000?"
      ]
    },
    {
      "input": "Tässä vaiheessa poimitaan tiivistelmävirkkeiden AMR-kuvaajat käyttäen tarinalauseiden AMR-kuvaajia. Jaamme tämän tehtävän kahteen osaan. Ensin etsitään tarinasta tärkeät lauseet ja sen jälkeen poimitaan keskeiset tiedot näistä lauseista niiden AMR-grafeja käyttäen.",
      "id": "task461-a06b7e5ed9be4bf7bbc882512a806226",
      "output": [
        "Miten lauseet valitaan yhteenvetokaaviosta?"
      ]
    },
    {
      "input": "Koulutimme logistisen regression perusmallin (rivi 1 taulukossa TABREF10 ) käyttämällä merkkien ngrammeja ja sanojen unigrammeja käyttäen TF*IDF-painotusta BIBREF13 , jotta saataisiin perusmalli, koska HAR:lla ei ole raportoituja tuloksia. SR- ja HATE-tietokokonaisuuksien osalta kirjoittajat raportoivat koulutetun parhaan logistisen regressiomallinsa tulokset omilla tietokokonaisuuksillaan.",
      "id": "task461-7527c7fbac524a9fb17603b39a7a73c9",
      "output": [
        "Mikä oli lähtötaso?"
      ]
    },
    {
      "input": "TF-IDF (leksikaalinen, ei-neuraalinen) on tärkeä valvomaton perustaso. NVDM (Lexical, Neural) on VAE-pohjainen lähestymistapa asiakirjojen mallintamiseen BIBREF10 .",
      "id": "task461-37a08c5e7d344f89a76b78f2d363d8d3",
      "output": [
        "Mihin leksikonipohjaisiin malleihin niitä verrattiin?"
      ]
    },
    {
      "input": "Jokainen harjoitusnäyte luodaan kolmessa vaiheessa: kohdistaminen, peittäminen ja valinta, jota kutsumme AMS-menetelmäksi. Kukin tietokokonaisuuden näyte koostuu kysymyksestä ja useista vastausehdokkaista, jotka ovat samassa muodossa kuin CommonsenseQA-tietokokonaisuus.",
      "id": "task461-06b178b84dea4646839295a5c2e57259",
      "output": [
        "Miten he valitsevat vastausehdokkaat QA-tehtäväänsä varten?"
      ]
    },
    {
      "input": "Taulukossa 5 esitetään tulokset monikielisestä harjoittelusta, jossa mallinnusyksikkönä ovat tavut. Kaikki virhetasot ovat kaikkien arvioitujen puhujien painotettuja keskiarvoja. Tässä \"+ molemmat\" tarkoittaa sekä JNAS- että WSJ-korpuksilla suoritetun harjoittelun tulosta. Monikielinen harjoittelu on tehokasta puhuja-avoimessa ympäristössä, sillä se parantaa suhteellista WER-parannusta 10 %. JNAS-korpuksesta oli enemmän hyötyä kuin WSJ-korpuksesta, koska ainu-kielen ja japanin kielen välillä on yhtäläisyyksiä.",
      "id": "task461-bbff54fda03e4828bcc375b638db36d5",
      "output": [
        "Kuinka suuria parannuksia saadaan aikaan monikielisellä ASR-koulutuksella verrattuna yksikieliseen koulutukseen?"
      ]
    },
    {
      "input": "Vaikka tietokokonaisuus kerättiin simuloidussa ympäristössä, navigointiohjeille ei asetettu mitään rakennetta, kun tietoja kerättiin joukkoresurssien avulla. Näin ollen monet aineistossamme olevat ohjeet ovat moniselitteisiä. Lisäksi ohjeiden käyttäytymisjärjestys ei ole aina sama. Esimerkiksi eräs henkilö sanoi \"käänny oikealle ja etene\" kuvaamaan osaa reitistä, kun taas toinen henkilö sanoi samankaltaisessa tilanteessa \"mene suoraan oikealle kääntymisen jälkeen\". Koska aineistomme luonnollisen kielen kuvauksissa on suurta vaihtelua, ohjeiden purkaminen käyttäytymiseksi ei ole aivan yksinkertaista. Katso lisätietoja tiedonkeruupyrkimyksistämme lisämateriaalin liitteestä A.",
      "id": "task461-6373445db9e84c76900440242e4e87ea",
      "output": [
        "Millä kielellä koe tehdään?"
      ]
    },
    {
      "input": "Hankimme tiedot kahdella annotaatiokierroksella. Ensimmäisellä kierroksella etsimme alkuperäisiä ja harvinaisia lauseenmuutosehdotuksia.",
      "id": "task461-2e028a9463fe430387eda01b11d9938c",
      "output": [
        "Miten ne tuovat kielellistä vaihtelua?"
      ]
    },
    {
      "input": "Tässä työssä hyödynnämme laajalti tunnustettua uusinta tekniikkaa - BERT BIBREF18 - ja koulutamme sen kolmella yleisimmällä tietokokonaisuudella: MNLI BIBREF19, GLUE RTE BIBREF20, BIBREF21 ja FEVER BIBREF22. Muutamme kaikki tietokokonaisuudet binääritapauksiksi: \"Jos joissakin aineistoissa on merkintä \"neutraali\", se muutetaan merkinnäksi \"ei-merkintä\".Merkinnät täysin näkymättömissä asetelmissamme sovellamme tätä esivalmennettua merkintämallia suoraan kaikkien $\\textsc {0shot-tc}$-näkökohtien testijoukkoihin. Osittain näkymättömien merkintöjen tapauksessa, jossa annotoitua dataa annetaan tarkoituksellisesti, esivalmennamme BERTin ensin MNLI/FEVER/RTE-mallilla ja hienosäädämme sen jälkeen annetulla harjoitusdatalla.",
      "id": "task461-d9b26fd4453840c4bfd34ae18d397d24",
      "output": [
        "Käytetäänkö niissä esivalmisteltuja malleja?"
      ]
    },
    {
      "input": "Vertaamme menetelmäämme seuraaviin perusmenetelmiin: (1) yhden tehtävän CNN: CNN-mallin kouluttaminen kullekin tehtävälle erikseen; (2) yhden tehtävän FastText: yhden FastText-mallin BIBREF23 kouluttaminen kiinteillä upotuksilla kullekin yksittäiselle tehtävälle; (3) hienosäädetty kokonaisvaltainen MTL-CNN: tavallinen siirto-oppimismenetelmä, jossa yksi MTL-CNN-malli koulutetaan kaikille koulutustehtäville offline-tilassa ja sen jälkeen hienosäädetään luokittelukerrosta (esim. $\\mathrm {M}^{(cls)}$ Kuva 1 (a)) kussakin kohdetehtävässä; (4) Matching Network: metriikkaoppimiseen perustuva muutaman otoksen oppimismalli, joka on koulutettu kaikkiin koulutustehtäviin; (5) Prototyyppinen verkko: Matching Networkin muunnelma, jossa on erilainen ennustinfunktio kuin Eq. 9 ; (6) Kaikkien yksittäistehtävämallien konvektiivinen yhdistäminen: koulutetaan yksi CNN-luokittelija kullekin metakoulutustehtävälle erikseen ja otetaan kooderi, minkä jälkeen kutakin kohdetehtävää varten koulutetaan kaikkien edellä mainittujen yksittäistehtäväkoodereiden lineaarinen yhdistelmä yhtälön ( 24 ) mukaisesti. ",
      "id": "task461-0d949da17fac47519f01ad7d875038a1",
      "output": [
        "Ovatko ne verrattavissa MAML-algoritmiin?"
      ]
    },
    {
      "input": "Koska INLINEFORM0 on vakio, meidän tarvitsee vain minimoida INLINEFORM1 , joten tappiofunktio on: DISPLAYFORM0",
      "id": "task461-b72477c485c74c8c80b75027b48c8aad",
      "output": [
        "Miten odotuksen tasaushäviö määritellään?"
      ]
    },
    {
      "input": "Tietyn transkriptoidun lausuman koodaaminen tapahtuu ensin BIBREF14 (Byte Pair Encoding, BPE) BIBREF14 -pakkausalgoritmilla, joka jakaa sanat perustavanlaatuisiksi osasanayksiköiksi (tavupareiksi tai BP-yksiköiksi) ja pienentää sulautetun sanaston kokoa. Sitten käytetään BiLSTM BIBREF15 -kooderia, ja BiLSTM:n lähtötilaa pidetään tämän lausuman vektoriesityksenä. Lopuksi käytetään täysin kytkettyä Feed-forward-neuraaliverkkoa (FNN), jota seuraa softmax-kerros, joka on nimetty monikerroksiseksi perceptron-moduuliksi (MLP), suorittamaan vektoriin perustuva toimialueen/intention luokittelutehtävä. Nimeämme sen Oracleksi yksinkertaisesti siksi, että oletamme, että hypoteesit ovat meluisia versioita transkriptiosta.",
      "id": "task461-d58583bebe4145a8b75835bdab34f13f",
      "output": [
        "Mitä ASR-järjestelmää tai -järjestelmiä tässä työssä käytetään?"
      ]
    },
    {
      "input": "Tarkastamme manuaalisesti 148 näytettä testijoukon nähdystä osasta, joka sisältää 440 relaatiota, ja laskemme ilmaistut, poisjätetyt, väärät ja liikaa generoidut (hallusinoidut) faktat.",
      "id": "task461-cfab1b2b8afd4f6698c6caece33e8228",
      "output": [
        "Miten tuloksena olevan tekstin uskollisuutta arvioidaan?"
      ]
    },
    {
      "input": "Muista töistä poiketen emme näytä työntekijöille asiakirjoja lainkaan, vaan annamme vain kuvauksen asiakirjaryhmän aiheesta sekä ehdotukset. Näin varmistetaan, että tehtävät ovat pieniä, yksinkertaisia ja nopeasti suoritettavia (ks. kuva KUVA 4 ).",
      "id": "task461-3f51cf6732f8457e91d1f686233dea4e",
      "output": [
        "Miten joukkojen työntekijöitä opastettiin tunnistamaan tärkeät elementit suurista asiakirjakokoelmista?"
      ]
    },
    {
      "input": "Raportissa tab:blueperpl ilmoitetaan BLEU-pisteet testisarjan lauseiden rekonstruoinnista niiden sisällön ja ominaisuuksien esityksistä sekä rekonstruktion mallien perpleksiteetit. Molemmissa malleissa käytämme säteen dekoodausta, jossa säteen koko on kahdeksan. Huomaa, että molemmilla malleilla kaikki ja paras luokittelutarkkuus ovat yleensä melko samankaltaisia, vaikka perusmallin osalta ne ovat usein lähes täsmälleen samat, kun perusmallin tuloksissa on vain vähän tai ei lainkaan monimuotoisuutta.",
      "id": "task461-35d5f3814e18424fb16a34e48ad0df00",
      "output": [
        "Mitä mittareita käytetään automaattisessa arvioinnissa?"
      ]
    },
    {
      "input": "Määritellään \"koodausjärjestelmä\", joka on joukko merkintöjä, huomautuksia tai koodeja, joita korpuksen kohteilla voi olla. Järjestelmät sisältävät muodollisia määritelmiä tai menettelyjä ja usein myös esimerkkejä, erityisesti rajatapauksia varten. Seuraavaksi koodaajat koulutetaan koodausjärjestelmän avulla, mikä tyypillisesti edellyttää vuorovaikutteista palautetta. Koulutus johtaa joskus muutoksiin koodausjärjestelmässä, jolloin ensimmäisestä kierroksesta tulee pilottitesti. Tämän jälkeen koodaajat tarkastelevat itsenäisesti ainakin osaa samoista asioista koko prosessin ajan, jolloin lasketaan \"inter-annotator agreement\" tai \"inter-rater reliability\". Lopuksi erimielisyyksien osalta suoritetaan \"sovitteluprosessi\", joka joskus toteutetaan enemmistöpäätöksellä ilman keskustelua ja joskus keskusteluun perustuen.",
      "id": "task461-e62237ede1ae4376a55e8db02a226b7f",
      "output": [
        "Mitkä ovat jäsennellyn sisällönanalyysin keskeiset parhaat käytännöt?"
      ]
    },
    {
      "input": "Kielimallin tavoitteena on määrittää sanasarjoille mielekkäitä todennäköisyyksiä. Kun annetaan joukko merkkejä $\\mathbf {X}=(x_1,....,x_T)$, jossa $T$ on sanajakson pituus, tehtävämme on arvioida yhteinen ehdollinen todennäköisyys $P(\\mathbf {X})$, joka onjos $(x_{1}, \\ldots , x_{i-1})$ on konteksti. Kielimallien suorituskyvyn sisäinen arviointi on perpleksisyys (PPL), joka määritellään merkkien joukon käänteistodennäköisyydeksi ja otetaan $T^{th}$-juuresta, jossa $T$ on merkkien lukumäärä Ehdotamme yhteisen todennäköisyyden approksimaatiota seuraavasti,Tämäntyyppisiä approksimaatioita on aiemmin tutkittu kaksisuuntaisten RNN LM:ien BIBREF9 kanssa, mutta ei syvien muunnosmallien osalta. Määritämme siis pseudo-epäselvyyspisteytyksen edellä mainitusta approksimoidusta yhteisestä todennäköisyydestä.",
      "id": "task461-99b8c0c03e41402ca0d7205ee113eb97",
      "output": [
        "Miten pseudo-epäselvyys määritellään?"
      ]
    },
    {
      "input": "Sisäinen tietokokonaisuutemme sisältää manuaalisesti annotoituja RE-tietoja 6 kielestä: kielet: englanti, saksa, espanja, italia, japani ja portugali. Se määrittelee 56 oliotyyppiä (esim. henkilö, organisaatio, geopoliittinen yksikkö, sijainti, laitos, aika, tapahtuma_väkivalta jne.) ja 53 olioiden välistä relaatiotyyppiä (esim. agentOf, locatedAt, partOf, timeOf, affectedBy jne.). ACE05-tietokanta sisältää manuaalisesti annotoituja RE-tietoja kolmella kielellä: Englanti, arabia ja kiina. Siinä määritellään 7 oliotyyppiä (Person, Organization, Geo-Political Entity, Location, Facility, Weapon, Vehicle) ja 6 olioiden välistä relaatiotyyppiä (Agent-Artifact, General-Affiliation, ORG-Affiliation, Part-Whole, Personal-Social, Physical). monikielinen ACE (Automatic Content Extraction) 2005 -tietokanta BIBREF11.",
      "id": "task461-a944388f220f42a693257ee36097b78b",
      "output": [
        "Mitä tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": "OIVALLUS 1: Poliittiset kahvat muuttavat profiiliaan todennäköisemmin kuin niiden seuraajat.  Analysoimme kuvassa FIGREF12 esitettyjä suuntauksia ja havaitsemme, että poliittiset kahvat eivät muuta käyttäjätunnuksiaan lainkaan. Tämä on ristiriidassa kuvassa FIGREF15 esitetyn suuntauksen kanssa, jossa nähdään, että monet käyttäjätunnukset vaihtavat käyttäjätunnuksiaan useita kertoja.  OIVALLUS 3: Poliittisilla kahvoilla on taipumus tehdä uusia muutoksia, jotka liittyvät aiempiin attribuuttiarvoihin. Seuraajat tekevät kuitenkin verrattain vähemmän aiempiin attribuuttiarvoihin liittyviä muutoksia.",
      "id": "task461-50c2c59553094a3ca2d9447d68cbb47e",
      "output": [
        "Miten profiilimuutokset vaihtelevat vaikutusvaltaisten johtajien ja heidän seuraajiensa kohdalla sosiaalisen liikkeen aikana?"
      ]
    },
    {
      "input": "Luokittelijalle syötettävien erilaisten syötteiden määrän rajoittamiseksi haluamme siis vähentää niiden erilaisten sanantunnistustulosten määrää, joita hyökkääjä voi saada aikaan, emmekä vain niiden sanojen määrää, joilla mallia \"huijataan\". Nimitämme tätä mallin ominaisuutta herkkyydeksi.",
      "id": "task461-75cadb826f9b44b2a953e6f33c4417e1",
      "output": [
        "Mitä tarkoittaa määrä \"herkkyys\"?"
      ]
    },
    {
      "input": "Viimeaikaisessa työssä on kuitenkin havaittu, että monet NLI-tietoaineistot sisältävät harhoja eli annotaatioartefakteja eli hypoteeseissa esiintyviä piirteitä, joiden avulla mallit voivat suoriutua yllättävän hyvin pelkän hypoteesin avulla oppimatta kahden tekstin välistä suhdetta BIBREF2 , BIBREF3 , BIBREF4 . Esimerkiksi joissakin tietokokonaisuuksissa negaatiosanat, kuten \"ei\" ja \"ei kukaan\", liittyvät usein ristiriitaisuussuhteeseen. Tällaisten vääristymien seurauksena mallit eivät välttämättä yleisty hyvin muihin tietokokonaisuuksiin, jotka sisältävät erilaisia vääristymiä tai eivät sisällä tällaisia vääristymiä.",
      "id": "task461-5085774b4b94468fbc8c1c42925ac4a5",
      "output": [
        "Johtuuko tällainen vääristymä huonosta annotaatiosta?"
      ]
    },
    {
      "input": "Käytämme moniluokkaista Naive Bayes -luokittelijaa toisen vaiheen luokitusmekanismina, jolla twiitit luokitellaan asianmukaisesti sen mukaan, minkä tyyppisistä hätätilanteista ne kertovat.",
      "id": "task461-9fbd7a6777ac44a9a0f922e699d8d567",
      "output": [
        "Mitä luokittelijaa käytetään hätätilanteiden luokittelussa?"
      ]
    },
    {
      "input": " Tässä luvussa suosittelemme joukon arvioinnin suunnitteluun liittyviä muutoksia, joita mielestämme tarvitaan ihmisen ja koneen välisen pariteetin arvioimiseksi ja jotka vahvistavat ihmisen suorittamaa monikielisen kääntämisen arviointia yleisesti.Suositukset ::: (R1) Valitse ammattikääntäjät arvioijiksi.Sokkokokeessamme (SECREF3) ei-asiantuntijat arvioivat ihmisen ja koneen tekemän käännöksen välistä pariteettia, kun taas ammattikääntäjät eivät arvioineet, mikä viittaa siihen, että ammattikääntäjät laiminlyövät hienovaraisemmat erot eri käännöksen tuotosten välillä.Suositukset ::: (R2) Arvioi asiakirjoja, älä lauseita. Kun ammattikääntäjät arvioivat lauseita satunnaisessa järjestyksessä, he arvioivat konekäännökset myönteisemmin, koska he eivät pysty tunnistamaan tekstin yhtenäisyyteen ja koheesioon liittyviä virheitä, kuten saman tuotenimen eri käännöksiä. Kokeilumme osoittavat, että kokonaisten asiakirjojen (eli kokonaisten uutisartikkeleiden) käyttäminen arviointiyksikkönä kasvattaa ihmis- ja konekäännöksen välistä eroa (jakso SECREF4).Suositukset ::: (R3) Arvioi sujuvuutta adekvaattisuuden lisäksi.Arvioijat, jotka arvioivat kohdekielen sujuvuutta ilman pääsyä lähdeteksteihin, suosivat enemmän ihmiskäännöskäännöstä kuin arvioijat, joilla on pääsy lähdeteksteihin (jaksot SECREF4 ja SECREF24). Kaikissa kokeiluissamme arvioijat suosivat ihmiskäännöstä sujuvuuden osalta, mutta aivan kuten BIBREF3:n BIBREF3-arvioinnissa, he eivät havaitse merkittävää eroa ihmis- ja konekäännöksen välillä lausetason riittävyyden osalta (taulukot TABREF21 ja TABREF30). Taulukossa TABREF34 esitetty virheanalyysi osoittaa myös, että konekielinen käännös on edelleen jäljessä ihmiskäännöksistä sujuvuuden, erityisesti kieliopillisuuden, osalta. suositukset ::: (R4) Älä muokkaa viitekäännöksiä voimakkaasti sujuvuuden kannalta.Ammattimaisissa käännöstyönkuluissa tekstejä tarkistetaan tyypillisesti kohdekielen sujuvuuteen keskittyen ensimmäisen käännösvaiheen jälkeen. Kuten jaksossa SECREF24 tekemässämme kokeessa kävi ilmi, aggressiivinen muokkaus voi tehdä käännöksistä sujuvampia mutta epätarkempia, jopa siinä määrin, että niitä ei enää erota tarkkuudeltaan monikielisistä käännöksistä (taulukko TABREF30).Suositukset ::: (R5) Alkuperäisten lähdetekstien käyttäminen.Arvostelijat suosivat merkittävästi ihmisen tekemiä käännöksiä sellaisten tekstien konekäännösten kustannuksella, jotka on alun perin kirjoitettu lähdekielellä, mutta eivät sellaisia lähdetekstejä, jotka ovat käännöksiä itsessään (jakso SECREF35). Tuloksemme ovat lisänäyttöä siitä, että käännetyt tekstit ovat yleensä yksinkertaisempia kuin alkuperäiset tekstit, ja niitä on puolestaan helpompi kääntää mekaanisella tekstinkäsittelyllä.",
      "id": "task461-7b839514dcbb4ba0a7d6b560e93eec67",
      "output": [
        "Mitä suosituksia he antavat?"
      ]
    },
    {
      "input": "CNN-Dailymail-tietokannan osalta Lead-3-mallia pidetään vahvana perustasona; sekä abstrahoiva BIBREF16- että uuttamismenetelmä BIBREF14 ylittävät tämän tietokannan osalta tämän perustason vain marginaalisesti. AMR-pankin proxy-raporttiosion osalta pidämme Lead-1-AMR-mallia perustasona.",
      "id": "task461-15f7926e9a5a425b86a50b7862ebc982",
      "output": [
        "Mihin muihin menetelmiin niitä verrataan?"
      ]
    },
    {
      "input": "Mallien hienosäätöä varten kokeilemme kustakin harjoitusjoukosta kolmea vaihtoehtoa: (i) alkuperäistä englanninkielistä versiota (Orig), (ii) englanninkielistä parafraasia, joka on tuotettu käyttämällä espanjaa tai suomea käännöksenä (BT-ES ja BT-FI), ja (iii) koneellisesti käännettyä versiota espanjaksi tai suomeksi (MT-ES ja MT-FI).",
      "id": "task461-22b45984e5b74db9a62679529f10fa2e",
      "output": [
        "Mitä kieliä he käyttävät kokeissaan?"
      ]
    },
    {
      "input": "Mallimme kouluttamiseksi loimme 20 000 demonstroidun 7 DOF:n liikeradan (6 robottiniveltä ja 1 tarttumisulottuvuus) muodostaman tietokokonaisuuden simuloidussa ympäristössämme yhdessä lauseen generaattorin kanssa, joka pystyy luomaan luonnollisia tehtäväkuvauksia kutakin skenaariota varten. Kieligeneraattorin luomiseksi teimme ihmissubjektitutkimuksen, jonka avulla keräsimme sijoittelutehtävän lausemalleja sekä yleisiä sanoja ja synonyymejä kullekin käytetylle ominaisuudelle. Näitä tietoja hyödyntämällä pystymme tuottamaan yli 180 000 yksilöllistä lausetta luodusta skenaariosta riippuen. Testataksemme malliamme generoimme 500 uutta skenaariota, joissa testasimme kutakin kolmea ominaisuutta oikean kohteen tunnistamiseksi muiden keilojen joukossa. ",
      "id": "task461-dc1c423fec60408586609ac81e2f627b",
      "output": [
        "Opitaanko ehdotetussa päästä päähän -lähestymistavassa vahvistetun vai valvotun oppimisen avulla?"
      ]
    },
    {
      "input": "$\\mathit {\\texttt {+}PPMI}$ epäonnistuu vain RW- ja analogiatehtävissä, ja oletamme, että tässä $\\mathit {\\texttt {-}PMI}$ on hyödyllinen: positiivisen informaation puuttuessa negatiivista informaatiota voidaan käyttää harvinaisten sanojen esitysten ja sana-analogioiden parantamiseen.",
      "id": "task461-31662df977ba4feeb6d34991a678c793",
      "output": [
        "Mitä haittoja negatiivisen PMI:n leikkaamisesta on?"
      ]
    },
    {
      "input": "Kun testaamme eri kieliä, ilmoitamme tarkkuuden kahdessa asetelmassa: keskimääräinen tarkkuus kunkin yhden kielen mallin osalta (Avg) ja tarkkuus, joka saadaan, kun koulutetaan kaikkien kielten paitsi kohdekielen yhdistelmällä (All). Jälkimmäistä asetusta käytetään myös sulautusmallissa. Raportoimme tarkkuuden kaikista kokeista.",
      "id": "task461-a7a90ad5e50f40f794f2996292153e3e",
      "output": [
        "Mitä arviointimittareita käytetään?"
      ]
    },
    {
      "input": "KBQA (Knowledge Base Question Answering) -järjestelmät vastaavat kysymyksiin hankkimalla tietoa KB-tupeleista BIBREF0 , BIBREF1 , BIBREF2 , BIBREF3 , BIBREF4 , BIBREF5 .",
      "id": "task461-00cd78268dfe4d91985718e978d3a488",
      "output": [
        "Mikä on KBQA:n ydinkomponentti?"
      ]
    },
    {
      "input": "Matematiikan varianssin käsitteeseen nojautuen paikallinen varianssin häviö määritellään sen varianssin vastavuoroiseksi arvoksi, kun odotetaan, että tarkkaavaisuusmalli pystyy keskittymään selvemmin erottuviin osiin. Tavallinen varianssilaskenta perustuu jakauman keskiarvoon. Koska aiemmissa töissä BIBREF15, BIBREF16 kuitenkin mainittiin, että mediaaniarvo on keskiarvoa kestävämpi poikkeavuuksien suhteen, käytämme mediaaniarvoa huomiojakauman varianssin laskemiseen. Näin ollen paikallinen varianssihäviö voidaan laskea seuraavasti: missä $\\hat{\\cdot }$ on mediaanioperaattori ja $\\epsilon $ käytetään nollan välttämiseksi nimittäjässä.",
      "id": "task461-c4da50b1e7fc4de5b8cb6a8f7c71ffae",
      "output": [
        "Miten he määrittelevät paikallisen varianssin?"
      ]
    },
    {
      "input": "Lopulliset, koodien kanssa sekoitetut twiitit lähetettiin kolmen annotoijan ryhmälle, jotka olivat yliopisto-opiskelijoita ja puhuivat sujuvasti sekä englantia että hindiä.",
      "id": "task461-f22ca3d92fd140c1974134199ffde1b5",
      "output": [
        "Kuinka monta merkitsijää merkitsi kunkin tekstin?"
      ]
    },
    {
      "input": "SanaverkkoKuten kuvassa KUVA 4 esitetään, sanaverkko on suunnattu graafi INLINEFORM0 , jossa INLINEFORM1 edustaa solmujen joukkoa ja INLINEFORM2 edustaa reunojen joukkoa. Kiinankielisen lauseen, joka on kiinalaisten merkkien sarja INLINEFORM3 , kaikkia mahdollisia sanoiksi katsottavia osajonoja käsitellään huippuina, eli INLINEFORM4 . Tämän jälkeen kaikki naapurisanat yhdistetään toisiinsa suunnatuilla reunoilla niiden sijainnin mukaan alkuperäisessä lauseessa, eli INLINEFORM5 .",
      "id": "task461-0869ee13c4d1432db757deda380d4d3c",
      "output": [
        "Miten sanoista saadaan sanaverkkoja?"
      ]
    },
    {
      "input": "Aiemmissa QA-SRL:n annotointiyrityksissä käytettiin aluksi koulutettuja annotoijia BIBREF4 , mutta myöhemmin turvauduttiin joukkoistamiseen BIBREF5 skaalautuvuuden saavuttamiseksi.",
      "id": "task461-30a4c5deffa847c78ee0b2f56cb5baec",
      "output": [
        "Miten korpus saatiin?"
      ]
    },
    {
      "input": "Block Zoo on avoin kehys, ja siihen voidaan tulevaisuudessa lisätä lisää moduuleja. Upotuskerros: Tuetaan sanojen/merkkien upottamista ja käsityönä tehtyjä lisäominaisuuksia, kuten pos-taggausta. Neuroverkkokerrokset: Block Zoo tarjoaa yleisiä kerroksia, kuten RNN, CNN, QRNN BIBREF2 , Transformer BIBREF3 , Highway network, Encoder Decoder architecture jne. Lisäksi huomiomekanismeja käytetään laajalti neuroverkoissa. Näin ollen tuemme myös useita huomiokerroksia, kuten Linear/Bi-linear Attention, Full Attention BIBREF4 , Bidirectional attention flow BIBREF5 , jne. Samaan aikaan tuetaan myös regularisointikerroksia, kuten Dropout, Layer Norm, Batch Norm jne., yleistämiskyvyn parantamiseksi. Häviöfunktio: PyTorchiin sisäänrakennettujen tappiofunktioiden lisäksi tarjoamme lisää vaihtoehtoja, kuten Focal Loss BIBREF6 .Metriikka: Luokittelutehtävää varten tuetaan AUC-, Accuracy-, Precision/Recall- ja F1-mittareita. Sekvenssien merkitsemistehtävää varten tuetaan F1/Accuracy-mittareita. Tiedon tislaustehtävässä tuetaan MSE/RMSE-mittareita. MRC-tehtävässä tuetaan ExactMatch/F1.",
      "id": "task461-6882e6d63c7c4172b058a7129a69b830",
      "output": [
        "Mitä neuroverkkomoduuleja NeuronBlocks sisältää?"
      ]
    },
    {
      "input": "Aluksi kokeilemme useita ei-neuraalisia malleja, kuten tukivektorikoneita (Support Vector Machines, SVM), logistista regressiota, Naïve Bayesia, Perceptronia ja päätöspuita.  Lopuksi kokeilemme neuraalisia malleja, vaikka aineistomme on suhteellisen pieni. Koulutamme sekä kaksikerroksista kaksisuuntaista Gated Recurrent Neural Network (GRNN) BIBREF20 -mallia että Convolutional Neural Network (CNN) -mallia (BIBREF21) rinnakkaisilla suodattimilla, joiden koko on 2 ja 3, sillä nämä ovat osoittautuneet tehokkaiksi tekstin tunteiden tunnistamista käsittelevässä kirjallisuudessa (esim. BIBREF22, BIBREF23). ",
      "id": "task461-f6bf5eab5a3b4973b14c7e7d2ebbff51",
      "output": [
        "Mitä valvottuja menetelmiä käytetään?"
      ]
    },
    {
      "input": "Valitsimme kokeita varten kolme erilaista tietokokonaisuutta: SNLI, MultiNLI ja SICK. Stanford Natural Language Inference (SNLI) -korpus BIBREF4 on tietokokonaisuus, joka sisältää 570 000 ihmisen kirjoittamaa lauseparia, jotka on manuaalisesti merkitty merkinnöillä entailment, contradiction ja neutral.  MultiNLI-korpus (Multi-Genre Natural Language Inference) BIBREF5 koostuu 433 000 ihmisen kirjoittamasta lauseparista, jotka on merkitty merkinnöillä entailment, contradiction ja neutral. SICK BIBREF6 on tietokokonaisuus, joka on alun perin luotu kompositionaalisen distributiivisen semantiikan (DS) mallien testaamiseksi. ",
      "id": "task461-20a3600ed2ba4ba6a4decc5966c2bc58",
      "output": [
        "Mitä tietokokonaisuuksia käytettiin?"
      ]
    },
    {
      "input": "Tämän seurauksena SNLI-VE:n neutraalissa luokassa on huomattavia merkintävirheitä. Vu BIBREF3 arvioi tämän luokan virheiksi 31 % ja ristiriita- ja seuraamusluokkien virheiksi 1 %.",
      "id": "task461-e3f3b669e0d24d71b0b8077a4b4269f5",
      "output": [
        "Missä luokassa SNLI-VE:n virheprosentti on suurin?"
      ]
    },
    {
      "input": "kuvan ominaisuuksien esivalintaosa, joka mallintaa taipumusta, johon ihmiset keskittyvät kysyäkseen kysymyksiä Ehdotamme, että ongelmien lieventämiseksi ja RoI-mallien mallintamiseksi suoritetaan saliency-tyyppinen esivalintaoperaatio. Kuva jaetaan ensin $g \\ kertaa g$ -ruutuihin, kuten kuvassa on esitetty. 2 . Kun alueeksi otetaan $m\\ kertaa m$ ruudukkoa ja askeleeksi $s$ ruudukkoa, saadaan $n\\ kertaa n$ aluetta, jossa $n=\\left\\lfloor \\frac{g-m}{s}\\right\\rfloor +1$ . Tämän jälkeen syötämme alueet valmiiksi koulutettuun ResNet BIBREF24 -syvään konvoluutiohermoverkkoon tuottaaksemme $n\\times n\\times d_I$ -ulotteisia alueominaisuuksia, jossa $d_I$ on ominaisuuden ulottuvuus viimeistä täysin yhdistettyä kerrosta edeltävältä kerrokselta.",
      "id": "task461-dc658cae7ee94137aa92a59ccc87f150",
      "output": [
        "Käytetäänkö uudessa järjestelmässä valmiiksi poimittuja rajauslaatikoita ja/tai piirteitä?"
      ]
    },
    {
      "input": "Ehdolliset satunnaiskentätEhdolliset satunnaiskentät (CRF) BIBREF10 ovat vakiintunut lähestymistapa, kun käsitellään peräkkäisiä tietoja sekvenssien merkitsemisen yhteydessä. BiLSTM-CRF Ennen syvien neuraalisten kielimallien syntymistä BiLSTM-CRF-mallit BIBREF11 olivat saavuttaneet huippuluokan tuloksia sekvenssien merkitsemistehtävässä. MonitehtäväoppiminenMulti-Task Learning (MTL) BIBREF15 on tullut suosituksi syväoppimisen edistymisen myötä. BioBERTDeep neuraaliset kielimallit ovat viime aikoina kehittyneet menestyksekkääksi menetelmäksi tekstin esittämiseen. Erityisesti Bidirectional Encoder Representations from Transformers (BERT) päihitti aiemmat huipputason menetelmät huomattavasti eri NLP-tehtävissä BIBREF17.",
      "id": "task461-de1a5032515d43fdae8217164ad0128a",
      "output": [
        "Mitä perusjärjestelmiä ehdotetaan?"
      ]
    },
    {
      "input": "Skenaarion simuloimiseksi jaoimme Microsoft COCO -tietokannan elintarvikealan ja muun kuin elintarvikealan tietokokonaisuuksiin. elintarvikealan tietokokonaisuudessa on 3 806 kuvaa harjoittelua varten ja 1 775 kuvaa validointia varten. Muuhun kuin elintarvikkeisiin liittyvässä tietokokonaisuudessa on 78 976 kuvaa koulutusta varten ja 38 749 validointia varten. Mukauttaminen elintarvikealan kuvatekstien laatimiseen",
      "id": "task461-18853558fd1b48299b649631eafdc28f",
      "output": [
        "Kuinka monta esimerkkiä on lähdealueella?"
      ]
    },
    {
      "input": "Taulukossa TABREF11 esitetään eri oppimismenetelmillä saadut testikokeiden tarkkuudet, mukaan lukien nykyiset huipputason tulokset.",
      "id": "task461-584dad0c05fa468d950ea51152d0dbe4",
      "output": [
        "mihin malleihin niitä verrattiin?"
      ]
    },
    {
      "input": "Yleisesti ottaen malli muuttaa segmentit TC-CNN:n avulla objektipareiksi ja siirtää lauseen bi-GRU:n läpi globaalin esityksen saamiseksi. Sen jälkeen yhdistämme objektit ja parit globaaliin esitykseen ja teemme pareittaisen päättelyn segmenttien välisen suhteen havaitsemiseksi. Ablaatiotutkimukset osoittavat, että ehdotetulla SCRN:llä segmenttitasolla on kyky relationaaliseen päättelyyn ja se edistää tulosta merkittävästi.",
      "id": "task461-fdb94d56ca8b4d3cac95e9dc70936a29",
      "output": [
        "Miten relaatioverkkoa käytetään kausaalisuuden päättelyyn segmenttitasolla?"
      ]
    },
    {
      "input": "Tällä lähestymistavalla parannamme tavallisten yhteistyömallien tarkkuutta jopa neljä prosenttiyksikköä.",
      "id": "task461-d9e9e938b50c464ca732334d815788e4",
      "output": [
        "Kuinka paljon paremmat tulokset kuin tavallisella BERT-järjestelmällä saavutetaan?"
      ]
    },
    {
      "input": "Seuraavassa on luettelo arkkitehtuureista, joille Transformers tarjoaa tällä hetkellä viitetoteutuksia ja esivalmennettuja painoja. Nämä mallit jakautuvat kahteen pääryhmään: generatiiviset mallit (GPT, GPT-2, Transformer-XL, XLNet, XLM) ja kielen ymmärtämiseen tarkoitetut mallit (Bert, DistilBert, RoBERTa, XLM).BERT (BIBREF13) on kaksisuuntainen Transformer-pohjainen kooderi, joka on esivalmennettu lineaarisella yhdistelmällä maskeeratun kielen mallintamisen ja seuraavan lauseen ennustamisen tavoitteita.RoBERTa (BIBREF5) on BERTin replikaatiotutkimus, joka osoitti, että hyperparametrien ja harjoitusdatan koon huolellinen virittäminen johtaa merkittävästi parempiin tuloksiin kielen ymmärtämisessä.DistilBERT (BIBREF32) on pienempi, nopeampi, halvempi ja kevyempi versio BERTistä, joka on esivalmennettu tietämyksen tislauksen avulla.GPT (BIBREF34) ja GPT2 (BIBREF9) ovat kaksi suurta automaattista regressiivistä kielenmallia, jotka on esivalmennettu kielen mallintamisen avulla. GPT2:ssa esiteltiin nollakohtaisen tehtävänsiirron valmiuksia erilaisissa tehtävissä, kuten konekääntämisessä tai luetun ymmärtämisessä.Transformer-XL (BIBREF35) esittelee arkkitehtuurimuutoksia, joiden avulla Transformerit voivat oppia riippuvuutta kiinteän pituuden jälkeen ilman, että ajallinen johdonmukaisuus häiriintyy segmenttitason toistuvuuden ja suhteellisen sijainnin koodausjärjestelmien avulla.XLNet (BIBREF4) perustuu Transformer-XL:ään ja ehdottaa automaattisesti regressiivistä esiharjoittelua, jossa yhdistetään BERT:n kaksisuuntainen kontekstivirta ja automaattisesti regressiivinen kielen mallintaminen maksimoimalla odotettu todennäköisyys sanasekvenssin permutaatioiden suhteen.XLM (BIBREF8) osoittaa esivalmennettujen representaatioiden tehokkuuden kieltenvälisessä kielten mallintamisessa (sekä yksikielisessä aineistossa että rinnakkaisessa aineistossa) ja kieltenvälisessä kielten ymmärtämisessä. vapautamme mallin ja vastaavat esivalmennuspäätteet (kielten mallintaminen, seuraavan lauseen ennustaminen BERT:lle) systemaattisesti mukautettavaksi esivalmennuksen tavoitteiden avulla. Saatavilla on myös joitakin malleja, jotka on hienosäädetty myöhempiin tehtäviin, kuten SQuAD1.1. Kirjaston kautta on saatavilla yli 30 esivalmennettua painotusta, joista yli 10 on esivalmennettu muille kielille kuin englannille. Jotkin näistä muista kuin englanninkielisistä esivalmennetuista malleista ovat monikielisiä malleja (kaksi niistä on valmennettu yli 100 kielellä).",
      "id": "task461-dd8fa7de23554871afac50c92753df7b",
      "output": [
        "Mitä huipputason yleiskäyttöisiä esivalmennettuja malleja on saatavilla yhtenäisen sovellusliittymän kautta? "
      ]
    },
    {
      "input": "Sanat esitetään kiinteän pituisina vektoreina INLINEFORM0, jotka on saatu yhdistämällä GloVen esivalmennetut upotukset ja DepecheMood BIBREF19 -leksikon esitys. Koska emme voi suoraan ketjuttaa token-pohjaisia upotuksia (jotka GloVe tarjoaa) ja DepecheMoodin lemma#PoS-pohjaista esitystä, rakensimme jälkimmäisen uudelleen token-pohjaisessa muodossa soveltamalla täsmälleen samaa metodologiaa kahdella erolla: aloitimme suuremmasta tietokokonaisuudesta (51,9K uutisartikkelia 25,3K:n sijaan) ja käytimme frekvenssirajoitusta eli säilytimme vain ne tokenit, jotka esiintyvät korpuksessa vähintään viisi kertaa.",
      "id": "task461-1e1e9ba9eee942fe9c1a2a979f000ce4",
      "output": [
        "Miten ne sisällyttävät sanaston neuroverkkoon?"
      ]
    },
    {
      "input": "69.10%/78.38%",
      "id": "task461-966156fc257e4f74996a1d88086fc588",
      "output": [
        "kuinka paljon parannusta sopeutumismalli voi saada?"
      ]
    },
    {
      "input": "Vastakkaiset kirjoitusvirheet ovat kuitenkin pitkäaikainen reaalimaailman ongelma. Roskapostittajat pommittavat jatkuvasti sähköpostipalvelimia ja kirjoittavat sanoja hienovaraisesti väärin yrittäessään kiertää roskapostin havaitsemisen säilyttäen samalla sähköpostiviestien tarkoituksenmukaisen merkityksen BIBREF1 , BIBREF2 .",
      "id": "task461-c8b518e8c1254f449c0e5f2911af8a8a",
      "output": [
        "Miksi vastakkainasettelu sopii oikeinkirjoitusvirheiden tunnistamiseen?"
      ]
    },
    {
      "input": "Käytämme kaikissa kokeellisen tutkimuksen tehtävissä 36 miljoonaa englanninkielistä twiittiä, jotka on kerätty elo-syyskuussa 2017. ",
      "id": "task461-3240809d8c594630842951bc16438ff6",
      "output": [
        "Raportoidaanko tulokset vain englanninkielisistä tietokokonaisuuksista?"
      ]
    },
    {
      "input": "Käytämme MS COCO-, Bing- ja Flickr-tietoaineistoja BIBREF26:sta kysymysten luomiseksi käytettävän mallin kouluttamiseen. Nämä tietokokonaisuudet sisältävät kuvia koskevia luonnollisia kysymyksiä, joiden tarkoituksena on saada lisätietoja kuvasta. Kuten kuvasta FIGREF8 voidaan nähdä, kysymyksiin ei voida vastata vain katsomalla kuvaa. Kukin lähde sisältää 5 000 kuvaa, joissa on 5 kysymystä kuvaa kohti, joten yhteensä 15 000 kuvaa ja 75 000 kysymystä. Käytämme kahta tietokokonaisuutta chatbot-mallimme kouluttamiseen. Ensimmäinen on Persona-chat BIBREF15 , joka sisältää kahden eri profiililla olevan ihmisen välisiä vuoropuheluja, jotka yrittävät tutustua toisiinsa. Sitä täydentää Cornell-movie dialogues -tietokanta BIBREF27, joka sisältää kokoelman fiktiivisiä keskusteluja, jotka on poimittu elokuvakäsikirjoituksista. Persona-chatin lauseissa on enintään 15 sanaa, mikä helpottaa koneiden oppimista, ja niissä on yhteensä 162 064 lausetta 10 907 dialogissa. Cornell-elokuvatietokanta sisältää 304 713 lausetta 220 579 keskustelusta 10 292 elokuvahahmoparin välillä.",
      "id": "task461-96b491e6c92b4cafad3ac2ffac51200a",
      "output": [
        "Kuinka suurta tietomäärää käytetään tämän järjestelmän kouluttamiseen?"
      ]
    },
    {
      "input": "Perinteiset tekstistä puheeksi -järjestelmät (TTS) koostuvat monimutkaisista putkistoista BIBREF0 , joihin kuuluu usein akustisia etuosia, kestomalli, akustinen ennustemalli ja vokooderimalleja. Neuraaliset tekstistä puheeksi -järjestelmät ovat herättäneet suurta tutkimusintoa viimeisten kahden vuoden aikana. Ensimmäinen, joka tutki tätä tutkimusalaa perusteellisesti, oli Googlen tacotron BIBREF1 -järjestelmä Mallimme arkkitehtuurissa käytetään RNN-pohjaista Seq2Seq-mallia melaspektrogrammin tuottamiseen tekstistä. Arkkitehtuuri on samanlainen kuin Tacotron 2 BIBREF4 -järjestelmässä.  Mallimme ja avoimen lähdekoodin Tacotron 2:n malliparametrien suorassa vertailussa mallimme sisältää 4,5 miljoonaa parametria, kun taas Tacotron 2 sisältää noin 13 miljoonaa parametria oletusasetuksilla.",
      "id": "task461-1501ddf7367e411395b241cf4892af1d",
      "output": [
        "Miten mallien koko mitataan?"
      ]
    },
    {
      "input": "Havaitsimme, että dynaamisilla yhteisöillä, kuten Seahawksilla tai starcraftilla, on huomattavasti korkeampi kuukausittainen käyttäjien pysyvyys kuin vakaammilla yhteisöillä (Spearmanin INLINEFORM0 = 0,70, INLINEFORM1 0,001, laskettu yhteisön pisteiden keskiarvolla kuukausien ajalta; kuva KUVA KUVA11 .A, vasemmalla). Vastaavasti erottuvammilla yhteisöillä, kuten Cooking ja Naruto, on kohtalaisen korkeampi kuukausittainen pysyvyys kuin yleisemmillä yhteisöillä (Spearmanin INLINEFORM2 = 0,33, INLINEFORM3 0,001; kuva FIGREF11 .A, oikea). Kuten kuukausittaisen pysyvyyden kohdalla, havaitsemme vahvan positiivisen yhteyden yhteisön dynaamisuuden ja niiden kuukausien keskimääräisen määrän välillä, jotka käyttäjä pysyy kyseisessä yhteisössä (Spearmanin INLINEFORM0 = 0,41, INLINEFORM1 0,001, laskettuna kaikkien yhteisön pisteiden yli; kuva KUVIO FIGREF11 .B, vasen). Tämä vahvistaa, että kuukausittaisen pysyvyyden osalta havaittu lyhyen aikavälin suuntaus näkyy pidemmän aikavälin sitoutumisena, ja viittaa siihen, että käyttäjien pitkäaikainen pysyvyys saattaa riippua vahvasti siitä, missä määrin yhteisö tarjoaa jatkuvasti uutta sisältöä. Mielenkiintoista on, että erottuvuuden ja pitkäaikaisen sitoutumisen välillä ei ole merkittävää yhteyttä (Spearmanin INLINEFORM2 = 0,03, INLINEFORM3 0,77; kuva FIGREF11 .B, oikea). Vaikka RandomActsOfMakeupin kaltaiset hyvin erottuvat yhteisöt voivat siis saada käyttäjät sitoutumaan lyhyessä ajassa, tällaiset yhteisöt eivät todennäköisesti pidättele käyttäjiä pitkällä aikavälillä, ellei niillä ole myös riittävän dynaamista sisältöä.",
      "id": "task461-59c5b45c9447421d9ff3f0b1f80474cd",
      "output": [
        "Miten tutkitut sosiaaliset ilmiöt ilmenevät erityyppisissä yhteisöissä?"
      ]
    },
    {
      "input": "Tässä tutkimuksessa oletetaan, että robotilla ei ole etukäteen mitään sanastoa, mutta se pystyy tunnistamaan tavuja tai foneemeja.",
      "id": "task461-6169356e010c481cb78d5af58da306e5",
      "output": [
        "Aloitetaanko heidän mallinsa sanojen ennakkotiedosta?"
      ]
    },
    {
      "input": "Titovcrosslingual-menetelmän mukaisesti suoritamme kokeilumme CoNLL 2009 -korpuksen BIBREF13 englannin- (EN) ja saksankielisillä (DE) osilla sekä Europarl-korpuksen BIBREF14 EN-DE-osalla.",
      "id": "task461-24cc106c56954165870aa7688281a68a",
      "output": [
        "Mitä rinnakkaisia korpuksia käytetään?"
      ]
    },
    {
      "input": "Vastaavasti agenttien lausunnot voidaan klusteroida järjestelmän reaktioiden tunnistamiseksi. Väitämme kuitenkin, että sen sijaan, että käyttäjän lausumia ja agenttien vastauksia käsiteltäisiin erillään toisistaan, on hyödyllistä klusteroida ne yhdessä. Näistä lausunnoista on olemassa vierekkäistä tietoa, jota voidaan hyödyntää käyttäjien aikomusten ja järjestelmän vastausten tunnistamisessa.",
      "id": "task461-42f88e762ca644638400e1ec3329a306",
      "output": [
        "Tutkitaanko usein esiintyviä käyttäjien vastauksia, jotta niiden mallintamista voitaisiin automatisoida?"
      ]
    },
    {
      "input": "Kussakin tehtävässä käytetään järjestäjien käyttöön antamaa harjoitusaineistoa, joka on valikoima twiittejä, joissa jokaiselle twiitille on annettu tunnetilan tai tunteen voimakkuutta kuvaava merkintä BIBREF1 .  Koska tässä tutkimuksessa keskitytään espanjankielisiin twiitteihin, kaikki englanninkielisten tietokokonaisuuksien twiitit käännettiin espanjaksi. Tämä uusi \"espanjankielinen\" datajoukko lisättiin sitten alkuperäiseen harjoitusjoukkoon. Tietokokonaisuuksien kääntämiseen käytettiin jälleen konekäännösalustaa Apertium BIBREF5 .",
      "id": "task461-574ea5421db240ea9713357f055fe97e",
      "output": [
        "Mitä tietokokonaisuutta he käyttivät?"
      ]
    },
    {
      "input": "Tämä asiayhteyden vaikutus ihmisten luokituksiin on hyvin samankaltainen kuin BIBREF5 -julkaisussa raportoitu vaikutus. He havaitsivat, että lauseet, jotka arvioitiin huonosti muodostetuiksi ilman asiayhteyttä, paranevat, kun ne esitetään asiakirjakontekstissaan. BIBREF5 ehdottaa, että kontekstin lisääminen saa puhujat keskittymään laajempiin semanttisiin ja pragmaattisiin diskurssin johdonmukaisuuteen liittyviin kysymyksiin sen sijaan, että he arvioisivat pelkästään syntaktista muotoutuneisuutta (mitattuna luonnollisuutena), kun lausetta tarkastellaan erillään.",
      "id": "task461-619b308f264d4acdb39d1cfec857d0d5",
      "output": [
        "Minkä alustavan selityksen kirjoittajat antavat asiakirjan kontekstin vaikutukselle?"
      ]
    },
    {
      "input": "Arvioimme ehdotettua lähestymistapaamme yhteiseen tunne- ja tunteiden analyysiin SemEval 2016 Task 6 BIBREF7 -vertailutietokannassa ja Stance Sentiment Emotion Corpus (SSEC) BIBREF15 -vertailutietokannassa.",
      "id": "task461-366ffe7da6c34525872b65a41983187f",
      "output": [
        "Mitä tietokokonaisuuksia käytetään harjoittelussa?"
      ]
    },
    {
      "input": "Käytämme koulutettujen mallien arvioinnissa kirjallisuudesta löytyvää vakiojoukkoa valvottuja ja valvomattomia vertailutehtäviä BIBREF16:n mukaisesti. Lauseiden sulautuksia arvioidaan eri valvotuissa luokittelutehtävissä seuraavasti. Ennalta määriteltyä koulutusjakoa käytetään L2-sakkoparametrin virittämiseen ristiinvalidoinnin avulla, ja tarkkuus ja F1-pisteet lasketaan testijoukosta.  Oppimamme lauseen upotukset arvioidaan valvomatta käyttämällä lauseiden kosinusarvojen samankaltaisuutta STS 2014 BIBREF31- ja SICK 2014 BIBREF32 -aineistoissa. Näitä samankaltaisuuspisteitä verrataan kultaiseen standardiin perustuviin inhimillisiin arvioihin käyttämällä Pearsonin INLINEFORM0 BIBREF33- ja Spearmanin INLINEFORM1 BIBREF34 -korrelaatiopisteitä. ",
      "id": "task461-7fecfff411314b5cb808d29b9c2fa2d7",
      "output": [
        "Millä mittarilla suorituskykyä mitataan?"
      ]
    },
    {
      "input": "Perusarvot. Vertaamme mallejamme neuraaliseen perusmalliin, hierarkkiseen LSTM-malliin (hLSTM), jossa huomio on poistettu, mutta jossa on pääsy täydelliseen kontekstiin, sekä vahvaan, avoimen lähdekoodin omaavaan, ominaisuuksiltaan rikkaaseen perusmalliin BIBREF7 . Valitsimme BIBREF7:n muiden aiempien töiden, kuten BIBREF0:n, sijasta, koska meillä ei ole pääsyä tietokokonaisuuteen tai järjestelmään, jota käytettiin niiden töissä, jotta voisimme tehdä jäljennöksiä. BIBREF7 on logistinen regressioluokittelija, jonka ominaisuuksiin kuuluvat unigrammien ja säikeen pituuden sanasäkkiedustukset, normalisoidut lukumäärät aiempiin viesteihin tehdyistä sopimuksista, ei-leksikaalisten viittausten, kuten URL-osoitteiden, lukumäärät ja Courseran foorumityyppi, jossa säie ilmestyi. Raportoimme myös aggregoidut tulokset hLSTM-mallista, jossa on vertailun vuoksi pääsy vain viimeiseen viestiin kontekstina. Taulukossa TABREF17 verrataan näiden perusmallien suorituskykyä ehdotettuihin menetelmiin.",
      "id": "task461-f4e4ad34533c4874b7bd8a4450cdfc7c",
      "output": [
        "Mikä oli tämän tehtävän aiempi tekninen taso?"
      ]
    },
    {
      "input": "ch Koska jatkuvat sanojen upotusavaruudet ovat rakenteeltaan samankaltaisia eri (jopa kaukaisilla) kielillä BIBREF35, käytämme monikielistä sanojen esitystä, jonka tarkoituksena on oppia lineaarinen kartoitus lähdeavaruudesta kohdeavaruuteen.",
      "id": "task461-a9bdd7ebbc104c1a8957b58edf07951c",
      "output": [
        "Mitä monikielisiä sanaesityksiä käytetään?"
      ]
    },
    {
      "input": "Sanojen sulauttamismallit ja erityisesti BERT-mallit sisältävät valtavan määrän tietoa, joka on kerätty niiden harjoittelun aikana. Esimerkiksi BERT Base -mallissa on 110 miljoonaa parametria, ja se on koulutettu sekä Wikipedea Corpus -korpuksella että BooksCorpus BIBREF0 -korpuksella, jotka ovat yhteensä yli 3 miljardin sanan kokoelma.",
      "id": "task461-d8592eb99c5f439f8a5b6cc30909f501",
      "output": [
        "Mihin kielimalli on esivalmennettu?"
      ]
    },
    {
      "input": "Zürichin kognitiivisen kielenkäsittelyn korpus (ZuCo) 2.0, joka sisältää 18 koehenkilön silmienseuranta- ja elektroenkefalografia- (EEG) tiedot sekä tallennus- ja esikäsittelyskriptit, on julkisesti saatavilla. Se sisältää fysiologiset tiedot kustakin koehenkilöstä, joka lukee 739 englanninkielistä lausetta Wikipediasta (ks. esimerkki kuvassa FIGREF1). Tallennussession aikana osallistujat lukivat 739 lausetta, jotka valittiin culotta2006integratingin toimittamasta Wikipedia-korpuksesta. ",
      "id": "task461-bea8b162382d4969ad1b4133dd096d6b",
      "output": [
        "Millaisia lauseita luettiin?"
      ]
    },
    {
      "input": "Emme myöskään rajoitu testauksen aikana kiinteän pituisten sekvenssien testijoukkoon. Pikemminkin luettelemme tyhjentävästi kaikki kielen sekvenssit niiden pituuksien mukaan ja käymme sitten testijoukon sekvenssit läpi yksi kerrallaan, kunnes verkkomme erehtyy $k$ kertaa, mikä antaa hienojakoisemman arviointikriteerin sen yleistämiskyvylle. Tutkiaksemme erilaisten pituusjakaumien vaikutusta LSTM-mallien oppimiskykyyn ja -nopeuteen kokeilimme neljää diskreettiä todennäköisyysjakaumaa, joita tuetaan rajoitetuilla väleillä (kuva 2 ), otantaan kielten sekvenssien pituuksista. ",
      "id": "task461-bb1b988496bd4b7aa789c36a75ee4aed",
      "output": [
        "Ovatko havaitsemattomat näytteet samasta jakaumasta kuin harjoitusaineisto?"
      ]
    },
    {
      "input": "Keräsimme kaikki saatavilla olevat kommentit Redditistä elokuussa 2015 julkaistuihin tarinoihin. ",
      "id": "task461-55099a1b76da4a69ae3b05ad0652a516",
      "output": [
        "Mikä on uuden tietokokonaisuuden lähde?"
      ]
    },
    {
      "input": "Tämän ongelman ratkaisemiseksi esittelemme uuden arviointitietokannan, joka kattaa laajan kirjon monotonista päättelyä ja joka on luotu joukkoistamalla ja kerätty kielitieteellisistä julkaisuista (kohta \"Tietokanta\" ).",
      "id": "task461-e06265b4797e429faa1643bd9f86c52c",
      "output": [
        "Julkaisevatko he MED:n?"
      ]
    },
    {
      "input": "Muiden tekniikoiden osalta poimimme kappaleet, jotka sisältävät minkä tahansa sanan ennalta määritellystä LGTBQ-termiä sisältävästä luettelosta (taulukossa TABREF19).",
      "id": "task461-875c16b0325a4013970d12f0b1c36268",
      "output": [
        "Miten he tunnistavat LGBTQ-ihmisiä koskevat keskustelut New York Timesissa?"
      ]
    },
    {
      "input": "McGurk-ilmiötä varten yritämme luoda illuusion kielimerkille (esim. foneemi, sana, lause) $x$ luomalla videon, jossa $x$:n äänivirta dubataan visuaalisesti henkilöllä, joka sanoo $x^{\\prime }\\ne x$ . Illuusio $f(x^{\\prime },x)$ vaikuttaa kuulijaan, jos hän havaitsee sanotun $y\\ne x$, jos hän on katsonut illuusiovideon, kun taas hän havaitsee $x$, jos hän olisi joko kuunnellut äänivirtaa katsomatta videota tai katsonut alkuperäisen, muuttumattoman videon, riippuen erittelystä.  Prototyyppinen esimerkki on, että äänne \"baa\", johon liittyy video, jossa joku puhuu \"vaa\", voidaan havaita \"vaa\" tai \"gaa\" (kuva 1 ).",
      "id": "task461-cf7d26f2d76a4ecb8a1e347ae5d1a8f1",
      "output": [
        "Mikä on McGurkin vaikutus?"
      ]
    },
    {
      "input": "Vertailemme lähestymistapojamme vastaaviin lähestymistapoihin, kuten pivoting, monikielinen NMT (MNMT) BIBREF19 ja kieltenvälinen siirto ilman esivalmennusta BIBREF16. Vaikka yhden mallin on haastavaa kääntää kaikki nollasuunnat useiden etäisten MultiUN-kieliparien välillä, MLM+BRLM-SA saavuttaa silti paremmat tulokset Es $\\rightarrow $ Ar ja Es $\\rightarrow $ Ru -testeissä kuin vahva pivoting$_{\\rm m}$, jossa MNMT:n avulla käännetään lähde pivotiksi ja sen jälkeen kohde kahdessa erillisessä vaiheessa, ja kussakin vaiheessa saadaan rinnakkaisten korporaatioiden valvottu signaali. ",
      "id": "task461-dd824f64c006498dad822a8b1f6d7217",
      "output": [
        "mitkä ovat pivot-pohjaiset peruslinjat?"
      ]
    },
    {
      "input": "Perinteiset tekstistä puheeksi -järjestelmät (TTS) koostuvat monimutkaisista putkistoista BIBREF0 , joihin kuuluu usein akustisia etuosia, kestomalli, akustinen ennustemalli ja vokooderimalleja. Mallimme arkkitehtuurissa käytetään RNN-pohjaista Seq2Seq-mallia melaspektrogrammin tuottamiseen tekstistä. Arkkitehtuuri on samankaltainen kuin Tacotron 2:ssa BIBREF4 Mallimme ja avoimen lähdekoodin Tacotron 2:n mallien parametrien suora vertailu osoittaa, että mallimme sisältää 4,5 miljoonaa parametria, kun taas Tacotron 2 sisältää noin 13 miljoonaa parametria oletusasetuksilla. Auttamalla malliamme oppimaan huomion kohdistamisen nopeammin, meillä on varaa käyttää pienempää kokonaismallia, jotta saavutetaan yhtä laadukas puheen laatu.",
      "id": "task461-eda5a248c7834022aec929859ed486bf",
      "output": [
        "Vähentävätkö ne arkkitehtuurinsa parametrien määrää verrattuna muihin suoriin tekstistä puheeksi -malleihin?"
      ]
    },
    {
      "input": "Arvioimme SDNetiä CoQA-tietokokonaisuudella.",
      "id": "task461-7d9be43662e3456d9a585960272f472b",
      "output": [
        "Arvioidaanko mallia muilla tietokokonaisuuksilla?"
      ]
    },
    {
      "input": "Tässä asiakirjassa käytettiin reaaliaikaista menetelmää, jolla kerättiin satunnaisesti 10 prosenttia julkisesti saatavilla olevista englanninkielisistä twiiteistä käyttäen useita ennalta määriteltyjä DDEO:hon liittyviä kyselyjä (taulukko TABREF6 ) tietyn ajanjakson aikana. ",
      "id": "task461-c89ae1761f194c2d86f3f0ea5ce697fc",
      "output": [
        "Arvioidaanko ne vain englanninkielisten tietojen perusteella?"
      ]
    },
    {
      "input": "Tämän ongelman ratkaisemiseksi sovellamme takaisinkäännösmenetelmää BIBREF13, jossa käännämme junasarjan epäsuoran ja fyysisen häirinnän twiitit englannista saksaksi, ranskaksi ja kreikaksi. Sen jälkeen käännämme ne takaisin englanniksi, jotta saamme aikaan datan lisäyksen.",
      "id": "task461-87d181d7101344abb2bebd5a3930c521",
      "output": [
        "Mitä kieltä (kieliä) aineistossa on edustettuna?"
      ]
    },
    {
      "input": "Resurssi koostuu kahdesta eri tutkimuksesta saaduista tiedoista. Molemmissa tutkimuksissa koehenkilöitä pyydettiin piirtämään kartalle (Mercator-projektiossa) monikulmio, joka edustaa tiettyä maantieteellistä kuvaajaa Luoteis-Espanjassa sijaitsevan Galician maantieteellisessä kontekstissa (ks. kuva FIGREF1 ). Ensimmäinen kysely suoritettiin, jotta saataisiin suuri määrä vastauksia, joita voitaisiin käyttää mallinnusalgoritmien arviointitestialustana. Siihen vastasivat 15/16-vuotiaat oppilaat Pontevedran lukiossa (Länsi-Galiciassa). 99 oppilasta vastasi 7 kuvaajan luetteloon (mukaan lukien kardinaalipisteet, rannikko, sisämaa ja oikea nimi). Toinen kysely osoitettiin Galician sääviraston BIBREF12 meteorologeille.",
      "id": "task461-9517f889680f4e8cbe04a7afe87310e0",
      "output": [
        "Mistä kahdesta tietokokonaisuudesta resurssi on peräisin?"
      ]
    },
    {
      "input": "Tutkiaksemme, miten multimodaalinen konteksti voi parantaa suorituskykyä verrattuna unimodaaliseen kontekstiin, arvioimme erilaisia malleja: Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM) ja Textual Kernels Model (TKM).",
      "id": "task461-cee3a54b56384a12b325e5c744b0e734",
      "output": [
        "Mitä malleja he ehdottavat?"
      ]
    },
    {
      "input": "TextGrid-repositoriossa oleva digitaalinen kirjasto edustaa laajaa saksankielisten tekstien kokoelmaa digitaalisessa muodossa BIBREF3.",
      "id": "task461-43595810fe1744a7817f1ff911d44d1f",
      "output": [
        "Mitä korpusta tutkimuksessa käytetään?"
      ]
    },
    {
      "input": "Suoritamme kokeilumme ActivityNet Captions -tietokokonaisuudella BIBREF2, jota pidetään tiheän videotekstitystehtävän standardivertailukohtana. Tietokokonaisuus sisältää noin 20 000 YouTube-videota, jotka on jaettu 50/25/25/25 %:iin harjoittelua, validointia ja testausta varten. ",
      "id": "task461-28a599c62b8d4781861bed180e573dfe",
      "output": [
        "Mihin alaan tietokokonaisuus kuuluu?"
      ]
    },
    {
      "input": "Tässä asiakirjassa valitaan kolme tekstin yksinkertaistamiseen liittyvää metriikkaa. BLEU BIBREF5 on yksi perinteinen konekäännösmittari, jolla arvioidaan, missä määrin käännetyt yksinkertaistukset eroavat referenssiyksinkertaistuksista. FKGL mittaa tulosteen luettavuutta BIBREF23 . Pieni FKGL edustaa yksinkertaisempaa tulosta. SARI on viimeaikainen tekstin yksinkertaistamisen mittari, jossa tulosta verrataan lähde- ja referenssiversioihin BIBREF20 .",
      "id": "task461-9b370ca749d84279af9dc1015d4102a7",
      "output": [
        "mitä arviointimittareita he käyttivät?"
      ]
    },
    {
      "input": "Suurin osa tuloksista näyttää vastaavan joidenkin asiantuntijoiden, kuten Washington Postin poliittisten asiantuntijoiden, näkemyksiä.",
      "id": "task461-4123d90e69644818a56bb744702e64a1",
      "output": [
        "Ketkä ovat asiantuntijoita?"
      ]
    },
    {
      "input": "Valikoima tämän tutkimuksen tuloksista on seuraava: Muu kuin englanninkielinen koodi on laajamittainen ilmiö.Translitterointi on yleistä kaikkien kielten tunnisteissa.Kielet ryhmittyvät kolmeen eri ryhmään sen perusteella, miten puhujat käyttävät tunnuksia/kommentteja/translitterointia.Muut kuin latinalaisen kirjoitusasun käyttäjät kirjoittavat kommentit omalla äidinkielisellä kirjoitusasullaan, mutta kirjoittavat tunnisteet englanniksi.Oikealta vasemmalle -kirjoitusasua (RTL), kuten arabiaa, ei ole havaittu esiintyvän GitHubin tunnisteissa, mikä tarkoittaa sitä, että nykyisillä koodaajilla, jotka puhuvat RTL-kieliä, on huomattavia esteitä äidinkielisen kirjoitusasunsa käyttämisessä koodissa.",
      "id": "task461-76514a8851e44be1ad727b8156bf1f18",
      "output": [
        "Mitkä ovat julkisia koodivarastoja koskevan tutkimuksen tulokset?"
      ]
    },
    {
      "input": "Tämän jälkeen yhdistämme nämä maininnat toisiinsa i) jos ne esiintyvät samassa asiakirjassa (tästä käytetään nimitystä DOC-BASED edges), ii) jos nimettyjen entiteettien mainintapari on identtinen (MATCH edges - nämä voivat yhdistää solmuja sekä asiakirjojen välillä että niiden sisällä) tai iii) jos ne ovat samassa ydinviittausketjussa ulkoisen ydinviittausjärjestelmän ennusteen mukaan (COREF edges). ",
      "id": "task461-a538a759cf3e40e9857937b7ce01f53d",
      "output": [
        "Miten he saivat suhteet mainintojen välille?"
      ]
    },
    {
      "input": "Samankaltaiset yhtälöt löydettiin käyttämällä yhtälöiden kontekstivektorien esitysten välille laskettua euklidista etäisyyttä ( INLINEFORM2 ). Annamme lisää esimerkkituloksia liitteessä B.",
      "id": "task461-b08c592dea3d401ba0f47bb3b64afb2b",
      "output": [
        "Miten ne määrittelevät samankaltaiset yhtälöt?"
      ]
    },
    {
      "input": "Esittelemme ensin menetelmän, jolla havaitaan pullonkaulat tekstipeleissä käyttämällä saavutettua kokonaispalkkiota ja tietämysgraafin tilaa. Menetelmä jäädyttää pullonkaulan saavuttamiseen käytetyn toimintatavan ja aloittaa harjoittelun uudelleen siitä eteenpäin, ja lisäksi suoritetaan takautumishaku sen varmistamiseksi, että ei ole jäädytetty epäoptimaalista toimintatapaa. Toisessa artikkelissa tutkitaan, miten tietämysgraafeja voidaan hyödyntää nykyisten etsintäalgoritmien parantamiseen, kun käsitellään kombinatorisia toiminta-alueita, kuten Go-Explore BIBREF9 -algoritmia. ",
      "id": "task461-0029d539b4a54e3fa0161b10e852c392",
      "output": [
        "Mitkä ovat nämä kaksi uutta strategiaa?"
      ]
    },
    {
      "input": "Kun näitä aiheita verrataan katolisen naisfoorumin aiheisiin, näyttää siltä, että sekä ISIS että väkivallattomat ryhmät käyttävät äitiyteen, puolisosuhteeseen ja avioliittoon/eroon liittyviä aiheita puhuessaan naisille. Lisäksi käytimme Depechemood-menetelmiä analysoidaksemme tunteita, joita nämä aineistot todennäköisesti herättävät lukijoissa. Tunneanalyysimme tulos viittaa siihen, että molemmissa korpuksissa käytettiin sanoja, joilla pyritään innostamaan lukijoita ja samalla välttämään pelkoa. Todelliset sanat, jotka johtavat näihin vaikutuksiin, ovat kuitenkin hyvin erilaisia näissä kahdessa yhteydessä. Kaiken kaikkiaan havaintomme osoittavat, että sopivia menetelmiä käyttämällä suurten tekstiaineistojen automaattinen analyysi voi tarjota uusia oivalluksia ääriainesten propagandasta, joista voi olla apua terrorisminvastaiselle yhteisölle.",
      "id": "task461-1f1de2296d7545f58409a261f67554f8",
      "output": [
        "Mitä johtopäätöksiä kirjoittajat tekevät havainnostaan, jonka mukaan ISIS:n ja katolisen materiaalin emotionaalinen vetovoima on samanlainen?"
      ]
    },
    {
      "input": "Yhdistämme lisäksi valvotun IR-mallin ja valvomattoman mallin, joka on koulutettu täydellä parittomalla datalla (4,8 miljoonaa) ja eri määrällä paritettua dataa (50 000:sta 4,8 miljoonaan).",
      "id": "task461-d9923f1b34c848d7b656795d19f88851",
      "output": [
        "Kuinka monta kommenttia käytettiin?"
      ]
    },
    {
      "input": "Vastauksena RQ3-kysymykseen, joka koskee toimialueen mukauttamista, voimme nähdä harmaista soluista välilehdessä: tulokset, jotka vastaavat toimialueiden välistä mukauttamista, jossa BERT-kielimalli koulutetaan kohdealalla, että toimialueen mukauttaminen toimii hyvin: absoluuttinen tarkkuus paranee 2,2 \\ % sylimikrojen testijoukossa ja jopa 3,6 \\ % ravintola-alan testijoukossa verrattuna BERT-pohjaan.",
      "id": "task461-f4e0ed2c584040c4bc2e641520e435d1",
      "output": [
        "Kuinka paljon heidän mallinsa päihittää perustason mallin toimialojen välisessä arvioinnissa?"
      ]
    },
    {
      "input": "Käytämme pääarviointimittareina ROUGE F1 ja METEOR.",
      "id": "task461-13fc5bebee0048538debaa3bdb80a8ed",
      "output": [
        "Mitä arviointimittareita ne käyttävät?"
      ]
    },
    {
      "input": "Esittelemme tässä jaksossa See et al. See2017:n perusmallin, joka on koulutettu CNN/Daily Mail -aineistolla. Perusmalli on syvä sekvenssistä sekvenssiin koodaus-/dekoodausmalli, jossa on huomio. Kooderi on kaksisuuntainen Long-Short Term Memory(LSTM)-solu BIBREF14 ja dekooderi yksittäinen LSTM-solu, jossa on huomiomekanismi. Huomiomekanismi lasketaan kuten BIBREF9:ssä, ja dekoodauksessa käytetään ahnetta hakua. Koulutamme alusta loppuun myös sanojen upotukset. Käytetty upotuskoko on 128 ja LSTM-solujen piilotetun tilan koko on 254.",
      "id": "task461-03cd4e4b81774cb7a0ddf61290b0ceba",
      "output": [
        "Mitä lähtötasoja he vertasivat?"
      ]
    },
    {
      "input": "Kokeilussa käyttämämme kliiniset muistiinpanot ovat toimialan asiantuntijoiden toimittamia, ja ne koostuvat 1 160 lääkärin lokikirjasta, jotka koskevat lääketieteellisen teho-osaston vastaanottopyyntöjä Mount Sanai -vuoren yhteydessä olevassa tertiäärisessä hoitokeskuksessa. Rikastettu korpus sisältää tehohoidon raakatietojen lisäksi 42 506 Wikipedia-artikkelia, joista kukin vastaa yhtä ehdokasta, 6 tutkimusjulkaisua ja 2 tehohoitolääketieteen oppikirjaa.",
      "id": "task461-40abe15fe5f74ddca4b95528f42de1fb",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät mallinsa rakentamiseen?"
      ]
    },
    {
      "input": "Arvioidaksemme tuotetulla datalla koulutettuja malleja annotoimme manuaalisesti nimetyt entiteetit -tietokannan, joka koostuu 53453 merkistä ja 2566 lauseesta, jotka on valittu yli 250 uutistekstistä ilur.am-sivustolta.",
      "id": "task461-65c4911e0146499f8357f7b3f123d995",
      "output": [
        "Mikä on uutislauseiden lähde?"
      ]
    },
    {
      "input": "Koillis-, länsi- ja eteläisten alueiden korkeakouluissa opiskeleminen lisää seksuaalista häirintää koskevien ilmoitusten tekemisen mahdollisuutta (positiiviset kertoimet), kun taas keskilännen alueella opiskeleminen lisää sitä. ",
      "id": "task461-b4b07f07bf184eb18268cefa14914bb0",
      "output": [
        "Mitkä maantieteelliset alueet korreloivat suuntauksen kanssa?"
      ]
    },
    {
      "input": "Jotta tekstin piirteistä saadaan kontekstisidonnaisia esityksiä, kirjan nimi ja selostus yhdistetään ja syötetään sitten BERTin kautta. Muut kuin tekstin piirteet luodaan erillisessä esikäsittelyvaiheessa. Metatieto-ominaisuudet esitetään kymmenenulotteisena vektorina (kaksi ulottuvuutta sukupuolen osalta, ks. SECREF10-jakso). Kirjoittajan upotusvektoreiden pituus on 200 (ks. SECREF22 kohta). Seuraavassa vaiheessa kaikki kolme representaatiota yhdistetään ja siirretään MLP:hen, jossa on kaksi kerrosta, 1024 yksikköä kussakin ja ReLu-aktivointifunktio.",
      "id": "task461-4ed8fa39f4b34d6ebe8640fe80a0b324",
      "output": [
        "Miten ne yhdistävät tekstiedustukset tietämysgraafin sulautuksiin?"
      ]
    },
    {
      "input": "Käytimme degen2015investigatingin raportoimaa annotoitua tietokokonaisuutta, joka koostuu puhelinkeskustelujen korpuksen Switchboard BIBREF21 sanoista, jotka sisältävät sanan some. Aineisto koostuu 1 362:sta ainutlaatuisesta lausumasta, joissa on substantiivilause, joka sisältää some (some-NP). Jokaisen some-NP:tä sisältävän esimerkin osalta degen2015investigating keräsi päättelyn voimakkuusarviot vähintään 10 osallistujalta, jotka oli rekrytoitu Amazonin Mechanical Turk -palvelusta. Osallistujat näkivät sekä kohdeilmauksen että kymmenen ilmausta edeltävästä diskurssikontekstista. Sen jälkeen he arvioivat alkuperäisen lausuman like (UNKREF8) ja lausuman, jossa some oli korvattu some-lausumalla, mutta ei kaikki like (UNKREF9), samankaltaisuutta 7-portaisella Likertin asteikolla, jonka päätepisteissä oli merkinnät \"hyvin erilainen merkitys\" (1) ja \"sama merkitys\" (7). Alhaiset samankaltaisuusluokitukset merkitsevät siis matalaa päättelyn voimakkuutta ja korkeat samankaltaisuusluokitukset korkeaa päättelyn voimakkuutta.",
      "id": "task461-eada2444a8f149188990b6739fe5c02f",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "perusmalli tuottaa hyvän tuloksen myös eksplisiittisten diskurssisuhteiden tunnistamisessa, mikä on verrattavissa aiempaan parhaaseen tulokseen (92,05 % makro F1-tulos ja 93,09 % tarkkuus, kuten BIBREF11 raportoi). Yhteenvetona voidaan todeta, että koko kappaleen tason neuroverkkomallimme saavuttaa parhaan makrokeskiarvoisen F1-tuloksen (48,82 %) implisiittisten diskurssisuhteiden ennustamisessa, mikä ylittää aiemmat neuraaliset tensoriverkkomallit (esim. BIBREF18 ) yli kahdella prosentilla ja ylittää parhaan aiemman järjestelmän BIBREF19 yhdellä prosentilla. Sitten luotiin myös ensemble-malleja soveltamalla enemmistöpäätöstä kymmenen ajokerran tulosten yhdistämiseen. Taulukosta 5 käy ilmi, että jokainen ensemble-malli parantaa suorituskykyään yksittäiseen malliin verrattuna. Täydellinen malli parantaa suorituskykyä (51,84 - 48,82 = 3,02) ja (94,17 - 93,21 = 0,96) makro-F1-pistemäärissä implisiittisten ja eksplisiittisten diskurssisuhteiden ennustamisessa. ",
      "id": "task461-1650a0a8191d460eb44f77803aace3a0",
      "output": [
        "Kuinka paljon tämä malli parantaa uusinta tekniikkaa?"
      ]
    },
    {
      "input": "Parannukset kaikkiin vertailutietoaineistoihin nähden osoittavat myös, että ehdollinen BERT on yleinen lisäysmenetelmä useiden merkintöjen lauseiden luokittelutehtävissä.",
      "id": "task461-c1d3f4a698f94309aa743745e1403adb",
      "output": [
        "Suoriutuuko uusi tavoite paremmin kuin alkuperäinen tavoite, johon bert on koulutettu?"
      ]
    },
    {
      "input": "Arvioidaksemme tuotetulla datalla koulutettuja malleja annotoimme manuaalisesti nimetyt entiteetit -tietokannan, joka sisältää 53453 merkkiä ja 2566 lausetta, jotka on valittu yli 250 uutistekstistä ilur.am-sivustolta. Annotoinnissa tukeuduimme yleisesti BBN Technologiesin TREC 2002 -kilpailun kysymysvastausten rataa varten laatimiin kategorioihin ja ohjeisiin.",
      "id": "task461-048dfaa3256546e080979d4c6db18002",
      "output": [
        "käyttivätkö he joukkoistamisalustaa manuaalisten merkintöjen tekemiseen?"
      ]
    },
    {
      "input": "Yleinen sarkasmi. Tarkastelemme ensin Gen-tietokannasta opittuja eri malleja.  Havaitsemme, että ei-sarkastiset kuviot näyttävät kuvaavan teknistä ja tieteellistä kieltä, kun taas sarkastiset kuviot kuvaavat yleensä subjektiivista kieltä, joka ei ole aihekohtaista. Havaitsemme, että sarkastisen luokan adjektiivi- ja adverbikuvioita on runsaasti, vaikka emme käytä adjektiivi- ja adverbikuvioita regex-hakumenetelmässämme. Retoriset kysymykset. Huomaamme, että vaikka RQ-kysymyksiä varten luodut ei-sarkastiset kuviot ovat samankaltaisia kuin yleisestä aineistosta löytyvät aihekohtaiset ei-sarkastiset kuviot, sarkastisissa kuviossa on joitakin mielenkiintoisia piirteitä, jotka ovat enemmänkin ainutlaatuisia RQ-kysymyksille: Monet sarkastisista kysymyksistämme keskittyvät nimenomaan hyökkäyksiin vastaanottajan henkisiä kykyjä vastaan. Tämä yleistäminen tulee selväksi, kun poimimme ja analysoimme verbin, subjektin ja objektin argumentit Stanfordin riippuvuusjäsennyksen jäsentäjän BIBREF32 avulla RQ-tietokannan kysymysten osalta. Hyperbole. Kuten edellä todettiin, yksi yleinen hyperbole-malli sisältää adverbeja ja adjektiiveja. Emme käyttäneet tätä kuviota hyperbolin hakemiseen, mutta koska jokainen hyperbolinen sarkastinen lausuma sisältää useita vihjeitä, opimme laajennetun luokan hyperbolin kuvioita.  Opimme useita verbaalisia malleja, joita emme olleet aiemmin yhdistäneet hyperboliin, kuten taulukossa TABREF34 näkyy. Mielenkiintoista on, että monet näistä kuvioista ilmentävät CanoMora2009:n havaintoja hyperbolesta ja siihen liittyvistä semanttisista kentistä: kontrastin luominen poissulkemalla, esim. ei rajaa eikä keinoa, tai laajentamalla predikaattiluokkaa, esim. kaikki tietävät. Monet näistä ovat myös kontrastiivisia. ",
      "id": "task461-6e1bccf6ebcf424ab299a734b1b9ad33",
      "output": [
        "Mitä kielellisiä eroja kunkin luokan välillä on?"
      ]
    },
    {
      "input": "Tarjoamme käsin kuratoidun kokoelman täydellisiä taivutustaulukoita 198 lemmalle. Morfologiset tunnisteet noudattavat UniMorph-skeeman BIBREF6, BIBREF7 suuntaviivoja, jotta ne mahdollistaisivat kieltenvälisen siirto-oppimisen, ja ne on merkitty seuraavilla tunnisteilla: Henkilö: ensimmäinen (1), toinen (2) ja kolmas (3) Luku: Aspekti/mieliala: täydentävä (CPL), progressiivinen (PROG), potentiaalinen (POT) ja habituaalinen (HAB).",
      "id": "task461-c740d279ef3941218557069f58901cbc",
      "output": [
        "Miten merkinnät tehtiin?"
      ]
    },
    {
      "input": "Tässä alaluvussa tarkastellaan mallin kunkin komponentin vaikutusta suorituskykyyn poistamalla tai korvaamalla sen komponentteja. kokeiluissa käytetään SNLI-tietokokonaisuutta, ja parhaiten suoriutuvaa kokoonpanoa käytetään muutosten perustasona. Tarkastelemme seuraavia muunnelmia: (i) mallit, joissa käytetään tavallisia pinottuja LSTM-malleja, (ii) mallit, joissa on eri INLINEFORM0 , (iii) mallit ilman INLINEFORM1 ja (iv) mallit, jotka integroivat alempia konteksteja kurkistusyhteyksien avulla.",
      "id": "task461-9d0c245de393412fae504b95e1e0c92d",
      "output": [
        "Mitkä olivat lähtötasot?"
      ]
    },
    {
      "input": "Mikä on esivalmennettujen representaatioiden vaikutus, kun transkriptoitua dataa on vähemmän? Jotta tästä saataisiin parempi käsitys, koulutamme akustisia malleja eri määrillä merkittyä harjoitusdataa ja mittaamme tarkkuutta esivalmistettujen representaatioiden (log-mel-suodatinpankkien) kanssa ja ilman niitä. Esikoulutetut representaatiot koulutetaan koko Librispeech-korpuksella, ja mittaamme tarkkuuden WER:nä, kun dekoodaus tehdään 4 gramman kielimallilla. Kuva osoittaa, että esivalmennus vähentää WER-arvoa 32 % nov93dev:llä, kun käytettävissä on vain noin kahdeksan tuntia transkriptoitua dataa. Esiharjoittelu vain WSJ:n ( WSJ) äänidatalla toimii huonommin verrattuna paljon suurempaan Librispeechiin ( Libri). Tämä vahvistaa entisestään, että esiharjoittelu useammalla datalla on ratkaisevan tärkeää hyvän suorituskyvyn kannalta.",
      "id": "task461-45b3e091bf7043f4bc19b13b1c73f5e7",
      "output": [
        "Tutkitaanko niissä, kuinka paljon siirtotietoja tarvitaan, jotta WER paranisi kuinka paljon? "
      ]
    },
    {
      "input": "Ennustustehtävämme on siis suoraviivainen sanatason binääriluokittelutehtävä. Kehitämme seuraavat viisi piirreryhmää, jotka kuvaavat ominaisuuksia, jotka liittyvät siihen, miten sanaa käytetään selityksessä (ks. taulukko TABREF18 täydellisen luettelon osalta):[itemsep=0pt,leftmargin=*,topsep=0pt]Sanan kontekstittomat ominaisuudet. Nämä ominaisuudet johdetaan suoraan sanasta, ja ne kuvaavat yleistä taipumusta siihen, että sana kaikuu selityksissä. sanan käyttö OP:ssa tai PC:ssä (kaksi ryhmää). Nämä piirteet kuvaavat sitä, miten sanaa käytetään OP:ssa tai PC:ssä. Näin ollen jokaiselle piirteelle on kaksi arvoa OP:lle ja PC:lle.Miten sana yhdistää OP:n ja PC:n. Nämä piirteet tarkastelevat sanan käytön eroa OP:ssa ja PC:ssä. Odotamme, että tämä ryhmä on tehtävämme kannalta tärkein. yleiset OP/PC-ominaisuudet. Nämä piirteet kuvaavat keskustelun yleisiä ominaisuuksia. Niitä voidaan käyttää luonnehtimaan kaikujen taustajakaumaa.Taulukossa TABREF18 esitetään lisäksi intuitio kunkin ominaisuuden sisällyttämiselle ja tiivistetyt $t$-testitulokset Bonferroni-korjauksen jälkeen. Erityisesti testataan, onko selityksissä kaikuuntuneilla sanoilla erilaiset ominaisuusarvot kuin niillä sanoilla, joita ei kaikuuntunut. Kaikkien sanojen tarkastelun lisäksi tarkastelemme myös erikseen stop-sanoja ja sisällön sanoja kuvion FIGREF8 valossa. Tässä korostamme muutamia havaintoja:[itemsep=0pt,leftmargin=*,topsep=0pt]",
      "id": "task461-631e1e47935242a9b4db2d7aef7a1083",
      "output": [
        "Mitkä ovat niiden ehdotetut ominaisuudet?"
      ]
    },
    {
      "input": "Paras perusmalli on NO-MOVE, jonka tarkkuus on 30,3 prosenttia yksittäisten lauseiden ja 0,3 prosenttia kokonaisten kappaleiden osalta.",
      "id": "task461-e3b3c3ef9b7a4654863235e1afaf03c4",
      "output": [
        "Kuinka hyvin perustaso toimi?"
      ]
    },
    {
      "input": "Attribuuttien upottamisen tehtävänä on upottaa jokainen attribuuttikolmioiden arvo jatkuvaan vektoriavaruuteen säilyttäen semanttinen informaatio. KG:iden molempien korkeamman asteen rakenteellisen informaation tallentamiseksi käytimme huomiopohjaista upotuksen etenemismenetelmää (attention-based embedding propagation method). Entiteettien, suhteiden ja arvojen lopullinen upotus syötetään kahteen eri syvään neuroverkkoon kahta eri tehtävää varten, joihin kuuluvat linkkien ennustaminen ja entiteettien luokittelu.",
      "id": "task461-76c559f1157248ea924ed8c038b80673",
      "output": [
        "Miten KANE tallentaa sekä KG:iden korkeamman asteen rakenne- että attribuuttitiedot tehokkaasti, selkeästi ja yhtenäisesti?"
      ]
    },
    {
      "input": "Kuvaamme WikiSQL:ää koskevat sääntömme tässä. Tunnistamme ensin WHERE-arvot, jotka täsmälleen vastaavat taulukon soluja. Sen jälkeen, jos solu esiintyy useammassa kuin yhdessä sarakkeessa, valitsemme sen sarakkeen nimen, jossa on enemmän päällekkäisiä sanoja kysymyksen kanssa, sillä rajoituksella, että päällekkäisten sanojen määrä on suurempi kuin 1. Oletusarvoisesti WHERE-operaattori on INLINEFORM0 , paitsi jos arvon ympäröivät sanat sisältävät avainsanoja INLINEFORM1 ja INLINEFORM2 . Sitten käsittelemme SELECT-saraketta, jossa on eniten päällekkäisiä sanoja ja joka ei voi olla sama minkään WHERE-sarakkeen kanssa. Oletusarvoisesti SELECT AGG on NONE, lukuun ottamatta sovittamista mihin tahansa taulukon TABREF8 avainsanoihin. Sääntömme kattavuus harjoitusjoukossa on 78,4 % ja suoritustarkkuus 77,9 %. Sääntömme KBQA:ta varten on yksinkertainen, eikä siinä käytetä kuratoitua kartoitussanastoa. SequentialQA:n sääntöputki on samanlainen kuin WikiSQL:ssä. WikiSQL:n kielioppiin verrattuna SequentialQA:n kieliopissa on lisätoimintoja, kuten edellisen kierroksen loogisen muodon kopiointi, ei suurempi kuin, ei enempää kuin ja negaatio.",
      "id": "task461-86d5dd2da38d44f3b6be7116f018d9c2",
      "output": [
        "Kuinka monta sääntöä oli määriteltävä?"
      ]
    },
    {
      "input": "Kukin näistä tokenizers, yhdistämme joitakin tyyppejä edustus menetelmiä, mukaan lukien sana-vektori menetelmiä, kuten jatkuva säkki sanoja BIBREF5, pre-koulutettu upottaminen kuin fasttext (koulutettu Wiki vietnaminkielinen) BIBREF6 ja sonvx (koulutettu vietnaminkielinen sanomalehti) BIBREF7 tietokokonaisuus tässä HSD tehtävä on todella epätasapaino. Puhdas luokka hallitsee 91,5 %:lla, loukkaava luokka vie 5 % ja loput 3,5 % kuuluu vihaiseen luokkaan.",
      "id": "task461-898426fd356b42289225be0c8b2fc9f5",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Olkoon kaikki sanavektorit normalisoituja ja $W$ sanamatriisi. BIBREF21:n innoittamana, jossa vektoriavaruusmalleja käytetään aihepiirien koherenssin arviointiin, ehdotamme, että $k$:nnen komponentin tulkittavuus arvioidaan seuraavasti: $ \\operatorinimi{interp}_k W = \\sum _{i,j=1}^N W_{i,k} W_{j,k} \\left(W_i \\cdot W_j \\right). $ ",
      "id": "task461-41dc24973e324b61b0773e0b769ccac9",
      "output": [
        "Miten tulkittavuutta arvioidaan tässä asiakirjassa?"
      ]
    },
    {
      "input": "Vähäisten resurssien käännöstehtävässä käytimme harjoitusaineistona BTEC-korpusta, joka koostuu 30 000 lauseparista, joissa on 0,27 miljoonaa kiinankielistä sanaa ja 0,33 miljoonaa englanninkielistä sanaa. Kehitysjoukkoina käytettiin CSTAR03- ja testijoukkoja ja IWSLT04-joukkoina testijoukkoja.  Käytimme NIST2008 Open Machine Translation Campaignin dataa. Koulutusdata koostui 1,8M lauseparista, kehitysjoukko oli nist02 (878 lausetta) ja testijoukot olivat nist05 (1082 lausetta), nist06 (1664 lausetta) ja nist08 (1357 lausetta).",
      "id": "task461-e35ae1821b9242a3a81910d174168200",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Arvioidaksemme ehdotettua LRC-kehystä ja AutoJudge-mallia suoritamme sarjan kokeita avioeromenettelyissä, jotka ovat tyypillinen mutta monimutkainen siviiliasioiden ala. ",
      "id": "task461-2a4259d63618446a9cc9d78347559a19",
      "output": [
        "mitä siviilialaa tietokokonaisuus koskee?"
      ]
    },
    {
      "input": "Kokeilimme monia verkkomallimme kokoonpanoja, mutta raportoimme tulokset vain kolmella muuntajien kokoonpanolla.Muuntajatyyppi 1: Tämä verkko on pieni tai keskikokoinen verkko, joka koostuu neljästä muuntajakerroksesta. Kukin kerros käyttää 8 huomiopäätä, joiden syvyys on 512 ja feed-forward-syvyys 1024. Transformer Type 2: Toinen malli on kooltaan pieni ja käyttää 2 Transformer-kerrosta. Kerrokset käyttävät 8 huomiopäätä, joiden syvyys on 256 ja feed-forward-syvyys 1024. Transformer Type 3: Kolmas mallityyppi on minimaalinen, sillä se käyttää vain yhtä Transformer-kerrosta. Tämä verkko hyödyntää 8 huomiopäätä, joiden syvyys on 256 ja feed-forward-syvyys 512.",
      "id": "task461-def8e6b6a011462c9fab1ff568f91e6d",
      "output": [
        "Mitä neuraalisia konfiguraatioita tutkitaan?"
      ]
    },
    {
      "input": "Arviointi suoritetaan käyttämällä kehitysjoukkoa, joka koostuu 22 asiakirjasta ja 1112 PIE-ehdokkaasta, ja testijoukkoa, joka koostuu 23 asiakirjasta ja 1127 PIE-ehdokkaasta. Kullekin menetelmälle määritetään paras parametrien ja/tai vaihtoehtojen joukko käyttämällä kehitysjoukkoa, minkä jälkeen kunkin menetelmän F1-pistemäärän mukaan paras vaihtoehto arvioidaan testijoukolla. Koska nämä korpuksen asiakirjat on tyhjentävästi annotoitu PIE:iden osalta (ks. kohta SECREF40), voimme laskea todelliset ja väärät positiiviset ja väärät negatiiviset tulokset ja siten tarkkuuden, palautuksen ja F1-pistemäärän.",
      "id": "task461-4e157fce4d3e405f9ad1bbf31a5b5edf",
      "output": [
        "Arvioidaanko automaattisesti poimitut PIE:t ihmisen toimesta?"
      ]
    },
    {
      "input": "Käyttäytymismalli toteutettiin LSTM-yksiköillä varustetulla RNN:llä, ja se koulutettiin pariterapiakorpuksen avulla. Korpuksen sisältämistä 33 käyttäytymiskoodista käytimme mallien kouluttamiseen käyttäytymismalleja Acceptance, Blame, Negativity, Positivity ja Sadness. Tämä perustuu aiempiin töihin, jotka osoittivat näiden käyttäytymismallien olevan hyvin erotettavissa ja helposti tulkittavissa. Käyttäytymismalli on esivalmennettu tunnistamaan kunkin käyttäytymisen esiintyminen sanasekvenssistä käyttäen monimerkkiluokitusjärjestelmää. Käyttäytymismallin esivalmennettu osa toteutettiin käyttämällä yksikerroksista RNN:ää, jossa on LSTM-yksiköitä, joiden dimensiokoko on 50.",
      "id": "task461-e97fdabbb697451799ed0d6d552dd122",
      "output": [
        "Miten käyttäytymistilaa analysoiva moduuli koulutetaan?"
      ]
    },
    {
      "input": "Kokeet ::: AGDT:tä verrataan useisiin kilpaileviin malleihin, jotta AGDT:tä voitaisiin arvioida kattavasti.",
      "id": "task461-90284e1d81a84cf1b2e25b2af500784c",
      "output": [
        "Arvioidaanko mallia suhteessa muihin Aspektipohjaisiin malleihin?"
      ]
    },
    {
      "input": " GLUE-tehtävistä nämä huipputason järjestelmät saavuttavat suurimmat voitot hyväksyttävyystehtävässä, jossa käytetään kielellisen hyväksyttävyyden korpusta BIBREF0 . CoLA sisältää esimerkkilauseet kielitieteellisistä julkaisuista, jotka asiantuntijat ovat leimanneet kieliopillisen hyväksyttävyyden kannalta ja jotka on kirjoitettu niin, että niissä näkyy hienovaraisia kieliopillisia piirteitä. Koska minimaaliset syntaktiset erot voivat erottaa hyväksyttävät lauseet sopimattomista lauseista (Mistä Bo kirjoitti kirjan? / *Mitä kirjaa Bo kirjoitti?) ja koska hyväksyttävyysluokittelijat ovat luotettavampia, kun ne on koulutettu GPT:llä ja BERT:llä kuin rekursiivisilla malleilla, on loogista, että GPT:llä ja BERT:llä on parempi implisiittinen tietämys hyväksyttävyyden kannalta merkityksellisistä syntaktisista piirteistä.",
      "id": "task461-5c03d327094a465180c80e0db40d7164",
      "output": [
        "Mistä CoLAn tiedot ovat peräisin?"
      ]
    },
    {
      "input": "Monimerkityksisten sanojen kohdalla otetaan huomioon vain ensimmäinen sanan merkitys (yleensä yleisin).",
      "id": "task461-631d963d5fb34c2cb9fd17b59ea1f733",
      "output": [
        "Miten he käsittelevät monikielisiä sanoja entiteettikirjastossaan?"
      ]
    },
    {
      "input": " Saamme aineistomme uutisjulkaisuista, viinikritiikeistä ja Redditistä, joiden suuren volyymin lisäksi voimme myös luonnehtia binomeja uusilla tavoilla ja analysoida binomijärjestelyjen eroja eri yhteisöjen välillä ja ajassa.  Kehitämme uusia mittareita binomijärjestelyjen yhteisymmärrykselle yhteisöjen välillä ja binomijärjestelyjen siirtymiselle ajan myötä. Käyttämällä subreddittejä yhteisöinä nämä mittarit paljastavat järjestysten vaihtelua, josta osa viittaa kieleen vaikuttaviin kulttuurisiin muutoksiin. Kehitämme nollamallin, jonka avulla voimme määrittää, kuinka paljon vaihtelua binomijärjestelyissä voisi odottaa yhteisöjen välillä ja ajassa, jos binomijärjestelyt järjestettäisiin satunnaisesti globaalien epäsymmetria-arvojen mukaan. ",
      "id": "task461-3b245310c0c342639449a14993aa5a64",
      "output": [
        "Miten binomien järjestystä seurataan ajallisesti?"
      ]
    },
    {
      "input": "Yhteistyöelimen avulla suoritetaan kaksi täysin valvomatonta tehtävää. Naamioitu kielimalli ja seuraavan lauseen ennustaminen (NSP).Tässä tutkimuksessa NSP:tä käytetään vastauksen merkityksellisyyden vertailuarvona.",
      "id": "task461-47944ee2d23c4a91a93ab3f5a7effec6",
      "output": [
        "käytettiinkö Bertiä?"
      ]
    },
    {
      "input": "Käytimme Amazon Mechanical Turkia (MTurk) kerätäksemme uusia merkintöjä ja selityksiä SNLI-VE:tä varten. Annotointityöhön osallistui 2060 työntekijää, keskimäärin 1,98 tehtävää työntekijää kohden ja keskihajonta 5,54.",
      "id": "task461-367a4cf2c30f463a8402762fa977ca9c",
      "output": [
        "Kuinka monta annotaattoria käytetään kirjoittamaan luonnollisen kielen selityksiä SNLI-VE-2.0:aan?"
      ]
    },
    {
      "input": "Tutkimme arkkitehtuuria, joka perustuu laajennettujen konvoluutiokerrosten pinoamiseen ja joka toimii tehokkaasti laajemmalla skaalalla kuin tavalliset konvoluutiot ja rajoittaa samalla mallin kokoa. Tavanomaiset konvoluutioverkot eivät pysty vangitsemaan pitkiä ajallisia malleja kohtuullisen pienillä malleilla, koska suuremmat reseptiiviset kentät lisäävät laskentakustannuksia. Laajennetuissa konvoluutioissa ohitetaan joitakin tuloarvoja, jolloin konvoluutioydintä sovelletaan laajemmalla alueella kuin sen omaa aluetta. Näin ollen verkko toimii suuremmalla mittakaavalla ilman, että parametrien lukumäärän kasvamisesta aiheutuu haittaa.",
      "id": "task461-5fdfe902bd8b4cab90e4652d399eb05b",
      "output": [
        "Mitä ovat laajentuneet kierteet?"
      ]
    },
    {
      "input": "Valitsimme zulun (ZUL), joka on bantoidien kieli. Kahdesta ensimmäisestä kielestä poiketen se on vahvasti etuliitteinen.",
      "id": "task461-ee9744304e374c82b23a65afad426c5d",
      "output": [
        "Mikä on esimerkki etuliitteitä käyttävästä kielestä?"
      ]
    },
    {
      "input": "Analysoidaksemme menetelmällämme opittuja sulautuksia tarkemmin käytämme t-SNE-työkalua BIBREF27 visualisoidaksemme opitut sulautukset.",
      "id": "task461-216d0c74526e44098eb280835396a40a",
      "output": [
        "Mitä lisäanalyysejä tehdään?"
      ]
    },
    {
      "input": "Kaikissa kokeissa sanojen upotusten ja rekursiivisten piilotettujen tilojen ulottuvuuksiksi asetetaan 512.",
      "id": "task461-981e34b99e024b8bb32188a97a16186b",
      "output": [
        "Käytetäänkö niissä samaa arkkitehtuuria kuin LSTM:ssä ja GRU:ssa, kun ne vain korvataan LAU-yksiköllä?"
      ]
    },
    {
      "input": "SMT-tekniikat edellyttävät rinnakkaista lähde- ja kohdekielistä korpusta. Koulutuksessa käytetään kuvan FIGREF12 kaltaista rinnakkaista tekstikoodikorpusta. Tässä rinnakkaiskorpuksessa on 18805 kohdistettua dataa. Lähdeaineistossa jokaisen rivin koodi on kirjoitettu englannin kielellä. Kohdeaineistossa koodi on kirjoitettu Python-ohjelmointikielellä.",
      "id": "task461-c5d19cc5bca44a93b974255f977c6c53",
      "output": [
        "Mitä tietokokonaisuutta he käyttävät?"
      ]
    },
    {
      "input": "Useimmat edellä käsitellyistä järjestelmistä toimivat hyvin joko a) Twitter- tai b) Facebook-tietokannassa (jotka on annettu TRAC-2018-julkaisussa), mutta eivät molemmissa englanninkielisen koodin ja sekoitetun koodin tietokannoissa. Tämä voi johtua molempien tietokokonaisuuksien tekstityylistä tai monimutkaisuudesta.",
      "id": "task461-4084d3d831ad45b1b79bd7e06ae54e42",
      "output": [
        "Miten Twitterin ja Facebookin viestintätyylien erot ovat lisänneet ongelman monimutkaisuutta?"
      ]
    },
    {
      "input": "Ensimmäisenä kokeiluna vertailemme (korkealaatuisella) kuratoidulla datalla ja (heikkolaatuisella) massatietoaineistolla koulutettujen fastText-sulkeumien laatua twi- ja yorùbá-kielien osalta. Twi-kielen valtava moniselitteisyys motivoi tutkimaan erilaisia lähestymistapoja sanojen upotusten estimointiin. Tässä työssä verrataan tavanomaista fastText-menetelmää, joka sisältää sanan alitietoja, merkkipohjaiseen lähestymistapaan, jossa käytetään sijaintiin perustuvia klusteroituja upotuksia (CWE-LP, joka esiteltiin jaksossa SECREF17).",
      "id": "task461-aa011e11da70424da518fcaac68d1d64",
      "output": [
        "Mitä kahta arkkitehtuuria käytetään?"
      ]
    },
    {
      "input": "Jotta hashtagien käytön vaikutusta kannan tunnistamiseen voitaisiin hyödyntää, olemme myös käyttäneet hashtagien olemassaoloa twiiteissä lisäominaisuutena unigrammien lisäksi.",
      "id": "task461-3b90aeab3adb4c4194ed38cec3bf15ab",
      "output": [
        "Mitä ovat hashtag-ominaisuudet?"
      ]
    },
    {
      "input": " Kunkin tekstikohdan merkitsi 3 eri kommentoijaa.",
      "id": "task461-6f53595f6e914e4fa9efd43cde6d69fd",
      "output": [
        "Kuinka monta kommentoijaa oli paikalla?"
      ]
    },
    {
      "input": "Mallissa on kolme pääkomponenttia: 1) syöttökooderi, 2) dynaaminen muisti ja 3) lähtömoduuli. Kuvaamme nämä kolme moduulia yksityiskohtaisesti. Syöttökooderin ja lähtömoduulin toteutukset ovat samankaltaisia kuin Entity Network BIBREF17 -mallissa, ja tärkein uutuus on dynaaminen muisti. Kuvaamme verkon suorittamat operaatiot yhden esimerkin osalta, joka koostuu asiakirjasta, jossa on $T$ lauseita, joissa kukin lause koostuu sanajaksosta, joka on esitetty $K$ -ulotteisilla sanasulkeumilla $\\lbrace e_1, \\ldots , e_N\\rbrace $ , asiakirjan kysymyksestä, joka on esitetty toisena sanajaksona, ja vastauksesta kysymykseen.",
      "id": "task461-772a451eefef4443b5aef8cecf6c7848",
      "output": [
        "Miten tieto tallentuu muistiin?"
      ]
    },
    {
      "input": "Cloze Track Käyttäjäkysely Track",
      "id": "task461-0bd0af4a85e94cfbb5629fd77ad2a3fd",
      "output": [
        "Mistä kahdesta eri tyypistä kiinalainen luetun ymmärtämisen tietokokonaisuus koostuu?"
      ]
    },
    {
      "input": "Arvioimme malliamme kolmella vertailutietokannalla, jotka ovat CNN/DailyMail-uutisten kohokohdat -tietokanta BIBREF24, New York Times Annotated Corpus (NYT; BIBREF25) ja XSum BIBREF22.",
      "id": "task461-e1d9bc7bfb664aaca741304ebc3be5c2",
      "output": [
        "Mitä tietokokonaisuuksia käytetään arvioinnissa?"
      ]
    },
    {
      "input": "Tätä tarkoitusta varten rakennamme 172 815 artikkelin korpuksen tagaloginkielisestä Wikipediasta, jota kutsumme nimellä WikiText-TL-39 BIBREF18.",
      "id": "task461-777581a1bcb44c4e8393eb500c118251",
      "output": [
        "Mitä muita tietokokonaisuuksia käytetään?"
      ]
    },
    {
      "input": " RelNet-mallin keskimääräinen virhe on 0,285 % kaikissa tehtävissä, mikä on parempi kuin EntNet-mallin BIBREF17 tulokset. RelNet-malli pystyy saavuttamaan 0 prosentin testivirheen 11 tehtävässä, kun taas EntNet-malli saavuttaa 0 prosentin virheen 7 tehtävässä. RelNet-mallin keskimääräinen virhe on 0,285 % kaikissa tehtävissä, mikä on parempi kuin EntNet-mallin BIBREF17 tulokset. RelNet-malli pystyy saavuttamaan 0 prosentin testivirheen 11 tehtävässä, kun taas EntNet-malli saavuttaa 0 prosentin virheen 7 tehtävässä.",
      "id": "task461-fd788c68184a4da0a57ccce9b86b1683",
      "output": [
        "Mitkä ovat havaitut suhteelliset parannukset nykyisiin menetelmiin verrattuna?"
      ]
    },
    {
      "input": "Esitämme kolme yksinkertaista perustasoa RUN-tehtävää varten: (1) NO-MOVE: ainoa huomioitu sijainti on lähtöpiste; (2) RANDOM: Kuten BIBREF4:ssä, käänny satunnaisesti valittuun suuntaan ja suorita sitten joukko *WALK-toimintoja keskimääräistä reittiä; (3) JUMP: poimi jokaisessa lauseessa olioita kartalta ja siirry niiden välillä siinä järjestyksessä kuin ne esiintyvät. ",
      "id": "task461-8d76b2537ef14c0a9e3129bd1c75e055",
      "output": [
        "Mikä on lähtötaso?"
      ]
    },
    {
      "input": "Tässä asiakirjassa ehdotetaan menetelmää, jolla tunnistetaan sanat, jotka voivat aiheuttaa sekaannusta puheentunnistukseen perustuvan järjestelmän tietyssä solmukohdassa. Käytimme editointietäisyyttä metriikkana aktiivisten sanojen välisen mahdollisen sekaannuksen tunnistamiseen.  Tämän analyysin avulla voidaan saavuttaa merkittävä säästö tunnistuksen pullonkaulojen tunnistamisessa valikkopohjaisessa puheratkaisussa, koska se ei edellytä järjestelmää testaavia todellisia ihmisiä.  Tätä analyysia käytettiin Intian rautateiden tiedustelujärjestelmää varten kehitettyyn puheratkaisuun, jotta järjestelmän pullonkaulat voitiin tunnistaa ennen sen varsinaista käyttöönottoa.",
      "id": "task461-74b78a91143f4f16a862e3c79a7ff2a1",
      "output": [
        "mitä pullonkauloja havaittiin?"
      ]
    },
    {
      "input": "Loimme oman kausaalisten selitysten aineistomme keräämällä 3268 satunnaista Facebookin tilapäivitystiedotetta.",
      "id": "task461-6cbc97dc24474eb8a002dc0a12619317",
      "output": [
        "Millaisia sosiaalisen median muotoja he harkitsivat?"
      ]
    },
    {
      "input": "Koulutamme $\\mathcal {F}$ ja $\\mathcal {G}$ yhdessä ja otamme käyttöön kaksi regularisaattoria. Muodollisesti toivomme, että $\\mathcal {G}(\\mathcal {F}(X))$ on samanlainen kuin $X$ ja $\\mathcal {F}(\\mathcal {G}(Y))$ on samanlainen kuin $Y$. Toteutamme tämän rajoituksen syklin johdonmukaisuushäviönä. Tämän seurauksena ehdotetulla mallilla on kaksi oppimistavoitetta: i) vastakohtainen tappio ($\\ell _{adv}$) jokaiselle mallille, kuten perusmallissa. ii) syklin johdonmukaisuushäviö ($\\ell _{cycle}$) kummallakin puolella, jotta $\\mathcal {F}$ ja $\\mathcal {G}$ eivät olisi ristiriidassa keskenään.",
      "id": "task461-fc779544e1fb4cb9bb08bd93b545d654",
      "output": [
        "Mitä regularisaattoreita käytettiin johdonmukaisuuden edistämiseksi takaisinkääntämissykleissä?"
      ]
    },
    {
      "input": "Mitä yhtäläisyyksiä ja/tai eroja näillä aiheilla on väkivallattomaan, ei-islamilaiseen uskonnolliseen aineistoon, joka on suunnattu erityisesti naisille? Kuten nämä kysymykset osoittavat, jotta ymmärtäisimme, mikä ääriliikkeiden vetoomuksista tekee erityisiä, tarvitsemme vertailukohdan valtavirran väkivallattomien uskonnollisten ryhmien naisille suunnattujen tiedotustoimien osalta. Tätä varten käytämme katolisen naisfoorumin verkkopalvelua. Katolisen aineiston ja ISIS:n verkkolehtien sisällön vertailu mahdollistaa uudenlaisen näkemyksen ääriretoriikan erityispiirteistä, kun se on suunnattu naisväestölle. Tehtävän suorittamiseksi käytämme aiheen mallintamista ja valvomatonta tunteiden havaitsemismenetelmää.",
      "id": "task461-4528523c4d5d4b50b343d6f818d385dd",
      "output": [
        "Miten väkivaltaisten ja väkivallattomien uskonnollisten ryhmien tekstien yhtäläisyyksiä ja eroja analysoidaan?"
      ]
    },
    {
      "input": "Taulukossa TABREF26 raportoimme mallimme tulokset kolmella tunneluokituksen arvioinnissa vakiintuneesti käytetyllä tietokokonaisuudella, jotka kuvasimme jaksossa SECREF3 .",
      "id": "task461-0aca5bdff95147ca8aeed0bb16f83192",
      "output": [
        "Miten he suoriutuivat tunteiden havaitsemisesta?"
      ]
    },
    {
      "input": "Yksi tapa analysoida mallia on laskea mallin gradientit suhteessa syöttöominaisuuksiin BIBREF26, BIBREF25. Kuvasta KUVIO 37 nähdään, että tässä esimerkissä tärkeimmät mallin syötteet ovat entiteettiin voihin mahdollisesti liittyvät verbit itse entiteetin mainintojen lisäksi. Lisäksi se osoittaa, että malli oppii hyödyntämällä verbien semantiikkaa poimimaan pinnallisia vihjeitä sellaisten toimien tunnistamisesta, jotka kohdistuvat vain seurattavaan entiteettiin riippumatta muista entiteeteistä.",
      "id": "task461-c58b90013b6e49f4a705e97166f22c30",
      "output": [
        "Mitä todisteita ne esittävät siitä, että malli ottaa huomioon matalat kontekstivihjeet?"
      ]
    },
    {
      "input": " Näissä tutkimuksissa raportoidun työn innoittamana ehdotamme, että käytämme muunneltuja tavoitefunktioita eri tarkoitukseen: tulkinnanvaraisempien tiheiden sanasulkeumien oppimiseen. Tällä tavoin pyrimme sisällyttämään ulkoisesta leksikaalisesta resurssista peräisin olevaa semanttista tietoa sanojen upotukseen, jotta upotusulottuvuudet ovat linjassa ennalta määriteltyjen käsitteiden kanssa. Tämä yhdenmukaistaminen saavutetaan muuttamalla upotuksen oppimisprosessia. Ehdotetussa menetelmässä, joka perustuu GloVe-algoritmiin BIBREF2 , minkä tahansa käsitteen sanaryhmien sanojen kustannusfunktiota muutetaan lisäämällä kustannusfunktioon additiivinen termi. ",
      "id": "task461-bc92657041a549828b0059cd74991f41",
      "output": [
        "Mikä on tavoitefunktion additiivinen muutos?"
      ]
    }
  ],
  "Contributors": [
    "Yeganeh Kordi"
  ],
  "Source": [
    "qasper"
  ],
  "URL": [
    "https://allenai.org/project/qasper/home"
  ],
  "Categories": [
    "Question Generation"
  ],
  "Reasoning": [],
  "Input_language": [
    "English"
  ],
  "Output_language": [
    "English"
  ],
  "Instruction_language": [
    "English"
  ],
  "Domains": [
    "Scientific Research Papers"
  ],
  "Positive Examples": [
    {
      "input": "Questions are gathered from anonymized, aggregated queries to the Google search engine. Queries that are likely to be yes/no questions are heuristically identified: we found selecting queries where the first word is in a manually constructed set of indicator words and are of sufficient length, to be effective.\n\nQuestions are only kept if a Wikipedia page is returned as one of the first five results, in which case the question and Wikipedia page are given to a human annotator for further processing.\n\nAnnotators label question/article pairs in a three-step process. First, they decide if the question is good, meaning it is comprehensible, unambiguous, and requesting factual information. This judgment is made before the annotator sees the Wikipedia page. Next, for good questions, annotators find a passage within the document that contains enough information to answer the question. Annotators can mark questions as “not answerable\" if the Wikipedia article does not contain the requested information. Finally, annotators mark whether the question's answer is “yes\" or “no\". Annotating data in this manner is quite expensive since annotators need to search entire Wikipedia documents for relevant evidence and read the text carefully.",
      "output": "how was the dataset built?",
      "explanation": "This is a good question, and it is answerable based on the context."
    },
    {
      "input": "Using this annotation model, we create a new large publicly available dataset of English tweets.",
      "output": "In what language are the tweets?",
      "explanation": "Based on the context, we can answer this question."
    },
    {
      "input": "To test the robustness of the taggers against the OOV problem, we also conduct experiments using artificially constructed unnormalized text by corrupting words in the normal dev set. Again, the CNN tagger outperforms the two baselines by a very large margin.",
      "output": "How do they confirm their model working well on out-of-vocabulary problems?",
      "explanation": "This question is answerable and grammatically correct."
    }
  ],
  "Negative Examples": [
    {
      "input": "Using this annotation model, we create a new large publicly available dataset of English tweets.",
      "output": "In what language is tweets?",
      "explanation": "This question is grammatically incorrect, and it's not acceptable."
    },
    {
      "input": "Questions are gathered from anonymized, aggregated queries to the Google search engine. Queries that are likely to be yes/no questions are heuristically identified: we found selecting queries where the first word is in a manually constructed set of indicator words and are of sufficient length, to be effective.\n\nQuestions are only kept if a Wikipedia page is returned as one of the first five results, in which case the question and Wikipedia page are given to a human annotator for further processing.\n\nAnnotators label question/article pairs in a three-step process. First, they decide if the question is good, meaning it is comprehensible, unambiguous, and requesting factual information. This judgment is made before the annotator sees the Wikipedia page. Next, for good questions, annotators find a passage within the document that contains enough information to answer the question. Annotators can mark questions as “not answerable\" if the Wikipedia article does not contain the requested information. Finally, annotators mark whether the question's answer is “yes\" or “no\". Annotating data in this manner is quite expensive since annotators need to search entire Wikipedia documents for relevant evidence and read the text carefully.",
      "output": "What is the size of the dataset?",
      "explanation": "This question is not answerable based on the context, and it's not acceptable."
    }
  ],
  "Instance License": [
    "CC BY 4.0"
  ]
}